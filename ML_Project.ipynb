{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbAqg_yFmBwT"
      },
      "source": [
        "# Import and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D3PDcsVAHx7S"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import math \n",
        "import seaborn as sns \n",
        "from tqdm import tqdm \n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from scipy.stats import norm\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import plotly.graph_objects as grp\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy import optimize\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fjs_aYjyQAWP"
      },
      "outputs": [],
      "source": [
        "#https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00640/Occupancy_Estimation.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df = pd.DataFrame(df) \n",
        "df.drop(columns=['Date'], inplace=True)\n",
        "numerical_cols = ['S1_temp','S2_temp','S3_temp','S4_temp','S1_Light','S2_Light','S3_Light','S4_Light','S1_Sound','S2_Sound','S3_Sound','S4_Sound','S5_CO2','S5_CO2_Slope']\n",
        "categorical_cols = ['S6_PIR','S7_PIR','Room_Occupancy_Count','day_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "cYvduLsFZ9y0",
        "outputId": "cafb5c4f-8d30-42a4-9e13-b74d484e22e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-db5f5aa2-bae6-47ed-ab66-bbfe1cfc4db3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>S1_Temp</th>\n",
              "      <th>S2_Temp</th>\n",
              "      <th>S3_Temp</th>\n",
              "      <th>S4_Temp</th>\n",
              "      <th>S1_Light</th>\n",
              "      <th>S2_Light</th>\n",
              "      <th>S3_Light</th>\n",
              "      <th>S4_Light</th>\n",
              "      <th>S1_Sound</th>\n",
              "      <th>...</th>\n",
              "      <th>S4_Sound</th>\n",
              "      <th>S5_CO2</th>\n",
              "      <th>S5_CO2_Slope</th>\n",
              "      <th>S6_PIR</th>\n",
              "      <th>S7_PIR</th>\n",
              "      <th>Avg_Temp</th>\n",
              "      <th>Avg_Light</th>\n",
              "      <th>Avg_Sound</th>\n",
              "      <th>Avg_PIR</th>\n",
              "      <th>Room_Occupancy_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10:49:41</td>\n",
              "      <td>24.94</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.56</td>\n",
              "      <td>25.38</td>\n",
              "      <td>121</td>\n",
              "      <td>34</td>\n",
              "      <td>53</td>\n",
              "      <td>40</td>\n",
              "      <td>0.08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>390</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9075</td>\n",
              "      <td>62.00</td>\n",
              "      <td>0.0975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10:50:12</td>\n",
              "      <td>24.94</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.56</td>\n",
              "      <td>25.44</td>\n",
              "      <td>121</td>\n",
              "      <td>33</td>\n",
              "      <td>53</td>\n",
              "      <td>40</td>\n",
              "      <td>0.93</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>390</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9225</td>\n",
              "      <td>61.75</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10:50:42</td>\n",
              "      <td>25.00</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.50</td>\n",
              "      <td>25.44</td>\n",
              "      <td>121</td>\n",
              "      <td>34</td>\n",
              "      <td>53</td>\n",
              "      <td>40</td>\n",
              "      <td>0.43</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>390</td>\n",
              "      <td>0.519231</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9225</td>\n",
              "      <td>62.00</td>\n",
              "      <td>0.1700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10:51:13</td>\n",
              "      <td>25.00</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.56</td>\n",
              "      <td>25.44</td>\n",
              "      <td>121</td>\n",
              "      <td>34</td>\n",
              "      <td>53</td>\n",
              "      <td>40</td>\n",
              "      <td>0.41</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09</td>\n",
              "      <td>390</td>\n",
              "      <td>0.388462</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9375</td>\n",
              "      <td>62.00</td>\n",
              "      <td>0.1750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10:51:44</td>\n",
              "      <td>25.00</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.56</td>\n",
              "      <td>25.44</td>\n",
              "      <td>121</td>\n",
              "      <td>34</td>\n",
              "      <td>54</td>\n",
              "      <td>40</td>\n",
              "      <td>0.18</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>390</td>\n",
              "      <td>0.253846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9375</td>\n",
              "      <td>62.25</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db5f5aa2-bae6-47ed-ab66-bbfe1cfc4db3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db5f5aa2-bae6-47ed-ab66-bbfe1cfc4db3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db5f5aa2-bae6-47ed-ab66-bbfe1cfc4db3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Time  S1_Temp  S2_Temp  S3_Temp  S4_Temp  S1_Light  S2_Light  S3_Light  \\\n",
              "0  10:49:41    24.94    24.75    24.56    25.38       121        34        53   \n",
              "1  10:50:12    24.94    24.75    24.56    25.44       121        33        53   \n",
              "2  10:50:42    25.00    24.75    24.50    25.44       121        34        53   \n",
              "3  10:51:13    25.00    24.75    24.56    25.44       121        34        53   \n",
              "4  10:51:44    25.00    24.75    24.56    25.44       121        34        54   \n",
              "\n",
              "   S4_Light  S1_Sound  ...  S4_Sound  S5_CO2  S5_CO2_Slope  S6_PIR  S7_PIR  \\\n",
              "0        40      0.08  ...      0.06     390      0.769231       0       0   \n",
              "1        40      0.93  ...      0.06     390      0.646154       0       0   \n",
              "2        40      0.43  ...      0.06     390      0.519231       0       0   \n",
              "3        40      0.41  ...      0.09     390      0.388462       0       0   \n",
              "4        40      0.18  ...      0.06     390      0.253846       0       0   \n",
              "\n",
              "   Avg_Temp  Avg_Light  Avg_Sound  Avg_PIR  Room_Occupancy_Count  \n",
              "0   24.9075      62.00     0.0975      0.0                     1  \n",
              "1   24.9225      61.75     0.2750      0.0                     1  \n",
              "2   24.9225      62.00     0.1700      0.0                     1  \n",
              "3   24.9375      62.00     0.1750      0.0                     1  \n",
              "4   24.9375      62.25     0.0900      0.0                     1  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_g=df.copy()\n",
        "avg=df_g[['S1_Temp','S2_Temp','S3_Temp','S4_Temp']].mean(axis=1)\n",
        "df_g.loc[:,'Avg_Temp'] = avg\n",
        "avg=df_g[['S1_Light','S2_Light','S3_Light','S4_Light']].mean(axis=1)\n",
        "df_g.loc[:,'Avg_Light'] = avg\n",
        "avg=df_g[['S1_Sound','S2_Sound','S3_Sound','S4_Sound']].mean(axis=1)\n",
        "df_g.loc[:,'Avg_Sound'] = avg\n",
        "avg=df_g[['S6_PIR','S7_PIR']].mean(axis=1)\n",
        "df_g.loc[:,'Avg_PIR'] = avg\n",
        "lc = df_g.pop('Room_Occupancy_Count') \n",
        "df_g.insert(21, 'Room_Occupancy_Count', lc)\n",
        "df_g.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "3WhTVe1suRIN",
        "outputId": "c051111f-cae8-428a-ff53-ed7496396a38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f0ba5a3-2739-4758-8f6d-19072c0e4358\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1_Temp</th>\n",
              "      <th>S2_Temp</th>\n",
              "      <th>S3_Temp</th>\n",
              "      <th>S4_Temp</th>\n",
              "      <th>S1_Light</th>\n",
              "      <th>S2_Light</th>\n",
              "      <th>S3_Light</th>\n",
              "      <th>S4_Light</th>\n",
              "      <th>S1_Sound</th>\n",
              "      <th>S2_Sound</th>\n",
              "      <th>S3_Sound</th>\n",
              "      <th>S4_Sound</th>\n",
              "      <th>S5_CO2</th>\n",
              "      <th>S5_CO2_Slope</th>\n",
              "      <th>S6_PIR</th>\n",
              "      <th>S7_PIR</th>\n",
              "      <th>Room_Occupancy_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.00000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "      <td>10129.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>25.454012</td>\n",
              "      <td>25.546059</td>\n",
              "      <td>25.056621</td>\n",
              "      <td>25.754125</td>\n",
              "      <td>25.445059</td>\n",
              "      <td>26.01629</td>\n",
              "      <td>34.248494</td>\n",
              "      <td>13.220259</td>\n",
              "      <td>0.168178</td>\n",
              "      <td>0.120066</td>\n",
              "      <td>0.158119</td>\n",
              "      <td>0.103840</td>\n",
              "      <td>460.860401</td>\n",
              "      <td>-0.004830</td>\n",
              "      <td>0.090137</td>\n",
              "      <td>0.079574</td>\n",
              "      <td>0.398559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.586325</td>\n",
              "      <td>0.427283</td>\n",
              "      <td>0.356434</td>\n",
              "      <td>51.011264</td>\n",
              "      <td>67.30417</td>\n",
              "      <td>58.400744</td>\n",
              "      <td>19.602219</td>\n",
              "      <td>0.316709</td>\n",
              "      <td>0.266503</td>\n",
              "      <td>0.413637</td>\n",
              "      <td>0.120683</td>\n",
              "      <td>199.964940</td>\n",
              "      <td>1.164990</td>\n",
              "      <td>0.286392</td>\n",
              "      <td>0.270645</td>\n",
              "      <td>0.893633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>24.940000</td>\n",
              "      <td>24.750000</td>\n",
              "      <td>24.440000</td>\n",
              "      <td>24.940000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>-6.296154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>25.190000</td>\n",
              "      <td>25.190000</td>\n",
              "      <td>24.690000</td>\n",
              "      <td>25.440000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>355.000000</td>\n",
              "      <td>-0.046154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>25.380000</td>\n",
              "      <td>25.380000</td>\n",
              "      <td>24.940000</td>\n",
              "      <td>25.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>25.630000</td>\n",
              "      <td>25.630000</td>\n",
              "      <td>25.380000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>465.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>26.380000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>26.190000</td>\n",
              "      <td>26.560000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>258.00000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>3.440000</td>\n",
              "      <td>3.670000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>1270.000000</td>\n",
              "      <td>8.980769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f0ba5a3-2739-4758-8f6d-19072c0e4358')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f0ba5a3-2739-4758-8f6d-19072c0e4358 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f0ba5a3-2739-4758-8f6d-19072c0e4358');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            S1_Temp       S2_Temp       S3_Temp       S4_Temp      S1_Light  \\\n",
              "count  10129.000000  10129.000000  10129.000000  10129.000000  10129.000000   \n",
              "mean      25.454012     25.546059     25.056621     25.754125     25.445059   \n",
              "std        0.351351      0.586325      0.427283      0.356434     51.011264   \n",
              "min       24.940000     24.750000     24.440000     24.940000      0.000000   \n",
              "25%       25.190000     25.190000     24.690000     25.440000      0.000000   \n",
              "50%       25.380000     25.380000     24.940000     25.750000      0.000000   \n",
              "75%       25.630000     25.630000     25.380000     26.000000     12.000000   \n",
              "max       26.380000     29.000000     26.190000     26.560000    165.000000   \n",
              "\n",
              "          S2_Light      S3_Light      S4_Light      S1_Sound      S2_Sound  \\\n",
              "count  10129.00000  10129.000000  10129.000000  10129.000000  10129.000000   \n",
              "mean      26.01629     34.248494     13.220259      0.168178      0.120066   \n",
              "std       67.30417     58.400744     19.602219      0.316709      0.266503   \n",
              "min        0.00000      0.000000      0.000000      0.060000      0.040000   \n",
              "25%        0.00000      0.000000      0.000000      0.070000      0.050000   \n",
              "50%        0.00000      0.000000      0.000000      0.080000      0.050000   \n",
              "75%       14.00000     50.000000     22.000000      0.080000      0.060000   \n",
              "max      258.00000    280.000000     74.000000      3.880000      3.440000   \n",
              "\n",
              "           S3_Sound      S4_Sound        S5_CO2  S5_CO2_Slope        S6_PIR  \\\n",
              "count  10129.000000  10129.000000  10129.000000  10129.000000  10129.000000   \n",
              "mean       0.158119      0.103840    460.860401     -0.004830      0.090137   \n",
              "std        0.413637      0.120683    199.964940      1.164990      0.286392   \n",
              "min        0.040000      0.050000    345.000000     -6.296154      0.000000   \n",
              "25%        0.060000      0.060000    355.000000     -0.046154      0.000000   \n",
              "50%        0.060000      0.080000    360.000000      0.000000      0.000000   \n",
              "75%        0.070000      0.100000    465.000000      0.000000      0.000000   \n",
              "max        3.670000      3.400000   1270.000000      8.980769      1.000000   \n",
              "\n",
              "             S7_PIR  Room_Occupancy_Count  \n",
              "count  10129.000000          10129.000000  \n",
              "mean       0.079574              0.398559  \n",
              "std        0.270645              0.893633  \n",
              "min        0.000000              0.000000  \n",
              "25%        0.000000              0.000000  \n",
              "50%        0.000000              0.000000  \n",
              "75%        0.000000              0.000000  \n",
              "max        1.000000              3.000000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00f4eba2"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhnKdHsRvx-u"
      },
      "source": [
        "Time analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L0MtL6YinsEh"
      },
      "outputs": [],
      "source": [
        "hours_1 = []\n",
        "hours_0 = []\n",
        "df['Time'] = pd.to_datetime(df['Time'], format=\"%H:%M:%S\")\n",
        "for date in df[df['Room_Occupancy_Count'] == 0]['Time']:\n",
        "    hours_0.append(date.hour)\n",
        "for date in df[df['Room_Occupancy_Count'] != 0]['Time']:\n",
        "    hours_1.append(date.hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "rwTyHPbYpS-o",
        "outputId": "323c49bd-ad47-4f47-c2ef-addf66b32292"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "ax = sns.histplot(hours_0, color='blue')\n",
        "ax = sns.histplot(hours_1,bins=9, color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97dd39ff",
        "outputId": "607639ca-1fcf-4659-919e-d79eba0c6d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time                    0\n",
            "S1_Temp                 0\n",
            "S2_Temp                 0\n",
            "S3_Temp                 0\n",
            "S4_Temp                 0\n",
            "S1_Light                0\n",
            "S2_Light                0\n",
            "S3_Light                0\n",
            "S4_Light                0\n",
            "S1_Sound                0\n",
            "S2_Sound                0\n",
            "S3_Sound                0\n",
            "S4_Sound                0\n",
            "S5_CO2                  0\n",
            "S5_CO2_Slope            0\n",
            "S6_PIR                  0\n",
            "S7_PIR                  0\n",
            "Room_Occupancy_Count    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fb8881",
        "outputId": "378ea091-c564-4b99-fae4-db7671888b6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 0])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Room_Occupancy_Count.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNGXZF9hp57I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pvnenm3EDe8n",
        "outputId": "306e5a8a-373e-448d-9762-99205f1132eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"5c583dd8-5f4b-4757-900d-64e964d00c65\" class=\"plotly-graph-div\" style=\"height:525px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5c583dd8-5f4b-4757-900d-64e964d00c65\")) {                    Plotly.newPlot(                        \"5c583dd8-5f4b-4757-900d-64e964d00c65\",                        [{\"text\":[8228.0,748.0,694.0,459.0],\"textposition\":\"outside\",\"x\":[0,2,3,1],\"y\":[8228,748,694,459],\"type\":\"bar\",\"marker\":{\"line\":{\"color\":\"blue\"},\"color\":[\"#d90429\",\"#fee999\"]}}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"yaxis\":{\"visible\":true},\"xaxis\":{\"title\":{\"text\":\"<b>Room_ occupancy</b>\"}},\"margin\":{\"pad\":10},\"width\":600,\"title\":{\"text\":\"Room Occupancy Count\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5c583dd8-5f4b-4757-900d-64e964d00c65');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def Room_Count():\n",
        "    gen = df.Room_Occupancy_Count.value_counts()         \n",
        "    title = 'Room Occupancy Count'           \n",
        "    colors = [\"#fee999\",                     \n",
        "    \"#fca55d\",\"#47a0b3\",\n",
        "    \"#fca55d\",\"#d90429\",'#fca55d']\n",
        "   \n",
        "    \n",
        "    fig_cmp = grp.Figure()\n",
        "    fig_cmp.add_trace(grp.Bar(             \n",
        "        x=gen.index,\n",
        "        y=gen.values,\n",
        "        text=gen.values,\n",
        "        textposition='outside'))\n",
        "    \n",
        "    fig_cmp_color = [colors[4], colors[0]]          \n",
        "\n",
        "    fig_cmp.update_traces(marker_color=fig_cmp_color, \n",
        "        marker=dict(line=dict(color='blue')))\n",
        "    fig_cmp.update_yaxes(visible=True)\n",
        "    fig_cmp.update_xaxes(title='<b>Room_ occupancy</b>')\n",
        "    fig_cmp.update_layout(width=600, margin={\n",
        "        'pad': 10}, title=title)\n",
        "    \n",
        "    show_figure = fig_cmp.show()\n",
        "    return show_figure\n",
        "\n",
        "Room_Count()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "BiWUzVdPGHQ7",
        "outputId": "333f4a98-692e-48ae-cf58-9265afbf448b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f78ee6d9290>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEHCAYAAABWecpSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zV9fX48dfJTW42CQHCDIQhICrDsio4UBzgAOse1NZWWlfV+vVXa2urnThpHXXiqHsh7ioqDhCRgMhW9ggQEkb2vDm/P+4FMm5yb8j7c3Nv7vv5eORh7mecvBNDzv28x3mLqmJZlmVZLRHT1g2wLMuyIo9NHpZlWVaL2eRhWZZltZhNHpZlWVaL2eRhWZZltVhsWzcgVDp37qzZ2dlt3QzLsqyIsmTJkgJV7dLweNQkj+zsbHJyctq6GZZlWRFFRLb4O267rSzLsqwWs8nDsizLajGbPCzLsqwWs8nDsizLajGbPCzLsqwWs8nDsizLIZ7CQqp37mzrZjjCJg/LsiwH5D/4ED+MP571E05m6y9+SW1paVs3yaioWedhWZYVCiVffsn+2W9S/MEHB4+VLljA7of/Q83OndTk55M2eRJpF1yAlpfj6tCh3v2VGzdS+cMPJI0aRWynTqFuftAkWvbzGDlypNpFgpZlOWn/m3PY+fvfB3exywUeD8nH/Zie99+PKz2dgidnkX/vvQBIQgJZjz5C8tixDrY4MBFZoqojGx633VaWZVmG7Hv5peAv9ngAKP1qIfkP/4eijz4i/777Dp7WigryH3zIdBONcTR5iEiWiMwTkdUiskpEbqhz7noRWes7frefeweJyLI6H0UicqPv3B0iklvn3GQnvw/LsqxgxCQlHdZ9FatWseP3t0GDniBP4X4TzXKE02MeNcDNqrpURFKBJSIyF+gKTAGGqWqliGQ2vFFVvweGA4iIC8gF3qxzyUxVvdfh9luWZQUtdeJEyhZ+3eL7PEWFqJ8B9fTzzjfRLEc4+uShqjtVdanv82JgDdATuBqYoaqVvnO7A4Q6Bdigqn4LdFmWZYWD1IkTIablf1ar1m9odCz5pJPo9POfGWiVM0I25iEi2cAIYBEwEDheRBaJyOciMirA7RcDDTsTrxOR5SLylIh0NN5gy7KsForr2pWkMaONxKrauBFPcbGRWE4ISfIQkRTgDeBGVS3C212WAYwFbgFeFRFp4l43cA7wWp3DjwD98XZr7QTu83MrIjJdRHJEJCc/P9/Ut2NZluVXbXk55Uu/NRKreutWit5910gsJziePEQkDm/ieEFVZ/sObwdmq9c3QC3QuYkQk4Clqpp34ICq5qmqR1VrgScAv6leVR9X1ZGqOrJLl0Z7mViWZRmlnlrUN4vKhNqKSmOxTHN6tpUAs4A1qnp/nVNzgAm+awYCbqCgiTCX0KDLSkS613l5LrDSVJsty7IOlyslmfRzpxqLt+eppwjXtXhOP3mMA6YBJzeYVvsU0E9EVgIvA1eoqopIDxF5/8DNIpIMnArMbhD3bhFZISLL8Sahmxz+PizLsoIS2yfbuwAQIC6uVbE8+fnseeyx1jfKAY5O1VXV+YDfsQzgcj/X7wAm13ldCjRan6+q00y10bIsy5T977xDwb11VhBUV7c6Zvl337U6hhPsCnPLsixDds+YYTxmrafWeEwTbPKwLMsyROLcxmO6e/QwHtMEmzwsy7IM6fmw4VpUMTF0+c31ZmMaYpOHZVmWIUlHHUWf2W8c1irzhmI6dmTA558Rm5FhoGXm2eRhWZZlUNKQIWS/9CLuAf29B/yvf/ZL3N5ur6SxY+k3Zw5xYbw+zW4GZVmWZVjisGH0f/dd1ONh689+TtnixU1e68rMZMDHcxGXC3G5UI8HOTDVN4zZJw/LsiwHVKxbR+5vf0ttbCyuzk0V0ADP7t3U7Nx5MGFEQuIA++RhWZZlXPmKFWy+8KJG+3M0ZcOUqQz8/DNcaWkOt8wcmzwsy7IM2z1zZtCJA4CKCnJv/T3VW7ZQW1pKx4svovPVVzvXQANs8rAsywoDpfPmHfw8/98P4O7Thw6Tw3eTVDvmYVmWZVjna69tdYzSRd8YaIlzbPKwLMsyRFUpev998u9rvMVQ6pln0nH69KBjVaxZg6ew0GTzjLLJw7Isy5D8+2eS+9ub/W4IVfzee9Tm7ybh6KODilWxfDmbLrwIrakx3UwjbPKwLMsyZN+LLzZ7vvDNOXS9846gFw5Wb9nS7BqRtmSTh2VZliGSkBDwmrwZd7WofEkwMduCTR6WZVmGdLm+ThFDEb9PGBXLlkGQW9VKfDyJw4ebap5RdqquZVmWIR0vvojEESMoX7aMskWLKHr//cYX+dsgKiEBKioaHdbKSsq/XUbSsSMcaG3rOL2HeZaIzBOR1SKySkRuqHPuehFZ6zt+dxP3b/ZtN7tMRHLqHM8Qkbkiss73345Ofh/hoMZTy7zvd/Px6jyqasJzcxjLsiBh0EDcfXpTnZ8f/E1+EsdBtcE9pYSa008eNcDNqrpURFKBJSIyF+gKTAGGqWqliGQ2E2OCqhY0OHYr8ImqzhCRW32vf+fENxAOKqo9XPTYQr7b7p22d0RmCrOvOY7UhNbtj2xZlnmbzjuPilWrjcRKHDaMxB/9yEgs0xx98lDVnaq61Pd5MbAG6AlcDcxQ1Urfud0tDD0FeNb3+bPAVDMtDk//W7nrYOIAWLe7hDe/zW3DFlnt2fL85cxcMpPXfniNSk9lWzcnohR98qmZxBEbS6frrqX3M08jLSjpHkohGzAXkWxgBLAIGAgcLyKLRORzERnVxG0KfCQiS0Sk7uqarqq60/f5LrxPMv6+5nQRyRGRnPyWPEKGmeKKxn2kReV++k0tq5W+2P4F0z6YxlMrn+IvC//CDZ/eEPgm66DKtWvNBKqpYf/Lr0AYV9gNSfIQkRTgDeBGVS3C212WAYwFbgFeFf/pdbyqHgtMAq4VkRMaXqCqijfJNKKqj6vqSFUd2SWMN1UJ5Iyju5OedKiLKtntYsrwnm3YIqu9enHti9TqoTG1BTsWsKlwUxu2KLKkT51iLJanoICKFSuMxTPN8eQhInF4E8cLqjrbd3g7MFu9vgFqgUYF71U11/ff3cCbwGjfqTwR6e6L3x1oabdXROmSGs/b147nVyf24xfj+/LWdePJykhq62ZZ7ZA7xt34mOvQscLKQtbvW4+2pGJsFInr2ZPM3996aB1Ha7qcYmKI65VlpmEOcHq2lQCzgDWqen+dU3OACb5rBgJuoKDBvcm+QXZEJBk4DVjpO/02cIXv8yuAt5z6HsJF705J/H7Skdx+1hAGZKa0dXOsdurKo68k3hV/8PU5/c+hZ4r3KffV71/llNdO4dy3z2XKW1PILbHjbg1V5eVR8NDDUOt7emtFkpX4eKpzw/dnLE6+gxCR8cCXwAq8TxcAtwEfA08Bw4Eq4P9U9VMR6QE8qaqTRaQf3qcN8HZzvaiqf/fF7QS8CvQGtgAXqure5toycuRIzcnJae6SNqWqfLImjznLdlBYVsWArqmUVtawYP0e+nVJ5k9nDeGIrqlt3UyrHVu3bx13L76bjYUb6dOhDxN6TWBL8RYSXAmc1e8sLv/g8noD6GO7j+WJ055owxaHny0//zllC782Fi+ud28GfPShsXiHQ0SWqOrIRsej5fEz3JPH9P/m8NHqvCbP9+mUxLybTyImJjxnXliRrbCikPPfPp9d5bsOHhME9Q0nprnTKKxqXOH1nhPu4dQ+pyIiFFUWkZ6QHrI2h6M1Q4469NRhyIBPPiauZ9uNcTaVPOwK8zCwbNv+ZhMHwJY9ZWzdW0Z25+QQtcqKBpWeSv44/4/8b/P/Gp3TOvNQCqsKiY+Jp7K2/tTdW764hb6pfanUSnaU7GBgx4Hcd+J9ZKdlO9308GQ4cQCULPiKjhdeYDxua9naViHy1foCfvb0N0ybtYhP1x5KFCu2F/LMgsCzWdKT4uiWFp4F0qzI9craV/wmDn9OzDrR7/FNxZvYUbIDgB/2/cDfF/3dWPsiTgsKHgarbNEi4zFNsE8eIbC5oJSfPb2YKo/3XcmC9QW8fd14dhdX8Mtnc6gN0HOYmRrPjPOOISEufOd8W5Hp+33fB3Xd0M5DiZHg/jD+sO+H1jQpoiUMG0bFt4338miNqu3bjcYzxT55hMAna3cfTBwAtQofrc7j6QWbAyaOUwZnktkhnl8/v5Tp/81hX2mVw621osnY7mODui6vLC/oJ5RgY7ZHrnTzYz7p559nPKYJNnmEQB8/azJUaykoCVz6YdGmvazMLaKqppaPVufx9/fN1MyxLICz+5/NDcfeQMf45muL5pX5H5Prk9qHWafNYkLWBLomdeWc/udw25jbnGhqZFDzYx5pU8wtPDTJzrYKgdpa5f9e/47ZSwPP2e7aIZ68oqaTikuElXeeTqLbdmFZZj254kn+vfTfLbrny4u+jPoZVnVtuuxyKpYsMRoza9aTpIwbZzRmSzQ128o+eYRATIzwz58cQ0Jc4B93p+TGK3zr8qjy6OcbTDXNsg765TG/5L+T/suJvfwPjDfkdrm5L+c+XljzAlUe250KEJOYaDxmXLduxmOaYAfMQ0TVuydHINv2lge8ZvOeUhNNsqxGRmSOoGNC4O1xBKHKU8WcDXNgAyzbvYx7TrwnBC0MbzEpZqfSx/XuTXz//kZjmmKfPEIkIc7FUT3SAl5XXl1/45f+ftZ1nHdsL2PtsqyGxvVouovkR5k/It2dXm8NCMBHWz6isLLxIsJo4ynYYzRel2uvMRrPJJs8QqSksobhWYH7hmvqTL8SYObFw7n1jEFkpsbTu2Mi95w/lBMGRm6FYCv8Hd/reFzSeEyte3J3VhSsYH/V/kbn3DHuegUUo1XVls3GYiWNH0/SyEZDDWHDdluFwFfrC/jVc0sorqxBaKJ+vB8KvLhoK68v2U5NrdIlNZ6hvezgpOWs2xfcjkcbb326s3Snn6u9XDEuymvKSYw13+cfSTxlgbudg1U2fz4bz5lC9muvEt+vn7G4ptgnjxD423trKK6sAbwJIT0xjpT4wLOl4mOFN7/NPfg0kl9cydSHF/DWsvCttGlFtu3F25m7ZW6L7yutLuX9je870KLIkjh4sNF4taWl7H/lVaMxTbHJIwR2FtZ/N1JYUc1fzjmKbh0alxsZN6ATPdISOLpnB/4+9Rgqa+oPspdXe7jplWVssYPmlkGl1aXsKNnht7vKnwRX49/dcN0uNZQyfnZF4ItaqOH4Uriw3VYhMCwrnc++P7QNrir89rXljfaJccfG8Lepx9C3ziD584u2smxb/T7mWoXFm/fRp5Mtkmi13ktrX2LmkpmU15QzrMswTu1z6sGnj9iYWDy1nkZ/wG4bfRszFs+grKYMgKTYJCZlTwp528NN6imnkDh8OOXLlhmL6c7uayyWSfbJIwR27Cvze7zu+swkt4veHRN5av5Gtte5ftYVIxk/oNEmiwzPCjxzy7ICyS/L565v7qK8xvt0/F3+d3RN6sp1w6+jV0ovuiV18/vO988L/3wwcQCU1ZTxbb7Zmk6RSGJiyHr6KWK7djUWU6vDcw2NTR4hkLu/IuA1ZVUe1ueX8tzXWznzgS8pKK6gotpDp5R4Rmdn1Lt2dN8MBmTajaGs1ttStKXR4PjiXYt5csWTbC/ZzvYS/0X5/CWUtXvXOtLGSFPwwIPU5DW/xUJL1OzOD3xRG7DdVg4rqqimtKrxzJXmFJbX8OMZn1LtURLiYqisrj/usWzrfiprPMTH2hIlVutU1TZ+Vxtspd2GYsX+OakuKGDv008bjakVgd98tgWn9zDPEpF5IrJaRFaJyA11zl0vImt9x+9u4b13iEiuiCzzfUx28vtojRgObxCx2uN9Z1dRXdvoPV58rOCyg5OWAWnx5ro/e3fobSxWpNr6UwcGzB0otmiC028VaoCbVXWpiKQCS0RkLtAVmAIMU9VKEckM9l5VPVBWdqaq3utw+1utrKrGeMyEuFhqahX74GG1Vu/U3vW2m22N/mnhWUYjlKpzzU+jd/cMz4oSjj55qOpOVV3q+7wYWAP0BK4GZqhqpe/c7hbcG1HcseZ/xPkllcxb2+hHZlkt9tHmj4wkjhhiWFGwgrJq/5NDokVMqvmxyJSTgitUGWohGzAXkWxgBLAIGAgcLyKLRORzERnVgnsPuE5ElovIUyLit5KbiEwXkRwRycnPb5tBJxEhxvYwWe1cLbXcsfAOfvL2T9hf0bh8SbRIGtXsn7LDUp27w3hME0KSPEQkBXgDuFFVi/B2l2UAY4FbgFeliRVGfu4FeAToDwwHdgL3+btXVR9X1ZGqOrJLl7apB5WWGMdlY/oYjzumX0bgiywrgNOyTyM1zty75dySXN7a8JaxeJEm7eyzjccs+yY89zB3PHmISBzeP/4vqOps3+HtwGz1+gaoBRotZmjiXlQ1T1U96h1JegIY7fT30Rq/O2OQ8aePWJedZc13r8AX90BFnWqutbWweT5sXnBoIU1pAXz8V3jtSnj3t/D14/DiJd57q8NzJkuoJLgSDq7xMKXSE3iHzPYq9eQJdPvbX4np0MFYzISjjjYWyyRHB8x9TxOzgDWqen+dU3OACcA8ERkIuIGCIO9FRLqr6oEqbecCKx36FozI3V8ecK/yliqr9NAhIc5s0EihCg8Mh32bva/n/ROu/BC6HQ3PnAW5vh0js8bAuBvh5Uv8x/nhfVg1B65eEJJmh6MFuQuoUXOTOhJdiZzdz/y770hRW1XF3idnUVtUFPjiILj79SP19NOMxDLN6bev44BpwMkNptU+BfQTkZXAy8AVqqoi0kNE3g9wL8DdIrJCRJbjTUI3Ofx9tEphebXxmE98EcW7CS597lDiAFAPPHcu/Hv4ocQBsG1R04njgLyVsDt6F7e99sNrRuMpSuekxhURokXpggVUbd5sLF7n668P25phjj55qOp8aHKhw+V+rt8BTA50r6pOM9XGUNhZaL5rxBMle8/79fV/Gh+rKvZ+HI45v4bpn7WmRRFrT7nZzYsqPBX8v8//HzMnzDQaN1KY3oa2Zkf4VtC2Hech8J95Zp8SBLj+lCOMxowo+YafFHZ8C7tWmI0ZIbqndDcec8GO6O0GjOvZE2LNvScv+t+HxmKZZpOHwzy1yvd5h/mOuAldUuPplBxvNGbEKFhH8NtptYBE5z+Fib0nGo8ZzB7o7VXBI49CjbkxpLhe4bu0LTr/xYSQOtC9VFxhftV6xNi3xYGgMdD1KAfihr/0BPM7U57WOzwHeEOherv/QpKHK1zLsYNNHo6LdcXQJyPJaMyRfaJ4K9o+x2H819Zt9v9PJHl/k/nd/z7b/pnxmJHC9Myo0s8/NxrPJJs8QqB/ptlNm9buMtsNFlGqSvEuCzIZswQ80fk0V1hZGPiiFiqpLjEeM1JkXHaZ0b08XBnhuxjYJo8Q+G672X+ge0vDc3OYkFj+sjNxd5rb+S2S9Ewx36cezWMe5StXUbPH0Ay22Fi6XHetmVgOsMnDYbW1Smml2Xe1/btE8fazTjwhSAx0GmA+bgQ4Ldv8+IQTg/CRYv8rr5gbMFclrl8/M7EcYJOHw2pqlaoas90sXVISjMaLKOV7zcccfBYkRuc40o+6/og4MVepoEtiF64aepWxeJFG4g3OgvR4KHjYz5qmMGGTh8PcsTF07WB2Wu2CjXsorjC/aj0iJPvb+qWVSsNzm89QmT5surFYp2efTlxMlJbNATIuv4yYNHMbbNkB8yg3eajZhVgikBgXpTtBpTiQPNLCc7OdUOmSGLjidJo7jakDpnLjsTfy0pkvcfvY27l11K10iu9U77rn1zxPQXlBE1HaP3d2Np2vNTdOEdfD/CJOU2zyCIGrTxxArMGyuqpRXFU3w4E+4JN+bz5mBKmpDdxHX1hVyJ7yPfzimF9wdOejuXDQhVw25DKqtfET8CdbPnGimRGhYt16dv/jH8bipZ4WvmtmovQvUGh1Toln2hiz+zv/YHjVesToeSykB7E/Sp/jgovXazR0iu7tU0/PPp1EV+CaTPNz5zP+pfGMfXEsty+4nUpPpd/ZWmN7jHWimRFhz1OzjMYrfPsdo/FMsskjBHYVVvD0QrMro/eXRel03RgXTHsThkz1f15iYOw1cMGz0PcE77HU7tChR+Nr45JgysPOtTVCpCekc8GgCwJepyiFVYWUVpcyZ/0c7lt8H33T6q+AjouJC6obrL0qW/i12YAx4fsn2tGqupbX3DW7jMcclR2+i4cc16k/XPgsvH4lrHzj0PGJd8KPrwOX79f6ineguhxiE7wDRc+fD+vnHrp+8r3QZWBo2x6mfn70z3lnwzvsq9wX9D1vrn+TCk/9itHVtdXkluRyRMfoLNxZs3u3uWAiZP72t+biGRZ08hARNzAYb1W671U1St/6ttzmgjLjMb/asIdxA6J33wQApj7q7Z7KWwUDJsLgMxtfE1enO+ai52DJs1DwAwyaBEecGrq2hrl1e9e1KHEAjRLHAR3jo3eRoCstDc++wD/HuD59qN7SdG9EyskT6HzddSQOGWKyeUYF9UwkImcCG4AHgIeA9SIyycmGtScu03vQAut3R28JiINi3TDql3DWTP+Jo6G4RBj7azjrfps46pizbg7TPzY3Xfefi/5pLFakSZ14SsBrUk46iZik5uupdZg0OawTBwQ/5nEfMEFVT1LVE/Hu3hedu70chr6do7fwnhXeKmoquP2r243GXLxrsdF4kaR85Sr/J1JS6PrXv9B//pdkPfoIaWc3v1Vv0bvvOtA6s4JNHsWqur7O641AwOk+IpIlIvNEZLWIrBKRG+qcu15E1vqO393E/WeIyPcisl5Ebq1zvK+ILPIdf8XXpRa2xvYz373UI93sjmVWdLpn8T3GY6oT+61EiDg/RRETR45kwNtvkXHBBUhNDbtn/ovqHbl0uuZqUk4+mfSLL2p0T2y3bqFobqsEO+aR49tb/FW8Yx4XAItF5CcAqjq7iftqgJtVdamIpAJLRGQu0BWYAgxT1UoRabTyS0RcwMPAqcB239d7W1VXA3cBM1X1ZRF5FPgF8EiQ30vI9e2czJjsjiza3LI+5eYkxYXvLAwrcjix61+sK3rn4XS58QbKV6zAs2cPxMbS9dZbybj8MgBqCgrYfOFFBwfVxe0m+7VXSRg0CFd6Onsee9xbz6pXLzpPD/8SL8H+X04A8oATfa/zgUTgbLzJxG/yUNWdwE7f58UisgboCVwFzFDVSt85f1MURgPrVXUjgIi8DEzxxTgZuNR33bPAHYRx8gDo3SnZaPLon5lqLJYVvfY6UCussMJ8mfdIkTB4MAM+/YSK5cuJ692HuK6ZaHU1O//0ZwrfegtqD9W506oqCt+cQ8KtvyPzxhtJP/8CanbnkTh0KGJwK1unBNVCVf15a7+QiGQDI4BFwD3A8SLyd6AC+D9VbdhR2hPYVuf1dmAM0AnYr6o1dY77rSstItOB6QC9e5tdpNdS89ebq58UI9AxOXrrB1nmBLO6vKX8rTqPJjHx8SSNGnXw9f7XX6fwzTf9X9vh0JtAd6+euMN429mGgkoeItIXuB7IrnuPqp4T5P0pwBvAjapaJCKxQAYwFhgFvCoi/dTwnq2q+jjwOMDIkSPbrCP2oU/XsbOw0li8XumJxMdGaW2rlqiphPduhhWvQWo3OP2fkDkY5lwD276BrDEw9T+QEb5bfTotPSGd/PLoLgzptIrVq5s8V7lufZPnwl2wHedzgM3Ag3hnXh34CEhE4vAmjhfqjI1sB2ar1zd4t4ZrOKqcC2TVed3Ld2wPkO5LQHWPh6Xiimrun/uD0Zjb95cbjReRfvgQXr3Cmxz2ba5/ThXWzYVZp8K3z0FNhfeaV3/qXVi4dSGoB7Z+BY8cB5u+aIvvICwcm3ms8ZgpsSnGY0aypLFNl2sp/uADypYsAaBq61a233wz6089jc2XT6NkgfnxKJOC7VirUNUHWhpcRASYBaxR1fvrnJqDd7rvPBEZCLiBhqU4FwNH+J56coGLgUtVVUVkHnA+8DJwBfBWS9sWKvvLqqk1/MxjOl7EWf8xvHjhoddr3oHfLIOSXdChF3x4Gyx+ovF9tdWw49v6x6rL4JXL4bdrwB19m2w5UT69f3p01wo7wFNcTG1JCWlnnkn19lz2v/oqntJSavfvr3dd9a5d1JaVsemSS6jd4x2Dqt62jW2/vIo+/322XhdYOAk2efxbRP4MfAQc7H9R1aUB7hsHTANWiMiBfT5vA54CnhKRlUAVcIUvKfQAnlTVyapaIyLXAR8CLuApVT0wifp3wMsi8jfgW7wJKix1T0tAwOjkxTiXUFVTizs2SmdcffVg/dclefCPVpSurij0rlLPGt26dkWgH/abfSoGqDW9x3wEKnjiCQoefAitqiJp7Fh6PfgAnX81nbLFi9ny0yu8T8d4V6SnHH88xfM+O5g4DlKl8N33Ij55HIM3CZwMB38z1Pe6Sao6H2hqefXlfq7fAUyu8/p94H0/123EOxsr7ClmEwdAtUe596O13DY5vFegOmbzfLPxYmKhy2CzMSNEVkoWP+wzm0C6J4fvHhShULVlC/n3zzyYIMq+/pqCRx4l47JLqdmzl+4z/sn+116npqAAd9++lC5ezL7nn/cbK7ZL+BaZDDZ5XAD0s/WsWi7OFUOS20VZlcdo3NU7orQkO4DpGUISCwkdzMaMELf/+HY+2/4ZHjX3+zm6W0S8r3NM2bfLDiaOA/Y+9RR7n3nGO1U3JubglN3qzZspnTfPb5zYzEw6Xnap33PhINh+j5VAdG7ybEB6ovl+5QtHRunud3lrzMf0VEBNdL4v6pTYia8v/Ro35oo0/Kjrj4zFikRV27b5P3FgjUdtEN16cXFkz36D2I7hW2Qy2OSRDqwVkQ9F5O0DH042rD3ZVeS/+ujhSoyL4ZzhkTMf3KgihybWeaIzeQAkxCZwXK8gN88KICMhgwEdBxiJFamKP2jU095y1dVUN5WEwkSw3VZ/drQV7dj2fWXGZ0ddd3IU/+PsPwHE5Z1qa4orHuKjc3pplaeK33z6G2NlSvZW7GVvxV4yEqJ3v5mqLVuNxCl69z2SRowwEssJQT15qC7r3agAACAASURBVOrneNd5xPk+XwwEmmllAZ2S4zFZkV2Aa06K4uQR44KffQAug7Uwp/lf/RsNPtj0gdH6VgmuBFLjort0jstQV1PZt98GvqgNBbufx1XA68BjvkM98a7VsAJIdLu4aGRW4AuDpHhnW0W1PmO8+3gEQ+pk7phYSGzwD7v3WMgeZ65tEWZH6Q6j8So8Fbyx7o3AF7Zj3f7yFyNxKlevPriAMBwF2211Ld6psYsAVHWdv0q4ln8b8kuNxtuxv5zsztG3oK2eXn7mvg+7BIZf6p3Ku38rZA7xbhK1ZYF3b/MhU7xb0n79CGz4BI76CYxoNGM8qkzsPZHHv3ucGjU3g+3tDW9z8eCLjcWLNOWLzO1jXvDY4/R+/LHAF7aBYJNHpapWie9dnK80SJS//Q1eaaXZQnEPf7aOe84fbjRmxDnqXNi1HL55AmLj4aTfw2hfGeu+J9S/tlODFc/jfuP9sDii4xE8dupjzFwyk72Ve0mNSyW/LJ99lfsOe1+OTgmdDLcycpSvXMXeZ/9rLF7l92uNxTKt2eQhItep6kPA5yJyG5AoIqcC1wDvhKKB7UF8nNkihu8s28nd5w1DxPz2thFDBCbe4f2wWmVJ3hJW7llpJJZLXFw97GojsSLRvueeMxqvJm83NQUFxHY2v6FcawUa87jS999b8e7hsQL4Fd5V3390sF3tRo2nlrW7zC7oq6ipZeHGPUZjWtHr2dXPGovlUY/RBYeRpvjzz43HzLs3qBq0IRfsfh61wBO+D6sFqj1KueHV5QB7S6N3XYJlzoLcBZRWmx2TS4yN3i2Sa0tLjMes3mpm6q9pgZ48hopIkZ+PYhEpCkkLI1yi28WgbmanLnZKdnPSIDtfwWq9j7Z8ZDSeO8Yd1YsEXR3SjMfsdE14dgMGSh4rVLWDn49UVY3OYkCHYX+Z2aeEN64+jpT48N+m0gp/PVPMVirISjU3LT0SpZ55ptF4iaNGkTp+vNGYpkRpTe/Q2lVkbhdB8E7VtSwTLhl8CUO7DDUW76x+ZxmLFYnSp5xTf21RK4XzlJhAyeO1YIKIyO8NtKXdcplcYg7c9uYKo/Gs6JXqTuWFyS/w+tmvc2zX1u8qOL5neL5LDpXiDz5oVFG3NWK7h295+2aTh6r+I8g4FxhoS7tl+t3D5j1lFFeYXTtiRbecvByW5rW+4lBUTx8HasvNFkEt+vRTPCVmJzSYYqrbKrp/YwLolGqwDpNPzuZ9xmNa0WlVwSruXXxvwOskwD/zYzOPZVDGIFPNikjp558HsQbHI0tKKA/TGlemkoff5zQRyRKReSKyWkRWicgNvuN3iEiuiCzzfUz2c++gOueX+WZ53Rjs/eFCVdlbYn5abf8u0VkF1jLvb1//LajyJE2tOM9KzeKWkbfwyMRHTDct4iQceSSuDg3mEgWbTFyuxuMlMTHE9+trpnGGmUqRTb0lqQFuVtWlIpIKLBGRub5zM1W1ybc7qvo9MBxARFxALlC3/Gmz94eLoooa44UMUxNc9O6UZDSmFZ1W7VnVqtXlJ/Q8gZkTZuI2WeU4gmltLZ7CwvoHa4KsG+apvx5MEhPJvOlG4nqG5949pp48/A6sq+pOVV3q+7wYWIO3Im9LnQJsUNUth9/EtpGWGGe8T6+4wsPaXXaZjdV6H2/5uNGxnik9+cf4fzCs8zC/9zw44UGOzTyWDu4OxEgM+ypsF+oBEhODK8PMXiYJw4aRcvIpRmI5IdiS7A/4+firiEyB4AbWRSQbGIGvMi9wnYgsF5GnRCRQAfyLgZcaHAt4v4hMF5EcEcnJz88P1ETHxLnMz4g2OKHDimLdkxvP5umX1o+MhAymHjHVb5HDe3LuYenupRRVFfHZ9s/4w/w/hKKpEcPdp4+ROOVff82OW24xEssJwf5VS8DbhbTO9zEU6AX8QkT+FehmEUkB3gBuVNUi4BGgvy/mTqDJ4i0i4gbOof7TTVD3q+rjqjpSVUd26dIlUDMdU+UJYs/iFjqyu12jabXepOxJJMfVL+//Ze6X/PrjX3PnwjspqS5pNFC+tbh+uYxFuxaxs2Sn422NFJ1+caV3/MKA8m+/pbYqPEsRBZs8hgITVPVBVX0QmAgMBs4FTmvuRhGJw5s4XlDV2QCqmqeqnjo1s0Y3E2ISsFRV8w4caOH9baqi2pkicZ9/v9uRuFZ0WbhzYbO1rSo9lYzpPoYuic2/+fr7or+j9nEYgNQJE+g7+w063/AbJLnBvjtxcc3f3OB8bGYmMe7wHE8KNnl0BOpO70kGMlTVAzS5fFq8k75nAWtU9f46x+s+K58LNDdidwkNuqxaeH+b8pjewNzn+zyzlXqt6BRMUUSXuAIWO/x8++fcv+T+Zq+JJgmDBpFx2WVQ26DXofrQ+izxlxSq66/fqtm9m6K5cxtfFwaCTR53A8tE5GkReQb4FrhHRJKBxiNuh4wDpgEnN5hWe7eIrBCR5cAE4CYAEekhIu8fuNkX/1RgdsP2+Ls/HCU7VIOqc0q8I3Gt6HJy75PpnNj8XhEjMkdw4aALA8Z65ftXqFXzXbSRqiwnBy1vupSQKzO44qYln84z1SSjgi3JPsv3R/1A99Btqnpg8+MmR3RUdT7+p/G+7+cYvpiT67wuBRqN2KnqtGDaHQ4qqj0I5rdd7J6WYDiiFY3S4tN46cyXOOP1M/Dgv4t13rZ5vHzWy3SM78gfF/yxyfUe8a54YsSWyzvAnd38+oyEIwZQsn174Dhhus4j2NlW7wAnAR+r6lt1EocVQFmVx3jiiHMJP+4ffjuLWZGpW3I3uiV3a/J8Xpl3uPGcAef4nZ11QDTvIOhPfL++xDQc8/BJmXgK3WfMwNWp+Wm9SWNGk3HppU40r9WCfZtwL3A8sFpEXheR80XEvvUNQkaymx6GnxLUoXEUKzot272M3NLcJs8fm+ktmLh+33p2lPp/3/iHMX/g0iPD849cW6nankttaYMxJRH6vvUWWQ89hCs5OWAtrNSJpzaZgNpaUMlDVT9X1WuAfsBjwIWAne4TBFU1vs6jRuGd7+zDn2XGjG9mNHv+oy0f8enWT5vcXvbMvmdy8eCLnWhaZKtt/POKHzKEhEEDAajatg0NMA1XPUGuTm8DQf9VE5FE4Dzg18Ao4BmH2tSu5O4vZ8veMuNxZy8N3FdqWYHkluSyas+qgNe9/sPrfmdTdUvqxh3H3eFAyyKfu3dvUk6ps0Lc5SLzxhsBKHz7bTZOPrPZ0iWSlETa2Wc73czDFtSAuYi8inew/H/AQ4AHuMjBdrUbGcnOzNGuqLGzWqzWS4lLITYmlpra5t/hrixYyb7KQ2VIBOHSwZdyzYhrSIi1PdhN6TXzfor+9z+qtm4jdeIpJAweDMDumTMbl4mIiSFp7Bi0ugZ3djaZN/yG2E6NV/iHi2Dnkc7CO+5xAfA0sAnvwj8rgBiH9jfold78vHvLCkZafBrTj5nOf777T5PXxEpsvcQB3gq7E/tMpIPbVjrwR2tqKF++gtjMLqSdc06j87VFftZp1dZSvjiHfu+/hzsr/LfzbbbbSkQGisifgX8D9wNbAVHVCar6UCgaGOkKSsxuQXvAZWPC/5fLigxXD7+at6a81WgL2fT4dG4fe3uT5dp//uHPOebZYxj1/Cje2/heKJoaEap37mTDmWey5dJL2XDqaey+r3F3X/oF/vfP0+pqSr74wukmGhFozGMtcDJwlqqO95UmcabeRjuVkeRMt9X1Ly1zJK4VnUqqS0iLT+OYzsfQNakrY7uP5fFTH2dC1oSA91Z4Kvjj/D9SUWN2F71IteeJJ6ne4qv/pcqeJ5+katu2etd0/s31Te7z4c7OdriFZgTqtvoJ3oq280Tkf8DL2F0DWyTG8P7lB+QVNb1y1bJa4vnVz3PX4rvqHbvy6Cs5stORgLc8SVMzrQ6o0Ro2F21mcMZgx9oZKSo3bap/QJXyFSvqdUUVvfue38Hy9AsvJPm445xuohGB9jCfo6oX4y2COA+4EcgUkUdEpNmCiJbXOodqUCW6nSl7YkWfx5Y/1uyxsd3HBozhEhd908JzJXSo+dvPo7rBSvKSzz5rdE3qmZPp/pc7I2Yf+GDLk5QCLwIv+vbOuAD4HfCRg21rFzo6NNsq04F90SNKdTlsmAdJnaD3GO+xNe/Cpi8grRfExkOHnuCphNK9sOJVcKfAsT8FdzIU5sL6j2DUdBgQuGumPfM306q69lCBvjuOu4PbF9xOTl4Ox3Q+hl2lu9hZWr8Ee4zEUFFTQbzL1lxLPeF4it+rPwYU1927Mr9q61YqVq8BPz0SSWPGhKR9prT47auq7gMe931YAfTq6NR2sZHx7sQRhdth1ulQ5Hs3N2QqFOXC9sWB7934af3X378Pg8+Gi583384IcfmQy3n0u0frHZt25KHycd2Su/HEaU8AUFZdxpgXG/+Rq66tZsqcKfxrwr8Ynjnc2QaHudRJk0h6YzZl33wDQNLYsaSefjr7Xn6ZXXf+xTtFN6Zxp0/Zom/IuDBwAcpwYfs+ItQZRzVdi6jd++qhQ4kDYPWc1sVb+w6U7YUkM9uHRpprh1/LkIwhvLPxHQDO6X8OJ2WdRHFVMa//8Do5eTlkp2Zz8eCL6ZXai14pvdhe0niR6p6KPdw2/zbeO/e9iOl6cUKM202f/z5L+YoVANSWlrLt2mspW/j1obUdDUu1AxW+6yOFTR4R6vyRUTxVd92H5mNWlUZt8gCY0HsCE3of6r6r8lRx6XuXsrloMwBf8AWv/PAKz53xXLNl17cVb6O0upQUd0qT10SLxGOOoXLTJjZfelmjfTr8CrRRVJix9ZMdVlwRxC/NYZi9tOlCdu1e8S6z8RLSID2Kk7EfX27/8mDiOKDSU8k1n1zTZHFEgGM6H2MTRx0l8z5rOnE0eDqr3raNDZMmt5t1HlYruQ0XRTxg1Y5CR+JGhDTDf+inPmI2XjtQVuO/HltBRUGT97jExV0n3NXk+Wjk7t34dzXx2GPp/s9/0vull3D3748k+cZFq6qo2rSJ7b+5gT3PPEPpwoVhvbWvTR4Oc8c68yPemBfFycPkhkMjLodBkwNfF2WSY1teBvzH3X9MVqp9gqsrZcIEOpx1aOV+6qmn0ufZZ0g/dyplX3xB1YYNaFn9RK0VFeyecRdbf34lu+68M9RNDpqjyUNEskRknoisFpFVInKD7/gdIpLbYGtaf/dv9m03u0xEcuoczxCRuSKyzvffjk5+H63h1B7mW/Y5U/Yk7BWsg/w1zV8TmwAJQf5KVBSDx5muxUg2NHMoLlwtuuernV+RWxLF3al+iMtFz3vvYcAnH9P/47n0evABJC6O2vJy9syaFfD+/a++RvXu8Nz9wuknjxrgZlUdAowFrhWRIb5zM1V1uO/D77a0PhN814ysc+xW4BNVPQL4xPc6LNU4lDw84fs066zEjhATYJ5HTQVU7Gv+mgPWvAXfvdT6drUznRM7M+PEGSTGBl+As1Zr2Vq01cFWRa64nj1x9+p18LV6alFP41X74m6wfqu2NrjB9jbgaPJQ1Z2qutT3eTGwBuhpIPQU4Fnf588CUw3EjCiJcVHa45jcGU74fxxc5yIte3fsV/7a1sdoh87IPoOFlyzkjOwzgrq+Y3zHqF/jESxXSjJpU6fUO9btjj/T45576g2kp5x8MnE9TfzJNC9kU3VFJBsYASwCxgHXichPgRy8Tyf+3ioq8JGIKPCYqh5YmNhVVQ8scd0FdG3ia04HpgP07t3b0HfSMm6XM/Pdu6RE8Qrzk34Hx5wPb10HW79qfbwjorvSzraibXy45UMyEjKY1HcScTFxfLT5I7YWe58i/rf5f03eKwip7lSSYpM4o+8ZVNZUtuhpJZp1v/NOkkeNomLt9ySPH0fKuHEAxL7wPMWffIK7Tx/Spobv+2IJxWi+iKQAnwN/V9XZItIVKMCbHP4KdFfVK/3c11NVc0UkE5gLXK+qX4jIflVNr3PdPlVttpN75MiRmpOT09wljthdXMHov39iPO6grsl8eNNJxuNGlAdGwN6Nh3+/xMApf4bxN5prU4RZu3ct096fRoXHWxF3aOehZCZl8vHWjwFvclCC/xvRI7kHr53zmt3nox0RkSUNhg2AEMy2EpE4vBtHvaCqswFUNU9VPapaCzyBd5fCRlQ11/ff3cCbda7LE5HuvvjdCeP91DNTndllzalNpiJK3xNad39yF+h6lJm2RKiX1758MHEALC9YfjBxAC1KHAA7Snfw0WZb8i4aOD3bSvDuQrhGVe+vc7x7ncvOBVb6uTdZRFIPfA6cVue6t4ErfJ9fAbxlvvXhbU9plM62OqCqzFvU0J16+DFK8uCFC2DDp4GvbaecKCMSY3IqtRW2nP6/PA6YBpzcYFru3b4puMuBCcBNACLSQ0QOzLzqCswXke+Ab4D3VPVA5+sM4FQRWQdM9L2OKlG9hfl3r8B9g+DR46CqtSXvFZa/aqRZkeiSwZeQFHuoeOdRnY7CHXP442lZqVmc1ie6x5CihaMD5qo6H//lX/1OzVXVHcBk3+cbgWFNXLcHOMVQMx21x6FtaBMcWnwY9iqL4d2boLrUXMwUv/MtosLAjgN5a+pbzN0yl4yEDOasn0NVbVWL48RKLL8b/TvO7HemLU8SJaL0L1DobMgvcSRuUrRO1S3cbjZxZPSHsdeYixeBuiV3Y9qQaYzrMY5FOxcdVowarWFC1gRSW9ONaEWUKP0LFDpDe6UHvugwVNZE6SrBzoPMrO2IS4EL/wvXfgOp0fvkUdeb694MeoC8YRmSIzOOpGuy/TlGE5s8IlSBQ91hYS8mxlt+pLWqS+CL+6B8b+tjtRMLdyxsdEwQ7hp/F2f1O4t4VzzxrnjO7nc2D054kNHdRpOZlMnE3hP594R/t0GLrbZk9/OIUBXR+uQBkJIJ+za1Ps6u7+A/P4Zffe7dujbKFdc0nnygKOsK17GpcBOVHu8blk+2fsIn2z6hrNpb0G9b8TY6J3UOaVuttmefPBxW5XFmWlRUL/M48qzA1zTUs9EaJ6+yAvg2eregrWtMN/97aD+98mlW7Vl18HVZTdnBxAHw/b7vmb99vuPts8KLTR4RSqJ5D/OTboMR0yAhHWKC3H0tt5nqAmG8Z0Io/XrYr5mUPanRcY82LuDX0OJdQewfb7UrNnk4rNahqrpH94jiWS3uJJjyENy6Ba76tHX7e7hTvXt6WHy982s+2PzBYd27v3K/4dZY4c4mD4cluQ3MDPLj2N5hu4VJaHU+As68D7JPhD7jDiNArbdMSZRbt28df5j/h8O+/5td33DDpzewYf8Gg62ywpkdMHfY/jJnavGvz2/tyup2YO8meHoyFPv21B75C9i2GFqyyK2qFEp2QcdsR5oYCVbvWc2096cFXBzYXJHEvLI88sryWLVnFR+c9wFxwXYnWhHLPnk4rMbPhi8mOLVyPaJ89cChxAGQM6tliQO8+6Gn9zHbrggze93soFaVB7MGJK8sj+/3fm+iWVaYs8nDYRkpzlTVdWgSV2QpzW/Z9S4/NZviU6N86hokuMz9jsbFxNEzJTw3L7LMssnDYdv2lgW+6DDsLW15/aF2Z/hlwV+bNQZuz4e4pPrHd6/2bvUZxS4efDEZCRkHXw9IG0Ciq/6GTn3T+nJE+hHNxomLieP3Y35Px2D3j7cimh3zcFh2RlLgiw5DUUV47mscUoMmwWWve6viJmXAokfrn49NhMGTvfWrfuyrX9XnOFh/aL8KMvpH/ZNHr9RevD31bT7b9hlp8WmM7zme6tpq1u1bx5JdS+iZ2pOJfSZSVl3GKa+dQlmN/zdEz57xLMd0OSbErbfaik0eDqtxaA1BpTNDKZHniFO9HwA1lbDkae/nEgNTHoZjzqt//dkPwBMTvHt5AOzdAF/eCyfcEro2h6G0+DSmDDi0p3ZsTCxDuwxlaJehB4+luFN4+JSHmfHNDHJLcslKzSKvLI8EVwJXD7/aJo4oY5OHw4oqahyJG93vlZtw9r9g3A2w5SsYMgXi/ZQGT+jQeKzk2+ejPnkEa2S3kbx+zutt3QwrDNjk4bBOyYe/sU5z4u3/Of8y+no/muKKB3cKVBYdOpbUyfl2WVY74/Q2tFkiMk9EVovIKhG5wXf8DhHJbbC7YFD3Bnt/uPh+lzPrMYb3THMkbrsX64ZT/sTBZ7fYRDj59jZtkmVFIqffv9YAN6vqUt9+5EtEZK7v3ExVvbel96rq6iDvDwu9OiYGvugwrHIoKUWF0VfBgFMgbxX0/jEk24qwltVSTm9DuxPY6fu8WETWAEFNAm/m3tXN3hhmEhwqT1IV1ZuYG5DRz/thWdZhCdk6DxHJBkYAB/a5vE5ElovIUyLS7MRwP/e26P62FB/rTPLo0sGZxYeWZVnBCEnyEJEU4A3gRlUtAh4B+gPD8T5d3NeCewn2fhGZLiI5IpKTn9/C1chhLjsjua2bEP62LoLlr0HZXshdCkv+C189BHP/5D1nWdZhc3zOjojE4f3j/4KqzgZQ1bw6558A3g323pbcr6qPA48DjBw5sl1t2jCwq59pqNYh794EOU95P3e5wdNgRf6Cf8PoX8Hku0PfNstqBxxNHiIiwCxgjareX+d4d9+YBsC5wMpg7w32/nBRWunMOo+vN+1xJG5EKdwOb/4acpd4Xyd1hqOmejeKynn60HUNE8cBi5+A8TdBh+7Ot9Wy2hmnnzzGAdOAFSKyzHfsNuASERkOKLAZ+BWAiPQAnlTVyU3dq6rvA3f7uz8cxbmc6RkscSgpRYzKEnjqdG8COaBwq7fSbtFOCKICLFrrLcluWVaLOT3baj7+F0O/38T1O4DJAe5FVaeZaqPT3LHOJI99pVFc22rrInjhPKhsYrrylvmQNRa2fd18nB7HQucB5ttnWVHAVtV1WEW1M0WojsiM4jGPj+9oOnGAd4B84OkwLEDV3U7NV4m1LKtpNnk4zKnupS6p8Y7EjQh1N4Dyx1MJn9wJpXnNX1dWYK5NlhVlbPJwmFMD5l9tiOIB86EXBXdd3mqIa2ZKc9YYM+2xrChkk4fDOiU5UxixOJprsp94K0y6GwaeAd2HN31dehZc9FzT5796wLsOxLKsFrPJw2EpiXGOxI3q/3ExMTDmV3DpK5DYRHGBmFg49S/w1YNNx6kqgdm/hPn/cqadltWORfXfoFCodmiz8V4ZtjwJAIOaKKhcWwOf3QUb5wWOsXiW2TZZVhSwycNh1Q4VMKyotoURAW+F3KZKqm/8lKC2zfJE8bRnyzpMNnk4bMmWvY7ELS6P8kWCB4hAt+a2Pw1isaBd62FZLWb3o3NYn05JjsRVovzJY/Xb3vpVFfuh+4jWxRp2iZk2WVYUscnDYW6XMyXZazWKdzGvLIHXrvCWFwHIXXz4sQZNhuGXmmmXZUUR223lsK37yhyJmxrvTFKKCKvePJQ4WiM2Ec5+wNv1ZVlWi9jk4bA+nZzZhjaqV5j3aGU31QHnPgYpXczEsqwoY5OHw2pqnXlXG+9Qtd6I0O1oGHy2gUBRPm5kWa0QxX+BQqNLijNPCGvymikMGA0ufh6uy6HZqbhdjvQuFmyKLU9iWYfNJg+HxbmcefKoiuLqJAft2wLi51c4MQMGTIQ9672LBf0RF+zbChWFzrbRstopmzwctmF3SVs3oX36+E7vnh7qJ4uW74X1H0NtM4v/1ANPnw73HQlr/O5ibFlWM2zycNiArqlt3YT2p6IYFj5kJlZ1Kbx/C2i72uLeshznaPIQkSwRmSciq0VklYjc4Dt+h4jkisgy34ffAkUicoaIfC8i60Xk1jrH+4rIIt/xV0TEmdK1Vvjx1MBzU5rel9yvAF2HxTtbGM+yLKefPGqAm1V1CDAWuFZEhvjOzVTV4b6PRtvSiogLeBiYBAzBu+/5gXvv8t0/ANgH/MLh7+Ow5e4vdyRufLQ+M66fC7lLgr8+LgluWgXnNVP80J0EsVE89dmyDoOjf4JUdaeqLvV9XgysAXoGeftoYL2qblTVKuBlYIqICHAy8LrvumeBqWZbbk6KQ4v5UhKidJFgdRDJOD4Vuh4NQ6bAFe9CWk9I7tz09Qlp5tpnWVEiZOVJRCQbGAEsAsYB14nIT4EcvE8n+xrc0hPYVuf1dmAM0AnYr6o1dY4Hm5BCbnN+qSNxiyujdI3CwDMgvQ/s3+L/fHyqdwpvarf6x/ueCIPPgrV+BsfH/Np8Oy2rnQtJ8hCRFOAN4EZVLRKRR4C/4i15+lfgPuBKB77udGA6QO/evU2HD8rg7h0ciZscF6X9Vu4kuOpT+PjP8N0r9WdUdR4Iv/oS4hKgqhS+fQE2feGtmjvql3DxC94ur4oiKM6DXcuh7/EwaFLbfT+WFaEcTx4iEoc3cbygqrMBVDWvzvknAH9zJXOBrDqve/mO7QHSRSTW9/Rx4Hgjqvo48DjAyJEj22Q6TXycM91LVZ4oXuix7AX49vnGx1W9iaPWA09Pgp3fHTq36HH41RfQ80d1brjY8aZaVnvl9GwrAWYBa1T1/jrHu9e57FxgpZ/bFwNH+GZWufH+S39bVRWYB5zvu+4K4C0n2m/C7qIKR+KWRvP+RQse8H+834ne/358R/3EAd4puUuedrRZlhVNnO77GAdMA05uMC33bhFZISLLgQnATQAi0kNE3gfwPVVcB3yId6D9VVVd5Yv7O+C3IrIe7xhI2O4jauu1OqBRFVyB4ZfBxDtg1yr4qonkYlmWMY52W6nqfPz//Ww0Ndd3/Q5gcp3X7/u7VlU34p2NFfbcsc50WyW5o3S2FcD4m+DD2w69PvVOGHeD9/M3r2r6Pneys+2yrChiN4NyWKpDU2qT3FE6YA7w42u9Zdm3fg1ZoyF7vPf43D9B3qqm71v7Hky4DbYugs/+AWV7YcQ0GDM9NO22rHbEJg/HOdNx1T3NmX1CIkaf47wfB6x+Cxb8u/l7qsu9CeP5n0CVr+bYB7dAcic4+jzn76czjwAACQhJREFU2mpZ7VAUv30NjZgYoWsH86uXzziqe+CLoskPHwW+ZvRVsGXBocTRknsty6rHJo8QuHSU+TUmk4/pFviiaNJloP/j4oIRV8AlL8PYq6HzoODvtSyrSTZ5hMClY/sQb3hfj9ho3knQn1FXwRGnNz6uHjjp/x1aCNhlIJzyJ4hN8L4eMBFG/yp07bSsdsL+BQqBLqnx/PXcY/yeSz6MWVO9OibSMz3KxzwacifBZa/CSbfWP559PKT1qn/s+Jvh/9bBb9fC5W9AfEro2mlZ7YRNHiFy4cgsuqUl1DsWIzDrZ6MY0r0DLhFcMf6fTlwiHN2jAx0SYvlRn448evmPiGni2qh30u9hyn/gyLPhhFvgIj8r0QESOkAHO25kWYdLNEo2wRk5cqTm5OS0aRs+WLGTa15cenDfoQtH9uLu84cdPF9bq5z7nwV8t927NWqS28Xsa45jcDdn6mNZlmUFIiJLVHVko+M2eYTWytxC5q3dzYDMFE4/qlujJ4jyKg9vf5fL3tJqzhranayMpDZqqWVZVtPJw67zCLGje6ZxdM+m949IdLu4yIHZWZZlWSbZMQ/LsiyrxWzysCzLslrMJg/LsiyrxWzysCzLslrMJg/LsiyrxWzysCzLslosatZ5iEg+sKWt2xGEzkBBWzeinbA/S7Psz9OsSPl59lHVLg0PRk3yiBQikuNvQY7VcvZnaZb9eZoV6T9P221lWZZltZhNHpZlWVaL2eQRfh5v6wa0I/ZnaZb9eZoV0T9PO+ZhWZZltZh98rAsy7JazCYPy7Isq8Vs8ggTInKGiHwvIutF5NbAd1hNEZGnRGS3iKxs67a0ByKSJSLzRGS1iKwSkRvauk2RSkQSROQbEfnO97O8s63bdLjsmEcYEBEX8ANwKrAdWAxcoqqr27RhEUpETgBKgP+q6tFt3Z5IJyLdge6qulREUoElwFT7+9lyIiJAsqqWiEgcMB+4QVW/buOmtZh98ggPo4H1qrpRVauAl4EpbdymiKWqXwB727od7YWq7lTVpb7Pi4E1QM+2bVVkUq8S38s430dEvoO3ySM89AS21Xm9HfuP0wpDIpINjAAWtW1LIpeIuERkGbAbmKuqEfmztMnDsqygiEgK8AZwo6oWtXV7IpWqelR1ONALGC0iEdm1apNHeMgFsuq87uU7Zllhwdc//wbwgqrObuv2tAequh+YB5zR1m05HDZ5hIfFwBEi0ldE3MDFwNtt3CbLAg4O8s4C1qjq/W3dnkgmIl1EJN33eSLeSTJr27ZVh8cmjzCgqjXAdcCHeAcjX1XVVW3bqsglIi8BC4FBIrJdRH7R1m2KcOOAacDJIrLM9zG5rRsVoboD80RkOd43jXNV9d02btNhsVN1LcuyrBazTx6WZVlWi9nkYVmWZbWYTR6WZVlWi9nkYVmWZbWYTR6WZVlWi9nkYVmWZbWYTR5W2BERj28twUoReefAoqoQt6GXiLwlIutEZIOI/Nu3gLNdEpE4EZnh+36XishCEZlk+Gtki8ilJmNabccmDysclavqcF859b3AtaH84r4V1bOBOap6BDAQSAH+Hsp2hNhf8S5gO1pVjwWmAqmGv0Y2YJNHO2GThxXuFuKrMCwiw0XkaxFZLiJvikjHAMc/E5GZIpIjImtEZJSIzPa9u/5bM1/zZKBCVZ8GbyE74CbgShFJ8lVFvdf3ZLRcRK73fb1RIvKVb6Ofb0QkVUR+JiIPHQgsIu+KyEm+z0t87VslIp+ISBff8atEZLEvzhsikuQ7/oyIPOD7GhtF5Pw6cX8nIit898wQkf4isrTO+SPqvq7LF/8q4HpVrfR9z3mq+qrv/CW+2CtF5K4695XU+fx8EXkmQDtnAMf7nipvaubnb0UAmzyssOXbJOsUDtX5+i/wO1UdCqwA/hzgOECVqo4EHgXewvsUczTwMxHp1MSXPgrvhkcH+arIbgUGANPxvose7vuaL/i6tF7Bu7HPMGAiUB7gW0wGclT1KODzOu2eraqjfHHWAHXLq3QHxgNn4f1jjK97aQowxnfP3aq6ASgUkeG++34OPN1EOwYAW/1VyhWRHsBdeBPqcP5/e2cPGkUUBOBvjhQqaiQIwcKIWIigEJCUaqGNnRYhmKBiZSM2BgxiCm1FBC0kEDGCsRMVLNQjaAix8AdJogE1qN0pQcVoNAHNWLzZuAm3udv8kDszX3O3897um/eO29l5s8xAnYjsKzCvvHoCLUCPeZUXiriGU8K48XBKkeVW7+AjUA1kRaQSWKOq3dbnGrAzSR67VmR4BoBXVthoHHjH1EzGadgDtFlOMlT1C7AZyKnqU5ONRO0zMEEwOADXCTdbgK0i0iMiA0ATwZhF3FbVCaviVx3T56qq/ozpA9AOHDEj3ADcmMVc64BHqjps8+lk6vomkU9P5z/CjYdTivyyegcbAGFuMY9x+5yIfY+OKxLOGQS2xwUishqoAYZSjv+bqf+zZTP0jRLNdQDHVHUbcGbaOfE5SIGxbwJ7CU//z1X1c0K/IaDG5piGeGK86fNKo6dThrjxcEoWe5I+DpwARoGvIrLDmg8C3ar6LZ98jkN3AStE5BBMbp+dBzpMpyxwVEQqrL0KeA2sE5E6k62y9g9ArYhkRGQ9oeRwRAaI4gGNhHrWEALVOQk1NJqK0DdL8DCi2EgVgKqOETI1XyZ5yypa5yvA5BtlElKH1wNPgF0istbW4QD/1veTiGwRkQywvwg9vzP/QXhnkXDj4ZQ0qvoC6CfctA4D5ySks64Fzlq3JPlsx1TCzbBeRN4Cb4Ax4JR1aSfEP/pFpA9otNrzDcAlk2UJT+O9wHuCN3MRiAetRwmV5F4SYgqR3q2EMq+9FFHrQVXvEbbnntl2X3OsuZPgZT0ocJnTwDAwaPrcBUZUNUeIVTwE+ggezB07p8X6PQZyhfQk/I5/LKjvAfMyx1OyO84iISI/VHXlAo/RDFSqautCjuMsPZL2fB3HKXNE5BawieDVOM684p6Hs2SxV3W78jTtniG4XNaYQdk4TXxSVe8vhj5O+eLGw3Ecx0mNB8wdx3Gc1LjxcBzHcVLjxsNxHMdJjRsPx3EcJzV/AWyUu/kCgNXyAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.stripplot(x=\"Room_Occupancy_Count\", y=\"Avg_Temp\", data=df_g,jitter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DcqAz_nkaaqs",
        "outputId": "b3d7264a-8a3f-4e1a-a7b5-d07c86e53df8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-71520d43-3ae8-43b0-9ff1-629e190429fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Room_count</th>\n",
              "      <th>S1_Temp</th>\n",
              "      <th>S2_Temp</th>\n",
              "      <th>S3_Temp</th>\n",
              "      <th>S4_Temp</th>\n",
              "      <th>S1_Light</th>\n",
              "      <th>S2_Light</th>\n",
              "      <th>S3_Light</th>\n",
              "      <th>S4_Light</th>\n",
              "      <th>S1_Sound</th>\n",
              "      <th>...</th>\n",
              "      <th>S3_Sound</th>\n",
              "      <th>S4_Sound</th>\n",
              "      <th>S5_CO2</th>\n",
              "      <th>S5_CO2_Slope</th>\n",
              "      <th>S6_PIR</th>\n",
              "      <th>S7_PIR</th>\n",
              "      <th>Avg_Temp</th>\n",
              "      <th>Avg_Light</th>\n",
              "      <th>Avg_Sound</th>\n",
              "      <th>Avg_PIR</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Room_Occupancy_Count</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>25.336365</td>\n",
              "      <td>25.371105</td>\n",
              "      <td>24.929206</td>\n",
              "      <td>25.659785</td>\n",
              "      <td>2.686558</td>\n",
              "      <td>3.053354</td>\n",
              "      <td>13.368498</td>\n",
              "      <td>9.234565</td>\n",
              "      <td>0.076895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063765</td>\n",
              "      <td>0.079680</td>\n",
              "      <td>404.446403</td>\n",
              "      <td>-0.308078</td>\n",
              "      <td>0.002431</td>\n",
              "      <td>0.001458</td>\n",
              "      <td>25.324115</td>\n",
              "      <td>7.085744</td>\n",
              "      <td>0.068225</td>\n",
              "      <td>0.001945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25.741590</td>\n",
              "      <td>25.831285</td>\n",
              "      <td>25.297211</td>\n",
              "      <td>26.091002</td>\n",
              "      <td>120.209150</td>\n",
              "      <td>31.427015</td>\n",
              "      <td>54.230937</td>\n",
              "      <td>37.579521</td>\n",
              "      <td>0.444619</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129216</td>\n",
              "      <td>0.094858</td>\n",
              "      <td>470.718954</td>\n",
              "      <td>0.310625</td>\n",
              "      <td>0.344227</td>\n",
              "      <td>0.041394</td>\n",
              "      <td>25.740272</td>\n",
              "      <td>60.861656</td>\n",
              "      <td>0.201503</td>\n",
              "      <td>0.192810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>26.003837</td>\n",
              "      <td>26.207233</td>\n",
              "      <td>25.594893</td>\n",
              "      <td>26.183168</td>\n",
              "      <td>136.109626</td>\n",
              "      <td>134.804813</td>\n",
              "      <td>138.339572</td>\n",
              "      <td>30.482620</td>\n",
              "      <td>0.642553</td>\n",
              "      <td>...</td>\n",
              "      <td>0.646217</td>\n",
              "      <td>0.240013</td>\n",
              "      <td>713.168449</td>\n",
              "      <td>1.141881</td>\n",
              "      <td>0.478610</td>\n",
              "      <td>0.427807</td>\n",
              "      <td>25.997283</td>\n",
              "      <td>109.934158</td>\n",
              "      <td>0.514138</td>\n",
              "      <td>0.453209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>26.066023</td>\n",
              "      <td>26.719035</td>\n",
              "      <td>25.827954</td>\n",
              "      <td>26.187378</td>\n",
              "      <td>113.317003</td>\n",
              "      <td>177.430836</td>\n",
              "      <td>156.393372</td>\n",
              "      <td>25.757925</td>\n",
              "      <td>0.556297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.769813</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>851.239193</td>\n",
              "      <td>2.145877</td>\n",
              "      <td>0.543228</td>\n",
              "      <td>0.655620</td>\n",
              "      <td>26.200097</td>\n",
              "      <td>118.224784</td>\n",
              "      <td>0.511290</td>\n",
              "      <td>0.599424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71520d43-3ae8-43b0-9ff1-629e190429fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71520d43-3ae8-43b0-9ff1-629e190429fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71520d43-3ae8-43b0-9ff1-629e190429fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      Room_count    S1_Temp    S2_Temp    S3_Temp    S4_Temp  \\\n",
              "Room_Occupancy_Count                                                           \n",
              "0                              0  25.336365  25.371105  24.929206  25.659785   \n",
              "1                              1  25.741590  25.831285  25.297211  26.091002   \n",
              "2                              2  26.003837  26.207233  25.594893  26.183168   \n",
              "3                              3  26.066023  26.719035  25.827954  26.187378   \n",
              "\n",
              "                        S1_Light    S2_Light    S3_Light   S4_Light  S1_Sound  \\\n",
              "Room_Occupancy_Count                                                            \n",
              "0                       2.686558    3.053354   13.368498   9.234565  0.076895   \n",
              "1                     120.209150   31.427015   54.230937  37.579521  0.444619   \n",
              "2                     136.109626  134.804813  138.339572  30.482620  0.642553   \n",
              "3                     113.317003  177.430836  156.393372  25.757925  0.556297   \n",
              "\n",
              "                      ...  S3_Sound  S4_Sound      S5_CO2  S5_CO2_Slope  \\\n",
              "Room_Occupancy_Count  ...                                                 \n",
              "0                     ...  0.063765  0.079680  404.446403     -0.308078   \n",
              "1                     ...  0.129216  0.094858  470.718954      0.310625   \n",
              "2                     ...  0.646217  0.240013  713.168449      1.141881   \n",
              "3                     ...  0.769813  0.249452  851.239193      2.145877   \n",
              "\n",
              "                        S6_PIR    S7_PIR   Avg_Temp   Avg_Light  Avg_Sound  \\\n",
              "Room_Occupancy_Count                                                         \n",
              "0                     0.002431  0.001458  25.324115    7.085744   0.068225   \n",
              "1                     0.344227  0.041394  25.740272   60.861656   0.201503   \n",
              "2                     0.478610  0.427807  25.997283  109.934158   0.514138   \n",
              "3                     0.543228  0.655620  26.200097  118.224784   0.511290   \n",
              "\n",
              "                       Avg_PIR  \n",
              "Room_Occupancy_Count            \n",
              "0                     0.001945  \n",
              "1                     0.192810  \n",
              "2                     0.453209  \n",
              "3                     0.599424  \n",
              "\n",
              "[4 rows x 21 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_val=df_g.groupby(['Room_Occupancy_Count']).mean()\n",
        "mean_val.insert(0, \"Room_count\", [0, 1, 2, 3], True)\n",
        "mean_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-aBhgmjq7Ene",
        "outputId": "6d47bc13-276f-4481-9ec1-b55f3330c2ca"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axs = plt.subplots(3, 2)\n",
        "axs[0,0].plot(mean_val.Room_count,mean_val.S5_CO2_Slope , color='red', marker='o')\n",
        "axs[0,0].set_title('Room_count Vs S5_CO2_Slope', fontsize=14)\n",
        "axs[0,0].grid(True)\n",
        "\n",
        "axs[1,0].plot(mean_val.Room_count,mean_val.Avg_Temp , color='red', marker='o')\n",
        "axs[1,0].set_title('Room_count Vs Avg_Temp', fontsize=14)\n",
        "axs[1,0].grid(True)\n",
        "\n",
        "axs[0,1].plot(mean_val.Room_count,mean_val.Avg_Light , color='red', marker='o')\n",
        "axs[0,1].set_title('Room_count Vs Avg_Light', fontsize=14)\n",
        "axs[0,1].grid(True)\n",
        "\n",
        "axs[1,1].plot(mean_val.Room_count,mean_val.Avg_Sound , color='red', marker='o')\n",
        "axs[1,1].set_title('Room_count Vs Avg_Sound', fontsize=14)\n",
        "axs[1,1].grid(True)\n",
        "\n",
        "axs[2,1].plot(mean_val.Room_count,mean_val.Avg_PIR , color='red', marker='o')\n",
        "axs[2,1].set_title('Room_count Vs Avg_PIR', fontsize=14)\n",
        "axs[2,1].grid(True)\n",
        "\n",
        "axs[2,0].plot(mean_val.Room_count,mean_val.S5_CO2 , color='red', marker='o')\n",
        "axs[2,0].set_title('Room_count Vs S5_CO2', fontsize=14)\n",
        "axs[2,0].grid(True)\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSmJhNRswLVS"
      },
      "source": [
        "##LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9UKZFsyjDgav",
        "outputId": "61cbeed0-f8eb-4625-cb82-6e1d6c4605db"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "y = df['Room_Occupancy_Count']      \n",
        "X = df.iloc[:,2:18 ] \n",
        "\n",
        "lda = LDA(n_components=3) #2-dimensional LDA\n",
        "lda_transformed = pd.DataFrame(lda.fit_transform(X, y))\n",
        "\n",
        "# Plot all series\n",
        "plt.scatter(lda_transformed[y==0][0], lda_transformed[y==0][1], label='Class 0', c='red')\n",
        "plt.scatter(lda_transformed[y==1][0], lda_transformed[y==1][1], label='Class 1', c='blue')\n",
        "plt.scatter(lda_transformed[y==2][0], lda_transformed[y==2][1], label='Class 2', c='green')\n",
        "plt.scatter(lda_transformed[y==3][0], lda_transformed[y==3][1], label='Class 3', c='black')\n",
        "\n",
        "# Display legend and show plot\n",
        "plt.legend(loc=4)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf81b562"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "8MwZ2f-HyN9X",
        "outputId": "305e50c4-202d-4289-fa64-2690e6aa8a1e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAIQCAYAAAA/7v7yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gUxf/HX7N3F9JID+n0XkNJKIoUaYoUsYNUsSIiIGIBVEBAvooFBVEsqAgoKkV6RzoSILQQIEAgvfdyd7u/Py4kuTQCgfj9+pvX89zz3O58dt772dmd/ezMzqzQNA2JRCKRSCQSieR2Uf7pHZBIJBKJRCKR/G8jA0qJRCKRSCQSSZWQAaVEIpFIJBKJpErIgFIikUgkEolEUiVkQCmRSCQSiUQiqRIyoJRIJBKJRCKRVAkZUEokEolEIpH8P0EI8a0QIl4IcbqcdCGE+EwIcVEIESqEaFeZfGVAKZFIJBKJRPL/h++BfhWkPwA0Kvg9ByyuTKYyoJRIJBKJRCL5f4KmaXuB5ApMBgE/aBYOAS5CCJ+b5SsDSolEIpFIJBLJDfyAa8WWrxesqxD9Xdsdyb8GY2JEtXyf0/jrx9Uhg677kGrRUcOPVotO/uot1aIDcHmvQ7Xo+DdPqxadQaG6atEBGItvtegkVFOtXstUPTrnDWr1CAEzvgiuFp1Gw5dWi84su8Bq0XEzV18Z9RiUVC06Tku2iGoRKuBO3mdtPBs8j6Wr+gZfaZr21Z3KvzxkQCmRSCQSiUTyL6EgeKxKABkFBBRb9i9YVyGyy1sikUgkEonkn0Q137lf1VkHjCgY7d0JSNM0LeZmG8kWSolEIpFIJJJ/Eq36XhsQQqwAugMeQojrwDuAAUDTtC+BjcCDwEUgGxhdmXxlQCmRSCQSiUTyT6JWX0CpadpTN0nXgHG3mq/s8pZIJBKJRCKRVAnZQim5o0ybs4C9+4/g5urCmp++vGP57r+SyH/2hKGqGoNb+jMmqJ5Vekx6DjO2niYjz4SqaYy/pxFd63lWKu99IWf4YOkvqKrKkN738Mwj1vO9RscnMWPhD6SkZ+LsaM+ciWPw9nAFIHDIizSqbZlNwdvTjYVvv1S+D+evM3/tIVRN5eHgJozp0cbah5RMpq/aS0ZuHqqq8coDQXRtZnkvOjwmmdm/7SMzz4giBMvHD6SGofzLV98qCNvh40BRMO7eSN6fK0vZGIK7UWPISNA0zJGXyFk8BwDbJ59D36YjCIHpzDFyf/yiXJ2a3drh985YhE5H0sqtxC/+zSrd7dGe+L41GmOsZWRmwg8bSF65DYA2EX+QG3YVgPzoBC6Pfb9cHUP7YBxeGI9QFHI3byDn159L2dh07YH906NA0zBFXCJz/iwA3P/ciflKBADmhHgy3nurXJ2O3YN4debLKIrC+hUb+emLFVbpTzz3KAOeehCzyUxqchpzJv2HuKg4AD76aR4t2jUn9OgpXh/5drkaN/Dr3pqOM4cjFIXwFbs59cX6Mu3qPBhEz68nsO6B6SSFXi5c7+DrzsO7P+DER79zesnGcnXqdWvN/e8MR+gUQlfu5vBia53AYT1pO6I3qlnFmJ3Llje/IelCNIpBR985z+Dduh6aqrLjvZ+4duhchf4EF/hz4Sb+9Ph6AuvL8GdwgT9nKvCncbfWPDRjBIpO4eiqXewp4U/wsPvpPLw3qqqSn5XHH28uJf6iZTyBd9MAHp4zlhqOdmiqyheDpmPKM5artf9cJPPX7ENVNR7u1Iwx91t/MCQmJYPpP+8kIzcfVVV5pX8nujavw4Zj4SzbdaLQ7kJMEismPUZTP48ydbrffw/vzXkDnU7Hih9/44tPv7FK79i5Pe/OmUqzFo0ZN3YKG9Zts0p3rOnAroNr2bJhJ9OmzinXn+o65wBq9WhNq1kjQKcQuXwXFz4vW8unfxDB30xkT9+3ST15Gf8h99Dwpf6F6U7Na7O799ukn7laoR6ArkUHbB9/AaHoyN+3ifwtv1il13jsefRNCupdmxooNV3ImPjITfOtDrRq7PK+W8iA8i4jhHgbGAqYARV4HggCXgUaAJ6apiWWs+1oYELBYnPgfEE+mzVNe+Mu7/ptMfjB3gx9ZCBvzfrwjuVpVjXm7TrH4iHt8XK0ZdiKQ3Sr70kDd8dCm6VHIujdyJvH2wRwKSmT8WtC6PrMzQNKs1llzpIVfPXeBLzcXXlqyly6B7emQUDRFC8fff8bA3p0YlDPzhwODeOzH9cwZ6LllZIaNjb8+sm0SvigMvePA3z5bD+8nB0YtnAd3ZrXpoGXa6HN1ztO0KdNPR7v3IxLcSm8/O1WNjV7ApNZ5e0Vu5n9ZDea+LqTmpWLXldB54JQsB35ClkfvI6WnIDjzEUYQw6iRhdVyIqXHzUGPEXmzFcgOxPh5AKArlFzdI1akPnWswA4TP8UXdM2mMNOltZRFPxnPc+lYTMwxibReN1HpG0/Qt6Fa1ZmKX/uI2rGklKbq7n5nH/w1ZseOxQFx3GvkvbWZNTEBFw+XUL+4f2YI4v54+uH/RPDSJs8Di0zE+HsUrR9fh6pL4+thIzC5Pcn8OpTU4iPSWDpxsXs23qAKxeKdC6cvsgzD7xIXm4eg0cMZNy055jxoiVw/fnLVdja2TLo6YduqiUUQaf3R7LlqXlkxyQzYONMIrceI+1CtJWd3sGW5s/0JT7kYqk8gt8dxvVdZZRLCZ1es0byy7B5ZMQmM2LdTC5uP0ZSMZ2zaw9yYvlOABr2akePaU+zeuR82jzVA4Dv+r6JvbsTjy6bwg8DZoBWenYToQg6vj+SrQX+PFSBP82e6UtCGf4EvTuMqEr4M3DmaL55ei7psUmMWzebc9tCCgNGgJNrD3Bk+Q4AmvVqR//pT/PdyA9QdAqPfzyOXyYtIvZcJPYujpiN5c99ZFZV5v7+F1++MMByzX78G91a1KWBt1uhzdfbjtEnsAGP39OSS7HJvPz1RjY1r0P/9o3p374xABeik5j43eZyg0lFUZg9fxpDhzxLTHQsG3asYuvmXVw4H1FoE3U9hknjpvH8y6PKzGPKW+M5fODYTY9ddZxzFqcEreeO5sDjc8mJSaLb5tnEbg0hI9x6oLDewZb6Y/uRfOxC4brrv+/n+u/7AajZNICO30+qVDCJULB7ahxZn7yJlpKIw5sLMYUeQo2JLDTJ+3UJeQX/DT0GogtoePN8q4tq7PK+W8gu77uIEKIz8BDQTtO01kAvLJOF7i/4X+FVomnad5qmBWqaFghEAz0Klv8rg0mADoGtcHaqeUfzPB2bRoCzPf7O9hh0Cn0be7P7UryVjUCQlW+5OWTmmfB0rFG5vC9cobZPLfy9PTEY9PS7N4hdh0OtbCKuxdCxVRMAgls1YdeRSlSoJXWuJRDg4YS/uxMGvY6+beqz+0yklY0QkJWbb/EhNx9PJ3sADoZH0cjHjSa+7gC4ONiiU8q/dHUNmqLGRaElxIDZhPHQLgztu1jZ2PToT972dZCdCYCWnmpJ0EAYbECvB4MBdDq09JQydewDG5F3JYb8a3FoRhMp6//CuXfHWz42N0PfuBnm6CjU2BgwmcjbsxObTvda2dj2G0DO+j/QMgv8SUu9ZZ1mbZty/UoU0ZExmIwmdqzdSde+1sct5MAJ8nItt6Qzx87i6VP00HJs33GyM7MrpeXRtgEZV+LIjExANZqJWHuI2n3bl7Jr9/qjnFr0J+Zc61a02n3bkxGZQOr5imfy8AlsQOqVONKuWXTOrT9Ew97WOvmZOYX/DfY1AEvA6N7Ij6sHzgCQnZROXno23q2tewbK8+dyBf6cLsefzEr4ExDYkKSrcaRci8dsNHNy/UGa9bHWySvmj419DbSCALhR19bEhkUSe85y3WWnZqKp5U/9dzoyngAP56Jrtm1Ddp++YmUjEGQV+JKZm4+ns32pfDYdv0DftuUHLoHtW3HlciSRV69jNJpY+/sm+jzQ08rm+rVozp0NRy0j6GjVpjkenu7s2XWgXA2ovnMOwLVtQ7Iux5EdGY9mNBO15iDeZWg1nfoYF79Yj1pOK7H/w12IWnPwpnoAunpNUOOj0RJjLfXe37vRt+lcrr0hqAfGo7srlbekcsiA8u7iAyRqmpYHoGlaoqZp0ZqmHdc07crtZiqEmCKEOFrw0fb3CtbVFUKECSG+F0KECyGWCyF6CSH2CyEuCCGCC+zeFUL8KIQ4WLD+2Tvh6N0kPisXr5q2hcteNW1JyMqzsnm+cwM2hsXQd+kexq8NYWr3ZpXKOy45BS+PolZCL3cX4pOtA6jGdf3Zfug4ADsOnSArJ5fUdEvgkp9v5MnJcxj2+gfsPHSC8ohPy8bbuWhScC9ne+LTs6xsXujdjg3HL9Hn/RW8/O1W3hhkqQyvJqYhBLy4dDNPfrKG73ZbB7wlEa4eaMkJhctqcgLC1bp1RPH2R+fjj8P0T3F4ZyH6VkEAmC+exXTuBE4Lf8Vp4S+YTv2NGm0d+N7A4O2OMaaocd0Yk4jB272UncsDnWmy+TPqLp6KwadoP5QaNjRe/xGN/vgPzn3KD0QVDw/UhKIHCDUxAcXd2h+dnz86vwCcP/wc548XYWhfbIJqGxucP12C88eLsOlsHYgWx9Pbg/joIp34mEQ8vctv5R7w1IMc2nWk3PSKsPd2JSu66Mtn2THJOHi7Wtm4t6yLg48b13dYn1d6+xq0GvcQJxb8flMdR29XMmKKdDJikqlZQgeg7YhePLv3I7q9+SQ73vkBgISzkTTs3Q6hU3AO8MSrZV2cfEuXb1n+ZMUkY19Cx61lXezL8adlJf1x8nIlLbpoYuv0mGScvdxK2XUa3pvX9nxMvzeGsv5diz8e9b1B0xj9wxu8/Of73Pd8xS3J8WlZeLsUu2ZdHIhPK3HN9uvAhmPh9HnvB17+egNvPNy1VD5bT1zigQoCSh+fWsRExRYux0bH4eNTq8J9u4EQghmzpjB7xs17hKrrnAOw9XElp1g55cQkY+tjXU7Orepi5+tO3Pby602/QZ24vqbiQPkGwsUdNaWo3tNSElFcym4VFm61UDy8MIeVr13taOqd+/1DyC7vu8tWYIYQIhzYDqzSNG1PVTIUQvTB8sH2YEAA64QQ9wGRQEPgMWAMcBRLV/u9wEDgLWBwQTatgU6AA3BcCLFB0zTrfo//MTafj2FAc19GtK/LyehUpm05xerhXVBE1T92MHn0I8z9aiXrdh6iXYuG1HJ3QSloIdz89ft4ubtyPTaBsdM/plEdPwJ8KvfuZikfTlxiYPtGjOjWipNX45i2cg+rJw3BrGocvxzH8lcGYWvQ8/xXG2nu50HHRlX48oqiQ/HyI2vOJISbJ45vf0zGW2NRHJ1RfGuTPuEJABym/gdT41aYw0/dlkza9qOkrNuLlm/CfWhfai94lUtPWV4RONvlGYxxydgEeNFwxWxywq6SHxl7kxzLRuh06Pz8SZs6AcXDE+f/LCT1xdFoWZmkjHwCNSkRxdsH53kfY7oSgRpTtdO9z5BeNG3TmHGPTKxSPuUiBEHvDGPfxNKvCrSdPIQzX2/GlJ1Xxoa3x/EftnP8h+00G9SZzuMHs3HyEkJ/2YN7Q19GrJ9FelQiUSEXUG/3iyhCEFyOP4GTh3D2Dvtz6MdtHPpxG20GdqHn+MH8OvlLFJ2OOkFN+GLgdIw5eYz9+W2iTl3mUkEr7O2wOeQiA4ObMKJ7ICevxDLt5x2snvIEimKpd05djcPWoKehT9mBeFUZ+cyT7Ny2l5jouKpnVp3nnBC0fO9pQiaU/569a9sGmHPyyAi7fmc0i2EI6o4pZN8/GnyV4s7MH/mPIgPKu4imaZlCiPZAV6AHsEoI8Yamad9XIds+Bb/jBcuOWALMSOCypmmnAIQQZ4AdmqZpQohTQN1ieazVNC0HyBFC7MISnK4pLiKEeI6CTzct+mg2Y0dUOMvAXaWWgy1xGbmFy3EZuXg6WHdprzkdxRcPW7pU2vi6kG9SSc3Jx82+4q5vLzdX4hKLWiTjklKp5Wb91F7LzYWP33gBgOycXLYfPI6To6Vry8vdYuvv7UmHlo05dzmyzICylrM9scVaN+LSsqnlZP0Zwz+OhrPomb4WH+p4kWcyk5qdi5ezPe3qe+PqYGmlvbdpAOeiEssNKLWURIRb0T4obp5oKdav6arJCZgvnQOzGS0hFjX2Ojovf3TN2mC+eA7yLMfbFHoEXaPmZQaUxtgkqxZHg49H4eCbG5hTMwr/J63chu+bo4q2j7O0luRfiyPz0GnsWtYvM6BUExNRPItabBQPT9Qka3/MiQmYzlv8UeNiMUddQ+fnjyk8rNBWjY3BGHoCfYNG5JcRUCbEJlLLt0inlo8HCbEJpew6dG3HyFeGMe6RiRjzyx/QURHZsSk4+Ba12Nj7uJEVW3QeGhxtcW3qT7/VlsE9dp7O9PpuEttHL8CjbUPq9A+mw9tPYuNkD6qGOc/Iue+3ldLJjE2hZrGWoZo+bmTElv0KA8C5dYfoM9vyfrBmVtk5a3lh2rDfZ5Byuey5jUv64+DjRnYJf1xK+HP/d5PYMXoBnm0bUreYP1qBP2Fl+JMel4JzsVZSJx830uKSS9ndIHT9QQbPHgNAWmwyV46EkZ1iOSfP7zqBb8t65QaUtZwdiE0tds2mZlHLucQ1e/gci56ztHS2qetNntFEalYObjUt9cPm4xfp167i9/RiYuLx8fMuXPb29SImJr6CLYpoH9SG4M7tGfHMkzg42GOwMZCVlc3cmZ+Usq2ucw4gNyYFu2LlZOfjRm6xlnK9oy01mwRw7+/TAajh6UzHZa9xeOSHpJ60DALyG9yZ639UrrsbQEtNQnEtqveEqwdqapnDEzB06EbuivIHG0puD9nlfZfRNM2sadpuTdPeAV4GqjqkTABzb7xbqWlaQ03TbgwJLP74qBZbVrF+eCj54lCpF4k0TftK07QOmqZ1+CeDSYAW3k5EpmYTlZaN0ayyJTyW7g2su4S8a9pyJNISzEQkZ5JnVnG1s7l53o3qcDUmnutxiRiNJjbvO0r34NZWNinpmYXvLi39bTMP3295ry49M4t8o7HQ5kTYJRoE+JSt4+9JZGI6UckZGE1mtpyMoFvz2lY2Pi6OHL5oCXQi4lLJN5pxdbClS2N/LsakkJNvwmRWORYRS30vl7JkADBHhKHz9kN4eoNOj6FTD4wh1t1GpmP70TezfOdXODqhePujJsSgJcWjb9oaFAV0OvRNW5fb5Z198gI16vliE+CFMOhxHdCV9G2HrWz0tYqCc+feweRetLQ26JwcEDaWU1LnWhOHDs3ILTGYp3Bfw8PQ+fqjeHmDXk+Nbj3JP7Tfyib/4D4MrQv8cXJG5xeAOSYa4ehoeRe0YL2heSvMkVfK1Ak7EYZ/PT98ArzRG/TcP6gn+7Za39AatWjI6/MmMXX0NFKTbv09zRsknojAqZ43jgGeKAYd9Qd14trWkMJ0Y0YOK1q9yOpOE1ndaSIJIZfYPnoBSaGX2TRkVuH6s0u3ELpwXbk39piTEbjW88a5QKfZgE5c3BZiZeNa16vwf4OegaRcsQT1elsbDHaWB7I697ZENalWg3kq8qdeGf6sLOHPjgr8KSuYBLh+8hIedb1x9fdEZ9DRZkBnzm2zHoziXrcoOGvSsy2JBf6E7wnFq0kABlsbFJ1CvY7NiL9QfutXi4BaRCakEpWUbrlmj1+kW8u6VjY+ro4cLsgjIi6FfJMZV0c7AFRVY+uJS/Rr26hcDYCTIaepV782AbX9MBj0DBryANs276pwmxuMf/4NOrbuTefAvsya8SG/rVxXZjAJ1XfOAaSeuIRDfW/sa3siDDr8BncmdmtROZkyctjc4nm2BU1gW9AEUkIuWgWTCIHvwE6Vfn8SwHzlPEotP4S7l6Xe69Ad08lDpewUrwCEvSPmiLOVzrtakF3ekooQQjQBVE3TbgxhC+QmA3EqwRZglhBieUELqB9wq80kg4QQc7F0eXcH7tggnynvzOPo8VBSU9O5f/DTvPTMcB4Z0LdKeeoVhak9mvLSHyGomsagFn40cHdk0cGLNK/lRPcGtZh0XxNmbT/LT8evIhDM7NMCUYnubr1Ox1vPPsGL732G2awyuFcXGtb25Yuf19G8YR16BLfh6OnzfPbjGoQQtGveiLeffxKAiOuxzFy0HEURqKrGmCH9rEaHW+sovDGoMy8u3YyqagwKakxDb1cWbTlGc38Pureow6SHgpm5eh/L/7K0mLz3RFeEEDjZ12D4fS0ZtnAtAksL5X3NapepA4CqkvPDQhymfGCZNmjvJtSoq9QYMgrz5fOYjh/EdOoo+lYdcJz3Lahmcld+hZaZjvHIXnTN2+I4ZykAptCjmI6XU6mbVa7PWEL9H95F6BSSf9lO7oVreE8aSnboRdK3H8Fz1ACcegeDyYwpLYPI1yw3uxqNAgiY8xKoGiiCuMW/lRodXuSPmczFn+A8+0PQKeRu3Yg58gr2w8dgCg8j//ABjMeOYNMuCJcly8CskvXNYrSMdPTNWuA4/jVLJSsUsn9ZbjU63Mods8rH0xay4OcP0Ck6/ly1icvhVxj72ijCToazb9sBxk1/HjsHW2YveQeAuKh4po62dOEv+v0Tajesjb29HX/8vYq5k//DkT1/l6mlmVUOTVtGn59ft0yzs2oPqeFRtH3tERJPXuZaiaDvdtHMKttnLOOxH15H6BRO/bKHpAtR3DvpEWJDL3NxewhtR/ah7r0tMBvN5KVnsWGSpcvT3sOJx3+YiqapZMSmsGHi4gp1Dk1bRu8Cfy4W+BP42iMk3UF/VLPKuhnfM+aHNxA6hb9/2U38hSh6TXyUqFMRnNseQueRfWh4T0vMJhM5aVn8Otmy37npWexbupFx62ajaRrnd53g/K7y36HT6xTeGNKVF7/603LNBjelobcbizYdoXmAJ91b1mPSwC7M/GUPy/eEgoD3nupZWO8ci4jG28UBf3enCn0ym81Mf30Oy1cvQdHpWLX8D8LDLvHam+M4efwM2zbvpk3bliz98ROcnZ3o3a87k94Yx/1dBleYb0mq65y7oRX61vd0XmEpp8gVu8k4H0XT1x8l9UQEsVsr1nLv3JSc6CSyIyvXUguAqpK78gvsJ8xBKAr5+7eixlylxoARmK+GYwq1BJeGoG4Y/67Sm2d3h3/BKG+hlTEFhOTOUNDdvRBwAUxYPmP0HJZ3G18HvIF4YKOmaRXOayKEuAJ00DQtUQgxAbhhnwk8jWU6oT81TWtZYP99wfJqIUTdG2lCiHeB+li6yT2A+ZqmfV2RtjExolpOEuOvH1eHDLruQ6pFRw0/Wi06+au3VIsOwOW9Djc3ugP4N0+rFp1Bobpq0QEYSxXeeb0FEqqpmaBW+TPu3FHOG6rvRjvji+CbG90BGg1fWi06s+wCq0XH7Xbfrb0NegxKurnRHcBpyZaqv4B/C+RHHLlj91mb+sHVuu83kC2UdxFN044BXcpI+qzgdyt51S32/1Pg0zLMWhazGVXs/5XiaUCopmkjbkVfIpFIJBLJ3UFObC6RSCQSiUQiqRr/gi5vGVD+l1Diqzg32K9p2i1/oL0iNE17907mJ5FIJBKJRCIDyv8SNE37Dvjun94PiUQikUgk1Yzs8pZIJBKJRCKRVIl/wcTmch5KiUQikUgkEkmVkC2UkptSXdP5GB67S5+xK0H+1+9Vi445ouyvitxphK2OvCt37rN1FVFd0/nkJlfPdD699WVPRH83ENU0zY5dNfWcGatpYhJHrfpmQFEPVe670VXF1/bufIqxJB7m6mn1MlKNZZSaX21a1Yrs8pZIJP801RVMSiQSieQu8S8Y5S27vCUSiUQikUgkVUK2UEokEolEIpH8k8gub4lEIpFIJBJJlZBd3hKJRCKRSCSS/+/IFkqJRCKRSCSSfxBN+9+fh1IGlBKJRCKRSCT/JPIdSsnNEEK8DQwFzIAKPA+8AnQAjMAR4HlN04xlbFv8+97NgfMF+WzWNO2Nu7/3N2f/lUT+sycMVdUY3NKfMUH1rNJj0nOYsfU0GXkmVE1j/D2N6FrPs8q60+YsYO/+I7i5urDmpy+rlJeufitseg0DRcF0Yg/GQxus0m3uH4pSpykAwlADYV+T7I9fQqndFJteQwvtFHcf8tYsxnwhpHK6LTpg++SLCEUh/6/N5G9eZZVe4/EX0DdtU7ATNVBqupAxYUil8jZ0CMbxpfEIRSFn0wZyVv1cyqbGfT2wHzEKNA1TxCUy5s4qTBP29rguXUb+gX1kfv5p+Trtg3F4waKTu3kDOb+W1rHp2gP7p4t0MudbdNz/3In5SgQA5oR4Mt57q1ydGp2CcJn0MkJRyFq3kYwfVpSysbu/G07PjgQNjBcukTzjfQA8PpmHTcvm5J08RdLkt8vVAGjYrTX93hmOolMIWbmbfYvXW6V3GHY/QSN6o5lV8rNzWf/mNyRciKLV4C7c89xDhXZezQJY0n8asWevlqvl1701wTOHIxSFCyt2c+qL9WXa1XkwiB5fT2D9A9NJCr1cuN7B153Buz/gxEe/c2bJxnJ1andvzX3vDkfoFM6u2M2xRWXrNHggiAe/msCq/tOJD72MrYsjDyx5hVpt6hP26172TP+hXA0A/+6t6fyeRef8it2cLMefug8G0furCfzx4HQSQy/jGVifrh88Y0kUELLgD65s/rtCrfrdWtPnHYvWiZW7OViinNoNu5/2xcpp45vfkHghCkWvo/8HY/FuWQ9Fr3Dqt30cWLSuXB1dwzbY9B8NQsF0bAfGv9Zapds8MBKlXgvLrhtsEA7OZM8ZXWRQww678QswnztK/oZvK/TpBp26BzN51ngURWHtig388Ln1NTX0uccZOLQ/ZpOZ1KRUZk36gNiouErl7dmjDS1njUDoFCKX7+Li52X77tM/mA7fTGRv37dJOxmB0Otos+A5nFvVReh0XP/1Ly4uXFvmtjfw6tGa1gVaV5bvIvzzss8H3/5BdPpmIjv7vk3qycsEDLmHRi/1L0x3bl6bnb3fJu1M2deSvk0QdqNeBkVH/s4N5K0tXTcYOnXH9jFL3WC+eonshbPRtwjEbsS4QhvFtzbZn87E+Pf+Cv2SlI8MKO8iQojOwENAO03T8oQQHoANsBWzOiEAACAASURBVBx4usDsZ2AssLjk9sW/7y2EuAL00DQtsRp2vVKYVY15u86xeEh7vBxtGbbiEN3qe9LA3bHQZumRCHo38ubxNgFcSspk/JoQuj5T9YBy8IO9GfrIQN6a9WHVMhICmz4jyF05Hy09GdtR72K6cBwtKbrQJH9HUYWub98LxasOAGpkGLnfzrAk2Dpg/8J8zJdPV1JXwW7oy2R9/AZaSiIOby/EdPIgakxkoUneL19yY4ZJQ89B6AIaVC5vRaHm+FdJnToZNTEB18+XkH9wP+bIogpZ5+eH3VPDSH11HFpmJsLFxSoL+1HPYDwVelMdx3GvkvaWRcfl0yXkH7bWUXz9sH9iGGmTC3Sci+nk55H68thK+eM6ZQIJ46dgjk+g1veLyfnrAKbLRTr6AD9qjhxK/LOvoGVkorgW6WT8tApha4vDww+VlXshQhE8OGsUPw6bS3psMs+um8X57SEkXIgqtDm19gB/L98BQJNe7eg7bRg/jZzPqTUHOLXGMil2rSYBPPn1xAqDSaEIOr4/kq1PzSM7JpmHNs4kcusx0i5EW9npHWxp9kxfEkIulsoj6N1hRO06eVOfus8eyZqh88iMSeaJP2cSse0YKSV0DA62tHmmL7HFdEx5Rg59uBr3Jv64N/G/qc49s0eyceg8smKSGbxhJle3HiO1DJ2WY/oSV0wnOew6fzw4Hc2sYlfLhUe2vs/VbSFo5rJbbIQi6DdrFD8XlNOYdbO4sD2ExGLldHrtAUIKyqlRr3b0mjaMlSPn06x/R3Q2Br7u+wZ6Wxue3z6fM+sOkHa9jGpVCGwGPEPu97PR0pOwfWEuprC/0RKKdPI3LSv8r+/YD8XH+oHa5v4nUK+eq/DYFUdRFF6f8yovPzmZ+JgElm1cwl9b9nP5QtG5dP70BUY+8Bx5OXk8MmIQ46e/wNsvVOJjDYqg1dzRHHp8DjkxSXTd/D6xW4+RGR5lZaZzsKXe2H6kHLtQuM53QEcUGz17ekxFZ2dD970fErVmPznXyrkdKYI2c0ez7/G55MQk0WPzbGK2hpBRQkvvYEvDsf1ILqZ17ff9XPvdEtQ5NQ2g0/eTyg0mEQp2YyaQ9f4U1KQEas79EuPfB1CjitVB3n7UGDyUzBnj0bIyEU6WusF05gQZU5+1ZONQk5qf/YQxtOIHmbuKHJQjuQk+QKKmaXkAmqYlapoWrWnaRq0ALC2UFdfWJRBCTBFCHBVChAoh3itYV1cIESaE+F4IES6EWC6E6CWE2C+EuCCECC6we1cI8aMQ4mDB+mdv17nTsWkEONvj72yPQafQt7E3uy/FW+8rgqx8yydCMvNMeDrWuF05KzoEtsLZqWaV81F866OmxKGlJoBqxnzuMPrG7cq11zfvhOnsodLrmwZhjggFU+W+4qCr1wQ1IRotMRbMJoxH96AP7FKuvSGoO8YjuyuVt75JM8zRUaixMWAykbt7JzZd7rWysX1gALnr/kDLzARAS00t2r5RYxQXV/KPHa1Yp7G1Tt6endh0KqHTbwA564vppKWWlVWF2DRviul6FOZoi07Otp3Y3Wd9rBwG9Sdz9Vq0DIuOmlKkk/f3cbTs7Jvq+AU2IPlKHCnXEjAbzZxef4gmvdtb2eRl5hT+N9jXQCsjn1YDO3N6/cEKtTzaNiDjShyZkQmoRjOX1x6idt/2pezavf4opxf9iTnXugOjdt/2ZEYmkHo+qtQ2xfEKbEDqlTjSC3TC1x2ifp/SOp1ee5SQRX9iyivSMeXkEXM03GpdeXgGNiD9ShwZBTqX1h6iThk67ac8yslFf2Iulqc5N78weNTXMKCVdVCL4VtQTqnXLFpn1x+icYlyyi9RTjfQNA0b+xoInYLB1gaz0UReRg5lofg3RE2KRUuJB7MZ86kD6JsFlbtf+tb3YDq1r2h733oIR2fMFysO+ovTom0zrl+JIjoyBpPRxNa1O7mvr/U1dezAcfJyLI+ap0LOUsuncg/orm0bknU5luzIeDSjmeg1B/Hu26GUXdOpj3Pxi/VWZaRpoCs4boqtDWq+CVM5xw3ArW1Dsi7HFWpdX3MQnzLO7+ZTHyO8hFZxAh7uwvU15V9LuoZNUeOiUeNjwGwi/8BODEH3WNnY3P8Q+VvXoGUV1EHppesgQ6dumE4cgfx/8CMRmnrnfv8QMqC8u2wFAgoCvEVCiG7FE4UQBmA4sLmyGQoh+gCNgGAgEGgvhLivILkh8BHQtOA3FLgXeA0o3p/YGugJdAZmCCF8b8M34rNy8appW7jsVdOWhCzrC/L5zg3YGBZD36V7GL82hKndm92O1F1DOLqipScXLmsZyYiarmXbOrkjXDxRr54tlaZv1rHMQLNcXRcP1OSEIt2UBBSXsj/HJtxqoXh4Yw47Uam8FQ8PzAlFgb2amIDOw8PKRufvj84vAJdPPsfls0UYOgQXiAkcnn+JrK9KNZiXqaOW0FHcS+j4WXScP/wc548XYWgfXJRoY4Pzp0tw/ngRNp2tb5pWedTywBxXpGOOT0TnaX0T1df2x1DbH8+vPsPzm8+p0an8G395OHm7kR6TVLicHpOMk3fpcyFoRG9e2buA3m8+xaZ3lpVKbzGgE6fXVhxQ2nu7khVddN5lxSRjX0LLrWVd7H3cuL7Dutz19jVoOe4hTiz4/aY+OXi7kllMJzMmGccSOp4t6+Lo68aVnZU7v8rU8XElM6aYP7HJOPhY67gX6FwrQ8ezbQMe3TGPR7bPZf+b35XbOglQ09uNjBLlVLOMcmo/ojcv7V3A/W8+xZaCcgrbeIT87DwmHP2Clw9+yuGvNpCbllWmjnByQ0sr0tHSkhA13cq2dfZAuNZCjSjooRACm34jyN/8Y7l+lIWntwdx0UXnenxMAp4+HuXaD3zqQQ7uPFypvG19XMmJLvInNyYJ2xJl5NyqLna+bsRvP261PubPw5iz8+gduphexxZyafGfGFPLPm5laeXEJGPnY33sXFrVxc7Xndjt5Z93foM6cX1N+Z/DVNw8UJOK1UFJCSiuJeogH38UnwAcZy7EcfYX6NuUrhsMXXqQv39HuTqSyiEDyruIpmmZQHvgOSABWCWEGFXMZBGwV9O0v24h2z4Fv+NACJbAsVFB2mVN005pmqYCZ4AdBa2gp4C6xfJYq2laTkH3+S4swakVQojnhBB/CyH+/nZfJbtxy2Dz+RgGNPdly9huLBzUjmlbTqHerAnivxR9846Yw45SsglFODij1PLHHHH7x6kiDMHdMYX8dWefPHU6dH7+pE6eQPqcmdScOAXh4IjtwMHkHzmMmphw8zwqgSjQSZs6gYx5M3GcYNEBSBn5BGkTnifjg1k4PP8yis9tPdcU+qMP8CfhxYkkT5uN61uTEY4Od8SHkhz9YRuf3TeJ7fNWct/4wVZpfoENMObkEx9+vWoiQhD8zjD+nln6ndTAyUM4+/VmTNl3oDVFCO6dMYx9s0rr3FGEoNM7wzhUhj8ACccvsfr+N1jTfwZtXh6AroahypLHftjGovsmsXPeSu4tKCffwAZoqspnwS/zxb0T6fjsg7gEVP0VHH3rezCfOVRYN+iD+2AOP271sHqn6TekN81aN+HHxSvvTIZC0Py94Zx576dSSS5tG6CZVba1eYkdwRNo8EJ/7GvXqpJWq/ee5lQZWjdwbdsAc04e6WFVvJYUHYq3H5nvvUr2p7Owf+41hH1R3SBc3NDVro/pZMU9Mncd1Xznfv8Q8h3Ku4xmmQtgN7BbCHEKGAl8L4R4B/DEMkjnVhDAXE3TllitFKIuUPwOoxZbVrEu65IRXakIT9O0r4CvALIXjy8zAqzlYEtcRm7hclxGLp4O1l3aa05H8cXDlq6ONr4u5JtUUnPycbO/M13fVUXLTEE4FT05i5puaBkpZdrqmnUif2vpgQm6ZsGYzofc0oWspSaiuBXdyISrJ2pqUpm2hqDu5P78eaXzVhMT0XkWVfaKhyfmxMQSNgkYw86B2YwaG4s56ho6P38MzVpgaNUauwGDEHZ2oDeg5eSQ9c1XZeooJXTUJGsdc2ICpvMFOnFFOqbwsEJbNTYGY+gJ9A0akR9j/c4dFLRIehXp6Gp5YE5IKGGTQP6ZMEvXZEwspsjr6AP8MZ47X+njlh6bjJNPUSuxk48b6bFlnwsAp9cdpP/s0UDRpdhyQGdOryu/ReUG2bEpOPgWnXcOPm5kF9MyONri0tSffqstg4jsPJ25/7tJ7Bi9AM+2DanbP5gObz+JjZM9mqphzjMS9v22UjpZsSk4FtNx9HEjs5iOjaMt7k38GfKLRcfe05n+305iw5gFxBcbAHQzsmJScCzWAuXg7UZWjLU/bk38eejXIn/6fDuJrWMWkFhMJ/ViNKasXFyb+FutL05GbDI1S5RTRgXldGbdQfoVlFOLQV24tDsU1WQmOymd68fC8Wldn9RrpR+gtPRkhHORjnB2R8soO0DUtepC/vpvipYDGqPUaYY+uA/CxhZ0erT8XIzbKg7cE2IT8fItOtdr+XiSEFP6PcWgru0ZPWE4Lwx5BWP+zV9JAMiNScHOt8gfWx93couVkd7RFqcmAXT53fJeeA1PZ4KXvcaRkR/iN+QeEnadRDOZyU9MJ/loOM6B9cmOjC+lU5aWnY8bOcVasG9odf19umVfPJ3pvOw1Do78kNSTlnL3H9yZ639U3NKvJieiuBerg9w9UVNK1HXJCZgvFtRBCbGYY66j+PhjvmSpGwyde2A8sg/M//C0Pf+CUd6yhfIuIoRoIoRoVGxVIHBVCDEW6As8VdCaeCtsAcYIIRwLNPyEELf6qDhICGErhHAHugO39WjWwtuJyNRsotKyMZpVtoTH0r2B9a5417TlSKQlUIpIziTPrOJqZ3M7cncFNfoyiqsXwtkDFB26Zh0xXTheyk64+SBs7VGjSg+OsLxXWXHFVxLzlfMotfwQHt6g02MI6obpZOk8FO8AhL0j5kulu9nLw3Q+DJ2fP4q3N+j12HbvSf5B65GLefv3YdM60OKbkzM6vwDMMdFkzJtN8rDHSR7+JJlfLSZv+5Yyg0kAU3gYOl9/FC+LTo1uPck/ZK2Tf3AfhjJ0hKMjGAyF6w3NW2GOvFKmTv65MPQBfuh8LDp2vXuSs9f6WOXs2U+NdpYR8YqzE/ra/pijYip9zACiT0bgXs8blwBPdAYdLQd04vy2Y1Y2bnW9Cv836hlI8pXYwmUhBC0e6sjpdTc/FxJPROBUzxvHAE8Ug456gzpxbWvR7ADGjBxWtnqR1Z0msrrTRBJCLrFj9AKSQi+zaciswvVnl24hdOG6MoNJgLiTEbjU9capQKfxwE5c3lakk5+Rw9I2L7Ksy0SWdZlI7PFLtxxMAiSctPhTs0CnwaBORG6z9ufH1i+ysvNEVnaeSPzxS4XBZM0AT4TOcity9HPHuYEvGWUEeDeIPhmBWz1vnAu0mg/oRHiJcnItUU4pBeWUHpVI3S7NATDY1cC3bSOSLpV+iAFQoy6huPsgXDwtLfqtumAKKz1oQ3j4ImwdUK+FF67LW72QnI9eImfBy+Rv+RHTib03DSYBzp4II6CeP74B3ugNevoM6slfW62vqcYtG/HmB5N5bdSbpCRV/p3k1BOXcKjvjV1tT4RBh+/gzsRuLTpupowctrR4jh1Br7Aj6BVSQi5yZOSHpJ2MICcqEfd7LaPZdfY1cG3fkMwLZR83gJQTl3Cs7419gZb/4M7ElNDa0OJ5tgRNYEvQBJJDLloFkwiB/8BOXKvg/UkA86UwFG8/FE9LPWrTpSfGv60f6IxH96FvXlAH1XRC5+OPGldUN9jc0xPjAdndfSeQLZR3F0dgoRDCBTABF7F0f8cCV4GDQgiA3zVNm1mZDDVN2yqEaFZs20wsI8Zv5fEqFEtXtwcwS9O08muGCtArClN7NOWlP0JQNY1BLfxo4O7IooMXaV7Lie4NajHpvibM2n6Wn45fRSCY2acFBftdJaa8M4+jx0NJTU3n/sFP89Izw3lkQN9bz0hTyd/2I7ZPTrFMDRK6Fy0xCkPXh1FjrmC+aAku9c07YjpX+l0l4eyBcHJHjax8SxgAqkruz59j/+ochFDI378FNfoqNQaOwHw1HNNJy/uYhqDuGI/uvsW8zWR+/gnOcz+0TOezZSPmq1ewHzkGU3gY+QcPYPz7CDbtg3BdugxUlayvF6NlpN+6zuJPcJ79IegUcrduxBx5BfvhBTqHD2A8dgSbdkG4LFkGZpWsbyw6+mYtcBz/muWpXChk/7LcanS4FWaV1A8X4vHZBwhFR9b6TZguX8HpuVHknwsn968D5B06im3HDnit/BbMKmkLl6CmW/zxXPIJ+jq1Uezs8F6/ipTZ/yHvcOnAQDWrbJzxPcN/mIrQKRz/ZQ8JF6LoMekRokMvc357CMEj+1D/3paoRjM56Vn8Maloyqo6HZuSHp1MSgXB0A00s8qhacvo/fPrCEXh4qo9pIZHEfjaIySdvMy1bZWbeqoyOnumL2PgT6+j6BTOrtpDcngUHSc/QnzoZavgsixGHvgYm5p2KAY99ft2YM2weaVGiN/QOTB9GQ8st/hzftUeUsKjaP/aIyScvGwVXJbEK7gxfV8agGoyo6ka+9/+nryUzAp92jLje576YSqKTuHkL3tIvBDFfZMeISb0Mhe2h9BhZB/qFSundQXl9PcP2xjw4fM8t+0DEILQX/cQH3atbCFVJf/Pb7Ed+bZlSrGQXWjx1zH0fBw1+hLmMEuApG91D6ZTN2+Vrgxms5n/vP0Jn/38IYpOYf3KjUSEX+G5KWM4dzKMv7Ye4JXpL2DnYMfcrywju2Oj4nltVPlTbhU/bqff+p5OK95E6BSurdhN5vnrNHn9UVJPXCZu67Fyt73y7VYCP32B7nv+AwKurdxDxrnIcu01s8qJt77nnhVvIHQKV1fsJuN8FM1ef5TUExHEbK34vPPo3JSc6KRyW0ALUVVyvv0Mh7fmg6KQv3sT6vUr2D42GlPEeUzHDmA6eRR96yBqfvSdxX75l2iZlrpB8fRCcffEdLbyA6fuGv+CUd5C+x99n01yewgh3gUyNU2r9Hw75XV532kMj02sDhnyv67EFBt3AHPErbWQ3S55V6pvZKKopkfQ3GRdtegsjfWpFh2AuqaqP0hVhoxq6neyraZbR7yu+u5Rr46oXPdxVenxTeXmjawq09UqvJd8CxipnnMboGe36qlXXVbtqj6ngNyDK+7YiW7b+alq3fcbyC5viUQikUgkEkmVkF3e/yWU+CrODfZrmjauLPvbRdO0d+9kfhKJRCKRSKrIv6DLWwaU/yUU/yqORCKRSCSS/0f8CwJK2eUtkUgkEolEIqkSsoVSIpFIJBKJ5B/EMmX1/zYyoJRIJBKJRCL5J/kXdHnLgFJyU3Tdh1SLTnVN52Pz7DvVomM6ub1adJIn/1otOgCXYsr+lvGdpk1g7M2N7gBX43JvbnSH0Oltb250B0gT1XNj8lGrZ2qnGGGqFh0ApWH9atE5m1o9n/m76BFQLTr+xuqb2smc/b8feP1bkQGlRCKRSCQSyT/Jv+DTizKglEgkEolEIvkn+Rd0ectR3hKJRCKRSCSSKiFbKCUSiUQikUj+SWSXt0QikUgkEomkSsgub4lEIpFIJBLJ/3dkC6XkltkXcoYPlv6CqqoM6X0PzzzSzyo9Oj6JGQt/ICU9E2dHe+ZMHIO3hysAgUNepFFtPwC8Pd1Y+PZL5ero6rfCptcwUBRMJ/ZgPLTBKt3m/qEodZoCIAw1EPY1yf74JZTaTbHpNbTQTnH3IW/NYswXQm7L32lzFrB3/xHcXF1Y89OXt5UHwP4zl5n/6y5UTePhLi0Z07ejVXpMcjrTl20mIycXVdV4ZXBXurasj9FkZtbP2zgbGYciBFMe60FQ44qnA7Hr0gG3118CRSHzj02kfbfKKt1xYB9cX30Wc0ISAOkr15L5xyYAXCeMxa5rMACpXy0ne+ueSvnn1qMNjWePQugUopfv5OrCtVbpPk90o+GMp8mLTQbg+rdbiF6+s1J5GzoE4/DCeIROIXfTBnJ++bmUjc19PbB/ehSgYYq4ROa8WYVpwt4el6+WkX9wH1lffFopTYCW3QIZOmMMik5h76odbFz8h1V692F9uH94P1RVJTcrl2Vvfkn0xeuVyrtBt9b0fWc4QqdwfOVuDixeb5Xebtj9BI3ojWpWyc/OZcOb35B4IQpFr+OhD8bi07Ieil4h9Ld97F+0rlydJt3aMGjGCBSdwuFVu9i12Nq287BedBneG1VVyc/KZfWbS4m7GFWY7uLrzpRtH7L1k9Xs+XpDyezLpG631vR41+Lb6ZW7ObJofZl2jR4IYuCSCfz00HTiQi9XKm+AZt3a8OiMUSg6hQOrdrJtsfW5du+wXtw3vC+qqpKXlcuKN78i9mIUddo04Km5z1mMhGDjJ78SuqX8KXz2X4pj/rZQyzXbpg5jujSxSo9Jy2b6+mNk5Bkt12yPFnRt6M3By/F8tusMRrOKQacwsWdLgut6Wm3bq/d9zP/PO+h0Csu+X8WCj6zrFhsbG75e+hGBbVuSnJzKyOEvExkZhcFg4LPP36dd21aoqsbrU97jr78OA2AwGFjw8Xvc27UTmqpyfsGfXNxUtn91urWm+7vDUQrK6Gg5ZdTwgSAGLJnAz7dYRl49WtN2puUciPh5N+c/Lzt/v/5BdFn6Ktv7TSPlpCV/52YBtJ//DPqadqBqbH9gOmqescztDe2CcXh2PCgKuds2kLu6jLrh3h7YPTUK0DBfvkTmh5a6wW3NTsxXIwBQE+LJmP1Wpf2748gub8nNEEK8DQwFzIAKPA88B3QABBAOjNI0LbOcbR8rWGwFnCr4/62maZ/d5V0vE7NZZc6SFXz13gS83F15aspcuge3pkGAb6HNR9//xoAenRjUszOHQ8P47Mc1zJk4GoAaNjb8+sm0mwsJgU2fEeSunI+WnoztqHcxXTiOlhRdaJK/o6ji0LfvheJVBwA1Mozcb2dYEmwdsH9hPubLp2/b58EP9mboIwN5a9aHt52HWVWZu2oHX77yKF4uNRn2wXK6tW5IAx/3QpuvNx2iT/vGPH5fIJdiknj5i9/ZNLs+v+0PBWD1tJEkZ2Qz7vPfWD71aRRFlC2mKLi9OZ64F6ZiikvEd/nnZO85iDEi0sosa+sekud9brXOrmswNs0aEv3ECwiDDd7ffEjO/qNoWdkVO6gImswbw/HH3ycvOomgLXNJ3PI3WeFRVmZxaw8Q/tYtfrJeUXAc9yppb05GTUzAZeES8g/txxx5tcjE1w/7J4aRNmkcWmYmwtnFKgv7Ec9gPB16S7JCURg+81k+fHomybFJzFj3ASe2HbUKGA+t/Yvdy7cCENirA09OH8WCkbMrkbeg36xRLB82l/TYZMaum0X49hASLxQdr9NrDxCyfAcAjXu1o/e0YawYOZ/m/TuitzGwpO8b6G1teHH7fE6vO0Da9cQydR6eOZqvnp5DWmwSE9a9z9ltx6wCxpC1+zm43DJnavNe7RkwfThLR84rTB84bThhu0/cwnET3D97JKuHzSMjJplh62dycdsxki9EW9kZHGxpN6Yv0SEXK533jfwfnzmGz59+n9TYJKasm8upbX8TW8ynv9fuZ1+BT616tWfI9BEsGjmX6PPXmD/gTVSzipOnC29ums/p7cdQzaVv5mZVY+6Wk3z51D14Odkx7LtddGvkQwNPp0Kbr/efp08zPx5vX59LCem8/MtBNjX0xtXOhk8f60StmnZcjE/nxZX72fbKA4XbKYrCgo9nMvCh4URFxbL3r7Vs3LCdsLCiYzFy1OOkpqbRplUPHn30IWbNfoORI8YzesyTAHQMfgBPT3d+X/Md9907CE3TeH3qOBISkmjbpidCCOY37FPuMew5eyS/F5TR0PUzuVROGbUd05eYWywjFEG7OaPY+8RcsmOS6bVpFtFbQ8goUR/oHWxpNLYfSceK8hc6heDPX+LI+MWknY3ExtUR1VjOXKSKgsMLr5I+fTJqUgLOC5ZgPLwf87VidYOPH3aPDiP99XFoWSXqhvw80iaMvTXf7hayy1tSEUKIzsBDQDtN01oDvYBrwERN09oUrIsEXi5re03T3tc0LVDTtEAg58b/fyqYBDh94Qq1fWrh7+2JwaCn371B7DpsfaOOuBZDx1aWJ/ngVk3YdeTkLesovvVRU+LQUhNANWM+dxh943bl2uubd8J09lDp9U2DMEeEgin/lvfhBh0CW+HsVPO2twc4fSWWAE8X/D1cMOh19G3fhN0nrStpIQRZuZb9zMzJw9PZAYCImCSCm9QGwK2mPTXtbTkTWf7E3zVaNsF0LRpTVCyYTGRt2Y199y6V2k9D/TrkHjsFZhUtN5f88Ajs7ulw0+2c2jUk53IcuVfj0Yxm4tYcwKNfUKU0b4a+STPM0VGosTFgMpG3eyc2ne+1srF9YAA56/9Ay7Q8l2lpqYVpuoaNUVxdMR67tcmk6wc2JP5qLAnX4jAbTRxZv4+2fax9ys3MKfxfw94WTavcBM++gQ1IuRJH6rUEVKOZM+sP0aR3eyub/GJ5G+xrFP7XNA2DfQ2ETsFga4PZaCIvI4eyqB3YkKSrsSRfi8dsNHNi/UFa9LEuz7xiOjb2NaCYDy36dCD5WjxxFyrX6grgHdiA1CtxpEVafDu//hAN+7QvZXfPa49yZPGfmMtpeSqPuoENSbwaR1KBTyHrD9C6gnKxsa9RWC7G3PzC4NFQw1BheZ2OTibA1QF/VwcMOoW+zf3ZfSHGykbA/7F33uFVVNvDfveck957p/feu1KEoCJFUUQRULGggApY6CogYtdLsaEiXECwICC9BaUJBAi9l4QkJ723U2Z/f5yQ5KSQ0OL9+c37PHlyZvaavWbNntmzZu1GjtHq7GQXmPBztU5e3yjQE383JwDq+rlRYLZgNBcvrdeuXUsuXbzKlSsxmEwmfvllKHW9YAAAIABJREFUHf0e6mOTd79+fVj2318BWL16Iz0Kn+FGjeqzK2IfAElJKWSkZ9KmbQsAho94jI8/WghY75P8tDJxCqD8MqpbThl1ef1RDn35B+abLCPv1nXJvpJATnQS0mQhZs1+QvqWzb/pW49yZv46LAXF9XNA9+ZknI4m45T1A9iYlg1q+eWkr98YS3wsakJh3fDnDuw6lqob+vYnf8NqZE7ZukHjzqI5lHeXICBZSlkAIKVMllLGSSkzAYQQAnACqrzMgBBCJ4T4SAhxUAhxTAjxYuH+HkKIXUKINUKIS0KIuUKIYUKIA0KI40KIuoVyi4UQXwkhDgkhzgkhHroZgxJS0wgobL4GCPDxJDE1zUamQa1Qtu0/AsD2/UfJycsnPdP6MBuNJoZOnMOwNz9gx/6Kox7C1QuZmVq0LbNSEW5e5cu6+yA8/VCvniqTpm/csVxHs7pJTM8m0KvYKQ3wciMxw7ayH92vM+sPnCZ8yteMXfAbkx6/D4AGof5EHLuI2aISm5zBqegEEtKyKtSl8/fFbEgq2jYnJKPz9y0j53xfN4JXfY3fR9PRBVib46wOZHuEowOKpzuO7VuhD/Cv1D7HQG/y41KKtgviUnAILFte/g91pMPOD2m+aDwOwT5l0stD8fFFTUos2laTk1B8be3RhYaiCwnD49P5eHy+ELt21iZ7hMD1hZfJ+fbLKukqiVeAN6lxxVG/1PhUvALKnnOv4ffzwa4FDJk0nOXvfF+lvN0DvcmML75emfGpuJVzvdqN6MOYPz/lvslPsPntHwE4veEAptwCxh9cwCv7vmDfN+vJz8gpV49HgBfpJcolPT4Fj4CyeroM78OkXZ/z0KQn+f0dqx57Zwd6ju7Pli9+rZJN13EN9CIrrvjZzYpPxbWUTv9mtXAL8ubyjqpHPq/jEeBNWgmb0iqw6d7h4by96wsGTRrGL+8sLtpfs1U9pm75mCmbP+anaYvKjU4CJGblE+juVLQd4OZEYpbtykqj723M+hMxhM/byNhV+5gU3qJMPtvOxNE40BN7ffHKQsHBgVyLLXZOY2MNBAcH2hwXHBxQJGOxWMjIzMLHx4vjx0/Tr19vdDodNWuG0qp1c0JDgvDwsNYv02dMYPfedSz97wKcfd0pj9JllH2Hy8gp0Jvc2OIyyo1PxanU/e3ZvBbOwT4Yttvm71Y3CCTcs+Item+ZTcOXK35FKT6+qMkl6oaUJHQ+peqGkFB0wWG4fzAf948WYtemQ3GivT0en35t3d/J1hGtdlT1zv39Q2gO5d1lCxBW6LgtFEJ0v54ghPgBMACNgHk3kecoIENK2R5oDzwvhKhdmNYSGA00BoYDDaSUHYBFwLgSedQCOgD9gK+EEGXWhBNCvFDodB5atOqPmzg9mPjMYCJPnmfI+Pc4dPIc/j6eKIr1Vtv07Xv89MkUPpjwLB9+t4qY+KRKcqscfZOOWM4ctImsAAgXDxT/UCyXbr25uzrZdOgMAzo1ZcucF5k/5hGmLd6AqkoGdW5GgJcrT37wXz76ZSct6wSjiAqau6tI7q59XHtwOHFDXiRv/2F8Z70BQP6+SPJ2HyDoxy/wmzuFgmOnQLVUklvVSNoSyZ52YznQ801Sdx2nybyK+8/eLEKnQxcSSsYbr5L1/kxcX3sD4eKKY/9BGA/+jZp8+/dZRexYuom3uo/h57lL6T9u8B3N+9CSrSy4dwI75v5Et3GDAGt0U1VVPu8wlnndxtP5+QfxDPOrJKcbs3fpVuZ2f431c5fTe9zDAIS/9ih/fbcRY27BbdthgxD0mD6MXbPL9nW7k/y5dAvvdn+VNXOXc/+44uVjrx69wHvhr/PhgCmEvzQIvYPdLevYdDKGAS1qsGXcA8wf0plpayNRS9RDF5Iy+WLnSaY90Oq2bCnJkh9XERsbz1971vLBRzP4++9ILKoFvV5PaGgwf+8/TLcu/fn778PcO+3JyjMsDyG4d/ow/rxbZSQELd8ZRtQ7y8om6RR8OzTg7zEL2DlwJiEPtMO/W9Nb16XToQsOJXPKq2R/PBOXsda6ASD92cfJmPAi2R/PwuW5sSiBwZVkdheR6p37+4fQ+lDeRaSU2UKItsA9QE9gpRBikpRysZTyGSGEDqsz+ThQ1Y5l4UALIcSjhdseQH3ACByUUsYDCCEuYnVowdr3smeJPFZJKVXgvBDiElan1uYzUUr5DfANQMHpnUU1ZIC3FwnJxRHJhJR0/L1Lfdl6e/LZpNEA5Obls23fEdxdna3H+1hlQwP9aNesAacvRxMWVPZlKLPTEO7F60YLN29kVloZOQBd404YtywpZ38HzGcP3zGH6Hbw93TFUCKqmJCWhb+Hq43M6r0nWDjG+uJrWSeYApOF9Jw8vN2ceePR4uIb8dFyagZUvKa2JTEZfWDxNdUH+GJJtO1fp2YUn0v26o14v/Z80XbGouVkLLK+SHzfn4zpqm2/p/LIN6TiWCLi6BDsQ4HBtrzMJZrfYpdtp96MYZXmC6CmJKP4FUdJFV8/1GRbeyzJSZjPnAaLBTXBgOVaDLqQUPSNm2LXrAWODw1EODmB3g6Zl0fu999UqjctIRXv4OJoh3eQN2kJKRXK/71uD8Nnv1AlmzINqbiX6D/rHuRNlqH8+xvgxNp9PDD7GeBrmg3swsWIY6hmC7kpmcREniO4RR3SY8o6zRkJaXiWKBfPIB8yEirWc3TdPh6ZPQqwNpe3eLAj/SY/iZO7M1KVmAtM7FmypcLjAbINabgFF9+fbkHeZJfQae/qiG/DUIasnAqAi58Hg76bwO+jPq3SoI+MhFS8StjkVYlNkev28vjssv3kEi7GUpCbT3CDMKKPXyqT7u/miCGzuOk8ISsPfzfbb+/VUVdZONTaFN0y1IcCi4X0XCPeLg4kZOYx4df9zOrfljAv22c9Ls5AaEhQ0XZISCBxcYZSMgmEhgQRF2tAp9Ph4e5GSorVzklvFffT3bbjFy6cv0xKSho5ObmsWbPJem6/beCNUU+Xe01Kl5FrBWX0aIkyGvDdBNZWsYzyDKk4hxSXkXOQN3kl7m+9qyMejcLo8Zu1P72jnwddF09kz9OfkBefStL+MxhTrfVF/I6jeDavReLuk2X0qCnJKL4l6gYfPywppeq65CTMZ4vrBjUuBiU4FMv5M6ipVlk1IR7TiaPo69THaLDtR6pRdbQI5V1GSmmRUkZIKd/G2ldycMk04KeS+6qAAMaV6E9ZW0p5vYYvGUpQS2yr2H48lG5ir3KTe9P6Nbkan8i1hGRMJjObdh+kRwfbZp60zGzUwrD7ol838fB91go3MzsHo8lUJHP0zEXqhgVRHmrcZRSvAISHLyg6dI07Yj5/pIyc8A5CODqjxpbtNG7tV7mvqqbdVZrWDCQ6MZ3Y5AxMZgubI8/SvUVdG5kgLzf+PmvtN3QpPgWj2YyXqxN5RhN5hX2Y9p2+gl6n2AzmKU3BybPoa4SgDw4EvR6Xvj3I3WV7HXS+xS8T5+6dMV0uHLCjKCiFTWd29WtjX782efsOVWpf1pGLONcJxLGGH8JOR8CgLiRvtj3O3r+4M7xf33bknK/cUQUwnz2DLiQUJcBqj0OPXhj377GRMe7djV0LaxRIuHugCw3DEh9H9gezSRs+hLSRQ8n59ksKtm+ukjMJcDnqAv61gvAN9Udnp6dD/24c2WprU0Ct4vu3Ra+2JFyJL51NucRFXcK7diCeYX4odjqa9u/Eua2RNjLetQKKftfv1YrUK1aHIzM2mVpdmgBg5+RASOv6JF8s/yUYE3UR31qBeIf6obPT0ap/Z06W0uNbq7iptXGv1iQX6lk45F3mdHuFOd1e4a/vN7J9we+VOpMAhqhLeNYOxL3Qtob9O3Fxa/EMC8asPBa2eolFXcezqOt44o9crLIzCXA16iJ+tQLxKbSpTf8uHCtVLn4lbGraqzVJheXiE+qHorO+9rxCfAmsG0zKtfKj102DvYhOyyY2PQeTRWXzqWt0r29bXwW5O/P3Fevxl5IzMZpVvJztycw3Mm7VXl7t0ZTWYWWf1cjIY9StV4uaNUOxs7Pj0Uf7s2H9NhuZDRu2Mewp66vh4YcfYFfhM+zk5Iizs7UpvmevbljMlqLBPBs3bOfeezsB0KNnF1IqeMYMUZfwKlVGl0qV0VetXuL7ruP5vrCMqupMAqQdvYRr7UCcw6z1QdjATsRtLr7vzFl5rG06mg0dXmNDh9dIOXyBPU9/QlrUZQwRx/BoHIbOyR6hU/Dr1JjMc+XbYT5/Bl1wibrh3l6YDpSqG/bvRt+8uG5QgsNQDXHWKKXermi/XePmWGKuVMm+u8K/oMlbi1DeRYQQDQFVSnm+cFcrIFoIUU9KeaGwD+UA4MxNZLsZeEkIsUNKaRJCNACq9mYu5jEhxI9AbaAOcLaqB+p1OqY8/zgvvfsfLBaVQb27UK9GMAuWr6VJvZr07NCSgyfO8p+lvyOEoE2T+kx90Toq8dI1AzMXLkNRBKoqefaR+21Gh9sgVYxbl+I49A0QCuZjfyKTY7G752HU+CtYLlidS32TjphP/13mcOHhi3D3QY2usmkV8sbbczl45Bjp6ZncN+gpXh41nMH9+95UHnqdwqTHe/HS/F9RVZWBnZtRL9iXhev20KRmAD1a1GPC4B7MXLaFZTsOg4B3h9+PEILUrFxenvcrihD4e7oye+SDN1ZmUUmdO5+AL9+3Thu0ZjOmi1fxfGkkBafOkbdrH25PDMK5R2cwW7BkZpE84yMAhF5H4PefASBzckme+gFU0MesJNKicnby97T+aQroFOJXRJBz9hp13nyMzKhLJG+OJOz5B/ANb4u0qJjTszn1ysKqXTzVQvaCz/GY87F1apAtG7BcvYLziGcxnzuDcf9eTIcOYN+mPZ7f/AiqSs63XyKzMquWf4VqVZbNWMTEJdNRdAp/rdpB3PkYBo0fypXjFzi67RD3jXyAJl1bYDGbycnIYdHE+ZVnjPV6bZqxmCeXvIXQKUSt2kXS+Vi6TxhM/LHLnNt2mHYjw6nTrRkWk4X8zBzWTrBOK3NwyVYGfPwio7d+AEIQ9fMuEs/EVGjD6hmLeX7JZIRO4eCqCBLOX6Pv+EeJOX6ZU9si6ToynPpdm2Mxm8nLyOGniTff37S0bTum/8jgpW9ap6RZuYuUc7F0mTCYhOOXbZzLW0G1qKya8T1jlkxB6BT2r4rAcP4a/cY/RvTxSxzfFsm9I/vSqGtzLGYLuRk5LJlovdfqtG9E+EsDsZgtSFWycvp35FTQH1mvKEwKb8lLP+1BVWFgy5rU83Nn4a5TNAnyokeDICbc14yZG4+w7MAFQPDuQ20QQrDy0CWi03L4evdZvt5trYO+eqIr3i7WwVUWi4WJE97m97VL0OkUli75mdOnzzNt+ngOHz7OhvXb+HHxShZ99xlRx3eSlpbB0yOsvZb8/Hz4fe0SpKoSF2fguVETis55+rQPWPTdp3zw4QySk1P4c3L5TdbXy+iRpW8idAonC8uoc2EZXbrNMpIWlSNTFnPvCuv9ffmnXWSei6XpG4NJjbpM/JaK8zdl5HLu643ct3EWSEn89qgy/SyLUC3kfPU57u9a64aCbRuwRF/BadizmM+fwXRgL6bDB7Br3R6PBda6IfcHa92gb9QUlzGvW5uIhULeL8tsRodXO/+CaYNEVUclatw8hc3d8wBPwAxcwNrHcTXgjjXaGAW8dH2gzg3yypZSugohFGA20L/w+CRgENAaeF1K+VChfETh9iEhRI/raUKIxUA+1mmL3IEJUsobdpIs2eR9NzH/vrg61GD//NvVosccta1yoTtAwsSfq0UPwMX4ipva7yQtW1U8iv1O8sbZsoOV7hZ1ZJmuyneFDFE9L6YgVVe50B3gsnJzI4xvh4/erV250B3A76WVlQvdAWb5dq0WPaGm6vMjerWr+owDt4PPul2311H9JslbPfeOXUSnhydV67lfR4tQ3kWklJFAefO13PRTLqV0LfyvAlMK/0oSUfh3Xb5Hid82acA2KeXomz0HDQ0NDQ0NDY3y0BxKDQ0NDQ0NDY1/kn9Bk7fmUP6PUGpVnOv8LKV8707qkVI+fSfz09DQ0NDQ0LhN/gUr5WgO5f8IhY7jHXUeNTQ0NDQ0NDSqA82h1NDQ0NDQ0ND4J9EilBoaGhoaGhoaGrfFv2DGHc2h1KgU9dzBatFjuVS1SaFvl+qazkffsne16DEbb26t5dshWameKiMzzqFa9DSUTpUL3SGqazqfDMzVokdVqucFmFVN9gDkrqqehRDslOqZcilGqZ5rF1M9jysAYZEVL+pwJ6keLf8uNIdSQ0NDQ0NDQ+OfRGvy1tDQ0NDQ0NDQuC3+BQ6ltpa3hoaGhoaGhobGbaFFKDU0NDQ0NDQ0/km0ic01NDQ0NDQ0NDRuC63JW0NDQ0NDQ0ND4/93tAilhoaGhoaGhsY/iTYPpUZlFK7R/SRgAVTgRSnl34Vp/wGelVK63uDY6+t7NweOF/7+Xkr5n7t64jdgz9lrfLhmP6pUebhDQ57t2dImPT4tm+kr/yQrvwBVlbzyQHvuaRwGwLn4VGb/upvsAhOKECwbNwAHu8pvQ13TdjgOfQmhKBj/2oRx00qbdIcho9E3KjwPewcUN0+yXn2kavacvMyHP+9ElZKHuzTj2b4dbe1JzWT6j5vIysu32jPoHu5pVgeT2cKs5Vs5FZ2AIgRvPNaT9g3CqqSzPKbN+ZQ/9xzA28uT3//71S3nA+DcrR2+k0eDTkfmLxtJX7TKJt1tUB98X38Oc2IKABnL1pL56yYAfCaOwrl7R4QQ5O47TPKcLyvUE9izBa1nDkfoFC4tj+DM/HXlyoX2a0/XRa+x5f5ppEVdBsCjcRjtPhyFnZsTUpVsfWA6aoGp3OOdurbD562XEDqFzN82kfGdbfm7DuyDz4Tni+zJXLGGrN+s9niPH4XzPdYyTft6GTmbd1VoT+3uLej99nAUnULUTxHs/9LWnlbDetFmRB+kRcWYm8+myd+Rcj4OxU7H/XNGEdiiNqgq2979L9H7T1eoB6BB9xY8NGMEik7h4Mqd7Cqlq8Ow++g8vA+qqmLMKWD15EUkXogFILBRGA/PeQ4HVyekqrJg4HTMFVy7pt1bMXTGMyg6hb9WbmfTl7/bpHcf1ocew+9Hqir5Ofksnfw18Reu4eLpyugvJ1KrRT32/hLBire/u6E9jbq3ZNCMkSg6hf0rd7Djy7U26Z2H9abb8HBUVaUgJ5+fJ39LQqE9AJ7BPry19RM2f/4LEd/+UaGe5t1bMWzGsyg6hV0rt7P+y9U26X1H9af70PtQzSqZqRl89+ZCUmKTABgy6Sla9mwLwJp5P3Pgj703tMmubQdcXhgHikL+lvXk/7y8jIx9t544DXsapMRy+SLZH80CwHvtDixXLwGgJiWSNXNKhXru630v7384DZ1Ox9IfV/H5p1/bpHfp2p45H0yjabOGjHr6Ndb+vqko7efV39O+fSv27zvE0MdeuKE91VVG1anLo0dras16FqEoJK7YRtx82/vBb0hPakwfgdGQCoDhh40kLd+GfYgfDb9/CxSB0OswfL+BxKVbbmjTXeVf0OStOZR3ESFEZ+AhoI2UskAI4QvYF6a1A7xudHzJ9b2FENlSylZ3+ZQrxaKqvL96L189fz8BHi4Mm7eW7k1qUDeg2JRvtx8lvGVthnRuzMWENMZ+v4WNjR/HbFGZuiKC2UO70zDYh/ScfPS6KvS6EApOT44l57NJyLRkXKbOwxy1DzU+ukikYNVXFBT+tus1EF1Y3arbs3I7X73yKAGebgz7YBndW9SjblDxtLbfbtxPeNsGDLm3FRfjUxi74Dc2zq7Dr3uOAfDLtJGkZuUyZv6vLHvrKRRFVEl3aQY92IcnBw9gyqyPb+n4IhQFv2ljiH1uMuaEZMJWziNn535MF6NtxLI2/knyewts9jm2aoJj66bEDBoNQOh/P8GpfQvyDh4ro0YogrZznibi8ffJi0+lz8ZZxG05TOa5WBs5vYsj9Z+7n5TIC8XH6hQ6zX+Zv8d9SfqpaOy9XJGmCiZhVhR8p44l/oVJmA3JhPw0j9yd+zBdsrUne/MuUubY2uN0TwfsG9fn2mOjEfb2BH3/Ebm7DyJzcsu1J3zWSH4aNpcsQypPr53J+W2RpJyPK5I5tWYfR5ftAKBe7zbcN+0pVo38kFZP9ATg+76TcfZxZ8iPb7C4/4wKow5CEQyY+QzfPfU+mYYUxqydzemth4scRoCoNXs5sGw7AI17t6Hf9Kf4YeQHKDqFIZ+NYdWEhRhOR+Ps6YqlgmsnFIUnZ47is6dmkWZIZera94naeoj4C9eKZP5es5tdy7YC0LJ3O4ZMH8kXI9/DVGBizScrCWkYRnCDGuWXTQl7Hpn5LF899R4ZhhTGr53Dya2RNg7C4TV72LfMuqhA095tGTh9ON+MnFuUPnDaCE5HHK1Ej8KImc/z4VMzSTWk8M7aDziy9SBxJey5euoy7/R/E2O+kV5P9eXxycNZOPZTWvZsQ82mdZj+4ET09nZM/mkmxyKOkJ+dV74yRcHlpdfInDYRNTkJj8++xrR/D5aYq8UiwSE4DRlG5htjkNnZCA/P4uONBWSMe+6G9ljVKHz06Ts8PGAkcbEGdvz5Gxs3bOfsmeLnJSYmjjEvvsnYV8vmN++Lb3F2cuLpZ4dWcu2qp4yqVZeiUHvO85we+i7G+BSabfiQtM0HyTt/zUYsZe0erkxdZLPPlJjGif6TkEYzirMjLXd+TtqWg5gS0iq1T6N8tD6Ud5cgIFlKWQAgpUyWUsYJIXTAR8CbN5uhEEInhPhICHFQCHFMCPFi4f4eQohdQog1QohLQoi5QohhQogDQojjQoi6hXKLhRBfCSEOCSHOCSEeuhn9J2KSCPN1J9THHTu9jr4t6xBx0vbFLgTk5BsByM434ufuDMC+c7HUD/KmYbDVWfN0cUSnVH4L6mo3RE2KQyYbwGLGdHAX+lZdKpS3a98D04GIqtlzxUCYnyehvp5We9o2JCLqgo2MEKLYnrwC/DxcALgUn0KHhtYXrbebM27OjpyMNlRJb3m0a9UcD3e3Wz7+Oo7NG2KKjsN8zQAmM9kbI3Dt1blqB0uJcLBH2OkR9nag12NOKb+C9W5dl6wrCeREJ6GaLESv2U9I37Zl5Jq/9Shn5q/DUmAs2hfYvTnpp6NJP2W9d4xp2Ui1fOfLoaQ9ZjM5G3fh0rPi8i+Jfd2a5EceB4uKzMvHeO4yzt3alSsb1KouaVcSyIix2nNq3X7q97G1x1jC+bBzdkBiPWef+iFc3XsSgNyUTPIzcwlqUbvC8wprVY+UqwmkxSRiMVmIWrePxuG2ugpK6LJ3dkAWOqf172mB4Uw0htPWa5ebXvG1q92qHklXDSTHJGIxmTm4bg+twm3tL+lQOZTQY8wr4MKhM5gqiHyWpEareiRfNZBaaM+RdXtpVkpPWXuK05qFtyM1JpGEUo5Aaeq0qkfCVQNJMQlYTGb+XrebNuHtbWTO7DuBsfB5vXDkHN6B1vomuH4YZw+cQrWoGPMKiDlzlRbdW1eoS9+gMZa4WFRDPJjNFPy5A7tO3WxkHPv2J/+P1cjsbABkRvoNz7882rZryaVLV7l6JQaTycRvv6znwX62q2zFRMdy8uRZ1HKiWH9G7CMrO6dSPdVVRtWpy7V1PfKvxFMQnYA0mUlZsxuvvh0qPT8AaTIjjdYPMcVBD7cYCLhjqOqd+/uH0BzKu8sWIKzQcVsohOheuH8ssFZKeStrDY4CMqSU7YH2wPNCiOtvrpbAaKAxMBxoIKXsACwCxpXIoxbQAegHfCWEcKyq8sSMXAILHSqAAA9nEjNtK7PRfdqw/shFwt9bwdjvtzBpoNWZuZqcgRDw0qJNDP38d36IKBv1Kg/h6YuamlS0LdOSUDzLXxhLePuj+AZiOVP5VzRAYno2gV7FTlyAlxuJGdm29vTrzPoDpwmf8jVjF/zGpMfvA6BBqD8Rxy5itqjEJmdwKjqBhLSsKum9m+gCfDAZiq+X2ZCMzt+3jJxreFfCVn9J4GfT0Af6AZAfdZq8A1HU2rWCWrtWkLsnEtOlmHL1OAV6kxebUrSdG5+KU6Bt0N2reS2cgn2I325bHm51g0DCvSveInzLbBq9XPF3jd7fF3NJexKS0AWULX+X3t0I+fUr/D+Zji7Aao/x7CWcu7ZDODqgeLrj1KEl+sK00rgFepEVn1q0nRWfiltg2UaENiN68+Kfn9Bz8lC2vb0EgMRT0dTv0wahU/AI8yOwWS3cgytevM09wIuMuOJrlxmfikeAdxm5TsP78Pquz7h/0pOse8eqy7dOIEjJM0smMfaP97j3xYqvnWeAN6kl9KTFp+JZzrXrMbwv7+2ax+BJT/HTO99XmF9FeAR4k15CT3oF9nQdHs6UXV/w0KRhrH5nMWB1JnqNHsDmL36pVI9XgDepcclF26nxqXiVY891ug+5j2MRhwGIOX2FFt1bY+9oj6uXG407N8M7qOJjFR9f1OTEom01OQmdj+1zpAsJRRcShvtH83H/ZCF2bUs4M/b2eHz+tXV/KUe0JEHBAcReK34VxMUaCAoOqFD+VqmuMqpOXfaBPhhL6DHGp2AfVFaP94Odab7tU+p/8wb2JZ5L+2Afmm/7lNaHviVuwep/Njop1Tv39w+hOZR3ESllNtAWeAFIAlYKIaZg7Rc57xazDQdGCCGOAn9jXXK0fmHaQSllfGFE9CJWhxasfS9rlchjlZRSlVKeBy4BjUorEUK8UBjFPPTd5r9v6gQ3Hb3IgLb12TL1CeY/G860n3ahqhKLKjlyOYE5T/Tgh5cfYueJK/xdojnxTmDXoQfmw3/d0Ydq06EzDOjUlC1zXmT+mEeYtngDqioZ1LkZAV6uPPnBf/nol520rBOMIv7hr9wqkrNzP1d6jyTm4ZfI3XcY/zmvA2BXIxj7OmHYUVcZAAAgAElEQVRc6TWMKz2fxLljSxzbNrs1JULQ6p1hHH1nWdkknYJvhwbsH7OA7QNnEvJAO/y7Nb1le3Ij9hPddwSxg0eTt/8w/u+9AUDevkhy/zpA8NLP8f9wCvlRp5G3+QV/eMk2vr53IhFzf6LLuEEAHFu1i6z4VJ5eN4veM54i9vB5VMvt34P7l27l4+7j2TR3Bb0KdSk6HTXbN2Tlqwv4+tF3adq3PXW73Pq1A4hYupmp3cfx69xl9Bs3+LbPuyL2LN3CnO6vsn7ucvqMexiAvq89xq7vNmDMLajk6Jujy6B7qdWiLhu+WQPAib+iiNp5mGm/zeGl/4znwuHyI343hU6HLjiUzEmvkv3hTFzGvYFwsXaJT3/mcTJee5Hsj2bh8sJYlMDg2zWpWqjOMqoOXWlbD3Kk44sc7z2BjD+jqPv5K0VpxrgUjveewNEuL+P3WE/sfD3uiM7/Cwgh7hdCnBVCXBBCTConvYYQYqcQ4khha+iDleWp9aG8y0gpLUAEECGEOA6sAFKAC8LqfDgLIS5IKetVMUsBjJNSbrbZKUQPoOQTqJbYVrEt69LtY2Xay6SU3wDfAOSt+bAo3d/DGUNGcUQyISMXf3cXm2NXHzzHwlF9AWhZM4ACs4X03HwCPJxpUycQLxdrQLRbozBOxybTsf6NK1qZnoziXRxVEl5+qOkp5crate9B/vL5N8yvJP6erhhKRBUT0rLw97AdI7V67wkWjrEO8GlZJ5gCk4X0nDy83Zx549GeRXIjPlpOzXK+wqsbS0IKdoHF10sf6IslMdlGRs0otjnzl034TLT2zXLp3YX8qDPI3HwAcv46hGPLxuRHniijJ8+QilNI8de+c5A3eYbiL3w7V0c8GoXR67dpADj6eXDP4on89fQn5MankrT/DMZUazQ4fsdRvJrXInH3yTJ6zInJRRFUAH2AH5YE2/IvaU/WrxvxGV/c1yz92xWkf7sCAP8PJmG6Wn4zWpYhDbcS0Q23IG+yDBVHLE6t3U/47GcAkBaV7bOKHeenfptB6uWKGyAyE9LwKBEpcQ/yJiMhtUL5Y+v2MWj2swBkGFK5cuAMuYX37dmdRwluVpuLe8teu/SEVLxL6PEK8iY9ofxnB+Dguj0Mm/08sKBCmfLISEjFs4Qez0rsObJuL4NnjwK+pGarerR8sCP9Jw/Dyd0ZqUrMBSZ2L9lc5ri0hFS8g4ujhN5B3qSVY0+Tri3oP3Ywcx6fjtlY3L903YJfWbfgVwBGf/EahksVl5Gakozi61+0rfj6YUkp9RwlJ2E+exosFtQEA2psDEpwKJbzZ1ALZVVDPKbjR9HXrY/RUPYDOj4ugZDQoKLt4JBA4uMSKjyvW6W6yqg6dRkNKbYRxyAfjPG2esxpxS1Oicu3UWPa8DL5mBLSyD0bjVvHJqSu31fhed5NKuq2cjco7Ha3AOgDXAMOCiHWSilPlRCbhjX49KUQogmwAdvAVBm0COVdRAjRUAhRv8SuVsDXUspAKWUtKWUtIPcmnEmAzcBLQgi7Qh0NhBAulRxTmseEEEphv8o6wNmqHtg01I/o5ExiU7MwmS1sjrpE9ya2HfaDPF35+4K14ryUkI7RZMHLxZEuDUK5EJ9GntGM2aISeclAnQDP8tTYYLlyFsU/BOEbCDo9du27Y44q+9ArgWEIZ1csF0+Vk0sF9tQMJDoxndjkDKs9kWfp3sJ2QE+Qlxt/n7X2V7sUn4LRbMbL1Yk8o4m8wv5l+05fQa9TbAbz/FPknziLXc0Q9CEBYKfH9YEe5OzcbyOj8y12nFx6dioa4GKOS8KpfQvQKaDX4dS+OcZSg1+uk3r0Em61A3EJ80Ox01FjYCdiN0cWpZuy8vi96Wj+6PAaf3R4jZTDF/jr6U9Ii7qMIeIYno3D0DnZI3QKfp0alxnMc52CInsCQa/H5YHu5ETYln9Je5x7dC4+Z0VB8bB2abBvUBv7+nXI2xtJecRHXcK7diAehfY06d+JC1sP28h41SpuiqzXqxVpV6x9ZvWO9tg5OQBQq1szpFm1GcxTmmtRF/GtFYhXqB86Ox0t+3fm9Fbb8/KpFVj0u2Gv1iQX6jq36xgBDcOwc7RH0SnU7tiYxAr6ml2JuoB/rSB8Q/3R2elp378rUVsP2cj4l9DTvFcbEq/cfE+cmKiL+NUKxLvQntb9u3CilD2+JfQ07tWa5EI984e8w+xu45jdbRx/fr+RbQt+r9BRuRx1gYAS9nTs340jpeyp0bQ2z8x5kc+fm0tWSmbRfqEouHhaPxbDGtUkrFFNTvxVcdcY87kz6EJCUQKs953Dvb0w/b3HRsa4fzf65taxksLdAyUkDNUQh3B1Bb1d0X67xs2xRF8pV8/hyGPUrVuTGjVDsbOz45FH+7Fxw/YKz+tWqa4yqk5d2Ucv4Fg7CIcwf4SdHp+B3UjbctBGxs6/uNuKV3h78s5b6xn7IB+Eoz0AOg8X3No3Ju9i+XVQtVC9fSg7ABeklJeklEbgJ2BgKRkJuBf+9gAqbU7UIpR3F1dgnhDCEzADF7A2f98Oi7B+JRwW1hBnEjDoJvOIBg5gvVlGSynzq3qgXqcwaWBnXlq0CVWVDGzfgHqBXizcHEmTUF96NK3JhIc6MPOX3Sz7yxoxeffxexBC4O7swPB7mzFs3hoE1gjlvY1vPHoUAFUlf/l8nF+bgxAKxj2bUeOu4jBgBJar5zBHWZ0lu/Y9MB2MuKkLodcpTHq8Fy/N/xVVVRnYuRn1gn1ZuG4PTWoG0KNFPSYM7sHMZVtYtuMwCHh3+P0IIUjNyuXleb+iCIG/pyuzR1baInBD3nh7LgePHCM9PZP7Bj3Fy6OGM7h/35vPyKKS9N4Cgr+dg1AUMldvwXjhKt5jR5B/8hy5O/fjOXwgzj07g9mCJSOLhCmfAJC95S+cOrWkxu9fA5Lcvw6RG1F+lwdpUTk8ZTHdV7xlnTbop11knoul2RuDSY26TNyWw+UeB2DKyOXs1xvps3EWSEnc9qgy/SxL2pM8Zz6BX81B6BSyVm/GdPEqXmNGUHDyHLkR+3EfNgiXHp2QFgtqRhZJ060j5YVeR/CPnwKgZueSOHkuVNAULS0qW2b8yONL3kToFI6t2kXy+VjumTCY+GOXubDtMG1HhlOzW1NUk4X8zBzWT7BO7+Li686QJW8hpUq2IY114yueaglAtaisnbGYZ5dMQugUDq2KIPF8LL3HP0rs8Uuc3naYziPDqde1GRazmbyMHH6eaM0zPzOH3Ys2MGbtbKSUnN15lLM7y792qkVl+YzveG3JVIROYc+qncSdv8aA8Y9z9fhForYdoufIB2jStTkWs4WcjGx+mFgc4X9/9wKcXJ3R2elpHd6ez4bPthkhXlLPbzN+4IUlU1B0CgdW7STh/DXuH/8YMccvcXJbJN1G9qVB12ZYzBbyMnJYPvHG16gie5bOWMQbS6aj6BT+XLWD2PMxPDx+KFeOX+DItkMMnTwCB2dHxiycCEBqbDKfPz8XvZ2OqT/PBiAvO4+vx39x424JqoWcLz/HfdbHoCgUbN2AJfoKTk89i/n8GUx/78UUeQC71u3x+PJHUFVyv/8SmZWJvnFTXMa+bn25Kwp5vyyzGR1eEovFwpsT3+XX339Ap9OxbOnPnDl9nsnTXuXo4RNs3LCd1m2as3TFl3h6unP/A72YNPVVurR/AIANW1ZQv0FdXFycOXF2N6+8PJkd2//6x8qoWnVZVK5MXUSj5TMQOoXEn7aTdy6G0DeGkhN1kbQtBwkc9SBe4e2RZhVzehYXx1t7mznVD6XhjJFWt0lA/FdryDtT/sfz/zWEEC9g62t8U9jqeJ0QoGTn+GuA7Xx58A6wRQgxDnABelMJQv4LJtPUqDpCiMXAH1LKqvWuxrbJ+25i+mNbdajBbuij1aJH37LS5++OcPXel6pFD0BkWtnBPXeD9r5JlQvdAVZl+lcudIfIENXTWT6Zykdl3wnc0FWLnpRqsgfg06bJlQvdAertqp5I2DO+5c9o8H+ZIUZj5UJ3gE5xv1Vrh/jcL8fdsfes80vzbnjuQohHgfullM8Vbg8HOkopx5aQmYDVR/ykcArE74BmUlY8QEGLUGpoaGhoaGho/JNUYx9KIBYouQpHaOG+kowC7geQUu4rnA3GF0ikArQ+lP8jCCGmCiGOlvqbeqf1SCmfvpnopIaGhoaGhsa/ioNAfSFEbSGEPTAUWFtKJhq4D0AI0RhwxNrFrkK0COX/CCVXxdHQ0NDQ0ND4/4hqnJBcSmkWQozFOshXh3U555NCiJnAISnlWmAi8K0QYjzWnqZPy0r6SGoOpYaGhoaGhobGP0k1r3AjpdyAdSqgkvtmlPh9Cuh6M3lqTd4aGhoaGhoaGhq3hRah1NDQ0NDQ0ND4J/kXzLijOZQalWL8peIJbO+oHoO5cqE7QOrEn6tFj9n4a7Xoqfnnrc0VdyuE7Phv9SjKCakWNV0mX64WPQC1QiteKeROkhDvXrnQHSDNXD3TBhn0TtWiByAnoXpeiatc2laLnkZ+1TP9VnKCa+VCd4hG80tPl/gvoZqbvO8GWpO3hoaGhoaGhobGbaFFKDU0NDQ0NDQ0/kmqdx7Ku4LmUGpoaGhoaGho/JNUvADN/xm0Jm8NDQ0NDQ0NDY3bQotQamhoaGhoaGj8k2hN3hoaGhoaGhoaGreD/BeM8tYcymqgcE3uJwELoAIvAu2B14C6gJ+UMvkGxz8NtJNSji21fwPwpJQy/QbHRgCvSykPldrfCggunC3/ptA3b4/j8DGgKJgiNlDwx09lZOw6dMfhkZEgJZboi+R9OQcAx6EvoG/ZEYTAfDKS/KULKtRj164Dri+PQygKeRvXk7dyeRkZh3t74jziaZAS86WLZL0/q9hGZ2e8Fv2Ice9usud/UaEepy7t8H7zZVAUsldvJOOHlTbprgPC8XrteSxJKQBk/rSG7NUbAfB69Tmc7ukAQPo3y8jdsqtCPc7d2uE7eTTodGT+spH0Rats0t0G9cH39ecwJ1r1ZCxbS+avmwDwmTgK5+4dEUKQu+8wyXNufaqgaXM+5c89B/D28uT3/351y/kA7Dkfx4frD6FKycNt6/HsvU1t0uPTc5j+2z6y8oyoUvJKeCvuaRBik/7IvD8Y3bM5I7s1qVjPpQQ+3HYcVYWHW9bg2c4NbPVk5DJ9/RGy8k1WPT2acE/dAPZdTuQ/EacwqSp2isL4nk3pUMuvQj1ePVtRd9YzCJ2CYdl2Yub/bpMe8HgPas8YjjHeOgVQ3PcbMSzfAUCz5VNxb1ufjANnODl8btUuYCGOndvj9br1mcr5fQOZP5Z9ppx7d8fjhZFIKTGdv0jKtDlVytu9R2tqzByFUBSSVmzDsOA3m3SfIT0JmzYSk8FqU8IPG0hesQ37ED/qffcWQlEQeh0JP2wgaWnFU4j59GxJo9kjETqFa8t2cGVe6aWBrfj360Cr7yewP3wKmVGXEHY6mnz0PO6t6oAqOTPtR9L2nrqhTcE9WtB+5nCEonBhRQQnFqwrV67Gg+3p8e2rrH9gOinHiqeIcgn2YUDEB0R98hunvq5aFXg3y6gkPj1b0nD20widQuyyHVyZt8YmPejx7jSY8RQFheUV8/1mYpftqLINnhMLbVizgaxybHDq3R2P50cCEuO5i6ROt9rg+5/3cWjWhIKjJ0ieMPWGety6tyb0necROoWUn7aSsNB2CjXvR3sRPPVpTAZrXZf84wZSftoKQKvLv5F35ioAprhkLo268YrEe87G8uEfB1BVycPt6/Nsj+Y26fHp2Uz/eU9xHdS3Dfc0CiU2LZtHPv2dmn7WabZahPkx7eHON9SlcWM0h/IuI4ToDDwEtJFSFgghfAF7wAj8AUTcat5Sygdv49RaAe0otfRSpQgFx5GvkPPBm8jUJFxnLsR0eB9q3NUiESUgBIf+T5A98xXIzUa4ewKgq98EXf2mZE95HgCX6V+ga9QSy5mosnoUBbdxr5H+1kTU5CS85n+Ncd8eLNHFenQhITg9MYz018Ygs7MRnp42WTg/PQrT8WM3tkdR8J48joTRb2FOSCZ42Xxyd+3DdCnaRixnyy5S58632ed0TwfsG9cj7vHRCDt7Ar/7mLw9B5E5ueXq8Zs2htjnJmNOSCZs5Txydu7HdNFWT9bGP0l+z9bJdmzVBMfWTYkZNBqA0P9+glP7FuQdrMS2Chj0YB+eHDyAKbM+vqXjr2NRVd5fd5Cvnu5FgLszw77aRPdGodT19yiS+XbXCcKb1WBIhwZcTMxg7NKdbJxY7FB+sjGSrvWDK9EjeX/LMb4a2oUANyeGLd5F9/qB1PUtnm/x273nCG8UzJA2tbmYnMnYVfvZ+HI4Xk72fPFoR/zdnLiQlMlLK/exdWzf8hUpCvXeH8XxIbMoiE+l9ab3SdlyiNxz12zEktbs5eKU78ocfm3hGhQnB4JG9KnK5bPR6/XWKySOeRNLQhKBSxaS++c+zJeL73V9WAjuzzyBYdQryKxsFC/PG2Rom3fN917g3BPvYIxPocmGD0nfcoD887Y2pa7dQ/S0b232mRLTOD1gEtJoRnF2pNmOL0jfcgBTQlo5egSN5z5L5JD3yI9LodPmOSRtjiTnXKyNmM7FkZrPP0B65PmifaFP3QfAvh5vYu/rTpvlk9jfd2qFEz0LRdDxvZFsfWIuufGpPLhhJjFbIsk4H2cjp3dxpPGoviQdvlAmj3bvDCN2Zzn1TkXczTKy0SNoNPdZDhdex46b3ydp86Ey19GwZi9np/xwk3kreL35ColjrTYE/LiQvPJsePoJEp4ra0PW0lVkOzri+vBDleoJm/0iF4a9jSk+hYbrPiZj6wHyz8fYiKWv2821Gd+UOVzNN3L2gfFVMsmiqry/dj9fjQq31kEL1tO9cRh1A4rP+9sdxwhvXpMhnRpxMSGdsYu3sbHRowCE+rix6pUBVdJ11/kXNHlrg3LuPkFAspSyAEBKmSyljJNSHpFSXrmdjIUQVwodVIQQ04UQZ4UQu4UQK4QQr5cQfUwIcUAIcU4IcY8Qwh6YCTwuhDgqhHi8qjp1dRuhJsQik+LBYsa0fyd2bbvYyNj37EfBtrWQmw2AzCwMoEoQdvag14OdHeh0yMxyXk6AvmFjLHGxqIZ4MJvJj9iBfZduNjKOD/Qnf+1qZHahnvTiQK2+fgMUTy+MkQdvaI9Ds4aYY+IwxxrAbCZncwTOPbrc8Jjr2NWpSX7kcbCoyPx8jOcu4dS1Xbmyjs0bYoqOw3zNACYz2RsjcO1Vxa9hKREO9gg7PcLeDvR6zCnlX7eq0K5Vczzc3W75+OucuJZCmI8bod5u2Ol19G1ek4jTti8NAeTkmwDIzjfi51Y8SfWOUzEEe7naOKDl6olPI8zLhVBPF+x0Cn2bhBBx3mCrR0CO0ToxfnaBGT83RwAaBXriX6izrq8bBWYLRrOlXD1ureuRd9lAfnQi0mQm6fc9+PQtvzzLI333CSw5eVWWv45900aYY2KxxFrv9dwtO3HubnsPuj7cj6xVa5FZ1ntdTauwUcIGl9b1KbgST0F0AtJkJnXNbrz6dqjSsdJkRhZeU+FgB4qoUNajTT1yLxvIu5qINFkw/L4X//vLXrt6k4Zwef5a1MJ7AsClQQipu08CYEzOxJSZa41WVoBP67pkXUkgOzoJ1WThypr9hPUtO1F4qzcf5cTCP7CU0AUQ1rct2dFJZJyNLXNMRdzNMiqJ9Tom2FxHv/vb33Q+FdlgKmnD1p04lbLBZVA/sn8u34aCg0fK/1guhXOr+hRcMWAsvOfS1v2FR3jV7rmb5URMMmE+7sV1UMvaZesgIcgpKFEHuTvflXO5baR65/7+ITSH8u6zBQgrdOYWCiG632kFQoj2wGCgJfAA1shjSfRSyg5Ym9jfllIagRnASillKynlSqqI8PJFphavvqCmJiG8fG1klMBQdEGhuEz/Ape356Fvbq0QLRdOYT59FPd5P+M+bxXm44dQ42wjdEV5+PpiSUos1pOchM7XVo8uNBRdSBien8/H8z8LsWvX4foFweXFl8n5pvJmYZ2/L2ZDsT3mhGR0/r5l5Jzv60bwqq/x+2g6ugBrk6nVgWyPcHRA8XTHsX0r9AH+5esJ8MFUUo+hfD2u4V0JW/0lgZ9NQx9o1ZMfdZq8A1HU2rWCWrtWkLsnEtOlmDLHVjeJmXkEehRXzgEeziRm2TpUo3u1YH3UZcI/+o2xSyOY1M96a+YWmFi8+xSje9o2T5WrJyufwBKOaICbE4lZ+bZ6ujVi/ckYwhdsZuyq/Uzq06JMPtvOxtM4wAN7ffkrvDgEeVMQl1K0XRCfin2QTxk5334dabPjYxovmohDcNn0m0Xn74slocS9kZhU5t7Q1wjFrmYoAd99QcAP83DsXDUnwz7QG2NccW8aY3wKdoFlz9nrwU403foZdb95A/sSNtkH+9B062e0PPgthgWry49OAo6B3uSXuHb5cak4BHrbyLg1r4VjsA/J247Y7M86FY1f37YInYJTDT/cW9TG8QbX1TnQi5y44lWHcuNTcQ70spHxblYLlyBvYrcftdmvd3ag2ZiHiPrUttm/Mu5mGZXEIbDUPRiXgkMp2wACHupIp50f0mLR+Crfgzo/WxssCUno/MraoK8Riv+iL/D//tZssA/0KXvPBZQ9R88HO9No8xfU+uot7IKKz0NxsKfhH5/Q4PcP8Qi/8ao4iZm5BHq4FG0HuDuTmJFjIzP6vpasP3KJ8Pd/Zuzi7UwaUJxnbGo2j/9nHaO+2cThywk3bauGLVqT911GSpkthGgL3AP0BFYKISZJKRffQTVdgTVSynwgXwhRukPR9dozEqhVlQyFEC8ALwB83rEhT9e/iaXwFB1KQAg5cyYgvP1wnfoZWVOeQ3H1QAmuQear1oCoy1sfYW7QHMu541XPuyQ6HbqQUNInvori54fnJ/NIe+EZHHr3wXjgb9TkO7PsWO6ufWRv3AkmE66D++E76w0SXniT/H2R5DVtSNCPX2BJS6fg2ClQy49+VYWcnfvJWh8BJhPuQx7Ef87rxD37FnY1grGvE8aVXsMACFn0Prltm5EfeeKO2Hc32XTsCgPa1GVE18ZERScx7de9/DL2Ib7aeZxhnRvh7GB3Z/ScusaAZjUY0bEeUbGpTFsXyS/P9UIR1qjahaRMvog4yZePVy36XBEpWw6RuHo30mgmaHhvGv5nLMceffdOmHBDhE6HPiyEhBcmoAvwI+Cbz4gf+hwyO6fygyshfeshUn//C2k04/dUOLU/f5WzQ2YAYIxL4WSf8dgFeFHvu8mkrt+LOTnjFgwQNHx3BCdeLfuRF7d8J671Q+i4ZQ7515JJP3ju9gYoCEG7t4exZ/zXZZJaTnyEU99uwpxbcOv5V6T2LpZRSZK3RGJYvQdpNBMyvDfN5r1M5OBZlR9YBa7bkPii1Qb/bz7DcBdsyNh2kLS1fyKNZnyG9aXmp69y4YnpAJzs/BymhFTsawRQb8Us8s5exXjVUEmOFbMp6jID2tZjxD1NibqayLRVf/HLqwPxc3Ni01uD8XRx5FRsCuOX7uDX1wbi6mh/p8y8Of4FTd6aQ1kNSCktWPtKRgghjgMjgcXVeArXa08LVSxzKeU3wDcAGcPvK7rTZVoywrt4UIPi7YdMsx1PpKYmYbl4GiwWZJIB1XANXUAousYtsVw4DQXW6JL52AF09ZuU61Cqycno/IqjfYqvH5bkUnqSkzCdsepRDQYssTHoQkKxa9wUu+YtcOo/EOHkBHo7ZF4eOd+V7a9jSUwuigQC6AN8sSSW0pORVfQ7e/VGvF97vmg7Y9FyMhZZBwv5vj8Z09Xym9EsCSnYldQTeGM9mb9swmficwC49O5CftQZZK71uuX8dQjHlo3/cYfS390JQ0ZxE1hCRm5R8/J1VkdeZOHIngC0rOFHgVklPbeA49eS2Xoyms+3HCEr34giBA56HUM7NSyrx80RQ4nIZ0JWHv6FTdpFeo5Fs3CItQtByxDvQj1GvF0cSMjMY8JvB5j1UBvCvFyoiIL4VJtoj0OQN8b4FBsZc1p20e/4ZTuoPX14hflVFUticlHUG0Dv71fm3jAnJmE8Yb3XLXEGzNHXsKsRivHU2RvmbTSkYh9cHP2xD/IpGghRpD+t+L5LWr6N0KkjyuRjSkgj72w0bh2bkLZ+X5n0fEOqTVTRMdi7aNAIgN7VEddGobT/zeqo2vt70GrJ6xwd8TGZUZc4O2NJkWyHP2aSezG+QptyDWm4BBdHP52DvMk1FEdO7Vwd8WwUSt9frANHnPw86PnDBHY+8ym+retRs18H2k4dir27M1KVWApMnF28tUJ9cHfLqCQFhlL3YLAPBQbbqLCpxD0Yu2w79WcMq1LeliRbG3QBfliSbG2wJCZh/H/snXd4FNXawH9ndtMb6Z3ekdBCVelVUbjqxXtFFEVRrICKNBsgcO0KUux6pdkAQTChIyX0pggBEgik9152d873xy5JNtlNQgtXv/k9Dw+ZOWfOO+973n3nzGnzx7XpUJaSWd3nUqv4XE6Fz2Wu2ETotIfLjw2pZr8pS0ilIOZ3XNs1tdugDPB0JaVSj2RqXhEBXta/8dUHz7DoEfO85g6NAig1mMgpKsHH3aV8tKJtqC9hPh5cyMijXVj1kaN64W+wylsb8r7BCCFaCSFaVDrVEbhgL/9Vshu4SwjhLIRwx7wIqDbygSueSGeKO4UuKBThHwQ6PQ49+mE4vMcqj/HQbvRtOgIg3D1RgsJQ05ORmWnoW0eAooBOh751hN0hb+PpU+hCw1CCgkCvx7lvf8r27rbKU7p7F44RFjmeXuhCwzElJ5E/fw5Zo0eRNeZfFHyymNLNUTYbkwClf5xG3zAUfYhZjtuQvhTtsH5g6vwqPbz69MQQb7lnRUHxMpvQoUUTHFs0oXiv1WL6ckp+P41Do1D0oYHgoMd9WF8Kt8XYlS2kfsgAACAASURBVOPWr0f5wiBjUjouXSNAp4Beh0vX9pTF2bZbfdIu1JeEzHwSswswGE1EnbhAn9ZhVnmCG7iy75z5YRCXlkuZ0YS3mxNfPjaYjS+MZOMLIxndszXjerez2ZgEaBfcgISsQhJzCjGYVKJOJtKneZC1HE8X9p0390jHZeRTZjLh7epIXomBZ7+P4fm+bekUVvPQYP7Rs7g0Dca5YQDCQY//yFvJjLauT8eAisn+vkMiKaqyuOVqKDt5CofwUHQWH3Qd3I/inda/qeLtu3HqYvZ1xcsTfcMwjIn2G12XKTx6BqcmwTiGm3XyGXEb2dHW84odAiqGVBsM7krJWbNODsG+CEtvjc7LDY9ubSg5Z/uFKe/IOVybBuHS0B/hoCNoZC/Sog6Vpxvzi9nedjy/dX2W37o+S+6hs+WNScXFEZ2rEwA+vdsjjaZqi1Aqk3k0Do8mQbiH+6M46Gg8ogcXow+Xpxvyi/mu/QR+6jGJn3pMIv3wObY98h6Zx+OJumd2+fk/P4vixIKfa21Mwo2tI1t2dK5kx/Qo+z7oPySSwjN1mwtadvIUDg0r6TDIhg47duPU+dp0KDpm7XPed91O7qb9Vnn0lXzOa1C3cp/TebkhHM19HjpvD9wi21RbzFOZdmF+JGTkkZiVb45Bx+Lp06ZqDHJnn+UFJS4txxKDnMkqKMFkacRdysonITOPMJ9rn1v+/xmth/LG4w4sEEI0AIzAWWC8EOI5YAoQBBwXQmyQUj5WQzljhRAjKx33uPyHlPKAEOJn4DiQCpwAahuX2gZMFUIcBebVeR6lqlL8zQLcXvqPedugnRtREy/gdM9YTPGnMR7Zi/HEAfTtI3Gf/wWoJkpWfoIsyMOwfye6tp1wn/sZAMbjBzAeqd7bYZZjomDhB3jNewehKJREbcB04TyuDz+KMfYUZXv3YDi4H8cuXfH+7GtQVQo/XYzMz6uTGuWYVLLmLyRw8TzztkFrozCcu0CDCQ9TejKW4h178fj3SFz79gSjCVNePhmvvg2A0OsI+uJ9AGRhERkz/gMmO2+ZJpX0Nz8m5NO5CEUhb3U0ZWcv4PPMQ5T8EUvRthgajBmBaz+LnNx8Uqe/C0BB9G+49OhAwzVLAUnRbwcp2r7vyvSsxEuvzefAkePk5OQxYOSDPDVuDPfeZWflcw3odQpTh0cy4eutqKpkROdmNA9swKItx2gb4kvfNmFMHtqFWWtjWLbnFAjBG/f0RAj7iztsylEUpg6OYMKqvahSMiKiIc39PVm080/aBjegb4tgJvdvx6yNx1h24BwIeOPOzgghWHUojoScQpbuPs3S3eZeliX398LHzam6IJPK2emfc8uKGeZtg1Zso+j0JRpNuZ/8o+fIij5IyGN34DskEmk0Ycwp4PTzFSvyO6yZhUuLUHSuznQ/vITYyYvJ3l6HlcQmlay3FxCw4D+gUyj8eSOGuAt4PTGWsj9PU7xzLyV7D+DcI5Lg775AqiZyPvoENbcOvm5SSZj5Ka2WvwaKQsaqLZTEXiTkxX9TdOwsOZsOEPjonTQY3BVpMusUP3EBAC7Nwwh/dSwgAUHKkjUUn7L9IiNNKqemfUnnldPN292s2Ebh6Us0m/JP8o7FkV6pcVkVRz8vuqychlQlpSlZnHjG/lZil2Xtn/k1A5dPMW8btGoHubGJdHjxXjKPxXNp0+Ear78qbmQdVdHt9LQvyu2YtGJ7NTs2fHwY/oO7IE0qhpwC/nhuUZ11yH5rAf4f/QehUyj4eSPGuAt4WnQouaxD90iCVll0+LBCh4BPPkDfOBzh4kLw+pVkz3mHkhgbL9AmlUuvfEKz/75u3jbI4nNBkx+g6MRZ8jbtx/+R4XgN6gaW39GFF8zbujk3Dyd83gTz8K8iSF30Y40NSr1OYerd3ZnwxWZUqTIisgXNA71ZtOkIbUN96du2IZPviGTW6j0s23XSHBvuuxUhBIfPp7Jo0xH0OgVFCGaO7ImXq424UF/8DYa8hbSzNYPGXwshhLtlvqYrsBMYL6W8LpG18pD3jaQsxVgfYihMr585Msay+hkAaLTz6vekvFKMW7+tH0GFBbXnuQ4cmBZfe6brROOwrNozXQdSkz1rz3QdyDbWz8M3RV9//R59g6+sN+5qOX2xfoZVWze0u73xdSUj1b1e5AC0/qDmhTrXC5d7pl/Zm+81UvjKqOv2nHWb/V293vtltB7Kvw+fCCHaAs7A19erMamhoaGhoaGhURtag/J/CCHEI8DzVU7vllI+Xdu1UsoHbsxdaWhoaGhoaNxQ/gZD3lqD8n8IKeWXwBV+/kBDQ0NDQ0Pjr8zf4Vve2ipvDQ0NDQ0NDQ2Na0LrodTQ0NDQ0NDQuJloQ94aGhoaGhoaGhrXhNag1Pj/QPxO+18XuZ6Etb2KT7pdBeeSfWrPdB3IUOrn5xVaX1v5APr+D9aLnJLXn6kXOami+neSbxTGi9f+3e+6EOR+fT+TZ48/SuonLhTU48Sswtz62QpJUj+7uuRkuNaLHAf91X9y9kqRF2/+Rx00bKM1KDU0NDQ0NDQ0bibyr78oR2tQamhoaGhoaGjcTLQhbw0NDQ0NDQ0NjWtB/g0alNq2QRoaGhoaGhoaGteE1kOpoaGhoaGhoXEz+Rv0UGoNSg0NDQ0NDQ2Nm8nf4Es5WoNS44rx6NOZ0NceQ+h0ZK6MJm3xj1bpPvf1J2T6IxhSMgFI/+YXslZuAqBD3GpKTl0AoCwpnfjH3rQrx6FLN9yefBahKJT8+gvF3y+vlsfx9n64PjgWpMQYd46Ct2YD4Lt+K6bzcQCY0tPIf2N6nXTz6deBlnPGInQKScu2cmHBWqv04Pv70PzVBylNyQLg0hdRJC3bWqeyg/pF0GnWGIROIW75dk4tXGczX9idXbn1s4lED51J9rF4ALzahBP51jgcPFyQqmTTsFdQSw12Ze0+k8RbvxxElZJ/dGnOo73bWaUn5xTyyk97yS8uQ5WS5wZ35PaWoVbp9yxYz5P92vPwbW3rpF9VZs59j5279+Pj3YA13y65qjIuo2vTBef7ngBFwbAnirJN31ulO93zOLqWEQAIR2eEuxcFU0YB4PLULHSNW2OKO0nxktdrlBNYpY5O26mj0Du70uuziWyuUkdd3hqH3sMFVMnmWuqoMj79OtBiziMInULysi3V/C7o/j40f3VMJb/7leQ6+p1b7y4EvTIeoVPIXhVN5lJr23ndO5DAlx/FmGr+vWb9dx0530UDoA/2J2TeczgE+4OUJIx7DUNimm2b9I2g26wxCEXhzIrtnPjYtu0a3dGVfp8+z7phr5B5PL7iPkN8Gbn9Pxx99yf+WLrBrj4N+0Zw++vmOjq5YjuHF9mW02xYV4Z98jzf3fkKacfjcW7gztClzxHQoSmnvt/Jzle+sW+0y/d0excCZz6B0CnkfBdF5idVbHfPQAJeHocxNQOA7P+uJ+f7KFy7RxA44/HyfI5Nw0mc+B8KNu+1Kce3Xwdaz3kYoVO4tGwr5xf8bDNfwJ3d6PjFZGIGTyfvWBzCQUfbtx/Hs2NTUCWnZn5N9p6TdvVx792ZkNceB0Uhe9Um0pf8YJXe4N4BBE97BIPFFzK/+YXsVWZfuOXsGkpOm2O3ISmdC4/PqVFO8KvjzXK+iybDhpygqY+Wy8n6Zj3ZFp9zCPEndN6z6C0+d+HR1+36HIDSqC2OfUaBUDD+sRvjwSirdIfe/0QX1tJ8oHdEuHpQvGSyOe3Wf6BrfItZp/0bMJ05ZFeORu1oDcp6QAgxA3gAMAEq8ATwHBAJGID9wBNSSptPHyHEWCBSSvlMlfMbgAeklDk1yN4OvCilPFjlfEcgREppP3LbQlEIm/0E50a/iiElk5Y/v0vu5v2UnrlolS17/S4SX11a7XK1pIzTd0yskxz3pyeSO/0F1Ix0Gny4lLJ9uzElXKjIEhKK6/2jyX3haWRBAcKrQcX1ZaXkPPPYFamGImg1/1GOjHqT0qRMukbNIyPqIIWxiVbZUtfuIXb6lX1yXSiCLnPHsv3+eRQnZzFo42ySog+TV6VsvZszLR4bSuahsxXX6hR6LHyKfc8uJudkAo7e7kiD0a4sk6oyb90BloztT6CnK6OX/Eqf1mE0C/Aqz/Ppjt8ZfEtDRnVrybm0XJ757zY2vlDRoHx34yFubRFyRTpWZeQdg3jg3ruZPvudayoHoeA86imKFs5A5mTg+tIHGE/EoKZU+FzpT5+W/+3Q5y50Yc3Kj8s2/wiOTjjedkfNchRB57lj2Xn/PIqSsxhoqaP8OtZRt4VPsf/ZxeRa6kitoY6qym01fxxHRs2hNCmTyKh5pEcdpKiK3LS1e4id/kXdyiwvWyH49QlceHgmhpQMmq5+n/wtMZSdtf695v2yk5Q3qjf6Q9+ZTMaiVRTuPopwdbY7LCcUQfc3Hyb63/MpSs5i+IZZJEQfIvdMklU+vZszbcYNIf3w2WpldH19NInbjtWojlAEfeY8zNoH5lOQnMWo9bOI33SI7CpyHNyciRg3hJRKcoylBva98wM+rcLwbRVWoxwAFIWg158iYewMDCkZNPnxA/K32rZd6qzFVueK9h0n/u5nzcV4udN88+cU7jpsR46gzfxHOTTqTUqSMukRNZf0qEPV4o7OzZlGjw8j59CZ8nNhDw4AYG/fKTj6edJ5+VRihswAaaOeFIWQWU8SP+YVjCmZNFv7Hnmb91FaRZ/cX34j6TXbsfvsnc/b1qGqnDcmEP/QTIwpmTRd8z75duQkv17d58LemUzaolUU7jqK4upc82IVIXDs+29KV3+ILMjG+V/TMMUdR2Yll2cx7Pyeyw9WfYe+KP7h5ttsfAtKQENKlr8JOj1O903GdOEPKCupXccbwd9gyFtblHODEUL0BIYDnaWUEcBA4CKwDGgNtAdcgCts/YCU8o6aGpO10BGo5QlbHdeOLSg9n0zZxVSkwUj2ut/wGtT9Km/BPvqWbTAlJaKmJIPRSOmOrTj2uM0qj/PQuyhetxpZUACAzL1aU5jx7Nyc4vhUSi6kIQ0mUtfswW9o12sq8zI+nZqRfz6VwoR0VIOJhLUxhA7pUi1f+5fv49TCdZhKy8rPBfVpT86fCeScNG/oW5ZdUGOQ/f1SJuG+HoT5eOCg1zGkfSO2/2kdzAVQWGIOswUlZfh7uJSnbT15kRBvd6sG6NUQ2bE9Xp4e11QGgNK4JWpGEjIzBUxGjId3oo/oaTe/Q5c+GA7tKD82xR6D0uJa5fh0akaBpY6kwcRFO3XUzkYdBfZpT+6fCeRWqqO6PiA8OzenKD6l3O/S1uzB/zr5nUuHlpRdSMJwMQUMRnLX78RjYI86XevYPByh11G4+ygAsqgEWVJqM6+fxb8LLP4dvzaGhjZs13nKffy+aD2mEut354ZDulCQkE7O6cRq11QmsGMzcs+nkmeRc+bnGJoOri6n+4v3cXjRekyVeoiNxaUkH4i1OlcTLhHWtsv7ZSceA+z7nT08h95Gwc6Ddm3nZan/Ykv9p6zZQ8DQyGr5mk8dRfzCn1Er2c6tZShZu/4AoCwjD0Nekbm30gauHVpQdiEZgyV2567biecNiN0uHVpSWlnO+p14DKqbzzk1Dwe9QuEus8+pNfgcgBLYGJmbhszLANWEMfYAuqYRdvPrWnbFGGvuW1F8gjElnjHv/2gsQ2YkomvUzu61NxxVXr9/NwmtQXnjCQYypJSlAFLKDCllkpRyg7SAuYeyDq/M1gghzgsh/Cx/vyKEOC2E2CWEWCGEeLFS1n8KIfYLIWKFELcLIRyBWcD9QoijQoj76yrTIcgXQ3JG+bEhOQOHoOpfAGkwrCetfv2IxotfxiHYr/y84uRIy3Xv0mL123gNth/MFD8/1PSKYQ41Ix3F188qjy40DF1oOF7vLMTr/UU4dOlWkejoiNeHS/F6fxGOPa0bovZwDvKhJCmz/Lg0KROnoOpfUgkY3p1u296i/WeTcAqp29dPXIJ8KE6sKLsoOQuXKmV7t2+MS4gvyVuOWp33aBYMEnqveJnB0XNo/dTwGmWl5RUT5FXxhYxAL1fS8q0bVE/2j+CXY/EMfvsnnvnvdqbeaX6AFZUa+GrXSZ7s175OetUHipcvanaFz6nZGQgv23YX3gEI3yBMp2vu6bKFS5APRbXUUYP2jXEN8SXFTh3dvuJlBkbPoVUtdVQZpyAfSqv5XfWvOfkP7063bW9zy2eT6+x3+kDr36sxJQOHwOrXegy9laa/LCRs4TT0lt+rU5NQTHmFhC2aQZOfPyJg6qOg2H5kuAZ5U5iUVX5cmJyFaxXb+dzSGNdgHy5VsZ3e1Ylbnh7O0fd+qlUftyBv8ivJKUjOwq2KHP9bGuMR4sOFrUerXn5F6IN8MVaOdSkZ6G3YznPIrTRZ9zGhC6ajD/Krnn5nH/LW76h2/jJV405JUla1+vdo3xjnEF8yNh+xOp9/MgH/IV0QOgWXhv54RjTB2Y5v6KvG7pRMm7Hbc2gvmm/8iIaLplaL3c3Wvkezn97Gs4YGovkZkV5+bEy27XOeQ3vRfMMCwj+eVi7H0eJz4Yun02zdhwROfcSuzwEId29kfnb5sSzIQbjb/vqV8PBB8fJDvXgKADXjkrkBqXcAZzeUsJZ2r9WoG9qQ940nGnhVCBELbAZWSSnLo4sQwgEYA9RhLME2QoiuwL1AB8ABOAxUngyil1J2E0LcAbwmpRwohHgVG8Po14PczQfI/nknssyI7wNDaPjeRM79eyYAJ3uNw5CahWN4IM1XzKH41AXKElKuSo7Q6dCFhpH78vMofv54vb2AnAmPIAsLyH74ftTMDJSgYLzmv4/xfBxqclLthdZCevQhUlbvRpYZCR0zkLYLnuLIvbOvuVyEoOPro9n3fPWhJqFT8OvWkk3DXsFUXEbf76aTdTyeNEvPxNXw6/Hz3N25GQ/d2oZjCenM/HEPPzwznCXbTjC6Z2tcnRyuRZubhkOX3hiP7roxX50Qgg6vj+ZADXW02VJHfb6bTvY11lFlMqIPkWrxu5AxA2m74GmO3DvrupRdsGUfeeu2I8uMNPj3UELfnsyFB6eDTodr13bE3fUchqQ0wj6aSoN7B5LzffSVCxGCbq+NZtek6rbr+MI9nPz0V4xF9nuirkTOba+OZvPk6nJuBAVb95G33mK7fw0j5K0XSHhoWnm63t8bp1aNKfjtGubmCUGrNx7i9+cXV0tKWr4N9xahdI+eS8mlDHIOxCKvYXFH/pb95K7bgSwz4vPvoYS9M5H40ebYfeq2RzGmZuEQHkjT5W9Scvr8VcfuynK8/z2U0Lcncf7BGQi9Dreu7Tg7/DkMSemEL3gZ7/sGkP3dpqvW6TK6lpEYzxwunw6gJvyJKbAxzqOmIIsLUJPjb+rXaqStaQp/MbQeyhuMlLIA6AKMB9KBVZY5kZdZBOyUUv52DWJuBdZKKUuklPlA1Vnql1/9DwGN61KgEGK8EOKgEOLgjwUV8xYNKZlWb60OwX7li28uY8rJR5aZ549lrtyE6y0V89kMqebehbKLqRTE/I7LLbaHZ9SMDBT/gPJjxc8fNTPDKo8pI52ymN1gMqGmpmBKvIgu1NzRezmvmpKM4fhR9M1a1KpzSUqW1du9U4gvpSnZVnmM2QXluiUu24JnhO37r0pxShYuoRVluwb7UFypbAd3Z7xah9P/p5kM3/8Bvp2bc/tXL+DdoQlFyVmkx5yiLKsAU3EZyVuP4t2+sV1ZAZ4upOQWlR+n5hYRUGlIG2D1oXMMvqUhAB0a+lNqVMkpKuXEpQw+iD7CsHfXsGzvKT7f+QcrY07XSccbhZqbieJdqafE2w+Zm2kzr75LHwwH7fcG1URxShauNdSR3lJHfX+ayR2WOrrVUkfFNuqoQQ11VJnSlCyrHkez32VZ5ansd0nLtuBRR78zplr/XvVBfuULIS5T+feasyoa51uam69NyaDkZJx5yNekkr9pL87tmmGLopRs3EIqetXcgn0oquLfDVqHMfSHGdwX8z7+nZsx4MvJ+EY0wb9TcyJn/Iv7Yt6n7WNDiHj2blqPHWRTTmFKNh6V5LgH+1BYSY6juzM+rcL4x3czeGjP+wR2asadX0wmIKJJnexVGWNKZnlvLYBDkF/5wqXLWNnuu6hy213G447e5EfvAaP9b11XjTvOIT5W9a93d8a9dRhdf3qV2w8swKtLczp+8yKeHZoiTSqnX/2GmAFTOfrwOzh4uVF0LtmWGIxVY3eQb42xO2tVNC6V9DFaYrfhYiqFMb/j3M62D5qfEf4V9x9cs89lr4rGpb1ZjiH5ss+lmn0uOsauzwHIgmyER0WvonBvgCzItplX3zISU+wBq3PGAxspWf4mpas/BAFqjv3FPzccbchboy5IKU1Syu1SyteAZzD3JiKEeA3wBybf4Fu4/Opvoo690lLKT6SUkVLKyHvdG5WfLzp2BqcmITiGByIc9HjfdTt5m/ZZXasPqPiBew3qRsnZSwDoPN0QjmbxOm8P3CLbUFJlMc9ljLGn0IWEoQQGgV6PU5/+5sZjJcr27sIhoiMAwtMLXWg4puQkhLs7ODiUn3do2x5Twvladc4/cg7XpkE4N/RHOOgIHNmLjCirtUw4BlQs/PEfEknhmZrnfF0m62gcHk2CcAv3R3HQ0XBEDxKjKnotDPnFrGn3JOu7TWR9t4lkHj7Lb2PfJftYPCnbj9OgTTg6F0eETsG/R5tqi3kq0y7Ul4TMfBKzCzAYTUSduECf1tYzKoIbuLLvnLl3IS4tlzKjCW83J758bDAbXxjJxhdGMrpna8b1bse/erSqk443CvVCLIp/CMI3EHR69J17YzweUy2fEhiGcHVHjf/zquRkH43DvUkQruHm+g8f0YOkSnVkzC/m53ZPsqHbRDZY6mh3pTryuoI6qozZ74LL/S6gFr/zGxJJ4ZlLdSq7+Hgsjo1DcQgLBAc9XsN7U7Clyu/Vv+L36jGwe/niieLjZ9B5uqHz8QTArWcHSs8m2JSTcTQOzyZBuFv8u8mIHlyMrliEYsgvZmX7CfzQYxI/9JhE+uFzbHnkPTKPx7Pxntnl509+FsXxBT9z6ivbPVKpx+LwahyEh0VOi7t7EL+pQk5ZfjGfd5jAN70m8U2vSaQeOccvj75HWqXV5HWl+EQsjo1Dym3neWdv8rdY+52V7QZ0p+ycdTzzGl7zcDdAniXuuFjqP2hkL9Kq+N32tuP5reuz/Nb1WXIPneXoQ++QdywOxcURnasTAD692yONpmqLeS5TdPwMThZ9hIMer7t6k7d5v119PAd2o9Sij2IVuz1x7dKm2kLMcrsdj7WWM7w3+Zvr7nOKp3uFz/WKqLaYpzJq6gVEgwCEpy8oOvQtu2KKO14tn/AOBGc31OS4SicFOLuZ//QLRfENRb1gf4W8Ru1oQ943GCFEK0CVUl5emtcRuCCEeAwYAgyQ8pr72XcDS4UQ8zDX6XDgk1quyQeufMWESeXSq0tp+s3rCJ1C1nebKTlzkaDJD1B0/Cx5m/fjP/YuPAd1A6MJY24+CS9+AIBTi3DC5z5lfoNSBKmLf7QblFBNFCz+AK8574BOoSR6A6aE87iOeRRj7CnK9u3BcGg/jp270mDp12BSKfx8MTI/D32bdrg/+6J5+EIoFH23zGp1uD2kSeX0tC/otHI66BSSV2yn8PQlmk75J3nH4siIOkT448PwG9wFaVIx5hRw8rlFdTKbNKkcnv4VfVa8bN6SZuUO8mITueWle8k6Fk9StJ0VoIAht4jTSzcyaONskJKkLceqzbOsjF6nMHV4JBO+3oqqSkZ0bkbzwAYs2nKMtiG+9G0TxuShXZi1NoZle06BELxxT0+EEHXSpa689Np8Dhw5Tk5OHgNGPshT48Zw711DrrwgVaXku8W4Pj0HhIIhJho1JQHHOx/ElHAG0wnzw0pfZTHOZVwmvoUSGI5wcsZt9jeULP8A05/V7S1NKkemf0VvSx3FW+qonaWOkmupo9ilGxlgqaPkLceqzbO0hzSpxE77go4rZ5i3q1qxjcLTl2gyZRT5x86REXWIsMeH4Tc4EmkyYcwp4M86+h0mlZQ3FtPwq9kIRSHnh02UnknAf+KDFJ84Q8GWffg8fDfuA7qDyYQpt4CkKe+br1VVUud9TqP/zgUhKPn9LNmromyKkSaVmJlfM2j5FISicHbVDnJiE+n44r1kHovn4ib7trsSpEll5ytfM+LbKeZtg1btICs2kW4v3Eva8XjO1yLnoT3v4+jhguKgp+mQSNaOnl9thXg5FtuFfzHHvG3QD9GUnU3A7/kHKTlxhoKt+/B+aAQeA7ojjSZMufkkvfxe+eUOoQHog/wo2n+iVp1OTfuSziunI3QKiZb6b2aJO+lR9ofLHf286LJyGlKVlKZkceKZj+0LMqkkvbaEJt+8Yd7O5/vNlJ5JIGDSaIpPnCF/8358x96F58DuSJMJU04+l178EADn5uGEvvk0UkqEEKQv+cF+Q8+kkvT6Ehp/PQuhKGR/b/a5gIkWOVv24zv2bjwGdEOaVLOcl8zPCFSVlHmf0+TbN0EIik+cJXulbZ8zG0+lbPsqnEY+Z9426OQeZFYyDj3uQk29gCne3LjUt+xarXcSRYfzfealBrKsmNKoL2/qkPffYZW3+DuM2/8vI4ToAiwAGgBG4Czm4e8U4ALmhh3AT1JKm5OiLEPkC4HKy5h7ALswz4PMEEK8jnlrolQgDfhVSvlp5W2DLAt4DkopGwshfIAozHMu50kpV9nT4Wiju+vFScLa5taHGI4dDqoXORlK/byv3f1h/fUg6vs/WC9ySl6/7lN7bfLrj/U3Cd9Xrdvq4mslyL2wXuTsL6kf2xXU4zjaAOes2jNdBy7medaLnGDX+vEFIeqvHdH0+Stev3pVuD6/5Pq+YddC7iMDr5sRvb7cXK/3fhmth/IGI6U8BPSykVRn20spvwK+spHUuNLf70gpXxdCuAI7fo9wXAAAIABJREFUsSzKkVL2rVROxuVrpJRZwPXZm0RDQ0NDQ0Pj/zVag/LvwydCiLaAM/C1lPL6jDFpaGhoaGho3Fj+BkPeWoPyfwghxCNU3z5ot5Ty6dqulVI+cGPuSkNDQ0NDQ+OG8tf/lLfWoPxfQkr5JXBl3/TT0NDQ0NDQ0LjJaA1KDQ0NDQ0NDY2bSI3fLP+LoDUoNTQ0NDQ0NDRuJlqDUuP/A/W1nU9Jlq5e5HToeHWfC7tS8pKc6kVO8ux0gid3rBdZ9bWdj/PrC+tFTqetE+pFDkBCple9yNlXT9v53OqZUXum68Cf2dW/a36jCIion212Dh+pH510Ra71Iifcp36eEQDotWbL/ypazWho/MWpr8akhoaGhsYNQluUo6GhoaGhoaGhcS38HeZQat/y1tDQ0NDQ0NDQuCa0HkoNDQ0NDQ0NjZuJNuStoaGhoaGhoaFxLWhD3hoaGhoaGhoaGv/v0XooNTQ0NDQ0NDRuJtqQt0ZdEELMAB4ATJjd5glgPBAJCCAWGCulLLBz/etAgZTynSrn90gpe9Ui+zwQKaXMqHK+L1Ampdxzpfo4dOmG25PPIhSFkl9/ofj75dXyON7eD9cHx4KUGOPOUfDWbAB812/FdD4OAFN6GvlvTLcrx6lHVxpMfgahKBT+vIH8b1ZUy+MyoA+ejz8MEgxnzpH16psA+H0wH8db2lJ67ASZL8yoWZ9Iiz46hZKNv1D8nQ19elv0waLP/NnlacLVlQaffE3Z3l0UfvyhXTkut0bi+/IEhE4h76dfyf18lVW6+4hB+E5+HGNaJgB5K9aS/9OvAPhMGofr7d0ByF66jMKoHTXqtDsulbc2n0BV4R8dGvJoz5ZW6cm5RbzyyxHySwyoUvJc37bc3iyQvfFpfLT9JAZVxUFRmNSvHd0a+9uVo2vTBef7ngBFwbAnirJN31ulO93zOLqWEWY7OToj3L0omDLKbI+nZqFr3BpT3EmKl7xeoz61MXPue+zcvR8f7was+XbJVZfjelskftOeBJ2OvB82kvPZd1bpHiMH4ffiY+V1lLvsZ/J+NNeR7wvjcO3THSEERXsPkzF3cZ3l+vTrQIs5jyB0CsnLtnBhwVqr9KD7+9D81TGUpmQBcOmLX0letrVOZYf2jaD7rDEIRSF2xXZOfLzOZr5Gd3Sl/6fP8/OwV8g8Ho9fx6b0emscAELAkXdXk/DrQbtyXG/rQsD0CaAo5P7wK9lVbOc5chB+L43DmGq2Xc7ydeT9YLad34vjcOvTDYSgaM8R0muwXUC/CNrPfgh0CgnLtnFmoW19gu/sSrfPJ7FjyAxyjsUTds+tNH/qzor7aduQ7YNmkPfHBbuyHLp0w238s6AolET/QomtWHdbP1xGjwUpMcWfo+Btc2zw+XkrpgvmWKemp5E/y36sC+4bQeRscx2dXbGdk3Z0Cr+jK70/e56NQ18h63g8bmF+DN/xFnlxyQBkHjrL/ql1+3qvT78OtJwzFqFTSFq2tZrPBd/fh+avPljJ56JIqqPPQf35w+7zGby98zSqlIxsF8qjkU2s0t/ZeZoDl8w6lBhVsorK+O3JfgB8uPsMv8WnA/B4t6YMaRlUZ/2uN1JrUGrUhhCiJzAc6CylLBVC+AGOwCQpZZ4lz3vAM8D8Kym7tsZkLfQFCoAra1AqCu5PTyR3+guoGek0+HApZft2Y0qoCMpKSCiu948m94WnkQUFCK8GFdeXlZLzzGN1kuP90vOkP/sSprR0Ar5aTPFvezDGV8jRh4fi8fADpD3+HDK/AMW7Qk7+t6sQzs64/WN43fSZZtFnwVLKYuzoM9mGPoDrQ+Mw/H68Vjl+M54hefxUjCkZhK5cQNG2vRjiEqyyFUTtIHPux1bnXG7vhmObFlz655MIR0eCv3ibol0HkIVFNkWZVMm86OMs+VcvAj1cGP3VDvq0CKKZn2d5nk/3xDK4dQijOjfhXEYez3wXw8anBuPt4siH93UnwMOFs+l5TFi1l03PDLGtk1BwHvUURQtnIHMycH3pA4wnYlBTLpZnKf3p0/K/HfrchS6sWflx2eYfwdEJx9vuqNl2dWDkHYN44N67mT77ndoz20NR8J/5NImPTcOYmkH4qgUUbovBcM66jvI37iTjTes6cu7YFudO7bg48kkAwr59F5euERQfqMUvABRBq/njODJqDqVJmURGzSM96iBFsYlW2dLW7iF2+hdXpJJQBD3efJiof8+nKDmLuzbMIiH6ELlnkqzy6d2caTtuCGmHz5afyz51iXXDXkGaVFwCGjBi05tc3HQYabLx5FMUAl55msRx0zGkZtDou48o3BZDWRXbFWzcSdqcRVbnnDu2waVTWy6MMG8yH76sBtspgoh5j7Bn1DyKkzPp8+scUqIPk1/FVno3Z5o+NpSsQ2fKz136aTeXftoNgEfrcLp/NbnGxiSKgtuEieTNNMcGr/eXYojZjemidWxwGTWavJdsx7rcZ2uPdUIRdJ37MFv/Za6joRtmcSnqEHk26qj1Y0PIOHTW6nzBhVQ2Dqr5pbm6boJW8x/lyKg3KU3KpGvUPDKiDlJYxY6pa/cQO71uDVTr8uvHH0yqZP72Uyz+R2cC3Z0ZvWoffZr408zXvTzPi71blf+94lgCp9PzAfgtPp0/0/JY+UAPDCbJYz8e5NZGfrg7ac2iq0WbQ3njCQYypJSlAFLKDCllUqXGpABcgCuekSuEKLD8rwghFgkhTgkhNgkhNggh7quU9VkhxGEhxAkhRGshRGPgSWCSEOKoEOL2usrUt2yDKSkRNSUZjEZKd2zFscdtVnmch95F8brVyAJzh6vMzblS1XBs2xrjpURMSWY5xZu24tLbuv3sNuJOCn5Yi8w3y1GzK+SUHjyCLLLd4LLSp1UVfbZvxbFnFX2G2ddH17wlirc3hkMHapTj1L4VhoQkjJdSwGikcOMO3PrV7X3AsVkjSg6dAJOKLC6hLDYe19si7eb/PTmbcG83whq44aBTGNI2lO1nrL8OJAQUlhkBKCg14u/hDEDroAYEeLgA0MzPg1KjiTKjyaYcpXFL1IwkZGYKmIwYD+9EH9HT7n05dOmD4VBFz6op9hiUFtfJBrUR2bE9Xp4e11SGc+U6Mhgp2Lgd9/729bFCSoSTI8JBj3B0AL0eY2Z2nS717NycovgUSi6kIQ0m0tbswX9o12vQpAK/Ts3IP59KQUI6qsFE3NoYGg7pUi1f5yn3cWLRekwlhvJzppKy8sajzsmhxgjlHNEKQ0IyBovt8jbswK2utgMr2wm9DpMd23l3ak5hfCpFCWZbJa7ZS5ANfVq//E/OfrwOtdRgoxQI+0cvEtfsrfGeqsW6nVtxqBrrhtxFyfpri3W+VerowtoYwm3o1GHKffzx8XpMdnS6Ejw7N6c4PrXc51LX7MHvOvkc1J8//J6aS3gDV8K8XM2xrkUQ2+PS7Zb76+kUhlp6IeOyCukc6o1eUXBx0NHCz509F+rn6082Ua/jv5uE1qC88UQD4UKIWEujr8/lBCHEl0AK0BpYcA0y7gEaA22BMUDVX26GlLIzsBh4UUp5HlgCvC+l7Cil/K2ughQ/P9T0tPJjNSMdxdfPKo8uNAxdaDhe7yzE6/1FOHTpVpHo6IjXh0vxen9RtYabVRkBfphSK+SY0jLQ+VsPveobhuHQMAz/Tz7C//OFOPW48oCo+NrQx6+KPmEWfd5biNcHi3CItOgjBO7jn6Lw09qHNvUBfhhTKgKdMTUdXaBvtXxuA28j9MclBLz7CrpAs75lp+NwvTUS4eyE0sATl24d0AfaH4ZOyy8hyNIoBAj0cCEtv8Qqz5O3teaXPy4y+OMonvkuhqmDIqqVs/l0Mm0CvXDU2/4kpuLli5pdEYDV7AyEV3WdAIR3AMI3CNPpY3bv+2ajC/TFULmOUjLQBfhVy+c++FbCVy8m6P2Z6IPM9VBy7E+K9x+j8Y4VNN6xgqLdhzDEXax2rS2cgnwoTcosPy5NysQpqPqn+fyHd6fbtre55bPJOIXYtnNVXIO8KUzKKj8uSs7CLcj604y+tzTGLdiHS1uOVrver1MzRm6dz8gt89gz9UvbvZOAPsC3in9n4GDDv90H30ajNYsJ/mAG+iCzbUuO/knRvmM03bmcpjuXU7jrEGV2bOcc7E1xJVsVJ2fhHGxtK6/2jXEJ8SV1c3V9LhM6ogeX1tQ8OKP4+qFmWMcGnZ1Y5/n2QjzftRHrPlhqPt/DfqxzCfKmqEoduQRb15F3+8a4hviQZKOO3Bv6Myx6DgN/nIF/t1bV0m3hHORDSTWfq/7JzoDh3em27S3afzapzj4H9ecPaQWlBLpXfOI20N2J9MJSm3mT8opJyiuma5jZX1r6ebDnQgbFBhPZxWUcvJRNSkGJzWvrA6lev383C61v9wYjpSwQQnQBbgf6AauEEFOllF9JKR8RQugwNybvB65ibAGA24DvpZQqkCKE2FYl/SfL/4cwNz5rRQgxHvM8T95t14KHwoPrfDNCp0MXGkbuy8+j+Pnj9fYCciY8giwsIPvh+1EzM1CCgvGa/z7G83GoyUm1F2oLnQ59eBjpEyahC/DHf+kHpD4wDllwfb/HW67PSxZ93l1AzhOP4DRgEGUH9qFm2H8jvhKKtsdQsGE7GAx4/PNOAt58ieTHplC89xBOt7Qk5L8fYMrOpeTYn0j12qLGrycvcfctDXmoe3OOJWYxc90hfnisP4oQAJxNz+PD7X+w+P5rmVVRgUOX3hiP7vrLTxQq3BZD/i/bwWDAc9QdBMx9kaRHX8ahYQiOTcM53380AKGfzaOoyy2UHPr9usjNiD5E6urdyDIjIWMG0nbB0xy5d9a1FywEXV8bza5JS23LPXKONf2n4tU8hNs/eILEbceuuoesYLvZdtJgwGvUHQTNe5FLj0zFoWEwjs0aEtfvQQDCPp9H0a6DFB/646r0ueWNBzn8vP15tN6dmmEqLiX/1KWr0sMKnQ5dSBh5U82xwfM/C8h92hzrch6piHWec98n73wcaspVxDoh6PLaaPZOrF5HxWk5rO46kbLsAnzaN6b3l5NY33cqxoJr7/lPjz5EisXnQscMpO2Cpzhy7+zaL6wj9eIPlYiKTWFA80B0ijnG9Wzkyx9puYz9fj/eLo5EBHuhs8Q/jatD66GsB6SUJinldinla5jnSt5bOQ1YWfncDeDyK5uJOr5ESCk/kVJGSikjKzcm1YwMFP+A8mPFzx8103qYwJSRTlnMbjCZUFNTMCVeRBcaZr7ekldNScZw/Cj6Zi1syjelZaALrJCjC/DDlJ5eJU86xb/tAZMJU3IKxoRL6MPD6qJehT6ZNvTJqEWfS2Z99G3a4Xz3P/D+eiVuj0/AacAQXB8db1OOMS2jvDcLQB/ojyk10yqPmpsPBvPDOv/HjTi1rbBNzqcrSPznBFLGT0UIMFyw/zAM8HAmJb/igZKaX0yAZUj7MquPJzC4TSgAHUJ9KDWq5BSVmfPnFTP5p/3MHt6ZcG83u3LU3EwU74oeG8XbD5mbaTOvvksfDAdrXkh0szGlZuJQuY6C/DClWftC5TrK++FXnNqZ68htYC9Kjp1CFpUgi0oo/O0gzh3a1EluaUqWVe+PU4hv+UKIyxizC5CWKQpJy7bgEdG0TmUXpWTjFlLRg+ca7ENhSsXwoYO7M96twxj6wwzui3kf/87NGPjlZHwjrBc25J5NwlhUQoNWtn9fxrTMKv7th6Gqf+fkIy22y61kO/eBt1ax3QGcO9q2XUlyNi6VbOUS7ENJcoWt9O7OeLQK57afXmHQgQ/x7tyc7l+/SIMOFfqEjuzJpdU1D3eDJTb4WccGU5VYp2akU7avIjaoiRdRQmzEuhP2Y11xSjauVeqoONm6jrxahzHwxxmM2Pc+fp2b0eeryfhENEEtM1KWbR5uzzpxnoLzaXg2rX1hSUlKFs7VfM56WLmyzyUu24JnHX0O6s8fAtydSC2o6JFMLSjF383JZt6o2FSGtrK2zWNdm7LqgZ4s+UcXpISG3q511vG6ow15a9SGEKKVEKJyJOkIJAghmlvSBXA3cOoaxOwG7rXMpQzEvOCmNvKBK550Zow9hS4kDCUwCPR6nPr0Nze2KlG2dxcOER0BEJ5e6ELDMSUnIdzdwcGh/LxD2/aYEs7blFP25yn04aHogs1yXAb1p3in9UOgeMdunDp3AEDx8kTfMAxTYvKV6XP6FLrQSvr0taHPnir6hJn1KfjPHLLHjCL74X9R+OliSrdEUfTFJzbllP5+GodGoehDzXLchvWhcLu1Pjq/Sg+Vvj0pu7xgR1FQvMxV5diyCY4tmlK855BdndoFNyAhq5DEnEIMJpWok4n0aW4dSIM9Xdh33txAj8vIp8xkwtvVkbwSA89+H8PzfdvSKazmIS71QiyKfwjCNxB0evSde2M8HlMtnxIYhnB1R43/s8bybjYl5XUUCA563If1pXCbtT6V68itX4/yRVXGpHRcukaATgG9Dpeu7Svqrxbyj5zDtWkwzg39EQ46Akb2IiPKejW1Y0DFYg+/IZEUnqlb71rG0Tg8mwThHu6P4qCj6YgeXIw+XJ5uyC9mRfsJ/NBjEj/0mET64XNsfuQ9Mo/H4x7uj9CZHxFuob54NQuh4KLt3viSE6dxaBRSbjvPO/pUt51/he3c+/cot48hOQ2Xru3Lbeca2Z6yc7aHOHOOnsOtaRCuFluFjuxJSnTFb8GYX8yv7Z5gU9fn2dT1ebIPn2Xfw++QcyzenEEIQu7uUev8SbDEusqxoXd/DPuqxIaYXejbV8QGJTQcNcUS6/SVYl0b+7Eu82gcHk2CcLPUUaMRPbhUpY5+vGUCa7tPYm33SWQcPseOse+RdTweJx8PhKXHzb2hPx5NAilISLMppzJmnwsq97nAWnzOf0gkhWcSqxZjl/ryh3aBniTkFJGYW2yOdWdS6Nu0+nSg+KxC8koNdAjyKj9nUiU5xeaX6NiMfM5k5NOzYd2H9a832pC3Rl1wBxYIIRoARuAs5gUxq4UQnpi3DToGTKilnJlCiImXD6SUlbsKfgQGACeBi8BhILeW8tYBPwghRgDP1nkepWqiYPEHeM15B3QKJdEbMCWcx3XMoxhjT1G2bw+GQ/tx7NyVBku/BpNK4eeLkfl56Nu0w/3ZF80eLxSKvltmtZraCpNKzjsL8PvoPwhFR+G6jRjjz+M5fixlf8ZS8tseSmMO4Nw9ksCVX4BJJXfBUtS8PAD8l36AvlFDFBcXgtatInvO25Tus7HliWqi4OMP8Jr7jmVrkA2YLpzH9SGLPjF7MBy06PPJ16CqFH5q1ueKMKlkzF1I0JK5CJ1C/uooDOcu4P30Q5T+EUvR9hg8R4/ErW8PpMmEmptP+ivmFctCryPk6/fMt1tQRNq0+WBnLhuAXlGYOjiCCav2okrJiIiGNPf3ZNHOP2kb3IC+LYKZ3L8dszYeY9mBcyDgjTs7I4Rg1aE4EnIKWbr7NEt3nwZgyf298LH11q+qlHy3GNen54BQMMREo6Yk4Hjng5gSzmA6sc98P1UW41zGZeJbKIHhCCdn3GZ/Q8nyDzD9ebhavrrw0mvzOXDkODk5eQwY+SBPjRvDvXfZWZ1uD5NK+psfE/LpXISikLc6mrKzF/B55iFK/oilaFsMDcaMwLVfTzCaMOXmkzr9XQAKon/DpUcHGq5ZCkiKfjtI0fZ9dRIrTSqx076g48oZ5i1cVmyj8PQlmkwZRf6xc2REHSLs8WH4DY5EmkwYcwr487lFtRdsKTtm5tcMXj4FoSicWbWDnNhEOr14LxnH4rm4yb69A7u1pP3Td6EaTaBK9k7/itJsmzubmW03ZxFhn70JikLeT2bb+T47hpLfz1C4LQbvB0fg1r9Hue1SpllsF7UL1+4dabR2CUhJ0a5DFNqxnTSpHJ/+FT1XTEXoFBJWbCf/dCKtp9xHztE4UqJr9h/fnq0pTsqkqA6NLlQThYs/wHO2OTaUbjLHOpcHH8V45hQGS6xz6NQVr8Xm2FD0RUWsc3vmRVBVUBSKf1hmtTq8qk4HZ3xN/+VTEDqFcyt3kBubSMRL95J5LJ7EGnQK6NGaiJfuLa+j/VO/pCyn9ik/0qRyetoXdFo5HXQKySu2U3j6Ek2n/JO8Y3FkRB0i/PFh+A3ugjSpGHMKOFlHnwPqzR/0isLLfVvx1NrDqKpkRLsQmvm6syjmLG0DPOnb1NzDHBWbwpCWQYhKQ9pGVeXRH8zPBHdHPW8OaY9e0frYrgUh5V//cz8aIIRwt8zX9AX2A7dKKVNqu64uZAzrUy9OUpJle/HH9ca5ge1Vy9ebvCTbQy/Xm+DJHetFDoDxOs0JrA3n1xfWi5wLvWt7j7t+JGR61Z7pOnBB71gvcm71rJ8VsX9mV1+gdKO4rUvde+GuhV+PhNeLnCDTta8IrwvhPrX1X1w/wp5pXi9yXJ9eWK8TKtMGXL/nbMCWHTdlMqjWQ/n3Yb2lF9QRmH29GpMaGhoaGhoaN5a/+HpFQGtQ/k9h+aLOP6uc/l5K+WZt10op+96Qm9LQ0NDQ0NDQqAWtQfk/hKXhWGvjUUNDQ0NDQ+NvhPzrb1mkNSg1NDQ0NDQ0NG4if4chb21Jk4aGhoaGhoaGxjWh9VBqaGhoaGhoaNxEpPrXH/LWtg3SqJVbQ/vXi5MM0tf9847XwgVRP99rbSVdas90HehVavvbtTeCVFE/W9J08q6fLWka7az9O+zXi0e7vFgvchxE/Qw87S2q28bt14qHvn5+RwDppTn1IifEuX420O7kUH2T7xvBcUP9/F4BbnUIrBc5884vr9cWXlKvftftORuyZ9tNaZ1qQ94aGhoaGhoaGhrXhDbkraGhoaGhoaFxE5HaKm8NDQ0NDQ0NDY1rQVvlraGhoaGhoaGh8ZdCCDFUCHFaCHFWCDHVTp5RQoiTQog/hBDLaytT66HU0NDQ0NDQ0LiJ1OcqbyGEDvgYGARcAg4IIX6WUp6slKcFMA24VUqZLYQIqK1crYdSQ0NDQ0NDQ+MmIuX1+1cHugFnpZRxUsoyYCUwokqex4GPpZTZ5vuTabUVqvVQalwx3ft2ZeKsZ1AUhXUrNvDtxyus0u8ffx93/fsOTEYTOVm5zJ38NqmJqQC8++182nVuy/EDJ5jy8Iwa5TTvE8HQ18ag6BQOr9zOrsXrrNIjRw+g60ODkCaVsqIS1k37nPQzibQf2Ytbxw8vzxfYJpyld84k5eSFWnW7pU9HHnj1URSdws5VW9iweLVVet/RgxkwZiiqqlJSWMLX05aQdPZSreUCNOkTwUCLPsdWbiemij4dR/encyV9fp32OZlnklAcdAydO46giCagqmx+41sSYv6sUZZ3v440m/0IQqeQsmwLFxeusUoPvL8vTV4dQ1lyFgBJX2wkZflWsw2Wz8CzSwty95/ijzHza5QT2C+CTrPGIHQKccu3c3rhOpv5Qu/sSq/PJrJ56Eyyj8UD4NUmnC5vjUPv4QKqZPOwV1BLDTavd70tEr9pT4JOR94PG8n57DurdI+Rg/B78TGMaZkA5C77mbwffwXA94VxuPbpjhCCor2HyZh79VsFzZz7Hjt378fHuwFrvl1y1eUAtO/TiTGvmX1t+8rNrK/ia0Mfu4u+/xqIyWgiPyuPT1/6mMzEdADunzqGjv27ALDmo+/Zt353nWSa/dvsF7+t2sKGxdZ+0Xf0YPqPGYKqqpQWlvD1tKV19u/b+vVg+psvoOgUfvh2LZ8t+MYqPbJHJ6bNmUTLts15YfxMoteb/a3brV2YOntSeb6mzRvxwhMz2bJxR53k9ujbjRdmP4uiKKxd8QvfLLQemXtg/CjufuBOczzKzGH25P+QYolHtdG7fy9em/cyiqKw6tvVLPnwC6v0bj0788qbU2jdrgXPPfYyG9dtLk87m3aY0yfPAJB0KYXHH3zerpz6iqlt+nTgvlfHougU9qzayqbFa63Sbxs9kN6V6n/FtE9IOZtI69vac/fLD6B30GM0GFkz91ti9/5hV063vl15btbTKIrCLys2sOzjlVbpo8bfx/ByfXKYP/ltUhPTaN6uGZPnTcTN3RXVpPLfBcvY+vP2GnVq2SeC4a8+hKJTOLBqGzuqxNVuowfQc8wgVFWlrLCU1dM+I+1sIgBBrcP5x9zHcHJ3QaoqH494BaOdGPRXQggxHhhf6dQnUspPKh2HAhcrHV8CulcppqWlrN2ADnhdSvlrTXK1BmU9IISYATwAmAAVeEJKuc+S9hHwqJTSvYbrXwcKpJTvVDm/R0rZqxbZ54FIKWVGlfN9gTIp5Z4r0UVRFF5483km/vsl0pLT+WzDYnZF7+H8mYrG2pnfzzJu2ARKS0oZ+dDdPD1zPK9OmA3A8iWrcHZxZsSDw+2JMN+fIrhj9lj+O3oeeSlZPP7zbE5vPkz6mcTyPCfW7uHgsi0AtBrYmSEzR/Ptw29xYs0eTqwxqxXQKpx/fTqpTo1JoSiMmfU47zw4i6yUTF79+T8c3XTA6oEas/Y3tv8fe+cdFsXV/u/77NJFlCZNFBV7w15j78Y0U23EElPUJJqY2DX2VJM3icb0mKjR+CYREo3Ye0dRYwEUFGGX3uuye35/7AossIBK8P3mN/d1cbE7c+Z85pk559lnTpuNIQAEDOrMswuf56PA5VXIWzBkWSA/j11NpjaF54OWErHnLMkRcUVpLm8/zvmNxh9Z/0EdGbhgHFsD3yPguf4AfDt0Lg6uTjz9w2y+H7XI8qOoSoX/qslcfHoZ+ZoUOvy1iuSQM+SEmwcGiduPcX3eN2UOv712Oyp7W7wmDK7YKJWg48rnOfTMKnI0KQzauYy4kFAyw2PNklnVsqPplGEkn40svh5qFV0/e4VTM9aRfvkWNs6OGHSFFu1xXzCN2ClzKYxPwnfLp2TvP4Huuvk6iJk7D5G04nOzbXYBrbDr0JqYx14CoP5PH2LfpR25py9UbJsFHhuprE5dAAAgAElEQVQxmDGjH2Hesg8qT1wBQqUicNkLvDv2HVK0ySwNeo/QPaeJiyi+Rzf/jmLRw7MpyCtg4LihPDt3Ap9P/5D2Azrh16Yx84fPwtrGmnlblhF2IJS8rNxKNcctncKH45aSok1hUdBqzu8+U2H5fmZhIGsCV1Rqj0qlYuG7bzH5qenExyWwNeQH9u86zPXwqKI0cbFa5r66lEmvjDM79tTRszwxwLitTl0n/jr5X44eOFH5RTTpvrXydaY/+wYJmkR+2LGew7uOElXCH127FEHg8Knk5+YzesKjzFj4EvNfeqdKeS99bx7jR7+INi6e7Xs2seevA0Reu1GUJva2ltnTF/LC9MAyx+fl5jOy3zNV0qkpn/r00kl8Nm4FadpkZget4uLuM2gji+vrme1HObLRGBS3HdSJJxZOYG3gKrJSM1k/+T3SE1LxaubLtA3zWND9ZYv2zFzxKrOee4tETSJf7ljLkZDj3Cxlzwsmex6dMIqXF0xlycvLycvNZ+Vrq7kdFYurhytf71zHqQOnycrItmjTI0sn8s24VWRok5kWtJwru0OLAkaAsO3HOGX6nWg5qCMjF47ju8B3UalVPL1mGltnrUV75RYOdR3RW/JBNUB1dnmbgscvK01YMVZAU6AfUB84JIRoK6W0uFir0uX9DyOE6AE8DHSUUrYDBmF6MhBCdAac7zXvyoLJSugH3PXxLTu04HZ0LHG3NBTqCtm7fR8PDTXPJvTYefLzjItt/332Mu5exYvrnj1yjpysnEp1fAKakBIdT2pMInqdnkvBJ2g+uJNZmvwSP6DWDraUF161faQHl4KPV8m2xgH+JNzUkhgTj15XyKngI3QY0sUsTckfbVsHO6r6YgCvgCakRseTHpOIQafncvAJmpayp6CMPca8XZv6cPOYsTUgJzmDvIwcvNo1sqhVu4M/uVFa8m4lIHWFJP5+FNehnat0ngBpRy6hz644OAFw6dCErOh4sm8lInV6YrafwGdopzLpWr/9JFc/C0afX1C0zaNvW9Kv3CL9sjEoLEjNAkP519KubXN0t+IovK0FXSFZOw/gOKBH1YyREmFrg7C2QthYg5UVhcmpVTu2HDoHtKWOU+17Pv4OTQL8iY/WFJW1E8FH6DS4q1maK8cvUZBnvGaR58Jx8TIuhu3TtD5XT13GoDeQn5tPzNVo2vXtUKlmcflOQK8r5GTwUQIqLN+2lFupyqFdx9bcirrN7Ztx6HSF7PgthAHD+piliYvREH45EoPB8nTWIaMGcHjfcfJyq7ZYf+sOLc38Ucj2ffQZ2tsszdlj58g35Xcx9DL1vKq22Hf7jm24GRVDzM1YdLpCgn/7i8HD+5mliY2J4+rliAptqoya8ql+Af4k3YwnOSYBvU5PaPAx2lVw/20cbIv82+2/o0lPMNYbTXgM1nY2WNmU3x7VskMLYqNj0RTZs5/epew5V8Key2evFNlz+8ZtbkcZg8Hk+GRSk9Oo61rXok2+Af4k34wn1WRTWPBxWg6x/DtR0qamD7VDe/UW2itGH5STloW04INqAmkQ1fZXBWIB3xLf65u2leQ2ECSl1Ekpo4BwjAGmRZSA8p/HC0iSUuYDSCmTpJRxpkGx7wNv3WvGQogs03+VEGKtEOKqEGK3EGKHEOLJEklnCCFChRAXhRAthBB+wEvATCHEeSHEQ1XVdPd0IyGueChFgiYJd0/LDnrUcyM4sf/UXVoGTp4uZGiSi75naFJw8iwbe3eZMJhXD33E4LnPsXPxD2X2tx7VnUvbqxZQOnu4kBJX3JCboknB2aPsGy0GjB/Guwc/5+k549m05Nsy+8ujtqczmabuZYBMTQq1y7Gn44RBvHjoQ/rPfZY9i41dhgmXb9F0cEeEWkUdX3c82/jh5G35TRu2Xi7kxxVfu3xNCjZeZdO7jexGx30f0PLrN7CtID9L2Hu6kBNbrJOjScG+lE112/rh4O2Kdu95s+21m3iBhIc2v82gkOU0f8Vy64rawxWdNrHoe6E2CXU9tzLpHIf0wve3dXiuWYCVqUzmhV0h91QYfgc343dwMzlHz6K7EVPm2JrG2dOVlBLlO0WTjLOni8X0fZ8ZyIUDoQDcumwMIG3sbHB0rk3LHm1w9S57PUpTt1T5TtUk4+xRVnPA+GGsPvgZT80Zz8YlZVuwy6Oep7tZN3K8JgGPKgZuJRnx2BB2/BpS5fTunm7Em/mjRNy9LF+LR54bwfF9J6uUt6dXPTSx2qLv2rgEPL2q/pYWWzsbtu/dxK+7fmTwiP4W09WUT63j4UJqCb+QqkmmjkdZH9Rn/BAWH/yEx+aMZduS78vsDxjejZhLURQWlN+a5+bpRkJccX1N1CTi7mn5nox8bjgny7GnZUBzrK2tiI2OK+coI04ezqTHmf9O1CmnTHcfP5g3D65h2JwxBC8x+lW3xp4gJRM3zGH6Hyvo82LFLbz/Mk4DTYUQjYQQNsCzQFCpNL9jbHhCCOGGsQv8BhWgBJT/PCGArxAi3BT09TVtn44x+tdUg8YTgB/QChgPlG6+SZJSdgTWAW9KKaOBL4A1UsoAKeXh0hkKIaYKIc4IIc5osy1X6IoY8sQgWrRvxqZ1W+7p+KpwesNu/tNnFntW/0yfGY+Z7fMJaIIut4CE8KqNAasq+378i7f7TuOX1T8yasboas07dMMe1vd5gwOrf6anyZ4LWw+SqUnh+eBlDFo0jtjQCAz6+1u0LDnkDKe6vELogDdJOxhG8/9Mr47TN0cI2i8ZS9iSjWV3qVW4dW3GyWmfs//RpfgM70y93q3vWSp7/wmiBwUS8/jL5BwPpd5K42sOrRt4Y9PYl+gBY4nuPwaHbu2x69TmnnUeBD0f70Ojtv78ud443vHS4TDC9p9l0a+rmPbpLCJDw++7PJRk349/MafvdH5Z/ROjZjxZ+QHVhHs9V5q1bMKR/VV7ALxbhj0xmJbtmvPjup8rT1wN9A4YzqMDx/Da1DksWjGbBn717zvPmvCph34M4Z2+r7F99SaGzXjCbJ9n0/o8OmcMP8/7qlq0Bj8xiObtm7F5nfmYaNd6Lsz/z1xWzXq/yr1AFXHix9180Hcmf63ezACTX1Wp1TTs0pwtr33O+iffofXQLjTpee8+6H6pyUk5UspCjDHILuAKsFVK+bcQYqkQ4hFTsl1AshDiMrAfmC2lTC4/RyNKQPkPI6XMAjphHCCbCGwRQswDngI+rSaZ3sAvUkqDlFKL8eaX5FfT/7MYA89KkVJ+KaXsLKXs7FnLu2h7ojaJet7FqwfU83IjsUTr0R06P9SRwFfH8tbzC9AV3P0g5wxtCk4lWtWcvFzI0FruqrwUdJwWQ8y7dduM6sGloKoPEU2NT8GlREuPi5cLqfGW68/J4KN0KNVNaYlMbSq1vYqfnGt7uZBZgT2Xg07Q1NR1I/UG9i7byHcj5vPfF9Zg6+RASpTl55B8TYpZi6OtlwsFGnM7ClOzkKYWBs3GfTi2a1wlO0qSq03BwadYx8HLhdwSNlk52lGnhS/9fl3AiFMf49rRn17fv4Fz+0bkalJIPHGVgpQs9LkFaPadp25bv3J19PHJWJdosbHydEOfYP7uYEN6JuiM5Sxj21/Ytjb2zNQa1JO8sKvInDxkTh7Zh89g177lXdta3aRqk4u6sAFcvFxJ1aaUSde6Vzsemf4ka6asMmsRCvrsvywY8QbvjnsHBGijKn/oSytVvp29XEmNL6t5h1PBR+kwuIvF/SVJ0Cbi6VPceufhVY94TVm/UBHDHh3Enh0HKCzUV/mYRG0SHmb+yJ1ETdn3Snd5qBMTXxvPm8/Pq7I/0moS8PLxLPru6V0PraZqk3nA2EoLEHMzlhNHz9C6bQuLNtSET02PT8G5hF9w9nIlPd6yDzobfIx2Je5/XU8Xpq5/gx9nrSXpluXrkKRNop53cX1193InUVv2nnR6qCMTXh3D3OcXmtnj4OjAuxtW8tW733I5tOLJhxnxqdTxNv+dSK+gTF8IPk6rwcbfiXRtCtGnrpKTmokur4Br+8/j3cbyUKJ/mhru8kZKuUNK2UxK2URKucK0bZGUMsj0WUopZ0kpW0kp20opK30SUwLKGkBKqZdSHpBSLsb4VPAO4A9EmibNOAghIivK4z65MyBJz31OxLp6/ir1G/ng5euJlbUVAx8dwJEQ8xaFpq39eWv1LN6euIC0ZIvjdyskLuwGro08qevrjtpaTZtR3bm2+6xZGhe/4h+wpgMCSIku7p4SQtD64W5cCqp6a0dUWCT1/Lxwq18PtbUVXUf15tzuM2ZpPPy8ij63G9CJ+OiqNTBrwm7g0siTOr7uqKzVtBrVncjdoWZpnEvY4z8ggFSTPVZ2Nljb2wLg17sNstBgNpmnNJnnI7Fv7IVdg3oIayvcH+tFcoi5HTb1iscluQ7tTE7E3bfipp6/gWMjTxx83RHWanwf7U7cruJ7VJiZS1Drl9jR9XV2dH2d5NBIjj7/IalhUWgPXKBOS1/U9jYItQr37i3JCC89hMdI3qVrWDf0wcrHA6ytcBzej+z95pM21G7FwXqt/t3R3TCOiyqMS8S+SztQq8BKjX2XthTcMJ/M8yC4ERaJZyMv3H2NZa37qN6E7j5tlqZh60ZMXPUSayavIiM5vWi7UKlwrGucw+fboiENWvhx8ZD5kILyiAqLxKNE+e42qhfnS2nW8ysOoNoN6EhCiTpVERfPXaZhY198GnhjbW3FiMeHsH9XmY6PChn5+BD+/K3q3d0Al89fxbdRfbxN/mjIowM4HGI+471Zm6bMffcN3nx+Lql34Y8unPsbv8YNqN/AB2trK0Y9Pow9VZx57lSnNjY21gA4u9SlU9cAIsLL7y2sKZ96M+w67n6euNY3+tSOo3pyoZR/cy9x/1sP6ECiyb/ZOznw0ndz2P7uZm6cvVahTll7+nM0xPzBvmlrf95cPZO5Exea2WNlbcWKb95h17YQDv55qFKbboddx83PE2eTTe1H9eBKqd8J1xI2NR/QgSRTmQ4/eAGP5r5Y29mgUqto1K0lCffgB6sLKUW1/T0olFne/zBCiOaAQUoZYdoUAKyXUk4vkSZLSul/HzJHgUAhxA+AO8ZxD5Wtap8JON2tkF5vYM2CT/lo07uoVWr+2LKTqPBoprz5PFfDwjmy+xjTFr6IfS07lq9fDEB8bAJvT1wAwNpfP6aBfwMcHOz57cwWVr3xPqcOnimjY9Ab2LHoe8ZveBuhVnFu60ESI2LpP2s0cReiuLYnlK6BQ2jcuw0GnZ7cjGx+m1W8jEvDbi3IiEshNabqrSQGvYGNi77mjQ0LUalVHN66j7iIGB6b+SzRFyM5v+cMAwOH06pXO/SFhWSnZ/P1G59VKW+pNxCy6Aee2fAWQq3iwtaDJEXE8tCs0WguRBG5J5ROgUNo2Ls1Bp2evIxs/py1HoBabk48veFtpDSQpU0leGYly97oDUTO+4Y2m+cblw3avJ+ca7dp+NYzZJ6/TkrIGbynjMB1aGdkoZ7CtCyuvVY8O7r970uxb+qD2sGObqFfED5rHakHwsq16dy87+mz2XiPon4+SEZ4LK1njyYlLApNSGiZY+6gS88hfP1OBu5cBlKi2RtWZpxlSXsSV3yO91crESoVGb+FUBB5E5fpE8j7O5yc/SeoO/5RHPr3gEI9+vRM4ud9CEBWyGHsu7enwe/rAUnO4TPkHKjaGLrymL14NafPXSAtLYOBj43jlcnjGT1q6F3nY9Ab2LDoa2ZvWGRcomrrXmIjYnhi1rNEXbjOuT2neXbeBOwc7Jix1th9nxyXxJopq7CyVrNgm3HmdW5mLute/7hKXd4GvYGfFn3NrA0LUKlVHNm6j7iI2zw28xmiL163UL6r1omi1+tZPud9vt7yH1RqFb9uCiby2g1mvD2VS+evsH/XYdoEtOTT79/DqY4T/Yc8xIy3pjKqz7MAePt64enjweljlsuMJd3353/MfzZ9gEqtIvjnHdwIj2bq7ElcCbvK4ZBjvLrwJexr2bPqS+PMbm1sAm8+P69KeS9+exUbflmHSq3il02/E3HtOjPnvMLF83+z56+DtOvQmi82rKFOHScGDu3L63NeYWivJ/Bv1pgVHy1EGgwIlYovPvnObHa4uU7N+dSti75l2oZ5CLWKE1sPoI24zciZT3Hr4g0u7jlLn8ChtOjVFn2hnpz0bDa8sRaAPhOG4d7Qg+GvjWb4a8ZhPp+NX0FWcka59ny84FM+2PQuKpWKHVt2Eh1+k0lvPs+1sGsc3X2clxdOxb6WPe+sXwRAQmwCcycupP+ofrTv1g4nZyeGPW2sV6tmvkfk39fLvXYGvYGgRd8zacMchFrFma0HSIiIZdDMJ4m9eIMre0LpETgE/15t0BcWkpuezS9vGP1nXkY2R77ewbSg5Ugpubb/PNf2V/5gpmAZUR3jExQsI4TohLFruy5QCEQCU0su42MKKCtbNuh1IOvONill/TvHCSFUwFqMgWQMIIB3pZS7Sy4bZJpV/oGUsp8QohmwDeMyRjPKG0d5h14+A2qkkAy28qo8UTVwU+TViE5zaV8jOj3zqzYjtjqIFzY1otPBuWwX2T9Bw0P3vibl3TKp05s1omMtaqbj6XhOzbT01raqmXoEkJh/b61/d4u33d1PgrsXOljf/cSoe+GCrmbqK0Av66pPjLofVkVvqtGmvshWQ6vtd9b/8q4H0kyptFD+w0gpz1LJ8jwVBZOm/UuAJZaOk1IahBBvSimzhBCuwCngommfX4n0ZzDN2pJShgPtqm6JgoKCgoKCwj+B4QF2VVcXSkD57+EPIURdwAZYZpqco6CgoKCgoKDwj6MElP9DmN6o81Spzb/cmYFVEVLKfv/ISSkoKCgoKCj8ozzIyTTVhRJQ/g9hChwrf8+ZgoKCgoKCwr+G6nz14oNCWTZIQUFBQUFBQUHhvlBaKBUUFBQUFBQUHiD/hgV3lIBSoVKm4F15ompAlP9q2GpHbWVXIzrpovpeh1cRfvUtvxmiuimMqZnlTm4l16kRnXdqaCkfgG/PflAjOhHdZtSITp5tzSzzZWNd9Tfn3C87rH1rREdTQ87uqfy7f6POvdAPz8oTVRNt7WrO39UkSpe3goKCgoKCgoLC//coLZQKCgoKCgoKCg8QZR1KBQUFBQUFBQWF++LfsGyQ0uWtoKCgoKCgoKBwXygtlAoKCgoKCgoKDxBllreCgoKCgoKCgsJ9oYyhVPj/Ep9+7ei2dDxCpSJ88wEufh5cbrqGI7ow4KvXCBq+kOQLUUXba3m78viBdzn/4a9cWr+jQp2uJp2ISnT6f/UaweXoPGbS+bsCnSZ92zF08XiEWsW5nw9wbJ25TsexA+kyYTAGvYGCnDz+nPsNSRGxqKzUPPzuFLzaNEJlpeLCf49wdG2QRZ1mfdvx8KIJqNQqTm/Zz8FSOl3HDqTH+MEYDAYKsvP5be7XJETGAuDZwpfHV07B1tEeaTDw+aMLKazikiB2Pbrg/OY0UKnI/n0HGT/8XCaNw6C+1JkaiJQSXcR1khesrFLeJXHp356myyci1Co0G/dy89PtZvs9n+mL/6Lx5GuNy37c/vYvNBv3/U/ptO3bgfGLJ6FSqzjw8x7+WPeb2f5hU0bR79lB6Av1ZKZk8NXsz0mOTQTgmTnjCRjQCYDf//MLJ/84ete23WHByo84dPQULs51+f2nL+45H4BafTrhuXAqQq0idUsIyet/MdtfZ/QgPN6eRGF8MgApPwaTtjUEACsvd7xXvYq1lztIya3Ji9HFJpSr49SvA/WXvABqFcmbdxO/9r9m+12eGoDP/OfRaY06id/vIPnn3UX7VY72tNr3GWm7TnJ74ZcW7XHs0xGvRVNBpSJ1awhJX2wz21939EA850xCd8eeDX+QarLH2tsdn1UzsDLZc3PSEov2ADTq246BJt9w4ecDnCxVZwPGDqCDyTfocvLYNfcbkiPiUFmrGbpyMp7tGiENBva+8xMxJ65Y1GnRtz2PLwpEqFWc3LKPvevM/UjPsYPoNX4I0mAgPzuPrXO/It7kGwDqersyZ/eH/PXxNg589YdFnbr9A2i0dBKoVSRs2kvsZ+bl2/3p/vgtGk+Bxlh3NN/tJGHTXhxa+9Fk9VTUtR2QegO3P9lGctAxizoAHv3bEbDUeO2iNh3g2mfl+2+fkV3o8fXr7B22gNQwo/+u09KXju9Nxqq2PRgke4cvxGDB3zn07oTH/JdApSJ921+kfGVevp0eH4T77CkUxicBkLYxmPRtu7Dv1o56c6YWpbNp7Itm1mqy9h6v0C4FyygBZTViehf3GEAPGIAXgS7A60ATwF1KmVTB8R7AN4AvYA1ESylH/MPnHA10rui8zNKrBN1XBLLrudXkaFIYtWMpt0LOkh4RZ5bOqpYdrSYPJSE0skweXZeM5fb+sEp1uq0IJMSk83AFOi0nDyWxHJ0uS8YSWwWdYcueZ+PYVWRoU5gStIzwPaEkRRQ760vbjxG6cS8AzQZ1ZPCCsWwOfI9WI7thZWPN+qFzsLKz4eU973Ep6Bjpt8teSqESPLJ0It+MW0WGNplpQcu5sju0KGAECNt+jFMmnZaDOjJy4Ti+C3wXlVrF02umsXXWWrRXbuFQ1xG9rorr2KlUOL/9KgnT3kIfn4jnhrXkHDpOYdTN4mvo64PTxOfQTn4VmZmFyrlu1fI20xE0Xz2Zc08vJz8umc67VpG46ww54bFmyRK2HyN83rd3n38N6AiVisBlL/Du2HdI0SazNOg9QvecJi7idlGam39Hsejh2RTkFTBw3FCenTuBz6d/SPsBnfBr05j5w2dhbWPNvC3LCDsQSl5W7j2Z+diIwYwZ/Qjzlt3n2pUqFV5LXuZm4AJ02iQa/7aGzL0nKIiMMUuW8echtO+UDVx9PphF0totZB89j3CwA4OFfjmVCt/lLxIxZjE6TTLN//iA9N2nyIsw10kNPmIxWPR+cyxZJ/+u1B7vd14masICCrXJNP59DZl7TpJfyp70Pw+jWVLWnvofzCJh7Rayj5xH5WCHtGQPxjo7aFkgW8euJlObwoSgpUTuOUtyCR90eftxzpseVvwHdaT/gnFsC3yP9s/1B+C7oXNxcHXiyR9ms2HUonL7NYVKMHrpJL4Yt4I0bTIzg1ZyafdZs4Dx7PajHNu4B4DWgzrx6MLxfBm4umj/YwsmcOXA+UqvXeOVL/D3M0sp0CTTbue7pIScJjf8tlmypO3HiJr/tdk2Q24+Ea9+Sl6UBmsPZ9rvep+0A+fRZ+RY0BJ0WPk8h59ZRY4mhYE7lxEXEkpmqXpqVcsO/ynDSD5b7L+FWkWXz17h9Ix1pF++hY2zIwZL/k6lwmPRNG5PmocuPomGv3xC1r6TFFy/ZZYsc+dBEpatM9uWe/ICNx+fbsymjiONd31L9tFQi5fvn0aZlKNQhBCiB/Aw0FFK2Q4YBMQAR02fb1Zw+B2WArullO2llK2AOf/U+d4rbh2akBkdT9atRAw6PTe2n6DB0E5l0nV860kurv0DfZ75U2WDoZ3IvJVI2rXYMsdUpBNVgc4lCzpZVdDxDmhCanQ8aTFGnb+DT9B8sLlOQYmgwNrBtuizlBJrB1uEWoW1nQ16XSH5meUHEL4B/iTfjCc1JgG9Tk9Y8HFaDjHXyS+hY+NgizT9+DR9qB3aq7fQXjE6yZy0rAp/CEti07oFhTGx6GM1UFhITsh+HPr2NEvj+PhIMrcGITOzADCkplUp75I4dfQnJ0pL3s0EpE5Pwu/HcB/W5a7zeZA6TQL8iY/WkBgTj15XyIngI3Qa3NUszZXjlyjIKwAg8lw4Ll7Ghd59mtbn6qnLGPQG8nPzibkaTbu+He75XDoHtKWOU+17N8aEfftmFNyMQxejBV0h6X8covag7lU61sbfF2GlJvuoMVCROXnIvPxy09YKaEp+tJaCW/FIXSGpQYepM6RruWnLPc+2TbByr0vGoYqDIvv2zci/qUEXY9RJ/+MQtQdXzR5bf1+wUpF9xKhhqMAeAK+AJqRFx5Nu8g1Xgk/gX6lvMNZL16Y+3DxmDI5zkjPIz8jBs12jcnUaBPiTdFNLssk3nAs+Rpshnc3SlPYNlKj+bYZ0JjkmAW2EeWBYGscO/uRGa8k33aOk7UdwGVq1upN3Q0NelAYAXXwquqR0rF0tv3zApUMTsqLjyb6ViNTpidl+Au9y/Hfrt5/k2mfBGPILirZ59G1L+pVbpF82+ruC1CyLDzJ27ZqhuxWH7raxfGfuOIjjwKqVh5LUHvoQ2YfPVFge/mmkrL6/B4USUFYfXkCSlDIfQEqZJKWMk1Kek1JG30UeRV5BSnkBQBh5XwhxSQhxUQjxjGl7PyFEUf+GEOIzIcTzps/RQoh3hBChpmNamLa7CiFChBB/CyG+Bu7qscjB05nsuOI3FeRoUqjl6WyWxrWNH7W8XLi91/zHwcrBlrbTHub8R7/etU62JgWHUjoubfxwsKDTpoo6Tp4uZGiSi75naFKoXUoHoPOEwUw79BED5z7HrsU/AHBlxyl0OfnMPP05rx7/hONf/kleenb5Oh7OpMeZ69TxcCmTrvv4wbx5cA3D5owheMkGANwae4KUTNwwh+l/rKDPiw9Xatcd1PXc0McnFn0vTEhEXc/NLI1Vg/pYN6yPxzef4PHdp9j1uPsAzdbThfwS9uXHJWPrWdY+94e70XX/+7T5eha23nf/1p1/UsfZ05WUEmUhRZOMczl536HvMwO5cMDYonHrsjGAtLGzwdG5Ni17tMHV283isTWFlYcrOk1xi3mhNglrj7LXo/awXjT+8zPqfzYXKy/jeds28kGfkU39tfNpFPQf6s2ZBKryfzKsPV0piCvW0WmSsfYsq+M8vActQz6h0RdvY23SQQjqL5xI7LLvKrXH2tMVnaZEedaUb4/TsJ747/gU38/nFunYmOzxXTePJsGf4DFnokV7ABw9ncnUFPugTFFSiLIAACAASURBVAu+ocOEQbxw6EP6zn2WvYuNdTbx8i38B3dEqFXU8XXHo40fThbKYV0PF9JKlOl0C76h1/ghzD/4CaPmjOXXJd8bbXKwZeBLj7Drk21l0pfG1tOFgtjie1SgScGmnHvkOrI77fd+RPOv3sSmnHN2DPBH2FiRF621qGXv6UJubLFNuZoU7Etdu7pt/bD3dkVbyn87NvECCb03v83AkOU0e8Wyv7PycDMvD9okrMor34N747d9Ld6fzMfKs2y9rD2iDxl/HrCoo1A1lICy+ggBfIUQ4UKItUKIvveQx+fAN0KI/UKI+UKIO+88fAIIANpjbO18XwhRlfeeJUkpOwLrgDvvmFsMHJFStgZ+Axrcw3laRgi6LB7L6aWbyuzq8MYT/P3VXxTmVMNToBB0XTyWM+XoBLzxBJerS8fEmQ27+bzPLPat/pneMx4DjK2bBoOBj7tO59PeM+nxwgjq+rrfl86JH3fzQd+Z/LV6MwNMOiq1moZdmrPltc9Z/+Q7tB7ahSY9W9+3TXcQajVWvj7ET51F0vwVuMyfhXCsVW353yEp5CzHOk/jVP/ZpBy8QKtPp1W7Rk3p9Hy8D43a+vPn+t8BuHQ4jLD9Z1n06yqmfTqLyNBwDPqaefXm/ZK19ySRfSdyY+R0so6ew+f9WcYdajUOXVoTv+oboh5/HRtfT+qOHnTPOum7T3Op5wtcGfIamYfP47fmNQDcJwwnY9/ZorGV90vm3lOE95lE5IgZZB05h8/7MwEQVmpqdWmNduU3XH9sJjYNPHF+cuB9653bsIev+rzBwdU/08NUZy9sPUiWJoUJwcsYsGgcsaER910ejv4Ywoq+r/HH6k0MmfE4AMNef4qD3+ygoJp8Xeru05zt+hJhA2eRdiiMpp+Yv8bTul5dmn76KpGvf3Z/TWFC0H7JWC4s2Vhml0qtwq1rM05N+5wDjy7FZ3hn6vW+d3+Xtf8kNwY+T/Sjr5B9LBTP1W+Y7Ve7O2PbrBHZR87es0Z1YJCi2v4eFMoYympCSpklhOgEPAT0B7YIIeZIKb+/izx2CSEaA8OA4cA5IUQboDewWUqpB+KFEAcxjs3MqCTLO010ZzEGpQB97nyWUv4phEgt70AhxFRgKsCEOl3pV6spADnaVGp5Fz89O3i5kK0tzsLa0Q7nFvUZtm0+APbudRj03Sz2TPwItw7+NBzZlc7zn8XGyQEMEn2+jivf76Y0pXVqebmQU0qnbimdgd/NYu/Ej3Dv4I9fCR1p0rlajk6GNgUnr+InWicvFzK15V4SAC4FHWf48onAeto82pPrBy5gKNSTk5xBzNlwvNs1Ji0mscxxGfGp1PE210mPt/xO2gvBx3ls+SQA0rUpRJ+6Sk5qJgDX9p/Hu00jrh+rZLwZoE9IQu1RHORa1XNHn2A+xrMwIZGCS1dAr0cfp6Xw1m2sG9Sn4PK1SvO/Q742xawl0NbbtWhSTJFOalbR57iNe/FfNK7K+deETqo2uagLG8DFy5VUbdl71LpXOx6Z/iQrn15IYUHx2K6gz/5L0GfGiSgv/+d1tFFxZY6taQrjk4tbAgErT7eiySp30KdlFn1O2xKCx9vGcleoTSLv8g1jdzmQufs49gEtwHzOAwA6bTI2JVpkrb1cywSIJXWSNu/GZ14gALU6tcCxayvcJgxHXcseYW2FITuPuNUbytWx9ipRnr0qtid1SwiecyYaj9XcsSfeaE/ICew7NAfK+gWALG0qtb2KfVDtSnzDlaATDFlu1JJ6A/uWFQdLY39dRKqpy7g0afEp1C1RputU4hvOBR/jyeWTgXU0DPCn/YhujJo7FnsnBwwGSWG+jiMbdpU5Ll+bgo1P8T2y8XKhoNQ9Kll34jfupeGC8UXf1Y72tPxpPrdWbyIrNMLi+QHkalOw9ym2yd7LhdwS187K0Q6nFr70/XUBAHbudej5/Rsce/5DcjQpJJ64SkGK8Vy0+85Tt60fCUfK+rvC+CTz8uDpVjS57A6GEuUh/ZdduL852Wx/7WF9yNpzDApr7p3x5aGMoVQwQ0qpl1IekFIuBqYDo+8hjxQp5SYp5XjgNMYA0BKFmN9Du1L77zy26rnLhwcp5ZdSys5Sys53gkmApPM3cGrkiaOvOyprNY0f7U5MSPFAZl1mLpvbvsy27jPZ1n0miaHX2TPxI5IvRLHziWVF2y9/vYsLnwaVG0yWp9OoHJ2fS+nsrUCnvGASIC7sBi6NPKlr0mk9qjvhu82fVF38PIo+Nx0QQIqpqycjNgm/nq0AsLa3xadDU5Kulx9E3A67jpufJ8713VFbq2k/qgdXSum4+nkWfW4+oANJJp3wgxfwaO6LtZ0NKrWKRt1aklDJeKk7FFy+irWvD2pvT7CywmFIf3IPmc/OzD1wFNtOAQCo6jhh1aA+hbHl//hZIvPcdRwae2HXwB1hrabeYz1J2nXGLI1NveLJPm5DO5NdRRtqSudGWCSejbxw962H2tqK7qN6E7r7tFmahq0bMXHVS6yZvIqM5PSi7UKlwrGuIwC+LRrSoIUfFysZD1gT5F4Ix8bPB+v6HmBtRZ2H+5C196RZGiv34q7I2oO6FU1wyb0QgdqpFmoXJwBq9WhPfqT5ZIc7ZIdFYOvnhY1vPYS1Fc6PPET67lPmOvWKdeoM6UpepPG+RL/6EZe6T+HvnlO5vfw7kv+7v9xg8o49tn7eWNf3QJjsydxTdXtUTo7F9vRsV2YyT0k0YTdwbuRJHZNvaDmqO5G7zSdtOJfwDU0GBJBqqrNWdjZY2xvHWzfs3QZDocFsMk9JYsKu4+7niYvJN3QY1ZO/S/kGtxK+odWADiRFG+vnp08vYVnvGSzrPYOD3+5kz+e/lxtMAmSdj8S+kRe2pnvk9mhvUkrVHesSdcdlaGdyTZMThbUVzb99i8RfDpD85wmL1+wOqedv4NjIEwdfYz31fbQ7ml3FNhVm5hLc+iV2dn2dnV1fJyU0kmPPf0hqWBTxBy5Qp6UvansbhFqFW/eWZISXPxY+72I41g29sfYxlu/aI/qStc/8/NQlyoPjgO4UXDe/504j+ynd3dWE0kJZTQghmgMGKeWdR7cAqjYRp2QeA4ATUsocIURtjDPDbwGHgReFED8ALhiDzNkYZ4K3EkLYAvbAQOBIJTKHMM5EXy6EGA6UHRRUAVJv4MSCHxiy6S3jcj5bDpIWHkuHN0eTFBZFzO7qmSV3R2ewSSfSpBPw5miSq1nnr0XfM2bD2wi1irCtB0mMiKXvrNFoLkQRvieUzoFDaNy7DXqdnryMbIJmGWePnt6wm0c+eJGXdr8LQhD2y0ESrpb/A2XQGwha9D2TNsxBqFWc2XqAhIhYBs18ktiLN7iyJ5QegUPw79UGfWEhuenZ/PKGcVZiXkY2R77ewbSg5Ugpubb/PNf2VzFY0RtIef9T6n36LqhVZAftRHfjJnVefJ6CK9fIPXScvOOnseveGa+t3yINetL+8yWG9Moav8tex/C53xLw83yEWkXc5v1kX7tNo7eeJjPsOkm7zlL/heG4DemM1OspTMviyqtr70rjn9Yx6A1sWPQ1szcsQqVWcWjrXmIjYnhi1rNEXbjOuT2neXbeBOwc7Jix1jiCJDkuiTVTVmFlrWbBthUA5Gbmsu71j++ri3P24tWcPneBtLQMBj42jlcmj2f0qKF3n5HegPaddTT4fhlCpSJt227yI27h/vo4ci9GkLX3JC6Bj+A4sJuxhTo9i7i31pguiIH4Vd/Q8MeVIAR5lyJJ3VJ+sILeQMzCL/H/aQlCrSJ5y17ywmPwemMMORciSd99inoTH6bO4K5IvR59WhbRsz65J3vilnyB3w9LESoVqb8Y7an3+lhyL0aQufcUrs8/Qu2BXZF6A/q0TG7P/rjIHu2qb2j00woQgtyLkaT+bMEejGVtz6IfeGrDWwi1iotbD5IcEUvvWaPRXogick8oHQKH4Ne7NXqdnvyMbP6ctR4ABzcnnt7wNlIayNSm8ufMdRZ1DHoD/130HS9umIdKreLk1v1oI24zbOZTxFy8wd97zvJQ4FCa9WqDvlBPTno2m96wnF9F1+7GvK9ptXkhQq0i/ud95IbH4Dv7WbLCIkkNOYPXlJG4DOmCLDTWncjXPwPA9ZGeOHVvhbVzbeo9bZzBHvH6Z+T8HW3x2p2f9z0PbTb61eifD5IRHkur2aNJDYtCE2LZf+vSc4hYv5MBO5eBlGj3hpUZZ1nSpoRl66j/zXJQqUn/bwgFkbdwnTGevEvhZO8/ifP4R3Hs3x2p12NIz0Q798Oiw6186mHl5UbuqYt3fz2rmX/DOpRC/huWZ/8fwNTd/SlQF2PLYSTGLuMxwFuAJ5AA7JBSTrGQx2xgIsUtj99JKT8UQgjgPYzd4BJYLqXcYjrmPeBxIArIAoKklN+XXA5ICNEZ+EBK2U8I4QpsBnyAY8AQoFNFywZ95zOuRgpJTVWnGKuaKfM5omZ0XnaLrxEdgMiYu59I87/Md3ZVXH6pGvj27H0uAVRFIrrNqDxRNZBXUDPtETbWNdcVuUN/D0tm3QMaUTPl7qkqrlV7v8SV6Rz752hbx/JwgOqk+dWdNRrhnfB+otp+MLrH/fpAolOlhbKakFKeBXqWs+s/pr+q5PE+8H452yXGFsnZ5ex7C2PAWnq7X4nPZ4B+ps/JGINIBQUFBQUFBYVqQQkoFRQUFBQUFBQeIP+GLm8loHwACCEmAq+V2nxUSvnPrKOioKCgoKCg8D/Lv2GWtxJQPgCklN8Bla/iq6CgoKCgoKDwfwAloFRQUFBQUFBQeID833gNQsUoAaWCgoKCgoKCwgNE1tg6J/8cSkCpUCmJNVRK7GvoES1d1IxQOjWzNMiyJBem6mpGy9Ox/HeVVzcn8+5qedR7xrqGygLU3HI+TU9+WiM6oe3erDxRNeBUO69GdABic2qmHjnW0DtF0gzWNaLjgB4HamZ5J12BukZ0FO4eJaBUUPg/Tk0FkwoKCgrlUVPB5L8Zw79gSXAloFRQUFBQUFBQeIAY/gVd3sq7vBUUFBQUFBQUFO4LpYVSQUFBQUFBQeEBokzKUVBQUFBQUFBQuC/+DcsGKV3eCgoKCgoKCgoK94XSQqmgoKCgoKCg8ABRurwVzBBCzAfGAHqMLdgvAq8CnQEdcAp4UUqps3C8B/AN4AtYA9FSyhH/8DlHA52llElVPaZR33YMXDweoVZx4ecDnFwXbLY/YOwAOkwYjEFvQJeTx66535AcEYfKWs3QlZPxbNcIaTCw952fiDlxxaJOg37t6LPEqHN58wHOrg0uN12T4V0Y8eVrbBm5kIQLUdjVdWT4+lep174xV385xMGFGyq0p3nf9jy6aAIqtYqTW/azf12Q2f4eYwfRc/xgDAYDBdl5bJv7NfGRsUX763q7Mnv3B4R8vI2DX/1pUad13wCeXTQRlVrF4S17+Wvd72b7+44dTL/xw5AGA3nZefw4dz2ayNvUquvIS+vewK+dP8e2HWDz4m8qtAfAqV8HGiydjFCpSNy8B+3nv5rtd326P74LAtFpUwCI/24HSZv3YOPjjv83byNUKoSVmvjvdpD44y6LOrX6dMJz4VSEWkXqlhCS1/9itr/O6EF4vD2JwvhkAFJ+DCZtawgAVl7ueK96FWsvd5CSW5MXo4tNKFfHp187ui0dj1CpCN98gIufl18WGo7owoCvXiNo+EKSL0ThFtCYnu9NBkAIOPfhb9z660yl1+8ObfoGMGbRRITpnu0odc/6jR3CgPFDMRgM5Gfn8cPc9cRF3q5S3jV17SpiwcqPOHT0FC7Odfn9py/u+niz8+3XgYbLJiFUKhI270Hz2W9m+92e7k+DhRMoKCpzO0ncZCxzzb59G1TCWOa+3UHCjyEWdRx6d8Zt7kugVpOxbSdpX28121/7scG4vTmFwgTjdUvfGETGf/8CwPWNyTj07YYQgpzjoSStXFehTS36tueJRYGo1CpObNnHnlK+odfYQfQeP6TIN/w89yviI2Np0L4Jz6x6AQAhBH99vI0Lu05b1Gnatx0jTT7ozJb9HCrlU7uOHUi38YORBgP52fn8PvdrEk0+yKOFL4+tnIKtoz3SYGDdowspzC/3Jwa3/u1ptTwQoVYRs3EfNz4NKjed58iudPx2FkeHzCM97AbCWk3b91+gTkBjpEFyecEPpBy7bNEel/4B+C831hvNxr3c+tS83ng+04/Gi8YXlYXYb3ei2bgPgHab5+PUqSnpp65ycdxqixp3cOzTEa9FU0GlInVrCElfbDPbX3f0QDznTEJ3px5t+INUUz2y9nbHZ9UMrEz16OakJfdUj6qDf0OXtxJQVhNCiB7Aw0BHKWW+EMINsAE2AuNMyTYBUwBLXmwpsFtK+Ykpz3b/7FnfPUIlGLQskK1jV5OpTWFC0FIi95wlOSKuKM3l7cc5b3IO/oM60n/BOLYFvkf75/oD8N3QuTi4OvHkD7PZMGoRyLILcAmVoN/yQH4fs5osTQrP/LGUG7vPklpCB8C6lh3tJw9FGxpZtK0wX8eJD7bh2rw+rs3rV2rP40sn8uW4laRrk3ktaAWXd581CxhDtx/l+MY9ALQa1IlRC8fzdWCxo3tkwXiuHjhfiY6KMUsns2bcMlK1KcwPWkXY7jNoSgQfJ7cf4eDG3QC0H9SZpxcG8kngCnT5OrZ/uAWf5r54N2tQoQ4AKhUNV0wl/LklFGiSabXjPdJCTpEXYR7opAQd5daCr8y26RJSufLIHGRBISoHO9rs+4S0kFPo4lPL1fFa8jI3Axeg0ybR+Lc1ZO49QUFkjFmyjD8PoX2nbLDi88EsktZuIfvoeYSDncWF2IRK0H1FILueW02OJoVRO5ZyK+Qs6aXKglUtO1pNHkpCibKQevU2wcMXIvUG7OvV5dHdK4jZHYrUV+6+hUrFuKVT+HDcUlK0KSwKWs353WfMAsYT2w9zYKPxxylgUGeeWRjImsAVleZdU9euMh4bMZgxox9h3rIP7un4IlQq/Fa+wNVn36FAk0zrHe+Rtus0uaXKXHLQUW7O/9psmy4hlb9HFZe5dvs/JjXktMUy575gGrFT5lIYn4Tvlk/J3n8C3fVbZskydx4iacXnZtvsAlph16E1MY+9BED9nz7Evks7ck9fKNckoRI8tXQSa8etIE2bzBtBK7lYyjec2X6Uoybf0GZQJx5fOJ4vAlejuRbDh6PmYdAbcHKvy1s73+XSnrMYyil3QiUYtXQi341bRYY2mZeDlnNld2hRwAgQtv0YpzbuBaDFoI6MWDiOHwLfRaVW8fSaafwyay3aK7ewr+uI3tK6tCpB69WTOPX0CvLikum1ayUJu86SFR5rlkxdyw6/F4aTejaiaFuDcQMBONzvLWzcnOiyaQ5Hh84v13ejUtF09WTCnl5GflwKnXatImnXGXLCzctC4vZjRMwr+3B8a+121Pa2eE8YXL4dpbS833mZqAkLKNQm0/j3NWTuOUl+qXqU/udhNEvK1qP6H8wiYe0Wso+cR+Vgh/w3LAb5AFHGUFYfXkCSlDIfQEqZJKWMk1LukCYwtlBWFOF4AUW1Tkp5AUAYeV8IcUkIcVEI8Yxpez8hxB930gshPhNCPG/6HC2EeEcIEWo6poVpu6sQIkQI8bcQ4mu4u3Z2r4AmpEXHkx6TiEGn50rwCfwHdzJLU5CVW/TZ2sEWMFZS16Y+3Dz2NwA5yRnkZ+Tg2a5RuToeJp2MW0ad8KATNB7SqUy67m8+SejaP8yeyAtz89GcDrf4lF6SBgH+JN/UkhKTgF6n53zwcVoP6WyWJr+EPTYOtmZOtPWQzqTEJBAfUXGrVKMAfxJvakmKSUCvK+R08FECSunkldCxdbBFmnQKcvOJPHMVXRXsAajVoSn50Rryb8UjdYWkbD+C89CuVTpW6gqRBcYfJGFrDSrLxcO+fTMKbsahi9GCrpD0Pw5Re1D3KunY+PsirNRkHzUG4jInD5mXX25atw5NyIyOJ8tUFm5sP0GDoWXLQse3nuTi2j/Q5xVfJ31eQVHwqLa1vlMUq0TjAH8SbmpJNN2zk8FHCRjSxSxN6XtW1fxr6tpVRueAttRxqn1Px5bEsYM/edVQ5lS2VhWWObu2zdHdiqPwtvG6Ze08gOOAHlU7SSkRtjYIayuEjTVYWVGYXE7QaqKhqc4mm3xDaPAx2lbiG+64Bl1eQVHwaGVrXX7gZaJ+gD8pN+NJNelcCD5Oy1K+zpIP8n+oHdqrt9BeMQbUuWlZFoOiuh39yYnSknszAanTo/n9GB7DOpdJ12zO01z/LAhDiXrk2MyHpCNG312QlIEuI4c6AY3L1XHq6E9ulJa8mwlIXSEJvx/FrRwdS6QdvoS+hL0VYd++Gfk3NehijOUu/Y9D1B5ctXpk6+8LViqyjxjrkeE+6lF1YKjGvweF0kJZfYQAi4QQ4cAeYIuU8uCdnUIIa2A88FoFeXwObBFCTDfl8Z2UMg54AggA2gNuwGkhxKEqnFOSlLKjEOIV4E2MraOLgSNSyqVCiJHA5Lsx0tHTmUxNStH3TE0K3h2alEnXYcIgOk8Zjtraii3PrQQg8fIt/Ad35ErQcZy8XfFo44eTtyvasBtljq/l6UxWXLFOliYFz1I67m38cPR2IXrfeTq8NPJuzCiijoczaXHJRd/TNMk0DPAvk67n+MH0mTISK2srvhizHDA69v4vjeLLcSvpN/XhCnXqeriQUkInVZNCo4CmZdL1Gz+UwVMexsraig/HvHNPNtl4ulAQVzyCoUCTTK0Ozcqkcx7RndrdWpEXFUfMkm8pMJ2fjbcrTX9YgG0jL24v+6H8liLAysMVnaZYp1CbhH375mXS1R7WC4eubSiIikW74isKNUnYNvJBn5FN/bXzsa7vQfax8yS89z0YyrpDB09nskuUhRxNCu6lyoJrGz9qeblwe+952pQqC24dmtD7wxdwrO/GoVe/qFLrJNy5Z8X2pWqSaVzOPRswfhhDTPfsvTFLqpR3TV27msLG07Wo/ICpzHUse61cRvTAqVsr8m5ouFmqzDXfMB/bRl7EVFDm1B6u6LSJRd8LtUnYtmtRJp3jkF7Yd26DLjqWpHfXU6hNJC/sCrmnwvA7uBmEIH1TELobMWWOvUMdD5dSviGlXN/Qe/wQ+k8Zidrais/HLCva3jDAn+feexEXH3d+mvV5ua2TAE4ezqSX0MnQpOBbjk638YPpNWUEamsrvh1jbAV3a+yJlJLnN8yhlkttLgQf5/D6P8ocC2Dn6UJeCZ3cuBTqdjTXcWrrh723K4l7ztH4lVHF53T5Fh5DO6H57Sh2Pq7UadcIe29X0s9dL6Nj6+lCfgmd/LgUnMopC24Pd6NOj5bkXtcQueh7s2OqirWnKzpNifKgScI+oGw9chrWk1pdW5MfFYd2+VfoNEnYmOqR77p52NT3IOvoeeLf++GB1aN/wxhKpYWympBSZgGdgKlAIsbA8PkSSdYCh6SUhyvIYxfQGPgKaAGcE0K4A72BzVJKvZQyHjgIdLGUTwnuDJw7C/iZPvcBfjLp/QmU67mFEFOFEGeEEGdOZkWUl6RCzm3Yw1d93uDg6p/pMeMxAC5sPUiWJoUJwcsYsGgcsaERFp1spQhB70VjObJs070df5cc+3E3q/u+zp+rNzFoxuMADHn9SQ5/s5OCnOp7qj3w4y7m953Bf1dvZOSM0dWWb2nSdp/hQvcX+XvwTDIOhdHo4+LnnIK4ZP4ePJOLvV7G9an+WLnVuWedrL0niew7kRsjp5N19Bw+788y7lCrcejSmvhV3xD1+OvY+HpSd/SgexMRgi6Lx3J6afllIencdX4fMIfgEYtoN32UsaWyGtn341/M6TudX1b/xKgZT1ZbvjVy7WqQtN2nOd/tRS4OmkX6oTAaf/xq0b6CuGQuDppFWM9XcLvPMpe9/wTRgwKJefxlco6HUm+l8Z3j1g28sWnsS/SAsUT3H4NDt/bYdWpz33Yd+TGEZX1fI3j1JoaYfAPAzfORrB4ymw8fmceglx81tlTeByd/3M1HfWeya/Vm+pl8qkqtpmGX5mx97XO+fPIdWg3tQuOere9NQAhavjOBK0t+KrPr9qb95GlS6BWyklbLAkk9HY68j8ArKeQMJzq/wpn+b5JyMIwWn06/57wqI3PvKcL7TCJyxAyyjpzD5/2ZAAgrNbW6tEa78huuPzYTmwaeOD858B87j/8fUALKasQU8B2QUi4GpgOjAYQQiwF3YFYV8kiRUm6SUo4HTmMMAC1RiPk9tCu1/06ko+cuW6OllF9KKTtLKTt3cyx+uszSplLby6Xoe20vFzK1lruNrgSdoKmp+0bqDexbtpEfRszntxfWYOfkQGqUptzjsrWpOHoX6zh6uZBVQsfG0Q7X5vV5Yut8Ao+twbNDE0Z+O4t6FrrQLZEen0pdb9ei73W9XEm30DoCGLvEBxu7bxoE+DNy7hjmHfkPD00azsBpj9FrwpByj0uLT8GlhI6zlwtp8ZafyE8HHyVgcNW6DEtToE3Bxtut6LuNlys6rbmWPjWzqJsxcdMeHNqW7b7SxaeSe+0Wtbu1KlenMD4Za69iHStPt6KB70U6acU6aVtC+H/snXd4VMX+/1+zm54AqaSQQOg9hBK60kNRioJelRIEy7UiRaSLdL2KFexSlCoXKYqS0LtAgAAipBAgJNn0Xrec3x+7JLvJbhIkbn7X73k9zz7P7syceZ855zOfnTNnikMHfY+IRpVO8bWb+le+Wh15EadxaF+5pxugUJWFs5EtOPm6U2BkC7YuDri18WfYjvmMO/MhXl2aM3jdDDwq2EJObBKawmJcqxlXew/9PSsvn5uvB1kpmRbTn917ks5DavKcZ71rZy1KVRnYGdm3na8H6mTTa6XJyi8rT+rmAzgHmbe5wht3qG/B5rQpGdj6eJX9tvHxRJtqOp9Ql5MHav3r2twdv2HfXu+/nAf3pjjqun6I3Y2hnAAAIABJREFUQGExBcfP49CprcUy5aRkVvAN7uRUcf8v7D1FRzP3PyUuiZLCYnxbBZg9LjcliwZGOvWr0bmy9zTtDD4oR5XJrbPXKczKQ11cSvThS/h1MO8Di1WZOBjpOPq5U6Iq17FxcaBeG3967FxE/3Of4tq1BV03zqJBp2ZIWh1/LtrIiUFziAx7H9sGzhTEmffdJapM7I107P3cKangf4xtIXnTIeqZsYWaoFZl6Cem3SuDb9X1KGtbOI4d9fVInXyvHqXo61H4mTqtRzpRe5+6Qm5Q1hJCiNZCCON+/WDgthDiOWAo8LQkSVU+0gkhBgohnAzf6wHNgTvAceBfQgilocfyYfTjMW8D7YQQ9kIIV6Amj1fH0M9ERwgxHHC7n3ImR93ErakPDQK8UNgqaTuyJ7ERF0zSuAV6l31vPjCYrFsqAGwc7LB1tAegSd8O6DQ6k8k8xqRE3cQ10If6Bp1Wo3oSb6RTmlfEN51eYkPv6WzoPR3VxTh+mbKa1Mvx91McEqLi8Az0wd3fC6WtkuCRvfgjItIkjWegT9n3tgM7k24oz9on32FF39dZ0fd1jn/3KwfX7OLkRvOzU29FxdIw0BdP/4YobW0IGdmHqAjT2cYNjXQ6DuxC6i3zDrs6Ci7FYN/UF7uAhghbG9xH9yUr3HSGqW3D8tvuGhpCsWGiia2vB8LBDgBlA2fqdW9LcZzpoP17FF2Oxi6wEbb+3mBrQ4NHHyb/4O8maWy8ynXqDe5RNli+6HIMyvrOKN3rA+DcqxMlsaYTK+6Rfukm9Zv64GKwhWaje5IQXm4L6rwitnR8iR09p7Oj53TSLsRx4NnVZFyOxyXAC6HUuznnRh40aO5HfkKaWZ2KxEfF4m10z3qM7MOlCNPraHzPggZ2IdVgG9VhrWtnLfIvxeLQ1Bf7GtqcW2gIxTF6u7KraHMhbSmyYHPFV29g26QRNo30181leH8KDp8xSaP0LH/4cB7QE/VN/bXRJKXhGBIESgXYKHEM6UjpTcvX7U5UHF5GvqHLyN5creAbvIzuf7uBnUkz1Fl3fy8UBrtza+SJd3M/Mu+at7vEqDg8An1wM+gEjezF9Qo6HkY6rQd2JsNgZzFHL+PTOgBbBzsUSgWBPdqSZmE8d87FOJyb+eDY2Athq8R3TG9S9pfraPKKONDuBY6EvMaRkNfIjowlctL75ETdROFoh9JJ77s9H+6IpNFWmsxzj7yLsTg288Whsd4WGo7pQ/p+U19n19C17Lvn0G4UVjMG3RJFl6OxD/TD1t8bYahHeQdqXo8U9V3K61HvoEqTeayJDlFrn7pCHkNZe7gAnxoadhogFv3rbxX6ht9pIQTATkmSlljIoyvwmRDiXs/jN5IknRNCnAd6AVHoh/3PliRJBSCE2A5cBeKBizU4z3eALUKIP4BT6BusNUbS6jiwaANPbJyNUCq4sv0oGTGJ9J0xFtXleGIPXKBzWCiBfdujVWspyS3glxlfAuDkWZ8nN76FJOnIU2Xxy3TLS3ZIWh1HF25g1A+zUSgVXNt2lMzoRHrMHEvq5XiTxqU5wk59iF09RxS2NjQb2o1d41dVmiEOoNPq+GnRep7fOBehVHBu+xFSYu4ydPo4Eq7Ec+1AJH3CQmnZpyNajYainAK2zqx6qRFz6LQ6Ni/6ljc2zkcoFZzcfpikmLuMmv4vbl+JI+rAeQaEDaddn45oNVoKcvJZN/OzsuNXnliDo4sTSlsbOoeG8OHEZSYzxE3Q6riz4Gtab34bFArStx2kODoBv1lPUxgVS3bEObynPIJraAiSVosmO5/4Nz4FwLGFPwGLJqM3M4Hqi10UXbdgIlodqnc+p/H6pQiFguwdEZTE3MHrjQkUXYkh/+DvuIeNwmVQD9Bq0ebkkzT7Q8MF0ZGy8luafL8ChKD4aixZ28wvTyRpdZxZsIHQzbMRCgUx246SHZ1I51ljSY+KJ6EKW/Du3oqOr4xEp9GCTuL0vPWUZOVXc7cMp6jV8cOib5ixcQEKpYIT2w+RFHOXMdP/xa0rcVw6cJ5BYcNp1ycIrUZDQU4B38z8tEZ5W+vaVcebb6/i3MXLZGfnMmjMBF6eOpGxI4fef0ZaHbfmf0PrzYsQSgVpWw9SFJ1AozefoiAqjuzwc/hMHaG3OY0ObXYecdP118qhpT+tF4UhSfqlnZK/2F2lzaUtX4Pf1ysQCgW5P4VTGnsb91cnUfxHNIWHz+A6cTROA3qBRos2J4+UeR8AkB9+HMeenWi860tAovD4eQqP/G5eB/39/++idby0cZ5+2aDth1HF3GX49CdIuHKTqwcieShsKK36dECr0VKUU8Amg29oFtKGwS+NQqvRIukkflz4HQVZeRZ19i5az+SNcxBKBRe2HyE1JpFB08eReOUm1w9coGdYKM37dEBn8EE7DDrFuQWc+GYfL+1ZBpLEjcOXuHHY/IoTklbHH3PX0X3rPFAquLvlMPk37tJy9hPkRN0kdX+k2eMA7D0bELJ1LugkilWZXHp1jcW0klZHzNxvCdqq93XJWw5TeOMugbP/RV5UHBn7z9Po+RF4hnZD0mpRZ+dz/fXy/IJ3L8GpRSOUzg70uvgF16d/TtaRKPNiWh1Ji78gcMMShEJB1o/6etTwjfEUXYkh7+BZPCaPot6g7khavd3dffMjw4XXoVr5LU1/WA5CUHQllqytf60eyegRUhWzz2RkAN5rMsEqRuJopbHQt5Vaq+jkYGH5jlrmBUvLhPwNODuUWkXn9+L76jj/yxy3LbaKDsAsZc1mrj4oLX+vYaP2AbkQNMsqOh6uBVbRAfi00Dp252Kll4N9iqzjVJ2wjk8F8HS2Tj3qcPNnq3b17fJ5ptb+Z8eoNtdJN6XcQykjIyMjIyMjU4fIC5vL/CWEEM9Sefmgk5IkvVIX5yMjIyMjIyMj8yDIDco6QJKkdcC6uj4PGRkZGRkZmbpHJ/7316GUG5QyMjIyMjIyMnXIP2E2i7xskIyMjIyMjIyMzAMh91DKyMjIyMjIyNQh8qQcmf8TNLTSqjRqKw0h8dUpraKjU1jnJUaWxjrlAfij2NkqOn3qp1efqBZ4L8PyjiS1TbG9r1V0rLWcT5fL71tFp2juv62iAxDyi3X+Ek/aWWf5rRQbO6vodBTWW36rqKR2t079/4W63OGmtpAblDIyMjIyMjIydUhd7nBTW8hjKGVkZGRkZGRkZB4IuYdSRkZGRkZGRqYO+SfM8pYblDIyMjIyMjIydcg/YQyl/MpbRkZGRkZGRkbmgZB7KGVkZGRkZGRk6hB52SCZ/5M06h9E9yUTEQoFMVuOcGXNXrPpmowIYcDX09g7fCEZl+PLwp39PBhz5F0ufbCTP77cZ1HHv38Qvd6ZiFAquLHlCFEWdAJHhDDkq2n8NGIh6Zfj8QpuxkPvTtVHCriw+idu/Xa+RmUL7BfEgMV6zatbj3B2rXnNlsNDGPXlNH54dCEpRmWrijb9OjFmURgKpYIz2w5x6PM9JvG9xg+m78RQdDodJQXF/Dj3a1JiE8viXf08eCviA/Z/tIMjX/9cpZbHgE60WRaGUCq4u+kQtz7dYzZdw0e6E/zdDM6EziM36ibCVkm7/zxP/eBmoJO4vmADWaeuWdSxli049e1Kw3kvgUJBzo7fyPpmu0l8/TFD8HxzKpqUDACyN+8ld8dvAHjOmopzv+4gBIWnLpK24nOLOn0H9GTe8pkolAp2/LCbbz7daBLfrWdn5i6bTqt2LZj5wgLCfz4EQPc+XZmzdHpZumYtmjDzxQUc/PWoRa36/Tvjv/h5UCrI2BJBytr/msS7PzGQRvMno1bpy5S2fh8ZWyPK4hUujrQ79BnZ+3/n7sKvLOo06N+ZJkunIBQKUrccIPmzn0ziPZ8cQOOFkyhV6ZdQSln3K2mbD2DXyItW370FCoGwUZLy3T5Svw+3qFMdC1as5tjJs7i7ubLrhy/+cj4VUbbvhsNTLyEUCkqP/0bpb9tM4u2f/Dc2bTrpf9jZo6jnSt60x2uUt2//IEKW6u07dssR/vjMvH0HjAih3zfT2DdsIZmX43H292Tk0ffIvZkMQHpkLGfnWN5tt12/Tjy56FmEUsHJbQcJ/3y3SfxD44fQb+LQMt+wae6XqGITadO3I4+9NR6lrQ1atYadK77nxuk/LOo06h9ED0N9ja6mvg78ehp7DPXVM7gZvd/T+1Qh4OIHP3GnGp9av39nGr/zHCgVpG+JQLVmp0m8xxMD8V8Qhtpgd6nrfyF9y4GyeIWLIx0Of0r2/t+5s+DrqnWWTEUoFKRtOVBZ58kBBBjppKzbR/oWvX23+PYthEKht+91+0j7fn+VZfo7kcdQypgghJgPPANo0T9wvAi8AHQDBBANTJYkKd/C8a2BLwFXwB44LknSC3/zOedLkuRS4/QKQY/lYYQ/vYrC5Ewe3beEO+GR5MQkmaSzcXag7dShpF2IrZRHyOLxJB6Oqlanz7Iw9j2zioLkTMb8soTb4ZFkV9CxdXagw5ShpBjpZF6/y08jFiJpdTg2dGVs+HJuR1xA0lb9DCgUgkHLwtgxfhV5yZmM37uE2IhIMs1odpkylCQzZasq78eXTOGLCcvJUWUwfc8K/oiINGkwXth9ktOb9A61/eCujF44ka/CVpXFj14wiT+PXKpeTCFou2oKkU8upzgpg577V5C2P5KC6ESTZEpnB5o8P5zsyJiyMP8JgwA43X82dp716bJ5DmeGzgepsruzli2gUNBw4SskTp2HOiWdJts/oeDwGUrj7pgky//1GKnL1pqEOQS3xbFzO26PfgmAgE0f4BgSRNG5y2ZkFCx8dzZTn3iVlKRUtodv4PD+48RFlzeAkxJVzH19CVNenmBy7NmTkTw+UB/WwLU+v/3+X04eOVNlmQKWvUjMM2+jTs6g9c/vkxNxluKYBJNkWXtPWGws+s0aT/7vlhsP93QCVzzP9afeoTQ5g/b73iN7/zmKYu6aJMvYc5Lb878xCVOnZvHHyDlIpRoUTg4EHf6IrPBzqFOyqta0wJgRQ3hm7CjmLa3F9SuFAsdnXqXgwzlIWek4z/8UTdRpdMnltlGy/QtKDN9tB45GGdC8hlkLuq8I4+BTevsevm8Jd/ebt+82zw0lLdLUvvNvp7BvyPwa6Ty1ZCqfTFhGliqDOXtWcjniPCoj33Bu9wmOb9I/TAQN7sq4hWF8FraC/Kw81k59l5zULPxaBfDaxvnM7Wl+3U6hEPRcHsZ+Q30dWUV9bTd1KKlG9TXr+l32Di/3qaMjlpNQlU9VKGi87EWiDfbd9pf/kB1+luIKdpe194TFxmKjN58h73fLD7P3dJosf4HopxdTmpxBu33vmdXJ3HOyko46NYs/R5Xbd4dDH5MdfvYv27eMPIay1hBC9AIeBbpIkhQEDAYSgOmSJHUyhN0BXq0im0+ADyVJCpYkqS3w6d993veLZ+fm5N1KIf9OGjq1lvjdZ2g8tGuldF1mj+Pq2p/RFqtNwhsP7Ur+nTSybyRWOsYYr+Dm5N5KIc+gE7f7DE1CK+t0fXMcUWt/RltSrqMtLi1zdDb2tubaQmbxCW5O9q0UcgyaN/aeoYUZzT6zxnH2c1PN6mgc3IL02yoyE1LRqrVc3HuKDqHdTNKU5BeVfbdzsjc57w6h3chMSCWlgqM0R4MuLSiMV1F0OxVJrUW16xQNh3WrlK7FnCeJ/2wPOqN75NyqEZkn9I2U0vRc1LmF+t5KM1jLFhyCWqO+k4z6rgrUGnL3HcV5YK9qr8M9hL0dwtYGYWeLsFGizTD/hxHUpT134u9y93YSarWGfT+FM3DYwyZpkhKSib4Wi05n+eEkdORAjh86TXFRicU0zsEtKbmlovROCpJaQ9ae4zQI7V7jMjl2bI6Nlyu5x6p+wHDp3ILiW8mUGHQyd5/AbWjNdCS1BqlUv6uBwt4GFA82a6BbcEca1K/3QHlURNm0Nbq0JKR0FWg1qM8dxSa4t8X0tiH9UZ89UqO8PSrY963dZ/A3Y9+dZo/j2pqf0d2HPzAmMLgFabdVpBt8w/m9p+gUGmKSptjENziUPeDd/eMWOal6e06KTsDWwQ4bO/P9RBXr680q6uuVCvXV2Kcq7W2r7U7T23dymX1n7j6Ba2iP6i+GAaeOzbH1dCX3aNX27dxZr/Og9i3sbR/Yvh8Unai9T10hNyhrD18gXZKkEgBJktIlSUqSJCkXQAghAEeqroq+QFmLQZKkK4ZjHYQQ64QQV4QQF4UQAwzhk4UQn91LL4T4WQjR3/A9XwixXAgRJYQ4I4TwNoQ3FUKcNuS17H4L6eTjRkFS+e4iBcmZOPm4maRx7xCIk687dw+aOgMbJ3s6vPIol1abvpIwh7OvG/nJRjqqTJx9TXU8OgTi4udOwqHKTserc3PGHVzF2AMrOTl3XbW9kwAuPm7kGZUtLzkTF29TzYYdAqnn6068Gc2qaODtTnZSRtnv7ORMGni7V0rXZ2Io845+zKNzxvPT4vWAvnE58N+j2P/xjhppOfi4U2ykVZyUib2PqVa9joE4+HmQfuCiSXjetTt4De2KUCpwbOxF/aCmOPh5mNWxli3YNPRAo0or+61JScfWu/I5uYT2pcmuz/H9aD42Pp76sl/6k8Lfo2h2bDPNjm2m4EQkpTcTKh0L0NDHC1ViStnvlORUvH29qj2/iowYE8q+nVW/Grb18aA0qXw3IHVyBrY+lcvkNrwXbcM/pukXb2Hrqy8TQuC/8FkSl1p+hXoPOx8PSo1soTQ5A1vfynbnPqIXHQ+spuVXb2JndL/t/DzoeGA1wee/JnnNT//f9d4IV090meW2IWWloXA1b6/CvSEKTx+012tWd5183Cg0su/C5EycKvgg946BOPu5k3iwcp4ujb0YEb6MIf+dj1f31hZ1XL3dyTK6R1nJGbia8Q39Jg5lydFPeGzOeLYtrnzvOw/vQcLVm2hKzW9tVrG+FiZn4uxT2ac6m6mvoG+Qjjm0ijEHV3JqTtU+1c7XndLkcvsuVWVgZ8buXIf3ol3ERzT7craJfQcsepaEZest5l+m4+NuUo9KLdWjET1pH/Ehzc3Yd/uID+l07mtUdWzfulr81BVyg7L2CAcChBDRQoi1Qoh+9yKEEOsAFdCGqnsdPwQOCSF+FUJMF0K4GsJfASRJkjoCTwMbhBAO1ZyPM3BGkqROwDHgeUP4x8DnhryS77OM1SME3d8ez/klmytFBc98nGtf/4am0HLPzf3o9Hx7PGfM6ACkXYxjx6A57HpkEZ1eHal/qq4Fzf4Lx3N0mXnN2uDk9+Gs6DeNX1ZtZshrjwEw9I0nOPrtPkpr47oBCEHrdyZxY/EPlaKSNh+mJDmTHuEraL00jOxz0UhV9MZVp2MVWwDyj5whflAYt8e8ROGpi/is1G8/aNvYF7vmjbk5YAI3+4/HqWcwjl3b14qmObwaetCqbXNOHD79wHnlRJzjau/n+TN0GnnHLxH44TS9xqTh5B6KLBtb+aBkR5zjUo8XuTJ4BjnHomj20etlcaVJGVwZPIOo3i/j+cQAbDwb1IpmXWDbvT+aC8dBqqW/XCHo+vZ4It+pbN9FqdnsDHmDfaELiFy8ib5rX8bWxfGB5I5+v59F/V5n16pNjHhtrEmcb0t/Hpsznk3zLI81rBYhCHl7POcs+NT0i3HsGjiHvSMWEVQLPjU74hxXer3AtSFvkHvsEk0NducVNpycQ5Gok2vLvs9zueeL/DFkOrnHomj60bSyuNKkDP4YMp0rfV7C43/cvv9/QB5DWUtIkpQvhOgKPAQMALYJIeZIkrRekqRnhRBK9I3JfwFmuxYkSVonhNgPDANGAy8KIToBfQ3HIknSdSHEbaBVNadUCtybuREJDDF87wPc80bfA++aO1gI8QL68Z+ENehOf+eWABSqsnD2K3/SdPZ1p1BV/lRn6+KAaxt/hu3Qjx1y9GrAoHUzOPjsarw6tyDwke50m/8UdvWdkHQS2hI119dHUJGC5CxcjJ5onX3cKUg21XFv7c+jP5brhH43g/Apq0k3mvSRHZuEpqAYt9b+JuHmyFdlUc+obPV83ck3emK1c3HAs7U/T27Tazp7NWDMtzPYNXV1tRNzclIycTV6Mnb1dScnxfI+0hf3nmLssqnA5zQJbkGnET0YOXc8jobrpilRc2Kj+QHkxapMk15FBz93SlTlWjYuDri08Sdk5yJ9uRo2IHjjLC5Nep/cqJvcWFQ+EaX7z0sojDP/3GEtW9CkZmDjU95TaOPtiTrF9M9Gl51X9j1nx294ztJPIHAZ3IfiqOtIhfq9hguOn8MhuC1FkZXHHqaq0vBp5F3229u3ISnJaZXSVcWw0YM5sO8IGo22ynRqVQZ2fp5lv219PSo1ELVGZUrfEkGjeWEAOHdtg0v3dnhOGo7S2RFha4OuoJikVaYTiMDQM2TcI+PrgTrZ1O40WeVDulM3HyBgwcTK55uSReGNO9Tv0Y7MXx68sVxbSNnpKNzLbUO4eaHLNt8QsQ3pT/Hmz8zGmaNQlYWTkX07+bpTWMEHNWjjz5D/ltt3//UzODJ5NZmX4ykt1V/XzCu3yL+VSr1mPmSa8RPZKZm4Gd0jN18PsqvwDef3nuLpZc+X/Xb1cefFL2exfsYa0u+kWDyuYn118nWnoEJ9datQXwevm8GBZ1ebTKTLiU1CU1iMa2t/k3BjSpMzsfMtt287Hw9KK9idqX0fwH++3r5durbGpXs7vCYNR+HsgMLWBm1BMYkrv6+so8o0qUd25upRVrlO2uYD+M+fVCkfdUoWRTfuUK9HO7LqyL7lWd4yJkiSpAWOAEeEEFeAMGD9vTghxFZgNhYalIZ0ScB3wHdCiKtAhyokNZj2Mhv3WqolqWwUnhbTe13tqEJJkr4CvgJY32hCWfr0Szep39QHlwAvClWZNB3dk2OvlE+EUOcVsbXjS2W/h/04n3NLN5NxOZ5fH19aFh4843HUBcVmGxAAaVF6nXoBXhSoMmk+uieHXzXV+T6oXOeRH+fz+9LNpF+Op16AF/lJGUhaHS6NPGjQ3I+8hOobBqqom7g29aF+gBf5qkxaj+zJvtfLNUvzilgbXK755Lb5HF2+uUazvBOi4vAK9MHd34uclEw6j+zN96+bdlZ7BvqQfksFQNuBnUm/pW/Iffbk4rI0Q98YR0lBscXGJEDuxTicmvng2NiL4uRMfMb05vJL5VqavCKOtCuf69Vt5yKi3/mB3KibKBztEEKgLSzB/eGOSBptpck897CWLRRfuYFtEz9sGnmjSc2g/oh+JL9p+hyk9HJHm6b/w3IZ2JPSm/pJGerkVBo8MRy+UoAQOHXrSNbGXWZ1rly8RpNmATRq7EdqciojHgvlzX8vNJvWEo88Fsrq5WurTVcQFYN9oC92AQ1RqzJxG/UQt177wCSNTUM3NIbxcQ1Cu1Mcqx8Nc+v11WVp3J8YiFNQC7ONSYD8S7E4NPXFPqAhpapM3Ef3Je6VD03S2DZ0Q23QcQsNoThGf7/tfD1QZ+UhFZeibOBMvZC2qL4yPyu4rtDeuoGiYSOEpw9SVjq2If0o+mZVpXQKnwCEkwvauGomeRiRcekm9Zr64BzgRZEqk8DRPTlRwb53dCi37yE75hO5ZDOZl+Oxd69HaXY+kk7CpbEX9Zp6k38n1azO7ag4Ggb64uHvRXZKJt1G9ua71z8xSeMV6EOawTd0GNiFVINvcKzvxCvr5rDr3c3cjLxRZXkq1tdmo3tytEJ5tliory4BXhQYfKqzwafmV+FTC6JicGhabt/uo/ty89XVJmmM7c41NKTMvuNfK7dPjycG4typudnGJEDBpRjsK+hUZd/GOra+HmiM7bt7W1K+Nr8ahjWQ/gELm8sNylrCMENbJ0nSvSmzwcAdIUQLSZJiDWMoRwHXq8hjGHBQkiS1EMIH8AASgePAePSvw1sBjYEbQH3gZSGEAmgE1GQ08kngKeAHQ573haTVcWbBBoZsnq1fSmPbUbKjEwmeNZaMqHgSIi7cb5YWdU4t3MDwTXqdG9uOkhWdSNdZY0mLiudOFTre3Vsx9OWR6DRaJJ3EyfnrKckyO7G+kuahhRsY+/1sFEoFV7cdJSM6kd4zxpJyJZ64ByibTqtj56J1vLBxHgqlgrPbD5MSc5dh058g4cpN/jgQSd+wobTq0wGtRktRTgGbZ1pe3qa6clyfu44uW+chlAoStxym4MZdms9+gtyom6Ttj7R4rJ1nA7punYukkyhRZXLl1TVV6ljDFtDqSFu2Fv9vloNCQe7OcEpjb+Px2kSKr8ZQcPgMbhNG4zywJ2i0aHPyUM3VN87y95/AqUcwTXZ/AZJE4YlICo78bl5Gq2XZnP/wzbZPUCgV7Ny8l9gbN3ntrRe4eulPDu8/Tofgtny6/j3qN6jPgNCHeG32C4x8+CkA/AJ88WnkzblTNSi3VkfCwq9o8cNihFJBxraDFEcn4DvzGQovx5ITcZaGzz5KgyHdkbRatNn53Jrx8V+6drfmf0PrzYsQSgVpWw9SFJ1AozefoiAqjuzwc/hMHYFraAiSRoc2O4+46fqHD4eW/rReFIYk6ZeKSf5iN0XX71QjaJk3317FuYuXyc7OZdCYCbw8dSJjRw79y/kBoNNRvPkznN5YgRAKSk/uR5d0G/tRk9DejkYTpZ9pbxvSH/W5I/eVtaTVcW7+BgZtno1QKojbepSc6ESC3hxLZlQ8d8Mt3+eGPdvQ6c2x6DRa0En8PmcdpdkF5oug1bF10Xe8tnE+CqWCU9sPkxxzl0enP8mdK3FcPhBJ/7BhtOnTEa1GS2FOPhtm6utl/0nD8Griw4hp4xgxbRwAn05cRl5GrtnynFmwgVBDfY0x1NfOs8aSXk199e7eio6vjCwrz+l51fhUrY47C7+m1aa3QaEkY9sBiqMT8Jv1NAVRseREnKPhlEdwNdi3JjufW9M/sZxfVToLvqb15rdBoSDdUI/vu5EQAAAgAElEQVT8Zj1NYVQs2RHn8J7yiN6+DTrxb+jt27GFPwGLJqPvXxGovtj1QPYtA0Kq6RRYmSoxvO7+FP2SPxogFvg38BP6hp8AooCX7k3UMZPHauARoNgQ9B9Jkn4wjJf8HP3yQxpghiRJhw2N1B+ArsCfgBuwWJKkI8bLAQkhxgGPSpI0WQjRFNgMuAC7gTeqWzbIuIfy70RtpSe0XCuNHE5UmB8cX9sMK6o+TW2RZGOdZ9De9dOrT1QLjM6w/Gqxttlk72sVHbVWaRWdLpdrcfmfKiiaa34ZnL+DPb80tIrOSbtSq+h0V9tZRaejqP6BvbaQrNSVF5L4k1X7DNcG1N7/7MsJP9RJf6fcQ1lLSJIUCZhbr6LPfeQxA5hhJrwYeNZMuISFXkbjRqIkSTuAHYbv8YDxmisLanp+MjIyMjIyMrXPP2EMpTzLW0ZGRkZGRkZG5oGQG5R1gBBivhDiUoVP9VsqyMjIyMjIyPzjkGrxUxOEEMOEEDeEELFCiDlVpBsrhJCEEJV3x6iA/Mq7DpAkaTmwvK7PQ0ZGRkZGRqbuseYON4ZlDNegX07wLnBOCLFHkqRrFdLVA6YB5mcyVkDuoZSRkZGRkZGR+b9DdyBWkqSbkiSVAlvRr31dkaXo16ouNhNXCblBKSMjIyMjIyNTh1h568VGgPEetHcNYWUIIboAAZIk/VLTMsivvGWq5YatdeafuVhpOYhkYZ3lfPKwjo7K5sG2dLsf8q30CPpnVuV9f/8O6tlYb80lO9uqd8+pLerXq1FnwgNjreV8HFd+YRUdgLMRc62iY623mxnWWUGKO6VO1hECtMJKywZZRaWc2vyXNd7pzsBXhs1Kanq8AlgNTL4fXblBKSMjIyMjIyPzD8F4pzsLJAIBRr/9DWH3qId+l74j+uWu8QH2CCFGSZJ03lKmcoNSRkZGRkZGRqYOsfIWM+eAloaNThLR7573TNm5SFIOULZJuhDiCDCrqsYkyA1KGRkZGRkZGZk6xZqzvCVJ0gghXgX2A0rgO0mS/hBCLAHOS5L0lzY1lxuUMjIyMjIyMjL/h5AkaR+wr0LYIgtp+9ckT7lBKSMjIyMjIyNTh/wTtl6UG5QyMjIyMjIyMnWIlcdQ/i3I61DKyMjIyMjIyMg8EHIPZS1i2I/7GUCLvgf7RUmSfjfEfQJMkSTJpYrjWwNfAq6APXBckqQXLKWvpXPOr+qczNGqXxCPLpqEQqng3LbDHP18r0l89/GD6DVxCDqdjtKCEn6a+w2psfoVCXzaBPDYiuewd3FE0ulYM3ohmhK1WZ1m/YIIfXsiQqng0tYjnK6g02X8ILpOGoKk1VFaWMy+ud+SHpOIwkbJI+8+h0+HpihsFFz57wlOrbU8xrhtv06MWzQZhVLBqW2HiPh8t0l83/GDeXjiUHQ6HSUFxWyZ+xWq2ESadGrO0ytfuHch2ffRj1zef86iTsd+wYxfNAWFUsHRbQf55fOfTOKHTh1Jv6cGodPoyM3M4dvZa8lITAPgyTkT6DSgKwC7P/2Rsz+fsqgD4Nc/iJAlExEKBbFbjnB1zV6z6RqPCKH/19P4ZfhCMi7Hl4U7+3kw6si7RH2wk2tf7jN7LEDj/kE8tFh/j65tOcKFteZ1mg8PYfhX09j+yEJSL8fj4OrCsC9fp2GnZlz/8RjHFm6ssjwNBwTRcekkUCq4s+kwMZ+Z1/F9JITu307n6ND5ZEfF4/94H1q8/EhZfP12jTkyZD65f9yuUu8ePft3Z+bS11AoFOze8gsbP9tsEv/MC08y6plH0Gq0ZGdks3TGu6gSU2qUt8vDXfBd9AIoFGRtDyf9ix0m8a5jB+EzZwrqlAwAMjf+TNb2cABs/bxotPI1bHy9QJK4PWUx6sRUszpOfbvhOfffoFSSu+NXsr/ZbhJfb8wQPGc9hyZVr5OzaQ+5//0NAI+ZU3Hq1wMhBIWnL5C+4vMalU3ZvhsOT72EUCgoPf4bpb9tM4m3f/Lf2LTppP9hZ4+init50x6vUd7VsWDFao6dPIu7myu7fniwNSzb9uvE4wbfcHrbIQ5U8A19xg/mISPfsM3gGxp3as5TBt8ghODXanxDu36deGLRswilglPbDhJeQeeh8UNMfNDmuV+iik2kTd+OjHlrPEpbG7RqDTtXfE/06T8s6gT2C2Kgob5e2XqEsxXqa6cJAwk28qkRc74lIyYJha2S0JVT8Q5qiqTTcXjxDySc+bPKa+c9IIigpZMQSgW3Nh0m2kKd9XskhJ7fTueQoc4GPN6HlkZ1tkG7xhwaMp8cC3XWe0AQnZfoy3Rz8xFuWNBp9EgIvb95gwPDFpAVpfd1DdoG0PW9qdjUcwSdxIHhC9FZ+D/6u9H9A/oo5QZlLSGE6AU8CnSRJKlECOEJ2BniugFuNcjmE+BDSZJ2G47r+Hed719FKASjljzLtxNWkqvK4JU9y/gz4kJZgxEgavcpzm46CEDbwV14ZOEE1oW9i0Kp4MkPX2H7jLWo/ryDk6sLWrX5xb+FQjBs6WQ2j19JriqTKXuWEnPgAukx5TpXd5/igkGn5eAuDF4wnq1h79H2kR4o7Wz5eugcbBzsePHAe/yx5xQ5d9PN6jy5ZAqfTVhOtiqDN/es5ErEeVRG5Tm/+yQnNh0AoOPgrjy+cBJrw1aSdCOB90bORafVUd/Llbm/vsfVA5HotJVHwwiFgklLnue9CUvIVGWweM+7XIw4R1Ls3bI0t6/Fs3jkbEqLSxk4YSj/mjuRta+uptOALjRp34yFI2ZiY2fL3K1LuHzkIsX55hflFgpBj+VhRDy9isLkTEbsW0JCeCQ5MUkm6WycHWg7dShpF2Ir5dFt8XgSD0eZzd9Yp9+yMHY/s4r85Eye/HkJ8RGRZFXQsXV2IGjqUFRGOpoSNb+/vwP31v54tPavUgeFIGjls5x6ciVFyRn0+20ZqvAL5EUnmiSzcXag2XPDyIyMKQu7u/Mkd3eeBKBemwB6rJ9R48akQqFg9oo3ePWpmaQmp7Fh35cc33+S+Jjy429cjSFs+AuUFJUwdtJoXlv4b+b/+52aZI7fOy8RP2kBGlUGzXZ9SN6B3ymJTTBJlvPLcZIXV24U+b8/g9S12yg4cQmFkwOSzsKfkUKB14JXSHxuLpqUdAK2fUrB4TOo4+6YJMv79Rjpy9eYhDkEt8Ohc3sSxugXMPf/4QMcQ4IoOne56rIJBY7PvErBh3OQstJxnv8pmqjT6JLLNUu2f0GJ4bvtwNEoA5pXned9MGbEEJ4ZO4p5S99/oHyEQvDEkimsMfiGWXtWcrWCb4jcfZKTBt/QYXBXHls4ic/DVpJ8I4H3jXzDW1X6BsG/lkzlkwnLyFZl8NaelVyuoHNu9wmOb4oA9D5o7MIw1oStID8rj8+nvktOaha+rQJ4beN85vU0v+C8UAgGLwvjx/GryEvOZMLeJcRFRJJhVF//3HWaqB8OAdB8SBf6L5zAfye9R9DTAwDYEDoXJ4/6PL7xTX54dBFIluxO0Gnls5ww1NkBvy0j2UKdbVGhzibsPEmCoc7WbxNAz/UzLDYmUQi6rJjMsX+tpDA5k8G/LiXJgk7L54aREVnug4RSQffPXubsa5+Tc+0Odm4u6Cz8H1mDf8IYSvmVd+3hC6RLklQCIElSuiRJSYZN2P8DzK5hHmUtDEmSrgAIIRyEEOuEEFeEEBeFEAMM4ZOFEJ/dSy+E+FkI0d/wPV8IsVwIESWEOCOE8DaENxVCnDbktex+CxkQ3IKM2ylkJaSiVWuJ2nuatqFdTdKUGDV07JzskQxOp+VDQaiu30H1p/6PpTA73+IfoV9wczJvpZCdkIZOreXa3jO0GmKqU2qkY+tkX/ZdkiTsnOwRSgW2DnZo1RpK8sw3vgKDW5B+O4UMQ3ku7D1FUKjpHgnFFsqjLi4t+4OwtbctCzdHs+AWpNxWkZaQglat4fe9J+hSQef66auUFpcCEHsxGncfD/21aBnAjbPX0Gl1lBaVkHD9NkH9OlvU8ujcnLxbKeTf0V+7W7vPEDC0a6V0wbPHcXXtz2iLTZ/IA4Z2Jf9OGjk3EisdY4x3cHNybqWQa9CJ2XOGZqGVdXrMGseFtT+jNXry1xSVkHwu2iTMEm6dW1AQn0LhnVQktZbEXafxMVOeNm89QeyavRZ7GPwf603irtPV6t2jfee23L2VSNKdZDRqDeG7D/Hw0L4maSJPXaSkSN80unLhGg19vWqUt2OnVpTcTkadkIKk1pDz8zHqDelZo2PtWwSAjYKCE5cA0BUWIxWXmE3r0LE16jtJaO6qQK0h/9cjuAzsVSMdJAlhb4ewtUHY2YKNDZqMrGoPUzZtjS4tCSldBVoN6nNHsQnubTG9bUh/1GeP1OycakC34I40qF/vgfNpEtyCtAq+oeNf8A021fiGwOAWpN1WlelE7j1Fpyp07J0cyhpyd/+4RU6q/p4kRydg62CHjZ35fiKf4OZk3Uohx1Bfr+89Q/PQKnyqo32ZjkfLRtw5pe/5LMzIpSS3EJ+gphbL5F6hzt7ddRpfM3W23VtPEL1mr0U/EPBYb+5WUWfdOzcn/1YKBXfSkNRaEnafoZEZnfZvjeP6Z3vRlpSWhXn360jOn3fIuab/PyrNygdLD2YyNUJuUNYe4UCAECJaCLFWCNHPEP4qsEeSpOQa5PEhcEgI8asQYroQwtUQ/gogSZLUEXga2CCEcKgmL2fgjCRJnYBjwPOG8I+Bzw151eScTKjv7UZOUkbZ79zkTBp4V94mr+fEIcw6+iHD5jzD3sX615mezXxAknh24xxe/Xk5D7/4qEWdej7u5CWb6tTzqdzJ23XSEF4+tppBc59m/9sbALi+7yylhSVMO7eGV09/zO9f/UJxToFZnQbe7mQZlScrOYMG3pV1Hp4YyttHP2bMnPHsWLy+LLxJcAvmh7/PvP3vs3XBN2Z7IADcvN3JTCrvIc1MzsTN28Ni+fs9OYjLRy4AkPDnLYL6dcbOwQ4Xt3q07dUBd1/Lxzr5uFGQlFn2uzA5E6cK1869QyDOvu4kHrxkEm7jZE+HVx4lavVOi/nfw9nHjTwjnfzkTJwr6Hh1CKSenzu3D12qeHiNcfB1o8joHhUlZ+Lga2pzDToG4ujnQcoByzqNRvfk7q6qhwoY4+XjSUpS+Wvk1OQ0vHw9LaYf9fQITh/6vUZ52/p4oE5OK/utSU7H1ow91B/Wmxb7PiVgzVxsDdp2TRuhzS0g4PN5NN/7Md5zngWFeVeu9PZArTLSUaWjbFi5DC6hfQj46XN8PlyAjY++UVwc9SdFZ6MIPLqFwKNbKDwZifpmQqVjKyJcPdFllmtKWWkoXM3bq3BviMLTB+31v24ffxeu3u5kG9ldtgXf8NDEUBYd/ZjRc8bz3wq+YW74+8zd/z7bq/ANrmZ9UGWf+vDEobxz9BMemzOe7YvXVYrvPLwHCVdvoik138tWz0x9rWemPMGTBvPc8Q94eN5THHxb77vT/rxD8yFdEEoFDQK88O4QSD0/yz7IXJ11rFBnXQ11VvUAddbRx53CxHKdwuRMHCv4INeOgTj5eaCq4OvqNfcFCR7a8haDw5fR+mXL/0fWQKrFT10hNyhrCUmS8oGu6PfPTAO2CSHmAU8An9Ywj3VAW+BHoD9wRghhD/QFfjCkuQ7cBlpVk10p8LPheyQQaPjeB9hi+P69pYOFEC8IIc4LIc5fyqv8SrQ6znwfwfv9pvPbqi0MfG0MAAqlkiYhrdk2bQ1fjnuH9kNDaN67/X3nbUzkxgjWPjyDQ6u20teg4xfcHEmn45Pur7Km73R6PD8C14Ca9RxZ4tj34bzTbxq7V21m2GvlY71uX4pleegs3hs1j9CXxmBjb/tAOgC9xzxMYFBz9n2lH0d19XgUUYcvsGDnCl76ZDqxF26g0z3ACxIh6Pb2eM4v2VwpqtPMx7n29W9oCs33eN2vTt9F4zmxtLJOrSIEHd6ZwNV3frCYxK1zc7RFJeRdv2sxzYMw7PEhtA1qzfefb621PPMOniX64SnEjniN/BMXafSf6QAIGyXOIe1RrfiWuDHTsWvsg9u4QX9Zp+DwGW4NDiPhsZcoPH2BhitmAWDb2A+7ZgHcGjieWwOewalHJxy6dqiVst3Dtnt/NBeOg/S/+8Lv+PfhLOk3jT2rNhNawTesDJ3F+6PmMaQWfMOx7/fzdr/X+WnVJoa/NtYkzrelP2PmjGfzvK8fSAPg0sYDfPPQTI6t3Eqv1/U+9cq2o+QlZzLx56UMeHsCSZExSBYayDVCCDq+M4ErNaizuQ9SZ4Wg0+LxRC3eVDlKqcCzeyt+f2UNh0cvodHwbjTs+2D/Rw+CrhY/dYXcoKxFJEnSSpJ0RJKkt9H3TL4DtABihRC3ACchRJWtM0mSkiRJ+k6SpNGABv1+mpbQYHoPjXst1VL5exYtpuNlq32IkSTpK0mSukmS1C24Xouy8NyULBoYPZnW93UnJyXTXBYAXN57mnZDugGQo8rk1tnrFGbloS4u5cbhS/h1MP/aJE+VST1fU508leXXbX/sOU2rUL1O+9G9iTtyGZ1GS2FGLncjo/ENamb2uJyUTNyMyuPm60FOimWdyL2nCBoSUik8JS6RksJi/FoFmDkKslIycfcr7xly93UnKyWjUrp2fYIY+epYPnpupUlPw941/2XRiFn8Z+IShBCoblruXC5UZeHsV94b4OTrTqHRtbN1ccC1jT9Dd8zn8TMf4tWlOQPWzcAjqCmenVvQdf5TPH7mQ9o+N5SOr42i9eQhZnUKVFnUM9Jx8XWnwEjHzsUB99b+PLZ9PpNOfYh35+Y88t0MGlbxqswcxclZOBrdI0dfd4qTy23OxsWBeq0D6LtzIUPOfYxblxb02DAL107lOo3G9OLuTzV/3Q2QpkrH269h2e+Gvl6kJVcehxvyUFeenTaRWZPnoS6t2YB+tSoDW6PX4za+nmWTb+6hzc5DMthA1rZwHDvq66E6OZ3iazdRJ6SAVkde+Bkc2psfg6hNycDWx0jHxxNtqmkZdDl5oNafd+6O37Bv3xIA58G9KY66jlRYjFRYTMHx8zh0altt2aTsdBTu5ZrCzQtddmVbh9p/3V2bZKdk4mpkd67V+IYL1fgGXwu+IdusD7LsUyP3nqKTkY6rjzsvfDmLDTPWkH7H8oSwPDP1Na+K8lzfc4YWhlfiklbHkSWb2Dh8Prue+xD7+k5kxVv2QebqbFGFOlu/dQAP7VzI0HMf496lBb0q1Fn/GtTZIlUmTo3KdZx83Sky8kE2Lg40aBNA/50LGHH2Izy6tKDP+pm4dWpKUXImaWeuU5qZj7aolORDl3DtGFilnkzVyA3KWkII0VoI0dIoKBj4UpIkH0mSAiVJCgQKJUlqYT4HEEIME0LYGr77AB7o99k8Dow3hLcCGgM3gFtAsBBCIYQIALrX4FRPot+3k3t53g93o+LwDPTBzd8Lpa2STiN78WdEpEkaj0Cfsu+tB3Ym/ZYKgOijl/FuHYCtgx0KpYKmPdqSGmP+6TMp6ibuTX1oEOCFwlZJu5E9ia6g4xboXfa95cBgsgw6uYnpBPZuB+jHAfl1bklGnOlEkXvcjorDK9AHD0N5uozszeUI0+1KvYzK035gZ9Ju6R2ph78XCqW+Crk18sSnuR8Zd9MwR3xULN6Bvnj6N0Rpa0OPkX25WEGncfumPLviRT56bhV5Gbll4UKhwNlVPxE/oE0TAto04epxy6+JMi7dpF5TH1wM1y5wdE8Swi+Uxavzitje8SV29pzOzp7TSbsQx+FnV5NxOZ79jy8tC//zm/1c+XQPN9ZHmNVJibpJg0Af6hl0Wo7qSXxEuU5pXhHfdnqJjb2ns7H3dFIuxvHLlNWkGs0mrwnZl+JwbuaDU2MvhK2SRmN6oQovtwVNXhG/tX+RiJBpRIRMI+tCLL+HvU+2YSYnQuA3qud9jZ8EuHbpOgFN/fEL8MHG1obQ0QM5Hn7SJE2rDi2Z++5MZk2eS1ZGdo3zLrocjX2gH7b+3ghbGxo8+jB5B0xfl9t4lb+6qze4R9mEnaLLMSjqu6B0rw+Ac++gSpN57lF89Qa2TRph08gbbG1wGd6fgsNnTNIoPcsbGc4DeqK+qR9TpklKwzEkCJQKsFHiGNKR0pumk3nMob11A0XDRghPH1DaYBvSD01U5Wuv8AlAOLmgjbtWbZ51wR2Db3A38g1Xaugb3Cv4Bu/mfmRa8A23o+JoGOhb5oO6VuODOgzsQqpBx7G+Ey+vm8PudzdzM/JGleVRRd3EzcinthnZkzij+grgauRTmw0q96k2Dnb6MZVAk4c6oNPqTCbzVCTrUhwuRnXWf0wvkivU2V/av8j+kGnsD5lG5oVYTleos/6jepJQTZ3NunQTl6Y+OAXodQJG9yRpv6nOnvb/Zl/3N9jX/Q0yLsRycvIHZEXFozpymQZtA1A62iGUCrx6tiU3uupx438nOlF7n7pCnuVde7gAnxrGPWqAWPSvv++HUOBjIUSx4febkiSphBBrgc+FEFcMeU82zCQ/CcQD14A/gQtmczVlGrBZCPEWsLu6xBXRaXXsWbSeKRvnIJQKzm8/QmpMIoOnjyPxyk3+PHCBXmGhtOjTAa1GQ1FOAT/O1C81UpxbwIlv9vHKnmVIksSNw5e4cdh8w0jS6ti/aD1Pb3wLhVJB1PajpMck8vCMsSRfjifmwAW6hYXStG8HdGotRbkF7Jmhnw17fmMEI99/kRci3gUhuPzjUVKvm//D1Wl1bF/0Ha9snIdQKjiz/QiqmLs8Mv0J7ly5yZUDkTwcNpQ2fTqi1WgpzClg48y1ADQLaUPoS6PRarRIOoltC7+lICvPos73i77hzY0LUSgVHNt+iMSYBB6b/hS3rsRy8cB5npo7CXsnB15ZOxOAzMR0Pnp+FTa2Sub/qJ8/VZRfxJfTP7Y4HuvetTu7YAODN8/WLxu07Sg50Yl0mjWWjKh47kbUxEyqR9LqOLZwA6N/mK1fNmjbUTKjE+k+cyypl+O5VY3OpFMfYlfPEYWtDc2GdmP3+FWVZojf07k8bz29tuht7s6WI+TdSKTN7HFkX7qJKrxqHY9ebShKyqDwjvlldSyh1Wr5z/yP+GTz+yiUCvZu3cfN6Fu88OYU/oy6zvHwU7y+8N84Ojuy8iv9zG5VYiqzJs+rQeY6khZ/QeCGJQiFgqwfIyiJuUPDN8ZTdCWGvINn8Zg8inqDuiNpdWiz87j75kf6Y3U6VCu/pekPy0EIiq7EkrV1v0WdtOVr8Pt6BUKhIPencEpjb+P+6iSK/4im8PAZXCeOxmlAL9Bo0ebkkTLvAwDyw4/j2LMTjXd9CUgUHj9P4ZEajBHV6Sje/BlOb6xACAWlJ/ejS7qN/ahJaG9Ho4nSN2htQ/qjPnek+vzukzffXsW5i5fJzs5l0JgJvDx1ImNHDr3vfHRaHTsWfcfLG+ehMPINIwy+4eqBSB4KG0prg28oyingB4NvaB7ShsFGvmF7Nb5h26LveHXjfP3yRNsPkxxzl0enP8ntK3FcORBJ/7BhRjr5bJypn5Hfb9IwvJr4MHzaOIZPGwfApxOXkW/0QHoPSavj4MINjP1+NgqlgivbjpIRnUifGWNRXYknLuICnSeH0qRve3RqLcU5Bfw640sAnDzrM+77t5B0OvJTsvj1jaqXj5K0Oi7NW08fQ529baizbQ11NrmaOutZwzoraXVcnLeeh7e8hVAqiN96lNzoRNq/OZbMqPgqddQ5hUR/+SuDfl0KkkTywahK4yytyT9h2SBR1ewzGRmAuYHPWMVIXCTrPFolC+ssDZGHdXQGqR2togOQa6V3GgFq64wEWq6wXo/Edw4PPvO4Jjg4WGcdvYZ9rPPf4bjywdaSvB9mdptrFR2NlRoPzXR21tEptd7IPa2wzv/EE8mbrNrXt6AW/2eX3dpcJ/2Ucg+ljIyMjIyMjEwd8k/o2pMblHWAYUedJyoE/yhJ0vK6OB8ZGRkZGRmZuuN/d52DcuQGZR1gaDjKjUcZGRkZGRmZfwRyg1JGRkZGRkZGpg75J0zKkRuUMjIyMjIyMjJ1yP9+c1Jeh1JGRkZGRkZGRuYBkXsoZapl0ZqarJf+4OjO1Hyf5QdB0cL8rjm1TeH2+1tI+69SkGK9alyQY28VnYZB5vder23SztR8MfIHZZ+t+Z1SapvEQussVxXyi3Xs7myEdZbyAfjg/Eqr6Dj6PWQVnVU+A6yio7SKip7+Pf+e7VPrGnlSjoyMjIyMjIyMzAPxTxhDKb/ylpGRkZGRkZGReSDkHkoZGRkZGRkZmTrkf79/Um5QysjIyMjIyMjUKf+EMZTyK28ZGRkZGRkZGZkHQu6hlJGRkZGRkZGpQ6R/wEtvuUFZBxj28n4G0KLv6X4ReAnoB+QYkk2WJOlSFXkMB5YCTkAJcEiSpJmGuBeAGYakucAMSZJOGOI2Ad0ANXAWeFGSJPX9nP/JP+/w3q4T6HQSj/Vsy5RBXUzik7PyWLj5EHnFpeh0Ol5/pCcPtWvCL5HRbDhcXqSY5Ay2zHiCNo08zeooW3TC7pFnQSjQRB5EfXy3Sbzd8DAUTdvrr4etHcK5AYUrni1PYO+I42ur0f55jtJfvrNcnrgU3ou4jE6SeKxTE6b0bm1anpxCFu6NJK9EjU4n8fqA9jzUwofT8al8cvgP1FodtkoF0wd2oHugl0Ud267dcX7hNVAoKA7/heIfN1dKY9d3AI7jJ4MkoY2PI/8/SwFw33MI7e2bAOjSUslbMs+iTkUceoXgNusVUCgo2LWP3A1bK6VxGtyPBi+EIUkS6pg4MhasqFHezg91xXvBiwilguzt+8n46keT+AaPD6bhW1PRpKQDkPX9z2T/uB+nHkF4z3++vNzNAkh8413yD5hfasla1+7hgb3/H3vnHR5F9f3h9+4mIQkkIYGEVHqHhNCrdBKKFKUoUoKoKAIiKE2a0m2goiAWEBAURG6G4BIAACAASURBVDqh915C7wQIqZteSd+9vz92TbJkN4Ri/P503ufJ82TnnrmfOTN37pw5d+4MM+dPQqVSse7XTXz/tXG7adayEdPnTqR2vRq89+Ykdm7bl1cWHHOeW9fvABAZruGtwWPN6gBUaedDp5lDEGoVl38/xOml24zKfQd1pOHQLui0OnLSM9k95Wfi70SislTjP+8NXH2qIHU69n/yK2GnbpjVqd2uAS/PCEClVnFq3QH2Ld1qVN56UGfaDPFDp9OR/TCT36f8SHRwBBUbVOOV+fpjJIRg11cbuLz7rFkdt/Y+NJ09BKFSEfzbIa59u82knVf3prT7aSyBXaeTcPk+pT3L0/PwZ6TciwIgLiiYM5NXFLnv6rRrwMszhqFSqzi57gD7lhr3Da0HdeaFIf7odDqyHmaybsoPaAw+vTp/RJ5PO7/6o0ifimLavIUcOX4GJ8eybP71+yde39+vPQsXzkKtUrF8xW989vl3RuVWVlb8suJrGjX0JiEhkYGDRvLggf6VOd7edVj63afY2ZdBp9PRomUPsrKy6N+/F1Mmj0GtVhMYuA++Mf/qssrtfOj4sb79Xfn9EGeWmD5eNbo1pfeysax+cTrRl+8X2z+XDj54zx4KahWhaw5yx0x7cOvRlGY/j+Ow/1SSLt3H8+XWVH+3R165fd2KHOoylZRrD0yub9mwGbZv6PuGrH07yNxoom9o1QGbV4chpUQbcpeHi/R9g6q8C6VHTURV3gWkJHX2JHSxmmL7+Dz5Nwx5KwFlCSOEaAm8CDSSUmYJIcoDVobiCVLKDcWooz7wLdBDSnlTCKEGRhjKXkQfoLaRUsYJIRoBm4UQzaSUGmANMNhQ1VrgTWBpcbdfq9Mxf+NRvn+nJxUcSjNo0Z+0q1eZaq5OeTY/7g3Cz7caA1rX564mgdE/BrKzbiV6NK5Jj8Y1AbgTGc+4FbvMBpMIgVXPN8j8ZQ4yJR7rd+aTe/McMjYizyR758q8/y2ad0XlVsWoCqtOr6B7YP5Cq/dHMn/3Jb4f2JoK9jYMWnGQdjXcqOZsn+/P8Vv41fFgQOOq3I1NYfT6k+ys7oqjjRVf92+Bi50NwTEpjPz9OHvf62ZaSKWi9Mj3SZn2Abq4WBwWLSPn1HG0YfmdpMrdA5sBg0iZMAqZloZwKJu/fnYWyWPeLNIXc7qOk94jZtREtNGxuK5aQvqRk+Tez9e18PLA/vWBaN54D5mahsqxbBEVGtft+vG7hA6bSo4mjip/fkXqgVNkB4cZmaXsOEL0LOMmln76Mvd7jdFX41CG6vt+5uGx82Z1SmLfqVQqZn32EUP6vo0mMpot+9ayb9chgm/dy7OJCNcwYfR03hodUGj9zIwserR/5bE6AEIl6Dw7gPWDFpCqSWDo1lkE7wsi/k5kns31LSe5uOYAANU7N6LDtMFsCPiMBgP17xZc4T8F23L29Fs5gVU9Z4AsnOEQKkH/WcNZMnguSZp4Ptg6jyt7g4gOzj+Pzm05zvE1+sC4fufGvDR9CN8HLCDqVhhf9vwInVaHvXNZJu78lKv7gtBpC1/6hErQbF4A+19dQHpUAt0CZxG+O4jkAv4AWJS2pvab/sQGBRstT3sQTWCXqcXed/1nDec7g08fbp3P1b3n0BTwKaiQT0NZGjCfqFthfNFzSp5Pk3Z+Ztanx9Gnexde69uLj2Z/8cTrqlQqvvl6Ll27DyQ8PIpTJwPZtn0PN27cybMZ/vpAEhOTqV23DQMG9GL+vKm8NmgkarWalb98w7DXx3L58nWcnBzJycnBycmRT+dPo1mLrsTFJbD856+wbl2P0OPXTO7DznMC+GPQAlKjEhi8bRZ39xq3PwDL0tY0Gu5P5PngQnUU7aDAZ/7rnBgwn4yoeNrtmoNmz3lSb0cYmVmUtqbqm11JCMr3O3zjccI3HgfArrYXzX8ZbzaYRKXCdsT7pH78Abr4WOw/W0b2mePowgv0DW4eWPcdRMqUUciHxn1D6bEfkbHhV3IvnQNrG9D9c2Gd8toghafBDYiTUmYBSCnjpJSRj1nnUSYCc6WUNw11aKWUf12xJ6EPTOMMZeeBlcAow+9AaQB9htLzSYSvhsbgVd4Bz3L2WFqo8W9YnUNXQ4xsBIKHmfqkZ1pmNs4OtoXq2XnhDv4Nq5vVUXlWRxevQSbGgFaL9soJLOo0NWtv4dOa3CvH8td3r4Io44A2+FLR/kQm4OVYGk/H0liqVfjX9eTQnahH/IGH2fqXRadl5eBcxhqA2q5lcbGzAaCasx1ZuVqyc7Wmt69mHbSREeg0UZCbS9aRA1i2aGNkY+3fk8ztm5BpaQDI5Gd/6bZVvdrkhkWgjdDrpu85iG27VkY2ZV7qQer6rchUva4usXi6Nj41yX4QSU6YBnJySdlxBLtOLZ94G+27tiHtyDlkZpbJ8pLadw0a1efB/TDCHkSQk5PLtk276NKtvZFNRFgkN6/fQfeMFx4332okhUSTHBaLLkfLjW2nqN6lsZFNdlpG3v+WtqX4ax5ouRoePDihDxLS41PISknH1cf4ZuovKvlWJ/aBhviwGLQ5Ws5vO4G3XxMjm6wCOla2pfLi0pzM7LxAy6KUpcmA9S/KNaxGakg0aaF6f0K2nMLTv3EhuwYT+3H9u+3osp5oUMSET9GP+GTcN2QW8kma9EkW4dPjaOLrjYO93VOt26xpQ+7eDeH+/VBycnJYv34LvXr6G9n06unH6tX6jP+ff+6gYwd9m/fr0o4rV25w+fJ1ABISEtHpdFStUpHg4PvExSUAsP/AUWp2M91nuvpWIzEkmmTD8bq57RTV/AofrzYf9uPs0u1on/B4OTaszsP70aSHxiBztERsPomrifZQe1J/gr/bZrY9eL7UiojN5rOsFjXqoIuKQBet7xuyjx3Aqplx31CqS0+ydm5CPjTuG1SelUCt1geTAJkZkG26D1IoHkpAWfLsAbyEELeFEEuEEO0KlM0VQlwWQiwSQhT1SZL6QJCZsnomys4ZluchhLAEhgC7nmTjY5If4lq2dN7vCmVLE5Ns/FWTd7o2YUfQbfw+WcXoH3cw+aXCX4XYc/Eu3YoIKIW9EzI5Pu+3TI5H2DmZtnUoj3B0QXfvqmGBwKrrULJ3rX68P6mZuNrb5PtjZ0NMaqaxP23rsONqGH6LdzJ6/Ukm+/kUqmffzUjquJbFysL0NyNU5cqji4vJ+62Li0Vdzjg7q/bwRO3hhf3n32L/5RIsGxf4QpGVFQ5fLdMvfySYKgq1S3m00bF5v3NjYlG7GOtaVPTEspInFX7+mgorFmPd0nzgbrSeazlyo+Lyfudo4rCoUK6Qnb1/a6ps+w6PxR9h4Vo4I23fox0p2w+b1Smpfefq5kJURP5wlyYyBle3CmbtH6WUtRVb9q9l4+7VdOle9BdKyrg6khqVkPc7NSoBO1fHQnYNh3bmrSNf0m7Kq+yfuQqA2OuhVO/SCKFW4eDlTIX6lbF3L7zfARwqOJEUmX8eJUUl4FCh8HnUZogf0w9/Ta/Jg9j48S95yyv5Vmfyns+ZvPtz1k/72Wwmz9bVkfTIfH/SoxKwdTP2x8m7MqXdnYjYX/hJnjIVnem+Zw5d/pyKc7NahcoLUraQT/E4VCi8714Y4seMw1/Te/Ig/nzEpyl7vmDK7i9YP+2np8pOPivuHq6EhefnEcIjonB3dzVro9VqSU5OoVw5R2rUqIqUELh9DWdO7+LDD0YCEHw3hJo1q1GpkidqtZrevfyxczfdZ9q5OpJa4HilRSVg98g+dKlfGTs3J+4dMPvklVms3RzJKHCMMqISsHYz3hYH78rYuJcjep/5+j16tyB8s/kvqAmn8mgL9g3xsage7RvcPVG5e2E371vsFyzBsmEzw3Iv5MM0ykyajf2XP2ET8A6o/rmQSD7Hv38KZci7hJFSpgkhGgMvAB2AdUKIycAUQIN++PsH9JnGWX/jpiwBjkgpj5oqNDyHOQJg8ej+vNG1lSkzk+w6H0yvZrUY2t6XSyEapq3dz4YJr6BSCQCuPIjG2tKC6m6mL4JPioVPa7TXTuVlUCya+aG9fQGZkvCYNYvHrmth9PKpyNDmNbgUHs+0rUFsGNEJldD7ExybwtcHr7F0YPH3kUnUatTunqRMHouqvDP2ny4medTryIdpJL3+Crr4OFSubtjPW0RKyD10midNbJtGqNVYeHkQPWI86grOVPhhEVGvvolMe/bPH6YdOE3K9kPI7FzKvtoN988+IHRo/qf0LJwdKVWrMmlHzd0fFZN/aN8VpI1vN6KjYvCq5MHazT9y6/odQkOe7TNxF1bt48KqfdTp3ZKWY/oQ+MEyLq8/TLnq7gzdNpuUiDgizt955qDo2Oo9HFu9h8a9WuM35iXWfKAf8HhwMZgFfhOoUM2dQV++y/VDF8l9muyiEDSeOYgT7y8rVJQRk8TGpu+TnZiGk3dl2q0Yx/b2k8kpkGV8Go6u3sPRPJ9eZs0HS/J8mu/3IRWqeTD4WXz6h7CwUNO6VVNatOpOenoGe3ev5/z5Kxw4eIzRY6bw25ql6HSSkyfP4V23+DdERghBh+mD2PlB4eP1XBCC+p8M5vxY88+eOjashjYji9Sbz/ipRbUatZsnqdPHoirnjN3cxaSMfR3Uaizq+JDywZvoYmMo8+FMrDp0JXt/4LPpPSXKkLfCU2EYoj4kpZwJjAb6SimjDCPRWcAKoKgPaF8DCo8f6LluoqyxYR0AhBAzAWfyJ+6Y2sYfpJRNpJRNCgaTLg6l0STlBxrRSQ9xcShttO6m0zfwa6DPPjao7EpWTi5JD/MvDrsuBNO1kfnsJIBMSUA45AecwqEcMtV0gKj2bkXu5eP5v71qYtG8Kzbjv8XKfwgWvm2x7PKayXVd7KzRpORvW3RqBi521sb+XHqAXx0PvT+e5cjSaklKz9bbp2Qw/s9TzO7ZGC/HMmb90cXH6R/8NqAq74w2Ps7YJi6W7NPHQatFF61BFxGGyt0zb30AnSaKnCsXsahWw6xWQbQxcagr5E8UsnBxRhtjrJsbE0vGkRP6RwsiNeSGhmNZ8fFPQuRq4rFwy88GWLqWJzc63shGm5SKNDwukLR+N9b1jY+7Xfe2pO45AWYeFYCS23eaqBjcPPKzRK7uLmiios1u16NER+kzJWEPIjh1/Bz1vGubtU3TJGJXIGNj5+ZEqibRrP2NraeoYRiSlFodB2avYWX3qWx6axHW9rYk3o8yuV5ydAJlC2Qvy7o5kRxt/kbr/LYTeHcpnKGOvhtJVnombjVNf488XZOIbYFsmK2bE+lR+f5YlrHGobYnXf6cSp/TiyjfqBrtfxmPk08VdNm5ZCfqhyMTroSQFhKDXVXXQhp/kVTIp3IkR5vfd+e3ncDHpE8RRfr0dxIZocHL0z3vt6eHG5GRGrM2arUaBwd74uMTCY+I4uix08THJ5KRkcnOXQdo2LA+ANt37KVVm560aduLW7fvknjf9ASTVE2iUfayjJsTqQX2oVUZa8rV8uSVdVN56/gi3BpW46Wfx1PBzKMVj5IZlYhNgWNk4+ZEZoGMvEUZa+xqedFm43S6nP0ax0bVab7yQ8o2yK/fo09LwjeZH+4GkAlxqAv2DeWc8873v9DFx5J91tA3xGjQRer7Bl18LNqQYP1wuU5L9uljWFSrWSz/FEyjBJQljBCilhCi4BXNF3gghHAzlAugD3C1iGo+Bz4SQtQ0rKMSQrxjKPsM+FQIUc5Q5gsMQ5+RRAjxJuAPDJRSPnFao56XC6GxSUTEp5CTq2X3hWDa1a9sZOPmWIbTd/R3lfeiE8nO1eJYRj+srNNJ9ly8S9eGRQdEuoi7qMq5Ico66+8wvVuRe/NcITtR3h1hXRpd2O28ZVkbFpPx5btkLBxN9u7V5F48Qs7ewjP/AOq5OxKamEZE0kNytDp2Xw+nXQ03Y3/sbTkdoh82vheXQnauDkdbK1Iysxmz/gRj29ejoVfR2dbc2zdRe3iiquAKFhaUatuRnNPHjWyyTx3DwttX75e9AyoPL3SaSESZMmBhmbfcso432tCQIvXy6rx+E0svD9Tuel1bvw764LEAGYeOU6qxXlflYI9FRU9yI0wHKEbrXbmNVWV3LD0rgKUF9j3akrr/lJGNhXP+MJpdp+Zk3zWesOPwYtHD3VBy++7yhWtUrloRz4oeWFpa0POlruzbWfS2/YW9gx1WVnodR6eyNG7my53b98zaR126h2MVVxy8nFFZqqnTswXBe40nJTlWzs8uVevoS2KIPjiwsLbC0kb/REylNvXR5eoKTab4i9BLd3Gu7IqTpzNqSzWNerbi6l7jbLBz5fzgrW7HhsSG6I+9k6czKrX+EuHoUZ4K1dxJCI/FFPEX72FXxZXSBn8q925B+J58f3JSM9hQfySbm49jc/NxxJ2/y6FhC0m4fJ9STnYIw+hFmYrO2FWpQFpojEkdcz5d2WvcNxT0qd5T+vR3cvbcRapXr0Llyl5YWloyYEBvtm3fY2SzbfsehgzpD0Dfvj04eEjf5vfsOUz9+rWxsbFGrVbT9oUWeZN5nJ31/VDZsg68804AV347ZFJf80j7q92zBXcLtL/s1AyW+I7kx9bj+LH1OKIu3GXTGwuLPcs76eJdSld1xbaiM8JSjUeflmj25Le73NQMdtV7m71Nx7K36VgSzwdzOuALki4Z6hcC914tinx+EiD3zk1Ubp6oXPR9g1WbjuScNe4bck4fw7K+oW+wc0Dl7oUuOhJt8E2EbRmEvQMAlt6N0IaFFMu/vwPdc/z7p1CGvEueMsBiIURZIBcIRj+0vF4I4Yx+DshF4B1zFUgpLwsh3gd+E0LYon9sYruhbKsQwgM4IYSQQCowWEr5V4TwPfAAOKmPXdkopSz20LqFWsXkl19g5A/b0ekkvZvVprqrE0t2nqGulzPt61dhfK9WzFp/mDWHL4OATwZ2xKBF0L1IXMuWxrOcfdFCOh3Z25djHTAVVCpyzx9ExoRj2XEAusi7aG/qOycL79bkXjH/jM1j/VGpmOzXgJG/H0eng94NKlHd2Z4lh69T182R9jXdGN+pPrN2XmDNmWBA8MmLjRBCsO7cPUITH7Ls2C2WHbsFwPcDW+NU2sTjrzotD5d+hf3sL/Svt9gbiDY0BJvBw8m9c5Oc0yfICTqDZcOmOCxdCTod6cuXIlNTsKhTj9KjP9TPQFSpyNiwxmiGc5FodSR8vhiXxZ+CWsXDrTvJufcAh7eHkX3jFhlHTpJ58izWLZrgtn45Uqcl6Zsf0CWnFKtuzSdL8Vo+R//aoA17yA4OpfzYwWReuUPagdM4Du2NXafmyFwt2uRUIictzFvd0sMFC9fypJ+5UrROCe07rVbLzEnzWfXHUlRqFX+s3cydW3cZN/ldrly8xr5dh/FpWI/vVy3CwcGeTv7teH/yu/i3fpnqNasyd+F0pE6HUKn4/usVRrPDH0VqdeybsZL+qybqX9uy/jDxdyJoM74vmsv3Cd53noYBflRuUw9tjpaslIfsGK8ffrQtb8+AVZOQUkeqJpEd48y/pEGn1fHnjBWMXPWR/rVB6w+iuRNOt3H9Cbtyj6v7gnghwJ+areujzdWSkfwwb7i7atPadB7ZC22uFqmT/DF9OQ8TU836c3bqSjqt1ftz9/fDJN+OwGdCXxIu3TcKLh/FpUVtGkzoiy5XCzrJ6ckryE4y/7iFTqtjw4zlvJvn0yE0d8LpPq4/oQV8qtXaO8+nXw3D3dWa1qbzyN55Pq2f/rNZnx7HhJkLOHvhMklJKXTqM5h33xhC30cm1phDq9Uy9v1pBO5Yi1ql4peV67h+/TYfz/yQc0GX2L59L8tX/M7KX77h5vVjJCYm8drgdwFISkrmq69/4NTJQKSU7Np1gMCd+wFYtHAWPj51AZgzdxGN7ps/Xvunr6Tv6omo1CqurDtM/O0IWo/vi+bKfaPg8mmQWh2XP/qFlr9NRqhVhP52iNRbEdSe2I+ki/fQFNEeAMq1rE1GZDzpRdxYAKDTkv7jV9jNNPQN+wPRhoVgM3A4ucE3yTl7gpwLZ7D0bYrDNyuROh0ZK/V9A0D6yqXYfbIIhEB79xZZe7c/k9/Pwr/hPZTiWWa5Kfw3yNjxVYk0Et2ppw8MnwRV9aolopO+vui76+fFw+iSuy98mFzUXLHnh0vNZ39+szg0OfXsM+mLy8gy3iWiEyFyS0SnaXbJtLszViX3fOOX5+aXiI6Ne+GJin8HC1yLnhz2vKiRXXJ5sRdaRjze6DngtOmwKBEhA29W7vfcrrM/hWwo0W3/CyVDqaCgoKCgoKDwD6K82Fzhb0UI8Trw6Oc2jkspR/0T26OgoKCgoKDw/Pk3DHkrAeX/MFLKFehnfCsoKCgoKCgo/M+iBJQKCgoKCgoKCv8gypC3goKCgoKCgoLCM6H7F0yQVt5DqaCgoKCgoKCg8EwoGUqFx1JjyE8louNu/Xw+xfg4riedLREdS5Xp73o/b9aXNvfRpOePpGTeRnH+gulvED9v3K1L5hgBRJXQ63zKlFCe4LhVdonolOT7T0rqdT4ZkSa/ePvcmdt4eonoaCxKLjeVFlYyYUvJ9ED5/P/PTyoBpYKCgoKCgoLCP4ryLW8FBQUFBQUFBYX/PEqGUkFBQUFBQUHhH0R5D6WCgoKCgoKCgsIz8W94bZAy5K2goKCgoKCgoPBMKBlKBQUFBQUFBYV/kH/DpBwloFR4Ytp3as0n8yajVqv5bfWffPf1z0blzVs25uN5k6hTryaj3pzAjq17jcrL2JXm4Mkt7N5xgGmT5hVLs0X7ZnwwewwqlYotv+1g1bdrjcpfGzGAXq/1QJurJSk+idnjP0UTEW22vs5d2vLZ5zNRq1Ws/GUdC7/83qjcysqKH3/6Et+G9UlISCJgyGhCQyOwtLTkm2/n0qihNzqdZOKETzh69DQAlpaWLFz0CW1eaIHU6ZgzayHbtuzOq7NT57bM/2waarWa1SvX89XCZUaarVo3Zd6n06hXvxZvDHufrZt35ZX9sWk5TZv6curkOV7tP6JY++wvynVoQK05wxBqFRFrDhCyeItRudsr7ag5YzBZmgQAwpbvJmLNgWLXXXtOAEKtInzNAUIWbzVp59KjGb7Lx3PK7yNSLt1DWKqp+/lb2PtWBZ3k5rSVJJ64blbHrb0PTWYPQahUBP92iOvfbjNp59W9KW1/GsvOrtNJuHyf0p7lefHwZ6TciwIgPiiYM5PNf820efumvD9rNCqVim2/BfLrd78Zlb8yoh89B3bXt7OEZOaN/5xoQzv78tcF1GtUl8tnrzAxYGqR+w2gdrsGvDRDv+9OrzvA/qXG+67VoM60HuKH1OnIepjJ+ik/Eh0ckVde1r0ck/d+ya6vNnDox+1mdWq086HHjKGo1CrOrTvIkaXG+67ZoE40H9LFoJPF5ik/EWvQqVDbiz7z3qRUGRukTsfS3tPJzcoxqVO3XQMGzHgdoVZxfN1+9iw1bmcvDOpCuyH+6Az+rJmyDE1wBLXbePPSpEGoLS3Q5uSycd5qbp28Ztafuu0a0N+gc8KMTtsCOmsL6PR5ROe2CR1/v/YsXDgLtUrF8hW/8dnn3xmVW1lZ8cuKr2nU0JuEhEQGDhrJgwfhAHh712Hpd59iZ18GnU5Hi5Y9yMrKon//XkyZPAa1Wk1g4D6zvpli2ryFHDl+BifHsmz+9fvHr1AE1dv50HXmEFRqFed/P8SxR9pCk0GdaDq0C1KrIzs9k21Tfib2TgTefVrResSLeXYV6nixrMc0NNcfmNXyau9Dq0+GINQqbv52iIvfmT5nq3Rvit8PY/mz+3TiLt/H2bcqbT99AwAh4NzCTYTsOlcs/6xbNsXxw1GgUvFwcyApK38vZGPbuR0OIwKQUpJz5y7x04p3Dfq7UZ6h/H+IEGIq8BqgRf/YwtvASKAdkGwwGyalvFhEHd2A2YAtkAUckFJ+YCgbAYw3mKYA46WUxwxla4AmQA5wBnhbSmmydxZCVAB+BrwASyBEStldCFEZ2C6lrP80/j8rKpWKOZ9N47WX3yIqUsOO/evYs+sgd27dy7OJCI9i/KhpvD16mMk6Jnw0htMngp5Ic+K89xn96gfERMWyMnAZR3cf5/6d/M7s1tU7BHQbQVZGFn2H9mbM9HeY+s4nZutbuGgWvV4cQkSEhiNHtxC4Yx83bwbn2QQMG0BSUjINvDvQr9+LzJ4zmYChY3h9+KsANG/WDWfncmzcvIK2bXojpWTipFHExsbTsEFHhBC4lC9npPn5wo95qVcAkREaDhzZyM7A/dwqoBkWFsmotycyeuybhbZ58dc/YmtjwzCDfvF3nqD2guGcHzCXzMh4mu+eT+zuczy8HWFkptlyglsfPeFn41WCOguGE2Sou8XuecTuDipUt7q0NZXe6kZS0J28ZZ6DOwFwsv1ErMrb02jtZE75TwUTX4sQKkHTeQEceHUB6VEJdA2cRfjuIFLuRBrZWZS2pvab/sQFBRstT3sQzc4ujw/wVCoVH8wdy/sDJxATFctPgUs5tucEIQXa2Z2rwbzRbSRZmVn0GdqLUdNGMGPkbADWfr8Oaxtreg9+0ZyEkU99Zw3n+8FzSdLEM27rPK7uDTIKGIO2HOfEGn3wUa9zY3pPH8IPAQvyyvtMG8qNQ2a7qTydnrNeZ8Xg+aRo4hm5dQ439p7PCxgBLm05wZk1+wGo3bkR3acPZmXAp6jUKgYsGsUf45eguRGKTdkyaHNMv0tTqASvznqDbwbPIVETz+St87m89xyaAjpntxzj6Br9zaVP58b0mx7AtwHzSEtMZckbn5Ick4h7TS/GrJrKlBbvmNV5xaCTpIln0mN0vDs3pu/0AL4z6Cw16LgZdD56REelUvHN13Pp2n0g4eFRnDoZyLbte7hxI7/tDn99IImJydSu24YBA3oxf95UXhs0ErVazcpfvmHY62O5fPk6Tk6O5OTk4OTkyKfzp9GsRVfijfjkfwAAIABJREFU4hJY/vNXCEtrZE5mkcfuL/p078JrfXvx0ewvimVvDqESdJ89jNWD5pOiSeCtrbO5te88sXfy992VLSc4Z2gLtTo3wn/aIH4N+Iwrm09wZfMJAFxqefHqj+OKDCaFStB6TgA7XlvAw6gEXt4xi5A9QSQ9cs5alrbGe7g/0efzz9nEm+Fs7D4dqdVh61KWfnvm8mDveaT2MU8ZqlQ4TnqPmFET0UbH4rpqCelHTpJ7P387Lbw8sH99IJo33kOmpqFyLFvc3adQDP5Tz1AKIVoCLwKNpJQ+QGcgzFA8QUrpa/grKpisD3wLDJZS1kUfIAYbyl5EH6C2kVLWBt4B1gohXA2rrwFqA96ADVA4cshnFrBXStnAoDP5qZx+zvg29ibkfiihD8LJyclly8ad+HXraGQTHhbJjeu30ekKdwDeDepS3rkchw+eKLZmvYZ1CA+JIDI0itycXPZsOUBb/zZGNkEnLpCVkQXAlfPXcXFzNltfkyYNuHf3ASEhYeTk5LBhwzZ6vNjFyKZHjy6s+fVPADZt2kn79q0AqF27BocPnQQgNjae5KQUGjX2AWDI0P588fkSAKSUJMQn5tXXuEkD7t17wAOD5sYNO+jeo7ORZlhoBNeu3TK5344cOklq2sPH76xHcGhUnfT70WQ8iEHmaNFsPoFz16ZPXI/5ujVGdbt0bVLIrvrkAdz/diu6zPx7p9I1PUg4ps8OZcelkJOSrs9WmqBcw2qkhkSTFhqLLkfLgy2n8PIv/DL3BhP7ce277WjNZNAeR52GtY3a2f4tB3jBv5WRzfkTF8nK1Leza0HXcS7QzoKOXSA9Lb1YWhV9qxP3QEN8WAzaHC0Xtp2gvp/xvstKy8j738q2lNGbj+v7NSE+LAbNnfAidTx9q5PwIJpEg87lbSep42e87wrr6IWqv+CD5mYomhuhAGQkpSF1prMolX2rE/tAQ5xB59y2EzTwM25nmUY61nk64ddCSI7RnyuRt8OwtLbCwsp0ruMvnb/2W9BjdEqZ0Ykyo9OsaUPu3g3h/v1QcnJyWL9+C716+hvZ9Orpx+rVfwDw55876NhB3xf5dWnHlSs3uHxZn2lPSEhEp9NRtUpFgoPvExenHwHYf+Aowqq0Sf9M0cTXGwd7u2Lbm8PDtxoJIdEkhsWizdFyddspanUx3xYsbUuZzJl592rJ1W0ni9Ry8a1GSkg0qYZzNnjLKSr7FT5nm07ox8UlxudsbmZ2XvCoLmVp6h7TJFb1apMbFoE2Igpyc0nfcxDbdsbnb5mXepC6fisyNQ0AXWJS8SovAXTP8e+f4j8VUAJuQJyUMgtAShknpYx8zDqPMhGYK6W8aahDK6VcaiibhD4wjTOUnQdWAqMMvwOlAfQZSs/HbGve1UJKeflRAyGEtRBihRDiihDighCig2H5MCHEFiHEISHEHSHEzALrDBZCnBFCXBRCLBNCPNGnQtzcXIiK0OT91kRG4+bmUqx1hRDMmD2BOTOe7E7b2bU80ZExeb9jomJxditv1r7XwO6cPHDabLm7uyvhEVF5vyMiNLi7uz5iUyHPRqvVkpySSrlyjly5coMePTqjVqupVMkT34beeHq44eCg7/CnzxjPsRPbWP3rdzi75Gco3dwrEBGerxkZocHNvUIx98DTU8rViazI+LzfWZHxlHJ1LGRX4cXmtDj4GT4/jaOUe/G+WGTt6kRmgbozIxMo5Wr8fQk778pYu5cjbt8Fo+Wp10Nx9m+MUKuwqeiMvU8VrM3o2rg6kh6ZkPc7PSoBGzdjHxy9K2Pr7kTk/sL3gmUqOtNtzxw6/zkV52a1zPrj7FqeGKN2Foezq/kbk54Du3Pq4Bmz5UVRtoITSQX2XXJUAg4VCn+bo/UQP6Ye/pqekwex8eNfAH3Q1+mdXuz+esNjdewrOJJcQCfFjE7zIV0Yf3gR/pNfY/vHqwAoX9UVKSXDVk1m1Pa5vPC2+cxr2QpOJBbQSYyKp6wJnXZD/Jl1+BtemjyIdR8Xzog37NacsKv3yM02nQk1pWPKn7ZD/PnEoLP+CXTcPVwJC8+/JIRHRBXuGwrYaLVakpNTKFfOkRo1qiIlBG5fw5nTu/jwg5EABN8NoWbNalSq5IlaraZ3L3+EuuQHB+1dnUiJMm4L9ib6gqZDu/DekYV0mTKQnTNXFiqv17MFV7cUHVDaujmSFpV/zj7UJFD6kXO2fP3KlHZ3IvRA4XPWpWE1+u9fQP998zk6ZcXjs5OA2qU82ujYvN+5MbGoXYyvExYVPbGs5EmFn7+mworFWLd8PjfXzwMp5XP7+6f4rwWUewAvIcRtIcQSIUS7AmVzhRCXhRCLhBCliqijPmBuvLaeibJzhuV5CCEsgSHALszzHfCzEOKgEGKqEMLdhM0oQEopvYGBwEohhLWhrBnQF/AB+gshmggh6gCvAK2llL7oh/0HFbENz5WAN17lwN4jREWaf7bxWen6chfq+NRi9dLCz848D1atXE9ERBRHj2/l089ncPp0EFqdFgsLCzw93Tl96jxtWvXk9OnzzJ475W/ZhudN3J4gjjYZzakOE4k/fIX6i999PhULQa1PhnLr418LFUWuPUhWVALN98yj1uwAks7eRprIzBZXp/HMQZz/ZG2hooyYJDY1fZ+dftM4//EaWi95F4syNk+nUwC/lztTu0FN1i5d98x1FcXx1XuY224s2xesxW/MSwB0fb8/h38OJDs967npnF69l4XtxrF7wW+0H9MHAJVaTaWmtVg/9jt+6PcJdf2bUrVVvcfUVDSHV+9mRrv32LxgDd3H9DUqc6vhyUuTB7Hmox+fSQPgyOrdzGz3HpsWrKGbCZ0+kwex9jnoFMTCQk3rVk0ZEjCadu370Kd3Nzp2aENSUjKjx0zhtzVLOXxwEw9Cwv+nv7N3dtVevmk7nn0LfqetoS38hYdvNXIysom5XXRm/LEIQcuZgzg5q/A5CxBz4S5/dJrMxh4zaDi6J+pSls+m95esWo2FlwfRI8YTN3UuTlPHI8oUP1usUDT/qYBSSpkGNAZGALHAOiHEMGAK+qHopug/4Tnpb96UJcARKaXZD7pKKXcDVYEfDdt2QQjxaLqkDfCrwf4m8ACoaSjbK6WMl1JmABsNtp3Q+39WCHHR8NvkOKMQYoQQ4pwQ4tzDrPw7zaioGNw88u/YXd0rEBUVY6qKQjRu2oBhb73GyYu7mT7rQ/q+2ospM95/7HqxmjgquOdnQV3cnImNiitk1/SFxrw+dggfDvuInGzzw56RkRo8Pdzyfnt4uBIZqXnEJjrPRq1W42BvR3x8IlqtlsmT5tCqRQ9eHTACBwd7gu/cJz4+kYcP09myRX+PsGljID6++RffqMhoPDzzNd09XP/WwPovsjQJRhnHUu7lyNIkGtnkJKYhDZmaiDX7sfMxPfT8KJmaBKOsorW7U97EHgCLMtaUqe1J040zeOHsYhwaV8d31YfYN6iK1Oq4NWMVpzpN5mLAF1g6lCb9bpQpGTI0idi652ehbN2cyIjK98GyjDUOtT3p/OdUep9eRPlG1Wj3y3icfKqgy84lO1E/vJVwJYS0kBjsq7oW0gB9O3MxamflidXEFrJr8kIjAt4bxMRh04psZ0WRFJ1A2QL7zsHNieToBLP2F7adoH4XfTalkm91ek4ZxPRji2k3vBudR/WhzVB/k+ulRCfiUEDH/jE6V7adpG4X/dB7siaBkDM3SU9MJSczm9sHL+Jev4pZfxwL6Di6lSOpCJ1z207QoEt+dqisqxNvL/uQX8Z/R1yo+fPClE5R/gSZ0Bmx7ENWmtGJjNDg5Zl/7+7p4Va4byhgo1arcXCwJz4+kfCIKI4eO018fCIZGZns3HWAhg31j7pv37GXVm160qZtL27dvovUPl27eRZSNAnYuxm3hZRH+oKCXN16ktqPPIZRv2dLrm59/ONK6VGJlHHLP2dLuzrxsMA5a1XGGsdanvT6YyqvnVyES8NqdF0+nvI+xu0rKTiSnIeZONYqajBPjzYmDnWF/EukhYsz2hjj60RuTCwZR06AVos2UkNuaDiWFR9fd0mgQz63v3+K/1RACXlD1IeklDOB0UBfKWWUYSQ6C1iBPrtnjmvogzJTXDdR1tiwDgCG4Wdn8ifuFLWtCVLKtVLKIcBZoO3j1im4uonfAlhZ4FnRWlLKj81o/yClbCKlbFK6VH7HcOn8VapUrYhXRQ8sLS3o/XI39u46WKwNGvP2ZJr7dKGlrz+zZ3zBn79vZf6srx673vWLN/Gq4om7lysWlhb49e7I0T3HjWxq1q/BlE8/4MNhU0iML/q5mKCgy1SrXplKlTyxtLSkX7+eBO4wnnkZGLiPQYP1mY2XXurG4cP6IR4bG2tsbfUZrg4d26DN1eZN5tkZuJ+2bVsA0L5DK6MJN+eDLlOtWiUqGjRf7teDnYH7H+v7s5Jy4S62VV2xruiMsFTj2qcVsbuNZ0xaueQ/mO7s34SHdyIerabIum0K1B2zOz9Bn5uawaG6IzjadAxHm44hOSiYi0O/IOXSPVQ2Vqht9QMBTm29kbnaQpN5/iL+4j3sqrhS2ssZlaWaSr1bEL7nfF55TmoGf9YfyZbm49jSfBxx5+9yeNhCEi7fp5STHUIlAP3Qt12VCqSFmr4BunnxJp5VPHAztLNOvTtybI/x0F6NetWZuGA8k16fRtJj2llRhF26i3NlV5w8nVFbqmnYsxXX9hoPbpSvnB/41u3YkLgQfcC9eMDHzG4zhtltxnB4+U72fbeZY6t2Y4qIS3cpV9kVR4OOT8+W3HxEp1wBnVodGxIfog+g7hy+jGstLyytrVCpVVRuXodYM89sPrh0F5fKbpQz6DTp2YrLe43bmXMBnfodGxFj8MfG3pZRKyaz+dO13Au6VeR+e1Sn8RPqvLtiMluK0Dl77iLVq1ehcmUvLC0tGTCgN9u27zGy2bZ9D0OG9Aegb98eHDyk74v27DlM/fq1sbGxRq1W0/aFFnmTeZyd9YFc2bIOvPNOALrM1CL9/DuIvHSPclVcKeul33f1e7bg1iNtwaly/mM4NTr6khCSH0wLIaj3YnOubi16uBsg5tI9HKq4Ymc4Z6v3bsGDvfnnbHZqBqt8RrK25TjWthxHzIW77Bq+kLjL97Hzckao9aFJGY9ylK3mTlpY4Ru7R8m+fhNLLw/U7q5gYYGtXwd98FiAjEPHKdXYFwCVgz0WFT3JjTB9I1vS/BueofxPzfIWQtQCdFLKv6bs+QIPhBBuUsooIYQA+gBXi6jmc2CjEOKYlPK2EEIFjJBSfg98BnwqhOgqpYwXQvgCw4DmBv03AX+gk5SyyOMuhOgInJJSpgsh7IBqQOgjZkfRD1kfEELUBCoCt4BGQBchhBOQYfBpOJAObBFCLJJSxhjK7aSU5qfrPYJWq2X6xHms2bAMlVrNujWbuH3zLh9OGcWlC9fYu+sQDRrW56fVX+HgYE+Xru0ZP3kUnVr1eXzlRWh+PvUrvln7BSq1im2/B3LvdggjJgznxqWbHN1zgvemv4NNaRvm/6Cf2a2JiOHDYR+Zre+D8TPZvHUVarWK1av+4MaNO0ybPo7z568QuGMfK39Zx08/L+LSlYMkJiYzbOgYQH9h2Lx1FVKnIzJSw5tv5N8XTJ/2KT/9vJBPP5tBXFw8Y0ZONtKc+MEn/Ll5BWq1mjWr/+DmjTtMmTaWi+evsjNwPw0bebP6t6WULWtP124dmTx1LK2adgMgcM9v1KhZjdKlbbl66xjvvTuFA/vNJrjzkFodt6Ysp9HvHyHUKiJ/O8TDW+FUm9iflEv3iN0dRMW3uuHs1xip1ZGTlMa195YU67hIrY6bU1bk1R3x28FCdZvDqrwDjX+fgtRJsjQJXBn9nVlbqdVxbupKOq6diFCruPv7YZJvR+AzoS/xl+4TUSC4fBSXFrXxmdAXXa4WdJIzk1eQnWR6cpNWq2PRtMUsXPspapWa7et2cv92CG9+OIybl25zbO8JRk1/G5vS1sxZpn8sOToihkmvTwNgycavqFi9Ira2Nmw6t475H3zOmcOmX3ei0+r4c8YK3l71ESq1itPrD6K5E07Xcf0Ju3KPa/uCeCHAn5qt66PN1ZKe/JC1Hyw1WVdR6LQ6ts34hWGrJiPUKs6vP0TMnQg6jetHxJV73Nx3nhYBflRrXR9dbi4ZyQ/ZYNDJTHnIsZ8CGbl1DkjJrYMXuXXQ9HxFnVbH7zOWM2bVVFRqFSfWHyTqTjgvjhtA6JW7XN4XRPuArtRu7W3wJ42VH+iPefuhXXGu5Er3sf3oPrYfAIuHzCE1PsWkzroZyxlt0DlZQOfBlbtcMejUMuhkJKexyqDTzqDTbWw/uhXQSSugo9VqGfv+NAJ3rEWtUvHLynVcv36bj2d+yLmgS2zfvpflK35n5S/fcPP6MRITk3htsP4RkaSkZL76+gdOnQxESsmuXQcI3Km/aVy0cBY+PnUBmDN3ESu/mlDsYzhh5gLOXrhMUlIKnfoM5t03htC3p+mMdFHotDoCZ/zCkFWTEGoVF9YfJvZOBB3G9yXy8n1u7TtPswA/qrapjy5HS0bKQzaNz39NUaXmtUmJTCCxGMGd1Oo4Nn0l3ddMRKhU3Fp3mMTbETT5sC+xl+4bBZeP4tqsJr7v9kSXq0XqJMem/kKmYZShSLQ6Ej5fjMviT0Gt4uHWneTce4DD28PIvnGLjCMnyTx5FusWTXBbvxyp05L0zQ/okgu3M4WnQ/yTD3CWNEKIxsBioCyQi3529ghgPfqsoQAuAu8YhsfN1fMi8An61wZJ9K/xmWgoGwm8b1ieCnwgpTxiKMtFPyz91+3pRinlLDMaE4DXDdupAlZIKb8s+Nogw/OSS9HPNM9F/4qig4Zh/D6AA/qJP79KKT8x1PsK+iF+FfrXF42SUp4qar95OtUvkUbibl28ySDPyvWkR+PyvwdL1RPNd3pq1pc2lzB//khEiejEltCkhSXiSefkPT3NLIs3ee1ZsS2hgacETE+ced6UTIvT80Pk8ccbPQcyIh9/M/g8mNt4eonouGlL7ih1cy2ZjGLFc/tLsunxYsUez+06uz10R4lu+1/8pzKUUsogoJWJoo4mlhVVz3bA5JuEDTO+TaYSpJTF3t9Sys/RZ0MfXR6CfmIQUspM9EGnKcKllIXSglLKdcDfO5NAQUFBQUFBodj8G76U8597hlJBQUFBQUFBQeH58p/KUD4JQojXgbGPLD4upRz1v64jpfwF+OUZNktBQUFBQUGhhPg3PH6oBJRmkFKuQD/j+1+ho6CgoKCgoPC/yT85O/t5oQx5KygoKCgoKCgoPBNKhlJBQUFBQUFB4R9E/gsm5fynXhuk8HSs8BhcIo2kvFZbEjIEW5XM63zCVCXzWhWAcc6Pfzfc8yApzrZEdGLSS0Zn07N/hbHYvJZVMu0hSfd8PlP3OKItSiYfEV8yp2uJkiZK5ro7NWh2iejca/NcpxYUiaNHeonouOw/XKKv3uns5f/cGsW+sN3/yGuDlCFvBYX/55RUMKmgoKCgoGAOZchbQUFBQUFBQeEf5N8wWqwElAoKCgoKCgoK/yDKi80VFBQUFBQUFBT+8ygZSgUFBQUFBQWFf5B/wyxvJaBUUFBQUFBQUPgH0f0LnqFUhrwVFBQUFBQUFBSeCSVD+T+CEGIq8BqgRf8VpreBM8AcoL9h+VIp5Tdm1h8GfA5EAFbAIinlj4blTaSUo4UQHwNvAbEGm9lSyt+edFs92vvQfNYQhErF7d8OceW7bSbtKnVvSscfx7K123TiL9/PW17avRwvHfqUi19u5OqyQLM6zh0aUH/2UIRaReiagwR/u9WknVuPZjT5eRxH/KeSfOkewkJNg4UjcPCujFCrCf/jKMGLtxTLt0rtfGj/8RBUahVXfz/E2SWmfaverSk9l41l7YvTiS7gW1HUbteAPjMCUKlVnFp3gANLjf1pOagzbYb4odPpyHqYyR9TfiQ6OCKvvKx7OSbt/ZLdX23g0I/bi9SybtmUsh+MApWKh1sCSV35eyEbm87tcHgrAJBk375LwvR5AJT/Zj6l6tcl6+JV4sZPLVKnTNtGuM98C1QqEtftJfb7DUblZft2wm3K6+RExwMQv2oHiev2AFA/eDOZtx4AkBMZy4O35hSp9RdOHRpQc84whFpF5JoDPHjk2Lq90o7qMwaTpUkAIHz5biLXHChW3XXaNaDfjGGo1CpOrDvA3qXGdbcZ1Jm2Q/zzjtFvU35AExxB7Tbe9Jr0GhaWFuTm5LJ53q/cPnmtSK2yHXypMms4qFXErN1PxLebjMqdB3Sg8owhZEfp/YhasZOYtfuxrVeZagtGoLazRWp1hH+9gfitJ8zqlO/QgLpzAhBqFWFrDnBvsenzyLVHMxotH89xv4/055GlGu/P38LBtypSJ7k+bSUJJ66b1XnafqG8b1VaffYGAELAhS83EbrrnFmdyu186PjxEIRaxZXfD3HmkXO0weCO+A7tgtTqyE7PZO/kn4m/E4nKUo3f/Deo4FMFqdNx8ONfCTt1w6zOk+r+RY1uTem9bCyrn6BvqN7Oh64z9f3O+d8PcWypcd1NBnWiaQGftk35mdg7EXj3aUXrES/m2VWo48WyHtPQXH9QbL8KMm3eQo4cP4OTY1k2//r9U9UBYNumMRWmvgMqFckbdpHw4x9G5fYvdcZ5wpvkRscBkLRmG8kbdmPT3AeXySPy7KyqehE1fgFp+0+a1bJq2owyo8aASkVm4A7Sf19byKZUuw6UDhgGUpJ79y4p82ajcqmAw6w5IATCwoL0TRvJ3G763CgJ/v/nJ5WA8n8CIURL4EWgkZQySwhRHn3ANwzwAmpLKXVCCJfHVLXOEDi6ANeEEKbOjkVSyi+EEDWAICHEBillTrG3VSVoMTeA3QMXkB6VQM/AWYTuCSL5TqSRnUVpa+q+4U/M+eBCdTT7eBDhBy8VLaQSeM9/nVMD5pERFc8Lu+ai2RNE2u0IIzN1aWuqvNmVxKA7ecvcezZHZWXB4Q6TUNtY0f7IF0RsPk5GWNxjfes4J4CNgxaQGpXAa9tmcXdvEAmP+GZZ2pqGw/2JMuFbUXW/PGs43w+eS7ImnnFb53Ftb5BRwHh+y3FOrtkHQL3Ojek9fQg/BCzIK+89bSg3Dl18vJhKhePE94gZPRFtdCwVVi4h48hJcu/nX2QsvDywHzaQ6DffQ6amoXIsm1eWuno9adbWlHnpRVO1G+m4z3qH+0Omk6uJp9qWhaTsO01WcJiRWfKOo0TOXFZodV1mNsE9xj7eHyNNQa0Fw7kwYC5ZkfE03T2fuN3nePhIu4jecoLbH614oqqFSjBg1nC+HTyXJE08E7bO58rec2gKHKNzW45zzHCMvDs35uXpQ1kSMJ+0xFSWvfEZyTGJuNX0YtSqj5jWYmQRfqioOu8trr0yi+yoeHx2fkrCnrNk3A43MovbcoL7U38yWqbLyOLOe4vJvB+FZQVHGuz+nKRDF9GmmHjhs0pQb8FwzgyYS2ZkPK13zyNmt+nzqPJb3YzOo4qDOwFwtP1ErMrb03TtZI77TwUTQ3PP0i8k3gxnW7fpSK0OG5ey9N47l7C955Hawl83FipB5zkB/GE4RwcbztH4Ajo3Np/k0q/6G4hqXRrRfvpg/hz6GT4DOwCw0m8KtuXseXnVBH59cYZJf55GF/R9Q6Ph/kQ+Yd/QffYwVg+aT4omgbe2zubWvvPE3sk/Rle2nODcmv0A1OrcCP9pg/g14DOubD7Blc36mwmXWl68+uO4pw4mAfp078JrfXvx0ewvnroOVCoqzBhF+PCPyImOo9IfX5N24DTZd0ONzFJ3HiZm9lKjZRmnL/PgpdH6ahzKUHX3ch4eP1+klt1775M48QN0sbE4LllG1snjaB/k7wO1hwe2AweR+N4oZFoaoqy+r9MlxJM45l3IyUFY2+D08wqyTx5HFx//9L4/A8osb4XnhRsQJ6XMApBSxkkpI4GRwCwppc6wPKY4lRns7gKVirC5A6QDjk+yoeUbViM1JJq00Fh0OVrubTlFRf/GhewaTezHlSXb0WYax6oV/RuTGhpL0q2IQusUxLFhdR7e15AeGoPM0RK5+SSu/k0K2dWeNIDg77ahzcrXkRLUtqUQahUqayt02bnkpmY81jdX32okhUSTbPDt1rZTVPMr7FurD/txbul2crOKHYdT0bc6cQ80JITFoM3RcmHbCer7GfuTlZa/jVa2pYyuc/X9mpAQFkP0HeOAwxRW9WqTExaBNiIKcnNJ33sQm3atjGxK9+lB2h9bkalpAOgSk/K34+wF5MPHf43CtkENsh9EkRMWjczJJXnbEey7NH/ses+CfaPqZNyPJvOBvl1Ebz5B+a5Nn0vdlX2rE/cgmnjDMTq/7QQ+fsZ1ZxY6RvqDFH4thOSYRACibodhaW2FhZX5+/UyDauTEaIhK1S/7+K2HMPJv3h+ZN6LIvN+FAA50YnkxCVjWc7BpG3ZRtVJv68hw7C/ojafoELXwudRzckDuPvtVnQFztcyNT2IO6bPsmbHpZCTko6Db1WTOs/SL2gzs/OCR3UpyyJTNa6+1UgscI7eNHGOZhc4RpY2pfICxnI1PAg9ofcnPT6FrJR0XH2qmBd7Ql2ANh/24+zS7Ub90ePw8K1GQkg0iWGxaHO0XN12ilpdjOsu2DdY2pYyuYu8e7Xk6jbzmbzi0MTXGwd7u2eqw9qnJjmhkeSEayAnl9TAw5Tp1OKJ67Hzf4GHR88hM7PM2ljUrkNuRAS6KH1fl3XwAKVatTHenh49ydi6CZmm7+tkkqGvy82FHMNxsrIEoYRDz4qyB/832AN4CSFuCyGWCCHaGZZXA14RQpwTQuw0ZBUfixDi/9g77/Coir2Pf+bsbnrvlV6lhRK69CaKYL1XEUVQLIgINroKKFyvjYtgV9QLiHqxoCChI70HVEogQIBseq/b5v1jN2XBdbcuAAAgAElEQVST3SRADN77no8Pj9kzvzPfmXN+Z2bOtNMMaAY4fU0WQnQBEuraSC3DI8yfwuSs8t9F+iw8w+zbpIHtm+AZHsDlLfa9aVoPVzpMvo1jb62tVcct3J/i5Io3xRJ9Jm7h9jq+HZrgHhFA2uajdsf1P+3HXFTK0OPvMeTwUs699xPGnMJaNb3C/MmvlLcCfRZeofaaIe2b4B0ewPmtdegprJzW0AByKuUnR5+Fb2hANbs+44Yxa8cSbpsxlu9eXgFYGy6DHr+djUu+rWbvCE1wEObUiq/nmFPT0QQH2dloG0WhbRRFyMdLCPl0KW69rr5Rpg0LxKiv6PU1pmSiCwusZuczojctNvyLRstnoAuvSIfi6kLzH96i+dp/4jO0bhWOW1gAJZWuY2lyJq5h1d+JQm7rQfdtr9Ph42m4RlRPkyN8QwPIrhR3tj4T39DqcfcbN4yXdixhzIyxfGu7R5WJuaUHl347j8ng/FOLrmEBGK5UXDuDPgsXB9cu8NaedNryFq0/eg4XB/nwimmBcNFSciHFoU7V61WcnIVrmL3f+XRogntEIOlVnqO8P5IIHd4VoVFwbxSMb8emuDu5ltdTLoC1QTpm62LGbFnEnhmfOeydBPB28Ix6O7hHMQ8O4ZFf36TfrL+z5aUvAEg/mUTzoV0QGgXf6GBC2zfBu46+URfdsrIh8SrLBp+wAPL0FfcoT5+FjwOfjn1wKE/vfIuhM+9jw0ufVwtvN6onv/1wfQ3K+kAbGoRRX1H+mFIy0IZWv87eQ/vS5IflRCyZjTYsqHr4yH7k/by9Ri1NUBCW9IoqzJKejhJUpayLikITFY3fknfxX7ocl9ju5WFKcDABH31K0OpvKFqz6ob1ToK1h7K+/tUFIcQIIcRpIcRZIcQMB+HThRB/CCGOCyG2CCGcdlCVoTYo/wJIKQuArsAkrPMb19jmProCJVLKbsBHwKe1RPU3IcQxYDXwmJQyy4HNNCHE78B+4FVnEQkhJtkasoe2FyY4M3N0IrEvjeXg/OrzWDo/eye/f/QLpiLnb5xXo3PTK+P4/ZV/Vwvy69wcabawqdOTbOk+leaP34pHo9pmC9RNs9/csexcWD1v9cXuL+N4rf9Ufl68iqFT7gBg+DP3sOOT9Rjq47rZEBoN2uhI0h6bTuacV/GfPR3h5Vlv8ZeRv+UAp2+eyNlbnqbg12NEvfFMedipvhM4N3o6SVPfIHzeI7g0CqsXzfS4w+zu9hQHBr5A1o4T3LT0yXqJt4ydX8bxSv+p/LB4FSOm3GkXFtYyitEz7uerWR9dt072poMc7v448YOnk7MznpZLptiF60L8aLn0ac4+826dhm0dIgRtX3mQky9Xf44ur9pGiT6LPnGvcdOCh8g+eAZpcdzQq4uOs3IBIOPoOb4fNIN1I+fR8alR1p7K6+DYF5v5+OZn2bnoK3o9PQaAE2t2kK/PYtxPCxj40gMkH05w2nC9aoRg4NyxbP8Ty4aDX2ziX/2ms3nxV/SbMsYuLDKmOcZiA2lnah/B+CtQsG0/iYPHc2H0kxTuOULY4mftwjXB/ri2akrhrsPXL6bRoI2MImf6VHJfnY/39OcRnl6AtQGa9egEMh+8H7dhIxD+VzVgV69IKevtX20IITTAMuAW4CbgPiHETVXMjmJdf9ER+BZ4vbZ41TmUfxGklGZgO7BdCHECeAi4DJR1530H1DYpbI2U8qlabMrmUN4OfCKEaC6lLHGQng+BDwE+i3yg3EOLUrLxjKjo4fAID6AwJbv8t87LDf82UYz41rqYwz3YlyGfTWfzw28R1LkFjW/tTrfZf8fFxwMsEnOpkZMrNlVLZIk+2643xC08kBJ9hY7Wyw2f1tH0XjsPANdgX7p//hwHHnqDyDv7kL4tHmkyY8jII+vgGXxjmlGUVHNnbEFKNt6V8uYVHkBBaoWmi5cbQa2juHuNNW+ewb7c/sl0fpz4Vq2T73NTs/CrlB+/8AByUx21960cXbeHuxZOBN6jcUwLOo3swaiZY3H38UBaJKZSI7u+2OjwXHN6BprQ4PLfmtBgzOn280fNaekYfj8JZjPm5BRMSZfRNYrC8MfpGvNRGVNKpl2Poy4sEGOK/Ru+OSe//O+sNXGEzRhfcb4t/8ZLqRTu+w23ds0wJDnuaSujJCULt0rX0TUikNJK/gdgyi4o//vKyi20mDe2TvnJTc3Cv1Lc/uGB5KZmO7U/vG4Pf1v4SPlvv7AAJn3wLF9OX05GUmqNWqUpWbhEVlw7l/AADFWuXeV8pK7cQuM548p/a7zcafvv2SQtXkXBEecvfFWvl3tEQPliJbA+R95touhR9hyF+NL1i+c4/OAb5MYncnLeF+W2vX6aT+E5vUOd6ykXKi/Yyz2bjKmoBL/WUXbHy8h38Izm13CPTv24j6GvPgyANFvYPn9ledh9a+eRfd5xfq5W18XLjcDWUfytUtlwxyfT+a4OZUNeShY+4RX3yCc8gLwU53n67ce93LrwYaBiXnL7Ub34rYaFWQ2JKTUDXXhF+aMNC8KUau/blkrlQu43Gwl+bqJduPeIfhRs3gMmc41a5owMlOCKzgIlOBhLhn1ZZ0lPx3jSWtZZUlIwX76EJioK0+lTFTaZmZjOn8elQ0dKd+6oe2b/e+kOnJVSJgIIIb4CRgPlq+6klNsq2e8DHqgtUrWH8i+AEKJ1leHsGOAi8D0w0HasP3CmvjSllD8Ch7A2XOtMxrFEfJqG4RUdjKLT0Gx0Ty7FVUyaNuYXs7rDE3zbcxrf9pxG+pFz5ZXGhjsXlB//4+ONHF/6o8PGJEDOsXN4NgvDvVEwQqchYkwvUuIq3lZN+cVsbDeJLbFPsyX2abKPnOXAQ9ZKsPhKBoF92wHWuZT+XVtQUGXyvCNS4hPxbxqGjy1vrUf1JHFTRd4M+cW8H/MEn/aZxqd9pqE/eq5OjUmAS/HnCG4SRkBUMBqdhs6jevPbJvu376AmFT10bQd1JuOCtbJ7996XWdh3Cgv7TmHnpxvYvOx7p41JAMMfp9A1ikQTEQZaLR5DB1K8076yKd6xG9cuMQAovj5oG0VhulK3yrWMouMJuDaJQBcVitBp8R3Vj7zNB+xstMEVb/w+Q7pTes66YEfx8UTY5hhq/H3w6NqW0gT7xTyOyD96Do9mYbjZ/CJ0TG8yNtqvCHYJqVhgFDy8G4UJNc/XLeOi7R4F2u5Rl1G9Ob7JPu7gSveo3aDOpNvukbuPB49/NoMf/rGaxMO1N8oLjp3FvWk4rtEhCJ2WoNF9yaqSD12lfAQM70axLR9Cp6X1py+Q/s12Mn/eV6NO7lH75yh8TG9SN9o/R5tvmsT22Clsj51CzuGz5Y1Jxd0FjYcrAEH9OiBN5mqLecq4nnLBKzoYobFWRZ6Rgfg2j6DgUrpDnbJn1Nem02ZUT85tsl+04dcktPzvZoNjyLZNB9C6uVjnVAKNb26PxWyptqjGGbXpGvKLWR7zBB/1mcZHtrKhLo1JgOT4RAKbhuEXbfW79qN6crpK2RBQKU8tB8WQVWmKgxCCdrf14Lcfb/xwN0DJiTPoGkegiwwFnRbvkf0p2Grvp5pK5YLXoJ4Yztk/+z63Dqh1uBvAdOoU2sgolDBrWec6cBCle3bb2ZTu3oUuxlrWCR9fNFHRmPXJKEHB4OJiPe7lha5DB0yXai+D/iwaeMg7Eqic2cu2Y86YCGyoLVK1h/KvgRewVAjhB5iwzn2cZPt7pRBiGlAAPOI8imtiPrBKCPFR2cKf2pBmC/vmfM6wVS8gFIWENTvIOXOFzs/dRUb8eS5tqmFF3lUgzRZ+m7WCnqtnWrc7Wb2dgtOXaf3C3eQcO09qnPOhkAufxhGz5HEG7PgnCLj01Q7yTyY5ta+suXXu59z55QsIjcLva3aQeeYKvabfReqJ83aNy6vFYrawdt5nTPpiFopG4cDX20hNuMyIafdw6UQiv28+TN+HhtOqT3vMJjPFuYWseva92iN2hNlC9utLCf7XPxAahYIfN2BKvIjPY+MxnDxNyc69lOw9iFuPboSt+RRpMZOz5EMsuXkAhHz4Dtom0Qh3d8J/+orshW9Qss/BNi5mC8kvvU/TL16xbhv0zWZKE5IImTaW4hMJ5G8+QOD4UfgM6YE0mzHn5HP5uSUAuLWIJvLVyUgpEUKQ/v631VaHO0KaLZye+Smdv5oFGgX96u0Unr5MsxfuIS8+kYyNh4l+9BaChnVFmi2Ycgr44+nldbpsFrOFr+d9yuQvZiE0Cvu+3k5KwmVunXYPSScSObH5MP0eGk6bPh0wm8wU5RbyxbPWuPs9OILgxqHcMvUubpl6FwDvjnuVgsw8p/cocdbH3LR6LkKjkPrVVorPXCL6+b9TEH+W7LhDhD9yKwHDYpEmM6acAuvQNhB4e298et6Ezt+bkHut75sJz7xL0e8XHF6v32d+Rnfb9bq8ehsFpy/T8oV7yI1PJG2j8+fINciX2K9mgkVSkpLFsaeWObW9nnIhtHsrOkwehcVkBotk76wVlFbqna2qs2Xu59z15QsoGoUTtme0z/S7SDlxnnObjtB5/DAa922HxWimJLeQDdOtPXkeQT7c/eWLSIuFgtRsNjxT9+erLrrXisVsYf28FYz74kWERuHo1ztIT7jCwOl3kXz8PKc3H6H7Q8No1rc9FqOZ4rxCvptesaVP4x5tyEvOIttJI/xqeP6lxRw8epycnDwGj3mAJyeO465Rw68uErOFtAXvEfXJQlA05P4nDsPZJAKnjKPktzMUbtuP/7jReA3siTSbseTmkzLzzfLTtZEhaMODKD5wonYti5n8pe/g9483EIpC8Yb1mC9ewHP8BIynT2HYuwfDwQO4dIsl4NPPwWyh4MP3kHl5aLt2w+/xJ8vLoKKv12A+n3iVV6z+qM8v5QghJmFtQ5TxoW3U8VriegDohrVTq2bbuoy3q/z/pvKQ959JkLnm4Y364qyLpkF0LinOF2XUJ9OCr78iqSs5GR4NopNW1DA637k3iAwA95c2jD/kWK5v/mFdSdU2TH9EZsM8rg1KgWiYenf24QUNopPYd3KD6AD4R9a+A0V9ELJlh2gQIRuxEf3qzSkOJu+sMe22rQpfllIOt/2eCSClXFTFbgiwFOhflwW8ag+lioqKioqKisoNpIE79w4CLYUQTbF+DOXvWD+sUo4QojPWiboj6robjNqg/C9DCPEwUHU36N1SyoZ7RVRRUVFRUVGpNxpyY3MppUkI8RSwEdAAn0opfxdCzAcO2dZY/BPrdLxvhBAASVLK22uKV21Q/pchpfyM2ld7q6ioqKioqPyX0NDTD6WU64H1VY7Nq/T3kKuNU13lraKioqKioqKicl2oPZQqKioqKioqKjeQ/4VveasNShUVFRUVFRWVG0h9bht0o1AblCq1ElBfnyerBSMNs0tDlLFhHtxLrg0iQ0aqV8MIATptw2ztFB2Q2yA6x/OMDaIDMID6+bRkbQRhaBCdDqLaB7b+FJIMDbOFFFhXJzQEKdqGmW3WUNv5NNvlfI/S+qZ45uMNpqVydagNShUVFRUVFRWVG4jlf2BPcLVBqaKioqKioqJyA/lfGPJWV3mrqKioqKioqKhcF2oPpYqKioqKiorKDUQd8lZRUVFRUVFRUbku1CFvFRUVFRUVFRWV//eoPZQqV03IwI50WPAgaBSSVm4j4d11Du3Cb42l+yfT2DF8Njnx54m6sw8tnry1PNznpkZsHzqbvN8vOjw/dGBHOi54EKFRuLByG2ec6ETcGkvPT6ax1aYTfWcfWlbS8b2pEVuHzia3Bp3O88chNAqJq7Zz2olO5K2x9P74GTaPmEN2/Hlr3G2j6fr6RLTe7mCRbL5lLpZSx1vRtOnfiTHzHkLRKOxbs5Wt7/1oF95r7BD6jhuGxWKhtLCEb2Z+ROrZK+XhfhGBvLjpTTa+8y3bP/rJoUYZ3v07E/XyowiNQuZXm0hd/h+78IC7BxExezzGlEwAMj5fT+ZXmwCIOb+W4lPWa2VMziBx4qtOdbz6dSF83iRQFLK/jiPj/W/twv3uGkzYjAkYU606WV/8RPbXcQDoIoKJXDQFbXgwSMnFCS9jvJLmUMejb1dCZj0BikLut7+Q/fHXduE+Y4YS9PxETDadnFXryPv2FwCCnpuIZ//uIARFe46S/tp7TvPTfUAsT8+fjKIo/Lx6PSuXfWUXfu+ku7ntvpGYTWZysnJYPP2fpF5Jo0W75kxf9AyeXh5YzBa+XLqSrT9ud6oDVr+Lsfnd+VU1+12vj59hSxW/61LJ77bU4HcBA2NosfBhhEZBv3ILSUu/twsP+9sAms0bhyElC4Arn25Av3IrAB1Xz8ana0tyD5zixAOLa8yPz4DONHrlEdAoZKzeRMqytXbhgfcMImrOQxhtOmkrfiZj9ebycMXLnfbblpKzcT9Jcz5yqtNQ5QI0XFkXPaAjvV+x+sKp1ds5tsyxTtORsQz7cCr/GTmXjOPnCY5pRr9/TARACDj01ndc+OWQ0/x49O1K6OzHy5+jrI++sQv3uWMIwc8/gik1A4CclevI/XYj7j06EjJjUrmdS7No9NMXU7Blr1Otmpjz2lvs3H2AAH8/vv/3+9cUhyM07brh9vcnEIqC4ddfMPyyxi7c9d7H0bbpZP3h4ori7Uf+1DvrTf96UIe8VeoNIcRs4H7ADFiAx4A3AG+bSQhwQEo5xsn547F+zP0K4AK8LaX8yHa8m5TyKSHEy8CjQLrNZoGUcvVVJVQRdFz0MHvuXUSxPpP+vywkJe4I+Weu2JlpPd1o9sgIsg4nlB+7vHY3l9fuBsC7TTQ9Vkx3WsCiCDotephdNp2BvyxE70SnRRWdS2t3c8mm49Mmmp4rpjuvNBRBl9fGs/NviyjSZzFkwwKSnei0fGQEmYfPlh8TGoXu7z7JgSnvkftHEi7+XliMJocyQhHcOX8C7z/wKrkpmUz78TV+33TYrsF45Ifd7F1prWDbDenK6Lnj+PChikp89JwHObn9mON82OVJIXrhY5wd+xJGfSat171B7qYDlCRcsjPLWbeLy/M+rHa6pcTA6Vum1Ukn4pUnOP/gHEwpmTT7/m3yN++n9Ky9Tu7Pv6J/uXqlEfXGdNKWr6Fw1zEUDzekxUmBqiiEzJ3MlYmzMKZm0Pjrf1G4bR+Gc0l2ZgUbdpK2cLndMbeYtrh3vomLo58AIHrlm7jHdqT44HEHMgrTXn2a6fe9QLo+nQ/XL2dX3F4uJlT4TsJvZ3n0licoLSll9IOjeGLOJF5+YiElxaW8NnUxl89fITA0kI83vMeB7QcpyCt0kidB59fG86vN7wbX4HctHPhd7LtPcrAOfoei0HLxROLvXUBpchZdNy4iY+Mhis5ctjNL/2EPCbM+qXZ60vIf0Li7EvHgUMfxV9JptPAxztxv9bm2P/+TnLgDlCTY62Sv2+W0sRj5/P3k7/+jFp0GKhdsWg1R1glF0GfhQ/x8/2IK9Vnc+fN8LsQdJich2c5O5+lGhwnDST1S4QvZpy6zduRcpNmCR4gfd8e9ysVNR5CO9g5WFELnTebyBNtz9M0SCrbur/Yc5W/YQdoC+5eu4v3HuXjHU9ZofL1otvFTCncfcX7tamHMyKHcf9ftzFrwxjXHUQ2h4H7/UxS+PQOZnYHn7KWY4vdi0Vfkr/Tr9ym1/a0bNBpNdPP6079O1CFvlXpBCNELuA3oIqXsCAwBLkkpb5ZSxkgpY4C9wNqa4gHW2GwHAK8JIUId2LxtsxkNfCCE0F1NWv07t6DwfCpFSWlIo5kr3+8lbHjXanZtXryHs8vWOe01ibqjN1e+d/52G1BF5/L3ewl3oHPTi/dwZtk6zE50ou/ozeUadZpTcCGVwqR0pNHMpR/2EelAp92Ld3Pq3XWYSys2jQ7t34Hck0nk/mEtsAzZBeCkUdQopgUZF1PIupSG2Wjm6Lo9tB/Wzc6mtKC4/G8XD1cqv7C2H9aNrEtppFapoB3hEdOS0gspGJJSkUYT2et+xXdY91rPu1rcO7Wi9KIe4yWrTu5PO/Ee2rNO57q2iAatQuEuawPZUlSCLCl1aOvWsTXGJD3GyylgNJG3fgeeg3rVOZ3C1QWh0yJcdAitBnNmtkO7tp3bcOXCFfRJekxGE1t+2Ebf4b3tbI7uOUapLZ1/HD5JcHgwAJcTL3P5vLWhkZmaSXZmDn6Bfk7T5MjvIpz43el312G5Rr/z6dKC4vMplFxMQxpNpH2/m6AR3RzaOiLn198wV/JLZ3jGtKT0gr7c57J+2IXfsB511vHo0BxdkB95O2p+YWqocgEarqwLiWlO3oVU8pPSsRjNnP1hH02GVdeJff5uji3/yS5PphJDeeNR46qjpk4ut46tMCYllz9H+et34DW4bs9rZbyH30zhr4ecPq91oVtMB3x9vGs3vAo0TVtjSU9GZqSA2YTx4A60Mb2d2utiB2A8sL1e0/D/HbVB+dcgHMiQUpYCSCkzpJTlr6dCCB9gEPC9k/PtkFKmAeeAxjXYJABFgP/VJNQt3J/i5Mzy38X6LNzCA+xsfDs0wT0ikNTNziuHyNE9ufz9nqvSca+i42fTSbkOHfewAIquVOgU6bNwD7O/JH4dmuAREUjKFnsd7+bhIOHm1S8yJG4hrZ+8zamOb2gAOZXyk6PPwjc0oJpdn3HDmLVjCbfNGMt3L68ArI3LQY/fzsYl31azd4RLWCCG5Izy3wZ9JrrQwGp2fiN70WbjEpq8/yK68KDy44qrC61/epNW37+Obw2NAl1YIEZ9evlvkz7DoY7PiN60WL+U6GUzy3VcmkZizisk+r1ZNF+3hNAZD4PiuDjShgRiSqmkk+pYx2tYXxp//x7h78xGG2bVKTl2kqL98TTbuYpmO1dRuOswhsRL1c4FCAoLIi25Qiddn05wWJBDW4Bb77uF/dsOVDveNqY1Op2WKxeSHZxlxT0sgOIrVfzbgd+5O/A7L5vf9V39IoPjFtKqBr9zDQugtJLflSZn4RpW/doF3daDbtveoN3Hz+IaUT28NlzCAzDoK/lcSiYu4dX92++WXty06R2affBChc8JQfS8h7m0cEWtOg1VLjjT+jPKOo9wfwr0WeW/C1Oy8Ay394Wg9k3wjAggaWt1nZDOzblny2Lu2byIX2d+5rh3EtCGBtk/rykZaB08R95D+9Lkh+VELKl4juzCR/Yj7+ftTvNzoxB+QViyKvIns9NR/Bz7sggIQQkKw3yqDiM+DYRFynr7d6NQG5R/DeKAaCHEGSHEciFE/yrhY4AtUsq8ukQmhGgGNAPO1mDTBUiwNT4dhU8SQhwSQhzaWOQ0Gkcn0v6VB/jtlX87NfHv3BxzcSn5p2rvbatJp8MrD3CiDjp516nT6eWxxL+8snqQRiGoeyv2T17GttHzibylGyF92127FrD7yzhe6z+VnxevYuiUOwAY/sw97PhkPYaia+8RqEru5oP83vtRTg2fSv6vx2j81tTysN97PcLp257lwtNvEvnSRFwaX/snA/O3HOBMvwmcHTmFgl1HifyndShdaDV4xrYj5bVPODdmGi6NwvC/e/A16xRs38f5wQ9xccwTFO05Stii5wDQNQrHpXkjEgc+QOKAsXj0jMG96/XdI4Chdw6hdadWrH7Pfi5nYEgAs/81k0XT/4m8noLd5nfHHfidYvO7A5OXsb0e/C4j7hD7uj3JoYHPkbUjnjZLn7r2dNdAzqaDnOg1iT+GPkPezmM0fedpAIIfuoXcrYcx6jNriaEONFS5YNNqqLKu10tj2Tt/lcPgtKPn+GbwDNbeOo/OT41C43pVg052FGzbT+Lg8VwY/SSFe44QtvhZu3BNsD+urZpSuOvwNWv8FdB1H4DpyK8gG+azwnVB1uN/Nwq1QfkXQEpZAHQFJmGd37jGNvexjPuAusx1/JsQ4pjN9jEpZZYDm2lCiN+B/YDT1RZSyg+llN2klN2Ge7QoP16iz8a9Ug+Ge3gAJZXerrVebni3jqbv2rkMPbgE/y4t6PH5c/h1alpuEzmmF5e/q3m4yZFOcRUdn9bR3Lx2LsMPLiGgSwt6VdGJqoNOcUoWHpEVOh7hARSnVAyJar3c8G0TzYC1cxh54B0Cu7Sgz4pn8e/UlGJ9Fun7TmHIKsBcbEC/9Rh+HZo41MlNzcKvUn78wgPITXV0e6wcXbeH9kNjAWgc04JRM8cyZ9dS+k24hSGTx9D3weFOzzWkZOISUdGz4BIeWL4opgxzTj7SYJ13l7l6Ex4dKuYSGW3pMiSlUrDvNzzaNXOoY0zJRGcb8gXQhgfVqJO9Jg73DlZfMuozKPkjEeOlVDBbyI/bh1s7x/OZTGmZaMMq6YRW17Hk5CON1qHA3G9/wbVdSwC8hvShJP4UsqgEWVRC4a8HcYtp61AnIyWDkIgKneDwYNJTMqrZdb25Cw8+fT8zx8/FaKgYfvTw8uAfX7zGR//4lD+OnHSoUUZxShbukVX8u4rf+bSJpv/aOdxy4B0CurSgt83viqr4XUoNfleakmXX4+gaEUBpiv21M2UXlN8j/cqteHd0fL9rwqDPwqVSL7dLWCAGvb1/V/aFjNWby33Oq2trgsePpMPeD4maO57AuwYSOXOcQ52GKhecaf0ZZV2RPhuvSj2fnmEBFOorfMHFyw3/1lHc/s1s7t/7NiGdmzPi0+kEdWxqF0/O2WSMhSX4t45yqGNKzbB/XsOCyhexlWH3HH2zETfbc1SG94h+FGzeAyZzjXm6EcicDJSAivwJ/2AsOY5fUtTh7j8HtUH5F0FKaZZSbpdSvgQ8BdwFIIQIAroDP9chmjW2OZc9pJTfObF5W0rZzhb/J0IIt6tJZ86xc3g2C8OjUTBCpyFyTC9S4ireVk35xfzS7jE2xU5lU+xUso+cZf9Db5BjW52KEETc3rPGOUUA2cfO4VVJJ2pML/RVdH5u9xgbY6eyMXYqWUfOsreKTtTtPblUq9CU1IUAACAASURBVE4iXk3D8Ii26kSP7knyRnudH9s9zvruz7C++zNkHjnL7vFvkh1/npTtx/FtG43G3QWhUQju2Za8KhP2y7gUf47gJmEERAWj0WnoPKo3v22yf8sPalLRE9h2UGcyLugBePfel1nYdwoL+05h56cb2Lzse3Z9sdFpnoriE3BtGo5LdAhCp8V/1M3kbrIfmtWGVAyp+Q7tTslZaw+KxtcT4WJdq6fx98azW9tqi3nKKD5+BtcmEeiiQhE6Lb639SN/8357neAKHe8hPcoX7BQfT0Dx8UIT4AOAZ++O1RbzlFFy4jS6xhFoI0NBp8VnZH8Kt+2zs9EEV1TIXoN6Yki0zi806tNwj+0AGgW0Gjy6dcBwzrHOqWOniGoaSXh0GFqdlsGjB7I7zn6osmW7Fjy3eBozH55LTmZORT51Wl795BU2fhvHjp93Ooy/Mo78Tl/F79a1e5wN3Z9hQ/dnyDpylj02v0ut4ndBNfhd/tGzuDcLx62R1RdCxvQhY6P9KmCXkIq5nkHDu1FUh3m6VSmMT8Ctks8FjO5LThWf01XyOb9hseU+d37K25zo8Sgnek3i8oIVZP5nG1cWfelQp6HKBWi4si4tPhHfpmF4Rwej6DS0GN2Ti5sqFrwY8ov5ouMTrOo1jVW9ppF29By/THiLjOPn8Y4ORmis1bhXZCB+zSMouJTuUKfkxBl0jSPQ2Z4j75H9Kdha9TmquEdeg3pWe1Z8bh3wlxzuBjBfOI0SEokICgONFl1sf0zx1a+9EhaN8PDCfK6WBWANjJSWevt3o1BXef8FEEK0Biy2eY0AMUDZksC7gZ+klCX1qSml/FEIMRF4CPigzueZLRyftYJeq2cgNApJq7eTf/oKbV64m5xjiaTE1bzyL7BXG4qTMylKcrw9TGWdY7NW0Memc9Gm09amo69FJ+gqdI7OWkG/1S9at2/5agd5Z67Q7vm7yIo/X6OOMbeIMx9sYPCGBSAl+i3x1ea7lWExW1g77zMmfTELRaNw4OttpCZcZsS0e7h0IpHfNx+m70PDadWnPWaTmeLcQlY963x7mxoxW7g890Oaf/myddugNVsoOXOJsOn3U3TiLHmbDhD88G34Du0OJjOmnAIuPrsEALcW0UQvesK6yEMRpC7/j9MGJWYLyS+/T5PP5yMUhexvNlGakETIM2MpPpFA/pYDBI6/He/B3ZFmC+acfC4//47tglhIWfQJTf/9KghB8YmzZH/lpJFstpC+cDlRH78KikLe2jgMZy8SOGUcJb8lULhtH/4PjMZzUE8wmTHn5pMy800ACjbuwqNHDI1/eB+kpGjXYQq373csY7bwzpylvLHqHyiKwvo1G7hw5iITnhvP6fjT7N60lyfmTsLd051XPpgHQNqVNGY+PJeBowbQqUdHfPx9GHGvtfd40bTXOfv7OYdaZf59s83vLtj87qbn7yK7Dn6X8MEGBtn8LqUGv5NmCwkzP6HjV7Ot2wat3kbR6cs0eeFv5MefI3PjISIfHUnQsG5IsxljTgGnnl5Wfn7MD/PxaBGJxtONXkff59S098jeHu/wHiXN/YhWK18CRUPmms2UnLlExHP3URh/ltxNBwmZcCt+Q7sjzVafuzDtX07z6IyGKhfKtBqqrNs193NGrnwBoSicXrOD7DNX6PbcXaTHn7drXFYlrHsrYp4chcVkRloku2avoCS7wLGx2ULagveI+mQhKBpy/xOH4WyS7Tk6Q+G2/fiPG43XwJ5IsxlLpecIQBsZgjY8iOIDJ2rMT114/qXFHDx6nJycPAaPeYAnJ47jrlHOR13qhMVCyap38XjmNYRQMOzeiCX5Iq63P4j54hlM8dbGsy52AMaD2687D/WN5X9glbe4rnk+KvWCEKIrsBTwA0xY5z5OklJmCCG2A4ullL/UEsd4bNsDOTtu2zaoQEr5RiXdVUBbWcNrzQ9h9zeIkzTUIIpZiAbR2evaMDkaZ6l9FW59odM2TJ5cXJ1sg1PPPJLneGXun8HTlmufi3o1BFkMtRvVA166hrl2SSaPBtEB0DSQToq2YQYHB3jVw7zUOtBs17LajeqJ4pmPN4iOz0dxDVNR2Ggc2LHe6tmLmccbNO1lqD2UfwGklIcBh/sbSCkH1DGOFcCKmo5LKV92oNu67ilVUVFRUVFRqW/+Fzr31AalioqKioqKisoN5H9hyFttUP6XIYR4GJha5fBuKeXkG5EeFRUVFRUVFRW1QflfhpTyM+CzG50OFRUVFRUVlfpBHfJWUVFRUVFRUVG5Lm7kF27qC3UfShUVFRUVFRUVletC7aFUqZWBoxtm6wlLTsNsd2IuapiNX6MPX/03ka+FNu86/952fSMvJTWMkLZhiqY+/3T+taL6poNbw2gZDQ2z+U1x6bV/4u9qaKhtvgAG9LzOzzHWkYJLDePfbr4Ns/1WQ23lA+C+6P0G02pIbuQnE+sLtUGpoqKioqKionID+V+YQ6kOeauoqKioqKioqFwXag+lioqKioqKisoNRN2HUkVFRUVFRUVF5bpQh7xVVFRUVFRUVFT+36P2UKqoqKioqKio3ED+F/ahVBuUKioqKioqKio3kP+FIe9aG5RCCDNwwmZ7Hhgnpcz5sxNWJQ1RwDLgJqzD9D8Bz0spG2bjwgZGCKEDFgB3AflAKTBfSrmhHjWaAL2llKuuJx5Nu2643fs4QtFg2LUBw8av7cJd73kMbetO1h8urijefuRPu6tOcWs7xeI+/ilQNBi2/kzpD6ur2eh6DsDtnodAgvniOYqWLkTbLgb3Bys+ba5ENKJoyXyMh3Y71NF16Y7no1NAUSjZ9DMl31a/JC59B+J+33hAYj5/joI3FgAQ8P1WzBcTAbCkp5G/cJbT/PgO6EyTBRMQikLa6s0kv/udXXjwvQNpNPdBDCnW/QpTPttA+qrNuEQG0/rTF0ERCK2GlE/Xk/ZlXI3XbvfpK7z+0wEsFskdsS2ZMKCDXbg+p4C53+wmv9iARUqeHt6Fm9tEcSW7gDvf+p7GwT4AdIwOZs4dvZzqKI1vwqX/vSAUTL/vxnRoo124rt89aKJaWX9oXRAe3hS/P90a1ucONE3aA2A8sB5zwmHn+bmQwT93nsYiJWPaRTKhW1O78Dd2nubgZet1KzFZyCoy8OvjAwFYsjuBX8+nA/Bo92YMbxXmVKdV/47cNu9BFI3CwTXb2PHeOrvw7mMH02vcUCwWC4bCUr6b+TFpZ68AENYmmjteewRXL3ekxcKy0XMxlRqdann07Uro7MdBUcj99heyPvrGLtznjiEEP/8IptQMAHJWriP324249+hIyIxJ5XYuzaLRT19MwZa9DnW8+nUhfN4kUBSyv44j4/1v7cL97hpM2IwJGFOt+81mffET2V9b/UsXEUzkoilow4NBSi5OeBnjlTSHOj4DOtNo/kSEopC+ejMpy9bahQfeO5DoOQ9htPl36mfryVht9e8Wn7yIUBSEVkPqZ+tJ/3KjIwkAQgd2pPP8cQiNQuKq7Zx+d51Du8hbY+n98TNsHjGH7PjzAPi2jabr6xPReruDRbL5lrlYarhHus7d8ZhoLRtKN/9MyVoHZUPvgbj/fTxSSswXzlH4trVsUIJC8Jz8AkpQCEhJ/oIXsaSnONUqw61XLP7PTQZFofD79eR9/lU1G48h/fGd9BBSSowJ58ic81qt8QK4xHbHa7KtrFv/M0VfVc+Pa/+BeD40HqTEdO4cea8tQAkJxXf+QhACodVS9N1aSn76sU6aYKsn/v4EQlEw/PoLhl/W2Gve+zjaNlXqial31jl+Z8x57S127j5AgL8f3//7f3P/yr8SdemhLJZSxgAIIT4HJgOv/qmpqoQQQgBrgfeklKOFEBrgQ1sanm+odDQwC4BwoL2UslQIEQr0r2eNJsD9wLU3KIWC+32TKXxnJjI7A8+ZSzEd34dFX7H5dek3H1Bq+1s38HY00S3qHveEqRS++jyWzHS8F72P8dAeLFculpsoYZG4jrmfgnlTkIUFCB8/AEy/HyP/xUet0Xh64/2vf2M8fsixjqLg+fgz5M19FktmOr5vfYBx/27MlyrphEfifvdY8l6YbNXx9as431BK7tRHas+PotD0tUc5+fdXMOgzab/+dbI3HqQ4wX4j5cwfd3Nh9sd2x4xp2fw2agbSYELxcKPTtnfIjjuIMTXboZTZYmHRj/t4f+IwQn08GLvsZ/q3jaZ5aEW6P9p6nGEdGnNvzzacS83hqRWb2dDmbgCiAr35+unba8+TELgMuI/S75YgC7Jx+/tMzInHkVn6irTv/Iay6lrbaQBKcLT1cjRpjxLSiJJVr4JGi+vd0zFf/B0MJQ7yI1m8/RTv3dGFUC83xq7ZT/+mwTQP9Cq3ea5f6/K/V8cncTo9H4Bfz6dzMi2Pr+7vidEseeQ/h+jTOAgv1+pFn1AEt89/mE8eWEReSiaTf1zIyU1HyhuMAPE/7OHAyi0AtB3ShVvnPsBnD/0DRaNw79uT+Xr6clJOJuHh54XZWMOm0opC6LzJXJ4wC2NqBo2/WULB1v0YztlvHJ+/YQdpC96zO1a8/zgX73jKGo2vF802fkrh7iNOdSJeeYLzD87BlJJJs+/fJn/zfkrPXrIzy/35V/QvV69wo96YTtryNRTuOobi4Ya0OOlFURQavzqJM/e9jEGfyU3rXycn7gAlVfw768fdJM35yO6YMS2bk7dX+Hf7rUvIiTvg2L8VQZfXxrPzb4so0mcxZMMCkuOOkH/mip2Z1tONlo+MIPPw2fJjQqPQ/d0nOTDlPXL/SMLF3wtLLffIY9Iz5L9sLRt8Xv8Aw4HdWC7blw1ud40lb2b1ssFz6iyKv/03pvhD4OYOljp8UEFR8H/xadImv4A5NZ2wL5ZTtHMvpvMVmtroSHwevo+UiU8j8wtQ/P1qiNA+bu+nnyH7hWexpKfjv/wDSvfuxnyxIm5NZCQe940l++nJyIIChJ81bktWJtlTngSjEeHmTsAnn2HYuxtLZh0+eiEU3O9/isK3Z1jridlLMcXvta8nvn6/op4YNBpNdPO65akWxowcyv133c6sBW/US3x/Jv8Lq7yvdlHOXiASQAgRI4TYJ4Q4LoT4TgjhX8vx7UKIt4UQh4QQJ4UQsUKItUKIBCHEwho0BwElUsrPAKSUZmAaMEEI4SGE0Agh3hBC/GbTnGLTixVC7BFCxAshDgghvIUQ44UQ75ZFLIT4SQgxwPZ3gS19vwshtgghgm3HHxVCHLTF8x8hhIft+AohxL9sGolCiLsrxfuiEOKE7ZzFQojmQogjlcJbVv5dGVv8jwJTpJSltjynSim/toXfZ4v7NyHEPyqdV1Dp77uFECtqSedi4GYhxDEhxLQarr9TNE1bY0lLRmakgNmE8dB2tJ2c92bpYgdiPLi9bnG3aIMlNRlLmh7MJgx7tqKL7WNn4zL4Ngxx3yMLrVmXedU7znU9+2M6dgAMpdXCALQt22LWX8GSqgeTidKdW9H16Gtn4zZ8FCXrv6vQyb36Dnqvzi0ouaCnNCkVaTSR+cMu/Id3r9O50mhCGqwVn+KqBaXmL4f8dimD6EAfogK80Wk1DO/UlO0n7RsQQggKbT0zBSUGgn08rjpPSmgTZG4aMi8DLGZMZw6iadbRqb2mVSymM9aGvRIQjvlKAkgLmAzIjCtoGrdznJ/UXKL9PIjy9UCnURjeMoztielOdX45ncIIWy9kYlYhXSL90SoK7joNLYO82HMxw+F50TEtyLyYSvalNMxGM/Hr9tJ2WFc7m9KC4vK/XTxcy4epWt7ckZRTSaSctFaSRTkFzhtfgFvHVhiTkjFeTgGjifz1O/Aa3NOpvTO8h99M4a+HkCWO/du9UytKL+oxXrL6Xe5PO/EeWjcd1xbRoFUo3HUMAEtRiVMdz84tKa3k31nX6N/CVVejfwd0bk7BhVQKk9KRRjOXfthH5PCu1ezavXg3p95dh7m0YhArtH8Hck8mkfuH9R4ZsgughnukbdkWS6WywbBrKy7d7csG16GjKN1QvWxQohqDRmNtTAKUFDstgyrj0q4NpktXMF+xahbFbcOjf287G687biX/6x+R+VZNS3bdyiNtm7aYrlzBoreVddu24tq7Sll36yiKf/wOWWDLT44tbpMJjLZXQxcdiLo3HTRNW2NJr1RPHNyBNqa3U3td7ACMB7bXOf6a6BbTAV8f73qJ689GSllv/24UdfYKW8/gYKCsn/sL4EUpZUesQ+Iv1XIcwCCl7Aa8D/yAtbezPTBeCOHsO3XtALuxMCllHpAEtAAmYe1ti7FprhRCuABrgKlSyk7AEKCYmvEEDkkp2wE7KqV7rZQy1hbPSWBipXPCgb7AbVgbaAghbgFGAz1s57wupTwH5AohYmznPQx85iQdLYAkWx7tEEJEAP/A2siOAWKFEGNqyZfDdAIzgF+llDFSyrfrEEc1hF8gluyKil1mZ6D4BTm2DQhBCQrFfOpYneJWAoKwZFYMrVky01H87ePWhEehhEfjNX8pXguXoe0UWy0eXe+BGHZvca4TGIQlw15HE1hFJzIKTUQ0Pv94F59/LkfXpVJF6eKC71sfWI/3tC+cK+MSFoghueJt3qDPxCU8oJpdwMhedNj8Fi0/fB6XiIpHwiUikA6b36LzoY9IXvad095JgLS8IsJ8Pct/h/p4kJZbaGfz+OBO/Hw0kWGLvuGpFVuYcXvF5xuvZBXwt3+tY+KHv3DkfKpTHeHlj8yvSIcsyEF4+Tu29Q5A8Q3CcukUAJaMy9YGpFYHbp4oUa2cnptWUEqol2tFfrxcSS90XDkn5xWTnFdMbJT12rYK8mbPxQyKjWayiw0cupxNSkH1XlAAn1B/civdozx9Fr6h1e9Rz3FDeW7H24yYcT/rXv4CgKBmYSAlD38xg6d+epV+j93mUKMMbWgQRn3Fs2NKyUAbWr0I9B7alyY/LCdiyWy0YdWfLe+R/cj7ebtTHV1YoL2OPgOdAx2fEb1psX4p0ctmogu36rg0jcScV0j0e7Novm4JoTMeBsVxleESFoAhuaKhbtBnogurruM/siftNr1Ncwf+3W7T23Q6+BEpNfi3e1gARVcq7lGRPgv3MHu/8evQBI+IQFK22Jc13s3DQcLNq19kSNxCWj9Z8z0SAUGYq5QNStWyISIKJSIa79fexWfxcnSdu9uORyMLC/B6cQE+b36M+0OPO712dvGFBGFOrXS/0tLRhNhrahtFoWscRegnSwj9bCluvaqXew7jDgrCkl4pP+npKEFV4o6KQhMVjd+Sd/FfuhyX2IqyTgkOJuCjTwla/Q1Fa1bVrXcSEH5BWLIq1xPpKH6Oq3trPRFW53pC5a9FXRqU7kKIY0AKEApsEkL4An5Syh02m8+Bfs6OV4qrrDF6AvhdSqm39cIlAtHXmIchwAdSShOAlDILaA3opZQHbcfyysJrwIK1EQrwb6wNMID2QohfhRAngLFYG7hlfC+ltEgp/8B6bcrS85mUsqhSegA+Bh62Ncz/xrUNNccC26WU6bb8rMT++jrDUTprRAgxydabfOizk9f/fVtd7ABMR3ZZe6TqC0WDEhZJwSvPULRkAR6TnkN4VDSkhF8AmkbNMMUfvD4djQZNRBR5s6ZS8MZ8PJ96HuFpHW7NmfA3cqc/RsEbC/B85CmUsIhrlsnedJCjPR7jxJDp5O6Mp/k7T5eHGZIzOTFkOsd6P0nwPQPRBfleV5Z+iT/P7V1bEDfzHt4dP5g5X/+KxSIJ9nbnlxfvYs3To3j21lhmrtlJQcn1T1XWtOqGKeEI2N6eLUknMV/4Dbd7X8D1lkew6M/Xi29sPJPC4BahaGy9XL0aB9K3SRDjvznAzF9O0DHcF811fht635ebeKP/NH5ZvJpBU6zvc4pGQ+PY1qyZuowP7n6FdsNjad7bcY9rXSnYtp/EweO5MPpJCvccIWzxs3bhmmB/XFs1pXCX87mndSF/ywHO9JvA2ZFTKNh1lMh/WgcshFaDZ2w7Ul77hHNjpuHSKAz/uwdfs07OpkMc7/kYvw+dRt7OeJq+M7U8zJCcye9Dp3GizxME3jMQ7bX6txB0enks8S+vrB6kUQjq3or9k5exbfR8Im/pRkjf67tHaDRowqPInzuVgrfm4/Hk8wgPL9Bo0LbtSNGK5eQ9/xia0AhcBo64Pq3yfGjQRkeSOmk6GbNfJWD2dISXZ+0n1gWNBm1kFDnTp5L76ny8p1eUdZb0dLIenUDmg/fjNmwEwt/xC+D1oOs+ANORX+u3nvgvwSJlvf27UdSlQVk2h7IxILD2Kl4rZd0Klkp/l/12Np/zD8BuTEMI4QM0As46PMM5Juzz7FaDbdldWQE8JaXsALxS5ZzKeaitlvoPcAvWXsLDUkpnr3dngUa2PF4Nlb2oar6uJp3WyKT8UErZTUrZ7eG2UY5tcjJR/IMrIvYPwpLjeDhR163/VQ1jWLIyUAJDyn8rgcFYsjOq2KRjOrwHzGYs6SmY9ZdRwivSqus1EOOBXWA2O9fJzLBOmq+kY86sopORjmH/bqtOagqW5EsoEVHl6QSwpOox/nYMbbOWDnUMKZn2PTLhgRj0WXY2puyC8qG/tFWb8ezYrFo8xtRsik4n4d3jJqd5CvHxIKVSj2RqXhEhvvYVzneHEhjWoQkAnRqHUGo0k1NUgotWg5+n1X1uigwkKsCbixnVOssBkAXZCO+KSkV4+SELHPcsaVt1w3zGvmFvOriBklWvUvrdEhBgyXG82CPEy5XUggoXTi0oJdjT1aHtxjOpjGhtv+jmkdhmrLm/F+/f0RUpoZG/4+H9vNRsfCvdI5/wAHJTsxzaAhxft5ebhnYDIDcliwsHTlGUnY+xxMDpbceIaN/U6bmm1Ax04RXPjjYsCFOqfZFgyclH2oYZc7/ZiFs7e9/yHtGPgs17wOTcv40pmfY64UHli2/KMOfkl/td9po43DtY5zkb9RmU/JGI8VIqmC3kx+3DrZ3juW2GlCxcIip6u1zCAzGmVNHJrtBJX7UZjw6O/bu4Bv8uTsnCI7LiHnmEB1CcUuFzWi83fNtEM2DtHEYeeIfALi3os+JZ/Ds1pVifRfq+UxiyCjAXG9BvPYaf7RlwhMzKQFOlbLBULRsy0zEctJUNaRVlgyUzHfOFs9bhcosZw/5daJu3cqpVfo3SMtCEVrpfIcGY0+w1TWnpFO+0lnvm5BRMSZfRNXJcRtvFnZGBElwpP8HBWDKq5Cc9ndI9tvykpGC+fAlNlH3clsxMTOfP49LB+fSWysicDJSAyvVEMJYcx9VffQ53/7ch6/G/G0Wdh7xtPW5PA88ChUC2EOJmW/A4YIeUMtfR8etM4xbAQwjxIJQPvb8JrLClaRPwmBBCawsPAE4D4UKIWNsxb1v4BSBGCKEIIaKBypN8FKBsfuH9wC7b396A3rbyemwd0rsJa09k2VzLAAApZQmwEXgP58PdZdf5E2CJbegeIUSwEOIe4ADQXwgRZLsO91FxfVOFEG2FEApwRx3SmW/L2zVjvnAaJSQSERgKGi26bgMwxe+rZqeERiM8vDAn/lH3uM+dQgmLRAkOA40Wl96DMB7aY2djPLgL7U3WWQTC2wdNeJS1ALfh0mcQxj3Oh7sBTAmnrMNWoWGg1eLabxDGA/arwQ37dqHtYNPx8UWJiMaSkmx9c9fqyo/r2nbAfOmCQ52CY2dxaxqOa3QIQqclcHRfsuPsG1i6kIrGmf+wWIoTrAsNXMIDEW4uAGh8PfGObUvxOftFCJVpFxVEUkYeV7LyMZrMbIw/T/8qLwXhfl7sP2e9VolpORhMZvw93cgqKMFsWzxwOSufpMw8ogIcu4kl9SLCLwThEwiKBm2rWMyJx6vZCf9QcPPEok+sdFCAm7WRK4IiUQIjsVx07B/tQn1IyiniSm4xRrOFjQkpDGgWXM3ufFYheaVGOoVV9G6ZLZKcYmsP65mMfBIy8unVyPFw2+X4cwQ1CcM/KhiNTkOnUb04ucm+9y+wSUVjtfWgzmRcsK7aPbPjOKGto9G5uaBoFJr2aEtagvOe/ZITZ9A1jkAXGQo6Ld4j+1Ow1f7Z0QRX+IPXoJ4YztnPg/W5dUCNw90AxcfP4NokAl1UKEKnxfe2fuRv3m9no62k4z2kR/mCneLjCSg+XmgCrO+2nr07VlvMU0bhsQRcm4bjYvPvgFr8229YLCVnrddHV9W/u7elxIl/Zx9LxKtpGB7RwQidhujRPUneWHGPTPnF/NjucdZ3f4b13Z8h88hZdo9/k+z486RsP45v22g07i4IjUJwz7bknXH+HJkSTqGER6GEWMsGl76DMB60LxuM+3eha19WBtnKhtRkzGdPITy8ED5WX9R16OK0bKiM4Y9T6KIj0URYNT2GDbQ2HitRvH03rl2tmoqvD9pGUZiu6B1FZ5+fU6fQRkahhNnKuoGDrI3HSpTu3oUupqKs00RFY9YnowQFg4v1HgkvL3QdOmC65NgXqlJeTwRZy3JdbH9M8dV3JFDCbPXEubrXEyp/La5qH0op5VEhxHGsDZmHgPdtDadErPMCqeH4NSGllEKIO4DlQoi5WBt+64Gy/Vk+BloBx4UQRuAjKeW7Qoi/AUuFEO5Y508OAXZj3froD6zzISsvjCkEugsh5gBpWIelAeYC+4F02/9rbIRJKX+xzZU8JIQwVEnrSqyNvZr3fIE5wELgDyFEiS1t86SUeiHEDGAb1p7Gn6WUP9jOmYF1O6V04BDgVT1aO44DZiFEPNbG+dXPo7RYKPlqGR5TX7NuB7E7Dov+Iq6jHsR88Qym49YKUhfbH+Ohq3yvsFgo/vRfeM56HRQFw/YNWC5fwO2ehzElnsZ0eA+m+INoO8bi/eZnVvuV7yMLrL1pSnAoSmAwpj/ia9ExU/j+O/i88oZta5D1mJMu4D52AqaEUxgP7MF45AC6zrH4LvscLBaKPnsPmZ+Htk07PCc/Zx2eEQrF+nk8VQAAIABJREFU3660Wx1uh9nChdkf02bVPIRGIe2rLRSfuUTU83+nMP4c2XEHCZv4f+3deZxddX3/8dc7CRD21QCK1rAKCCKExcLPUqPSWkEUcKMCRQtVhGKVipaKbCoqikDZtECsLEIBQZRdBQUVyAKJyBLZZZMiECFAyLx/f5xzk5thJhOYc8+de+b9fDzmwb3nJuf9nZDc+5nv+h5WfffW+KU+XnpqDn/4zIkALLvBOmz0pWJrJASPnHoJc+94YOAcYNzYMRy6y7Z88oxr6HMf75u0AeuvuSonXz2dTV63Ojtu8gb+7T2TOPLiGzn7V7eD4Ijdt0cS0+57jJOvns64sWMYI3HYrm9j5eUG7g3Efbz4ix+yzK4HFdsG3X4jfvIRltpuZ/oeu5/59xbF5bgNt35Z7yRjxjJ+988Vt3lxLi9ceeagw1zjxozh8ztuxKcumUZfn3nfpq9lvdVX4OTfzGaTCSux47pFr8uVdz3KThuuhdqGtF/q62Pf/y0WRqyw9DiO2Wkzxg0yl61vfh+Xfuks9v3+oWjsGG45/xc8fvcfeednduePM+/h99dM4217v5v1t38z8196iblPP8sFny1WYD//zLP86ns/5YBLj8Y2d/58Bnf+fDHzwOb38fhRp7DOfx8NY8by9IVX8eLsB1j9wI/x/Ky7ePbnv2XVj72PFf52Ozx/Pn1Pz+HRLxy38M/kdRMYt/YazL1p5uAZZc7DXz6VN045Eo0Zw58vuJoX7n6ACQfvydyZdzPn2ptYfZ9dWHHyNnh+H/OfmsNDhxxf/oH08ehX/5uJPzgGJObOnM2fzxtkO5/5fTxw2HfZ6JzDYcwYnvjhtTx/14O89nMf4blbZ/PU1Tez5r7/wCrv3hrPn89LT/2Few8u/36vvw6v/9I+tP6CP3rqjwb9++35fUz/4lm8/dzPo7FjuPe863jmrj+y6SG78eSt9/LIVYOsdgfmPf0cd512OZMvPwpsHrn21pfNs1xE33ye++7xrHh4+d5w7U+Z/+B9LPuRfXlp9h3Mu/lG5k2/iaW22JqVT5iC+/qYO6V4bwB4bsoprHjEt0Fi/h/u5IWrL1v8/6vyz/HJb5zIhBOPhbFjePbSy5l3z/2svP8+vPj7O5l7/a95/tc3M367Sax9/hm4bz5PnXA6fU8PPIrQ//uZc+LxrHLsN9GYMcy9/KfMv/8+lt9nX+bdeQcv/vpGXrz5JpaetDWrnTEF5vfxl9NPwc88w7itJrHKv3wK20jiufN/yPx77xk6E4rPiXNOYrmDv4I0hhdvuJK+h+9nmV3Kz4lbW58TOy7xos0ldcjhX+Pm6bfx1FPPMHnXf+RTH/8Yu+28U6UZVWnCxuZqwmaaVZD0F9tDFWHDzfgcsLLt/+xkTtWe2X+nWv6S9D1Vz7ai85+rZ37O3VMHW2dWrbecNKmWHAA/OHghW6lx9Zy5cNQ3Bh/Srto+4wdfSFWleS+OrSVn7gtL1ZJzX98r34Hg1Zq83fDniy+JvzxYz9/v8SsPtXSgopx1B/mhswOW/Wo9+0kutca6w5ts/QqNH/+Gyj5nn3/+gVrb3pKTcmoi6WJgPYoV2hERERGNMWIKynLboIEmvE1ezAKWynS6d9L2y+Y1lkVm/5n7n7c9+DERERER0SjdXExTlRFTUJZF4xZD/sIGGajIjIiIiNGlCdMPX+lJORERERERixgxPZQRERERo1ETeihTUEZERER0Ue+Xk9k2KDpE0n62T29KTp1ZyRn5WckZ+VnJGflZTcsZ7TKHMjplv4bl1JmVnJGflZyRn5WckZ/VtJxRLQVlRERERAxLCsqIiIiIGJYUlNEpdc1XqXNeTNO+p6bl1JmVnJGflZyRn9W0nFEti3IiIiIiYljSQxkRERERw5KCMiIiIiKGJQVlRERERAxLCsqIIUhaWtLmkjaTtHQv50jaY0mu9UpOed/tl+Rar+RERDUk/euSXItqZFFOVErSWsA2FCdJ3Wz70R7P+QfgVOAPgICJwP62L+/RnGm2txzqWq/k1JnV6RxJqy3uddtP9lJOE0kaC3wCWAe4wvYNba8dZvvoDmQK2BNY1/aRkt4ArGX7pgozxgKr2n6ifL40sA/wGdsb91pOW95A/2an235r1VmRs7yjQpI+AXwJ+BlFUXSipCNtn9GLOaXjgL+1PbvMXg/4CVBpodfpHEl/D7wHeJ2kE9peWgl4qYqMOnPKrLcBfw28RtK/9csa22s5wFSKH5AEvAH4c/l4FeABih8yeikHSXNYzDHFtlfqpRzgNGA54CbgBEnX2W79nfgAUHlBCZwM9AHvAI4E5gAXAltXcXNJH6b4vp6VdDdwDHAGcDNFIVuJunLKrI8AHwUmSrq07aUVgfzA1CEpKKNKhwBvtf1/AJJWB26keNPoxRyAOa0ir3QPxRt6r+U8DNwC7EJRUCzIBT7TgzkASwMrULyPrdh2/Rlg917LsT0RQNJ3gYtt/7R8/vfArr2WU2atWN77KOAR4H8oitc9gbV7LQfYxvbmZdZJwMmSLgI+UuZ1wra2t5Q0HcD2nyueEnMYsJXt2ZK2BH4N7G77xxVm1JkDxefBI8AaFD+st8wBbutAXpAh76iQpBuBHW2/WD5fGviF7b/uxZzy3qcAfwWcT9EDsgdFL841ALYv6rGcpWzPq+JeIyGnzPor2/c3KGem7c2GutYrOeV9b7X9lqGujfQcSXfYflO/a18CdgIm2N6gipx+9/8tRQ/5zWVh+RrgqqqGbfsPC0uaZfvNVdy7GznRPemhjCrNBn4r6RKKouh9wG2tYULb3+qxHIDxwGPA35TP/wQsC+xcZldS6NWYs42kL1MUr+MoelVse92K7l93DsAykk4H3kjbe5rtd/RozsOSDgN+UD7fk6Lnt2p15UAxzLkncB7F3+ePAM/2YM4tkv7O9hWtC+W8xoeBUyrMaXcCcDGwpqRjKHrFD6vw/hP6TeVYpf15he+ndeUsIOkDwLHABIr3oNb7UFVTIKJNeiijMpIOX9zrto/opZwmknQHxdDzVGB+63pr+kCv5ZRZt1IsaOqfNXXQ3zSyc1YDDgfeXl66Hjii6sUydeWUWW8EvgNsT1Ho3QAcbPu+Xsypm6Q3AZPLpz+z/fsK793Y921Js4Gdq/zzisGloIxYDEkTgQN5ea/ULj2a81vb21Z5z27mlFlTbW/VlJwY2SRNAA4ANi0v/Q442fZjHczcEtiBski2Pa1TWU0i6Qbb2dqrJikoozKSJgH/wcJhTgBak9h7LafMuhX4b2AmxUrLVtZ1vZRTfiABfJBiZfJFwAttOZV8QNWVU2a1tr85CHicYliwPavqbXY6mtOWtyHwOTo8tF5XTpn1GuCfB8jat5dyVOw7eg5wFgsXnW0F7A3s2b6NUFXKOZp7UKzsFsXCqQuq2qKo324ML2P7oF7K6Zf5HWAt4Ecs+m+2qilE0SYFZVRG0p0UK7D7F0WVLmSoK6fMakSPnqSfL+ZlV1VE1JVTZt3Lwu1vBsqqZL5mXTlteY0awi+zbgR+OUDWhb2UI+k3wCdtT+93fQvgtE78Gy7f795i+/ny+bLADNsbVXT/vRf3uu0pvZTTL/PMgaOq/UEmCikoozKSfmV7h6bklFkfBTYArqJDPW115sTI18QhfEkzbG/R6zmSbre9ySt9bZiZPwfeb/up8vkqwEUV/3D2GooRn9mtnE6oKye6I6u8o0qHS/oecC2dHV6oKwdgM+BjFJsKt3pDXT7vuZx+qyxbngam2p7Razll1gcGyZpp+/FeywF+LOlTdHhovcYcgMskvcflnpcd1OkcSVrV9p/7XVyNzh1l/DTwO0lXU7wnvAu4qTWEPNyhYhUHRXyF4pSuiZL2s33pEL9txOb0yzyTATa8Tw9lZ6SHMioj6QfAmygmqS8oijowT6qWnDJrNrCJyz0vO6XGnHOASUBrM+H3Umz0+0aKeVlf76WcMusnwNuA1nD7jhRDnhOBI23/T4/l3DvA5U4MrdeSU2bNAZanKFzn0aHtWzqdI2k/ijmanwNaowdbUWxNc4bt06rI6ZfZ0aFiSbMoTun6k6R1gbNtv2049+xmTr/M3dqejgfeDzzcifmakR7KqNbWVc3rGSE5ALMojqSrsgeqmznrAFva/gss2MrjJxRbx0wFqir06sqB4n1s49YqW0lrAt8HtqXYCqeSQq+uHJcn2XRaXTll1opD/6qRn2P79HLPyaMoVnkbuB042p058QXbU1Qc3rBheelOV3towIu2/1Rm3SNpmQrv3Y2cBfrPnZV0LvCrTueOVikoo0o3StrE9u0NyYGiyLtD0s0sOixY6XY+NeZMaL8/RS/OmrbnSnphkN8zknMAXt9vy5bHy2tPSqryg7eWHEl7DXTd9veryqgzp8x6+0DXbV/fazm2LwMuq+p+Q5G0IzAFuI+ix/X1kvau8Htap98K7EWeV9ibV1fO4mxA8d4UHZCCMqq0HTCjHEp7gYXDTVVv51NXDhQbP9ehrpyzWXjKEBQn8ZwjaXmKnpZeywH4haTLgAvK57uV15YHqpz4X1fO1m2Px1NsaD2Noje0SnXlQLErQ3vWNhQ91VXPRe5ojqRvUCwoOa3f9f2BibYPrSKnn+OAd9u+s8zaEDiXYqi9Cof0e175Kv+acxYop0C0dmgw8Cjw+U7njlaZQxmVkfRXA13vwLZBteT0y9vA9jWSlgPG2p7TwzmTKE4SgWKT5Fuqzqg5RxTF3YIs4EJX/OZWV84AuasA59n+uybklFmvB463vduQv3gE5UiaCkzq//9c0hjgNnfmDOzb+v+wPNC1TpN0ou0Dm5IT1UtBGZWStANFUXRmuUXECrYHmvzfKzn/DOwHrGZ7PUkbAKfanjzEbx1ROZJWsv2MFm7SvYiqVvbWlTOaSFoKmNXpecN15ZRZAn7nDmyz08kcSbMGKxol/c72pgO9NszMMygWH7afuT627pXKkqbZ3nLoXzmyciTtwsLjRX9RTlmIDsiQd1SmXHgxCdgIOBNYiuJNsNKjr+rKKR1AMWz2WwDbd6s4eq3Xcs6hWGk9lUW30WgNBVW1sreunAX7kbYNay2SVeHK3lpy2vJ+3JYzFtgYOL/KjDpzyqwT27LGAFuwcJV0L+XMlbSB7bv75W4AzK0wp90nKd4fWnMMfwmc3KGsRpH0NYqpHWeXl/5V0l/b/mIXm9VYKSijSu8H3kr5Bm77YUmdWHVZVw7AC7ZfLDo6QNI4BtjXbKTn2H5v+d+XreyV9Lpeyykzdij/2+mVvbXktPlm2+OXgPttP9TDOQDt0x1eAs51B44prCHnS8Dlko5m4RzAScAXgIMrzFnA9gvAt8qveGXeA2xhuw9A0hRgOpCCsgNSUEaVXrRtSQYoFyv0ZI6kT9s+CbhO0heBZSW9C/gUC/dW7JmcIfwaeEODcpD0gO2OZ3Uix/Z15ZZErUUzdy/u14/0nDLrZVvf9GKO7csl7UqxwKQ1z28WsJvtmVVmSZrJYn6orHsOJQx49Ggv5KwCtKbarFzxvaNNp3b2j1FE0lfKh+dLOg1YpZwTeA3w3V7LKbXmJx0K/Ini3PD9gZ8Ch/VgzuL06gfFSMiqPEfSB4GbgD2AD1Kslt+9V3PKrB0pCtb/ohiuvWuwLX5Geo7tWbb3tr1V+bV3/2KyHHofrvdS7I4w2FfdvtODOV8Fpks6q+ydnAocU+H9o00W5cSwtU+iLnvX3k3xQXul7at7Lad/VifVlTNEG3q2N6/bWZ3IkXQr8C6XxzmWi86usf2WXswp7z0V+Gj/rW9c8VnideUsQTsq/3ctaXWKxSUP2K5syx1Jn6ZY3f+EpPWBM4DNKXp3P1FVz6uki4CLgB+5PPCgDpLWZmEv/E22H60re7TJkHdUYaykVSmKu6m07S8mabUKV/bWlQOwuaRnBrhe9UKMWnL6LVbon7NKFRl15pRZA50X3spaoddy2ozxomeD/x+dGU2qKwdgqVaRB2D7rnJVea/mdJyKPU8PtT2rLIqmUcwRXU/S6baPryjqk+W0Gyh6B79t++Kyt/dUqlvsuC3FavUTJF1DsZfmT9yB42Yl7QSsaPt/bT8CXFpe313S01V3QEQhBWVU4U0UxV1rJW9L1St768oBmGn7rRXer9s5i9sDssr9IevKAVjcIpkqh83qymm5QtKVFB+4AB+imALRqzkAt0j6HotufdOJfUnryqnDRNuzysf/BFxte69yAeINQFUFZXsdMMH2xQC2f1HxYsfHbe8uaSXgfRRnop9eFs7n2r6qwqwvAbsOcP0XFHPTU1B2QIa8Y9gkTa+jKKorp86sOr+nJaEGbl4s6Qu2v9pLOZI+AOxQPv1l60O+ajXmLEOx9c2CLODkcgVzz+UsQTuG/e9a0gzbW5SPrwW+a/u8/q8Nl6RjgNcBRwIfBp4DLqY4XWi31s4NFeS8bBqApDWA3YEP2q7s1CRJt9ieNMhrtW8KP1qkoIxha2LxJemLtr+yBL9uWEVEXTmvoD2Nmzvaq99T+WH7/6h4zly3csqspYFNgT/2G27vyZzF5O9j+6xh3uPHwFXAQxTzGifafkrSssAtrnATdUn7UOx3uR6wDPAg8CPgWNtPV5Rxve3KF2INknUXsIntl/pdXwq43fYGdbRjtMkq76jCEg37VbDysa4clqTIK+3RCzmjXE+s+JZ0maQ3l4/Xpljxvy/wfUmV7XFYV055/1MlbVo+XhmYQXFW+HRJH+nBnM3bHi8l6TBJl0r6iorjUgEYbjFZ+jhFUbwP8CHbrfPit6M40KESkrYGrrC9re01gE8DsynmB4+tKgf4nKS12nL3knSJpBM0yMlaw3AR8F21bSknaQWKOaEXVZwVpRSUMWyv4M1zWJO768p5hXqiWBnl6hqGGW7OQHPmdqYoIKo8Zq+uHID/Z/t3bVl32d4M2Ar49x7MOavt8deA9YHjgGUpipXK2H7c9r/Yfl/7/ELbP7e9YFP6Cn6APg14sbzX2ym22pkCPA2cPsx7tzu1X87XKIr+qnOg2HLtMeB+SVPL1f/3UmzNVtd2bKNOFuVEDE+vFCtLqokFcq98T/PaHk+m3FvV9hxJfcO8dzdyoCwgSu8CLiizHpUq/d9SV077zSYDW9ueJ+l64NYqg16B4f4APbZth4wPAafbvhC4UNKMYd67GzmUQ92HSjqCougHmG17keMxJb0rK76rk4IyYnh6pVhZUr24efFQLuiRnAclHUgxZ25L4AqAcs5clVvf1JUD8JSk9wJ/pCh8Pl5mjaPo1eu1nJUlvZ9idG8Z2/Og2N9L5cldPWispHFlETYZ2K/ttSprhLpyFigLyMXto3ksWfFdmQx5R52aVnxB7xQrg5K0YLipgoUEYyXtL+koSdv3e23BUFMVc8wkLSfp3yUdImm8pH3K+WxfL+dLtbKWdJ7qK8m+q/+1CnJqmTNXYw4Upz59urzvwW2bSk8GftKDOdcBu1CcYvMbFUdXUs4NfKLCnDqdS3H06yXAXIqV8ajY5LySBTk157wSmUpUoazyjtpUsfKxrpxygv2nKYaaT6TYTuMDwB3AkZ086UHSXbY3HPpXvqJ7DjbpXcCtttepKOd7wHIUR/p9DLjO9r+Vr1W9Cvp8itWoywIbAb8Hfkjxgb+W7Y9VlDOHhVMOWh9Ay1Fsr1LlJvdL2p5s7dSlnHIBy0PlZtlI2gvYDbgf+LKrPVxhSdtUxRZF2wFrA1fZfra8tiGwgu1pFTSz1pxX0J6un1TWJCkoo6NUnOiw39C/conuNRb4BLAOxarEG9peO8z20VXklPdrVLEiaT7Fh177T+Qun7/O9tIV5SzY460cbjwZWAP4CPCbKrd9UrkXn4pJco8Aa5dDj60iuZK95iSdQHHKzyG2Hyuv3Wt7YhX3fxXt6cltkEZC1nBzJE0D3mn7yXJhyXnAgcAWwMa2O3IW+hBtquUH9SZKQVmtzKGMYRui9+s9FUadxsLerxMkLej9oug9rKygBDa0/cG2YuWdZbHyK6qdfH8m9RQr9wCTbT/Q/wVJD1aYs6AwLedK7SfpcOBndOaYwtb8tZ+6/Om46vlstg+StBVwrqQfASdR3yKp0aJXpsPUtrBkSX+ATjE5LPd1uwFNkjmUUYU/URxvNrXt65bya0KFOdvY/qiLM2y3BVaQdJGK0zE68oFUFimLFCtUWEzYPohigcq5kg6SNKbK+7c5Hlh1kNe+XmHOLZL+rv2C7SMoCuc3VpjTylqhzFiw3Y2k9YA5VQa52PD7neXT64DxVd4/ema3hLFlzzsU8zN/1vZa1R00pwF/Q3HG+gmSvtX22gcqzmqkcsugAyQN+N5nO3+OFUpBGVW4B9jR9sS2r3XLXrbHKsxZpPerHEq/lc70fjWtWLmJtv8XattUGDi7wpzv0NaD28oBNgfWrDAHig/cBf/f27IOZuBzfF8VSVtLWst2n+0TKM67XkPSdxbTO99JvdKbNxKzhptT58KS2n+AbqAPAa8FbpZ0nqSdylGn6IAUlFGFJvZ+Na1Y6b95cac2FT4NeKGGnFbWQN/TU1S7yXT/nAMp5oQ+Q/Xf05LI1k5dyrF9DPBZig3Od2iNXFB8lla9gGmgH6Bn0MHpI01je7bt/wA2BM6hOMLyfklHdOmHwUbLopwYtnLl44OtrTo6tfKxzhWWdU2+rzHnVttvKR//F/An218un8+wvUUv5dSZVef3tJg29OritkbtllAnST8AfmD7in7XPwGcYrvqPUMbScVxmf9EMZ//SooRmR2Aj9Xxb3c0SQ9lVKGJvV8DTr63/Z8sPHmhp3JqmvtV5xyzRn1PklYb5Gt1ql/cVtfcvLMopjpMpNgPchLwDYoh21OqCpE0R9Iz5dccFbsnrNe6XlVOnWz/Y/9isrz+vRSTS0bFkYvfBm4GNrd9kO3f2j6OYqpWVCirvKMKjTu6i+adHtGa+/UE9Wxe3OmcOrPqyvkTg2/tVPXittbWTicBJ0u6iGIYv+r5ZU3bLaFWkiYAB1BsRA/wO+Dk1vcYQ9rD9oCFYxbkVC8FZVShacUXNKxYsX2MpGtZuKlwR+Z+1ZVTZ1aN31O2dnr192/c1k4qTpo6h6KX9/vl5a2A30ras32qQgzqE5K+7vI0KBWrvT9r+7Ahfl+8CplDGcMm6T8ohuSeAN4AbFl+YKwPTLG9/WJvMMJy2vJG5ekR0R2SDgB+ZftlPXeSDrR9YkU5tc3NU3Fy0sH950qq2C1hiu0dqsoq7zuGYs7mHsB6tl9b5f3rJOk3wCdtT+93fQvgNNvbdqdlvUMDnCKkbGbeMSkooxIpviKGp6GL2wb7nh4AjrBdyfnXA+R8ATiCYp7mEVV+T3WRdLvtTV7pa7GQpNuArW235t4vC9xie9PF/854NbIoJyph+ze2L24VeeW1u6ou8urKieiCJi5uG61bO1VBGmBDbhXb3eSze8mcDVwr6eOSPg5cDUzpcpsaK3MoIyJGhkYubmvg91SXbwNXSfoc0PqBeSvg2PK1GILtY8teysnlpaNsX9nNNjVZCsqIiJGhiYvbmvg91cL26ZIeBo6iWOVt4HbgaNs/7mrjeojty4HLu92O0aAn/6FFRDRQo3YWqDmrzu+pNrYvAy7rdjt6laQPUPToTqDYEksUmwys1NWGNVQW5UREjBBNXNzWxO+pDpK+Acy2fVq/6/sDE20f2p2W9Q5Js4Gdbf++220ZDVJQRkREjDDlKS+T3O9Dutwa6Tbbb+5Oy3qHpBuq3k4uBpch74iIiJFnmf7FJIDtvvLkoRjaLZJ+CPyIcmcDANsXda9JzZWCMiIiYuSZK2kD23e3X5S0AcU80RjaSsBzwLvbrhlIQdkBGfKOiIgYYST9PXAicDQwtbw8CfgCxelDP+1W2yIGkoIyIiJiBJL0ZuAQoDVfchbwTdszu9eq3iFpPPBxim2Xxreu2963a41qsOy2HxERMQLZnmV7b9tblV979y8mJVVyxntD/Q+wFrATcB2wDjCnqy1qsPRQRkRE9ChJ02xv2e12jESSptt+q6TbbG8uaSngl7a363bbmig9lBEREdFE88r/PlVOH1iZYpPz6ICs8o6IiIgmOl3SqsB/ApcCK5SPowMy5B0REdGjWsO63W5HRIa8IyIietd3ut2AkUrS6pJOlDRN0lRJx0tavdvtaqoUlBERESOMpM3bHi8l6TBJl0r6iqTlWq/ZPqsrDewN5wGPA7sBuwNPAD/saosaLEPeERERI0z76m1JxwGrA2cCuwKr296rm+3rBZJm9T/zXNJM25t1q01NlkU5ERERI0/7ed2Tga1tz5N0PXBrl9rUa66S9GHg/PL57sCVXWxPo6WHMiIiYoSRdA/wWYqpaUfb3rjttVttv6VrjesRkuYAywN95aUxwLPlY9teqSsNa6j0UEZERIw81wG7lI9/I2lN249JWotiLmAMwfaK3W7DaJKCMiIiYuQ5GXjI9iMAkvaStBtwP7BHV1vWIyS9faDrtq+vuy2jQYa8IyIiRhhJ04B32n6yLIzOAw4EtgA2tr17VxvYAyT9uO3peGAbYKrtd3SpSY2WHsqIiIiRZ6ztJ8vHHwJOt30hcKGkGV1sV8+wvXP7c0mvB47vUnMaL/tQRkREjDxjJbU6fSYDP2t7LZ1Br85DwMZD/qp4VfKXMiIiYuQ5F7hO0hPAXOCXAJLWB57uZsN6haQTgda8vjEU0wWmda9FzZY5lBERESOQpO2AtYGrbD9bXtsQWMF2CqMhSNq77elLwH22b+hWe5ouBWVEREQ0jqTlgedtzy+fjwWWsf1cd1vWTJlDGREREU10LbBs2/NlgWu61JbGS0EZERERTTTe9l9aT8rHy3WxPY2WgjIiIiKa6FlJW7aeSNqKYoFTdEBWeUdEREQTHQxcIOlhQMBaFHt6RgdkUU5EREQ0kqSlgI3Kp3fantfN9jRZhrwjIiKicSQdACxve5btWcAKkj4GuGcjAAADq0lEQVTV7XY1VXooIyIionEkzbC9Rb9r022/tVttarL0UEZEREQTjZWk1pNyH8qlu9ieRsuinIiIiGiiK4AfSjqtfL5/eS06IEPeERER0TiSxgD7Ae8sL10NfK91ck5UKwVlRERENI6k8cD65dPZtp/vZnuaLnMoIyIiojEkjZP0deAhYArwfeBBSV8vtxGKDkhBGREREU3yDWA1YKLtrWxvCawHrAJ8s6sta7AMeUdERERjSLob2ND9CpxylfcdtjfoTsuaLT2UERER0STuX0yWF+cD6UXrkBSUERER0SS3S9qr/0VJ/wjc0YX2jAoZ8o6IiIjGkPQ64CJgLjC1vDwJWBZ4v+0/dqttTZaCMiIiIhpH0juATcunt9u+tt/rq9r+c/0ta6YUlBERETHqSJpWrgCPCmQOZURERIxGGvqXxJJKQRkRERGjUYZoK5SCMiIiIiKGJQVlREREjEYZ8q5QFuVEREREI0laFXg9MK51zfa08rXVbD/ZrbY1TQrKiIiIaBxJRwH7AH9g4XxJ235H1xrVYCkoIyIionEk3QlsZvvFbrdlNMgcyoiIiGiiWcAq3W7EaJEeyoiIiGgcSZOASygKyxda123v0rVGNdi4oX9JRERERM+ZAhwLzAT6utyWxksPZURERDSOpJttb93tdowWKSgjIiKicSR9i2Ko+1IWHfKe1rVGNVgKyoiIiGgcST8f4HK2DeqQFJQRERERMSzZNigiIiIaR9LKkr4l6Zby6zhJK3e7XU2VgjIiIiKa6AxgDvDB8usZ4MyutqjBMuQdERERjSNphu0throW1UgPZURERDTRXEk7tJ5I2h6Y28X2NFp6KCMiIqJxJG1Bsbn5yoCAJ4G9bd/W1YY1VArKiIiIaCxJKwHYfqbbbWmyDHlHRERE47RWeQM/A36WVd6dlYIyIiIimiirvGuUIe+IiIhonKzyrld6KCMiIqKJssq7RumhjIiIiMbJKu96paCMiIiIxmqt8gaeBT5s++xutqepMuQdERERjSFpJUlfkHSSpHdRLMzZC5hNsTgnOiA9lBEREdEYki4B/gz8GpgMTKAY8v5X2zO62bYmS0EZERERjSFppu3NysdjgUeAN9h+vrsta7YMeUdERESTzGs9sD0feCjFZOelhzIiIiIaQ9J8igU4UAx1Lws8Vz627ZUG+73x6qWgjIiIiIhhyZB3RERERAxLCsqIiIiIGJYUlBERERExLCkoIyIiImJYUlBGRERExLD8fyJZhlA1cWOuAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cormat = df.corr()\n",
        "round(cormat,2)\n",
        "f, ax = plt.subplots(figsize=(10, 7))\n",
        "sns.heatmap(cormat, annot= True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beYUzf3tHsRi"
      },
      "source": [
        "cols = ['S3_Temp', 'S4_Temp', 'S1_Light', 'S5_CO2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "95_D4XUJfYph"
      },
      "outputs": [],
      "source": [
        "cols = ['S3_Temp', 'S4_Temp', 'S1_Light', 'S5_CO2']\n",
        "df1 = df.copy()\n",
        "df1.drop(columns = cols, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-IAmGZvgAqC"
      },
      "source": [
        "### Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "075164df"
      },
      "outputs": [],
      "source": [
        "from pandas.core.common import random_state\n",
        "class Preprocessor:\n",
        "\n",
        "  def __init__(self, df, stnd = True, drop_corr = True, corr_cols =[], n=1000,\n",
        "               undersample = True, oversample = True, encode_y = True, unskew = False, ) -> None:\n",
        "    self.df = df\n",
        "    self.stnd = stnd\n",
        "    self.mean = None\n",
        "    self.std = None\n",
        "    self.drop_corr = drop_corr\n",
        "    self.corr_cols = corr_cols\n",
        "    self.undersample = undersample\n",
        "    self.n = n\n",
        "    self.oversample = oversample\n",
        "    self.encode_y = encode_y\n",
        "    self.unskew = unskew\n",
        "\n",
        "  def undersample_0(self):\n",
        "    df = pd.concat([self.X_train, self.y_train], axis=1)\n",
        "    temp1 = df[df['Room_Occupancy_Count'] == 0]\n",
        "    temp2 = df[df['Room_Occupancy_Count'] != 0]\n",
        "\n",
        "    temp1 = temp1.sample(self.n, replace=True, random_state=0)\n",
        "    #print(temp1.shape, temp2.shape)\n",
        "    df = pd.concat([temp1, temp2], ignore_index=True)\n",
        "    #print(self.df.shape)\n",
        "    self.y_train = df['Room_Occupancy_Count']\n",
        "    self.X_train = df.loc[:, df.columns!='Room_Occupancy_Count']\n",
        "\n",
        "  def oversample_123(self):\n",
        "    sm= SMOTE(random_state=42)\n",
        "    self.X_train, self.y_train = sm.fit_resample(self.X_train, self.y_train)\n",
        "\n",
        "  def data_split(self, df):\n",
        "    self.y = df['Room_Occupancy_Count']\n",
        "    self.X = df.loc[:, df.columns!='Room_Occupancy_Count']\n",
        "    X_tv, X_test, y_tv, y_test = train_test_split(self.X, self.y, test_size = 0.25,\n",
        "                                                  random_state= 0, stratify= self.y)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, \n",
        "                                                      test_size = 0.2, \n",
        "                                                      random_state= 0,\n",
        "                                                      stratify= y_tv)\n",
        "    self.X_train = pd.DataFrame(X_train)\n",
        "    self.X_val = pd.DataFrame(X_val)\n",
        "    self.X_test = pd.DataFrame(X_test)\n",
        "    self.y_train = pd.DataFrame(y_train)\n",
        "    self.y_val = pd.DataFrame(y_val)\n",
        "    self.y_test = pd.DataFrame(y_test)\n",
        "  \n",
        "  def fix_skew(self):\n",
        "    self.df['S1_Sound'], _ = stats.boxcox((1+self.df['S1_Sound']))\n",
        "    self.df['S2_Sound'], _ = stats.boxcox((1+self.df['S2_Sound']))\n",
        "    self.df['S3_Sound'], _ = stats.boxcox((1+self.df['S3_Sound']))\n",
        "    self.df['S4_Sound'], _ = stats.boxcox((1+self.df['S4_Sound']))\n",
        "\n",
        "  def standardize_data(self):\n",
        "    for column in self.X_train:\n",
        "      if column in numerical_cols:\n",
        "        self.mean = np.mean(self.X_train[column],0)\n",
        "        self.std = np.std(self.X_train[column],0)\n",
        "        self.X_train[column] = (self.X_train[column]-self.mean)/self.std\n",
        "        self.X_test[column] = (self.X_test[column]-self.mean)/self.std\n",
        "        self.X_val[column] = (self.X_val[column]-self.mean)/self.std\n",
        "\n",
        "  def fix_collinearity(self):\n",
        "    self.X_train.drop(columns= self.corr_cols)\n",
        "    self.X_val.drop(columns= self.corr_cols)\n",
        "    self.X_test.drop(columns= self.corr_cols)\n",
        "  \n",
        "  def encode(self):\n",
        "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
        "\n",
        "    self.y_train = enc.fit_transform(self.y_train.values.reshape(len(self.y_train), -1))\n",
        "    self.y_test = enc.transform(self.y_test.values.reshape(len(self.y_test), -1))\n",
        "    self.y_val = enc.transform(self.y_val.values.reshape(len(self.y_val), -1))\n",
        "\n",
        "  def preprocess(self):\n",
        "\n",
        "    if(self.unskew):\n",
        "      self.fix_skew()\n",
        "    self.data_split(self.df)\n",
        "    if (self.undersample):\n",
        "      print(\"undersampling\")\n",
        "      self.undersample_0()\n",
        "    if (self.oversample):\n",
        "      print(\"oversampling\")\n",
        "      self.oversample_123()\n",
        "    if (self.stnd):\n",
        "      print('standardize')\n",
        "      self.standardize_data()\n",
        "    if (self.drop_corr):\n",
        "      print(\"dropping correlated columns\")\n",
        "      self.fix_collinearity\n",
        "    if (self.encode_y):\n",
        "      self.encode()\n",
        "    \n",
        "    colnames = ['S1_Temp', 'S2_Temp', 'S3_Temp', 'S4_Temp', 'S1_Light', 'S2_Light',\n",
        "       'S3_Light', 'S4_Light', 'S1_Sound', 'S2_Sound', 'S3_Sound',\n",
        "       'S4_Sound', 'S5_CO2', 'S5_CO2_Slope', 'S6_PIR', 'S7_PIR', 'day_time']\n",
        "    \n",
        "    self.X_train.columns = colnames\n",
        "    self.X_test.columns = colnames\n",
        "    self.X_val.columns = colnames\n",
        "    self.y_train = pd.DataFrame(self.y_train)\n",
        "    self.y_val = pd.DataFrame(self.y_val)\n",
        "    self.y_test = pd.DataFrame(self.y_test)\n",
        "\n",
        "    return self.X_train, self.X_val, self.X_test, self.y_train, self.y_val, self.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KIoqVmbXQosl"
      },
      "outputs": [],
      "source": [
        "correlated_columns = ['S3_Temp', 'S4_Temp', 'S1_Light', 'S5_CO2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lG7q4fEAREn_"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "df1['day_time'] = [1 if (date.hour >= 7 and date.hour <= 19) else 0 for date in df.Time]\n",
        "df1.drop(columns=['Time'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECLSgmNyBSiZ",
        "outputId": "d454ba74-81e3-473e-cab5-590d7d88dcfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersampling\n",
            "oversampling\n",
            "standardize\n",
            "dropping correlated columns\n",
            "(4000, 17) (1520, 17) (2533, 17) (4000, 4) (1520, 4) (2533, 4)\n"
          ]
        }
      ],
      "source": [
        "pp = Preprocessor(df1, corr_cols = correlated_columns)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pp.preprocess()\n",
        "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
        "#X_train, X_val, X_test, y_train, y_val, y_test = pp.X_train, pp.X_val, pp.X_test, pp.y_train, pp.y_val, pp.y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXcBs8dwPVQw"
      },
      "source": [
        "### Skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tuO644AVPUhZ",
        "outputId": "5b3abcf8-4641-421a-c2ba-b9a5de2bc974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S1_Light\n",
            "S2_Light\n",
            "S3_Light\n",
            "S4_Light\n",
            "S1_Sound\n",
            "S2_Sound\n",
            "S3_Sound\n",
            "S4_Sound\n",
            "S5_CO2\n",
            "S5_CO2_Slope\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "for col in X_train:\n",
        "  if col in numerical_cols:\n",
        "    plt.figure()\n",
        "    print(col)\n",
        "    X_train[col].plot(kind = 'density')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yItvX_QkvOyd"
      },
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4nPdSCDE56WG",
        "outputId": "91cd5251-6889-47cb-e3aa-33273092fe03"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8YAAABkCAYAAABErSm5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaE0lEQVR4nO3df3Rc9Xnn8c9j/bABpzGSJRsbgmBdp03d1A0OazZZShLYtU1O63O6e7Y5cQzt6cH0BMfY/LAgNsY2P7xAYMFt8LKQxBxod0lK2p7EdjGkNEaKA3IwwmACEypA/oEt+acsy9LIz/6hubczVzOaGcme8Xjer3N0juZ+v/f7fXSvZu7zzL0z19xdAAAAAACUq1HFDgAAAAAAgGKiMAYAAAAAlDUKYwAAAABAWaMwBgAAAACUNQpjAAAAAEBZozAGAAAAAJS1ynw6jx8/3hsaGk5TKAAAAAAAnB7btm3rcPe6dG15FcYNDQ1qaWk5NVEBAAAAAFAgZvZBpjYupQYAAAAAlDUKYwAAAABAWcvrUmoAALJZu3atYrGYdu3apXHjxunJJ58sdkgAAABDojAGAJxSsVhM23fslPr7dPz48WKHAwAAkBWXUgMATrn+c2ukCt57BQAApYHCGAAAAABQ1iiMAQAAAABljcIYAAAAAFDWKIwBAAAAAGWNwhgAAAAAUNYojAEAAAAAZY3CGAAAAABQ1iiMAQAAAABljcIYADAia9eu1dq1a09ZPwAAgEKrLHYAAIDSFovFTmk/AACAQuOMMQAAAACgrFEYAwAAAADKGoUxAAAAAKCsURgDAAAAAMoahTEAAAAAoKxRGAMAAAAAytpZebumlpYW3X777XrwwQfV0NCglStXasWKFaqtrVVnZ6dWrlypb33rW3rsscfC5cmCPtF10vWNymX85L7Lli2TmWnJkiV67LHHdN111+muu+7SrbfeqoceekirVq3S+vXr044Ti8W0cOFCXXTRRbr99ttzmm/58uXq6enRnj17wvuJBmPcf//9kpQS05o1a7R7926tXr1aTz31lPr6+iRJVVVVWrJkiR544AF99NFHWrt2raZMmTJozlgspkWLFmnVqlV68sknZWZavXp1GGPytpWk5cuX68iRI9q9e7cWL16sdevWhdtg/vz5WrFihR599NFBc8ViMd10000yM61du1bnn3++Ghsb9eGHH4Z9Jk+eLEnas2ePbrvtNj300EOaPHmyli5dqocffljurltuuUUPP/ywuru7tW/fPt1444165JFHdMEFF6izs1Nmpvr6eu3bt081NTXas2eP3F1mpsrKSsXj8fDxpEmT1NHRIXdXb2+v5s2bp2eeeUZ1dXXav3+/zEx33XWXnnvuOXV3d+uDDz6QmammpkadnZ2aMGGCDh8+rP7+/nC7BxYsWKD169fL3dXf3694PK66ujodOnQopW9FRYX6+/vT/j8M1+kYE0MzM7l7Ttt+1KhROnnypCSF/5OF0tjYqDVr1mRsf+ONNyRJV111VYEiQjpVVVWDXlPKyZgxY9TT0xM+Dp4nwfPMzDRhwgR9/PHHqqioSHkO3XXXXXrqqae0a9cuSVJ1dbXq6+vV3t6u0aNHa+nSpXrwwQdVV1enjz/+WNLA8/fee+/V448/rvb2dp08eVIVFRW655579Pjjj2vXrl2qr6/X7t27w/0SxDRx4kQdOnRIkyZN0smTJ9Xe3q54PB6+FpiZFixYoHXr1qm6ulpmFh5H9u7dq+XLl+vHP/5xmJPMnz9fy5cvD49DF154oRYsWKAVK1aEx9p0+UuQrwSvP0H80Rzp4MGDWrRoUXicjh6bp0yZEuYi7h6OkU26daL5Q5C7rF69WpLCXOw73/nOoNyj0NLlkfnkloWIJ5e2Ups/21i5zjWSmAq5rYOcO12ePJLYJKXtl0/NUyoq7r777pw7P/HEE3ffcMMNpy+aU+SGG27QiRMn1NzcrCNHjmjLli3q6enRFVdcoXXr1mnLli1qbW3Vu+++Gy5PFvSJrpOub1Qu4yf3bWpq0v79+8P+TU1NOnbsmJqamsK/ob29Pe04S5YsUUdHhzo7O3Oe75VXXtHBgwcVj8fV2tqqn//85+EYJ06c0Pbt21Niev/999XX16fm5mbt2rVLBw4c0IEDB8L23/zmN+FYc+fOHTTnkiVLtH//fjU3N2v37t3av3+/Tpw4EcaYvG23b9+uV155RUeOHJG7a+vWrert7Q23QXNzs44dO5Z2rmBbBLHs3btXv/jFL9Tf3x/+HDx4MPzbg+174MABtba26r333lNHR0f4e1Bgbt26Ve6uo0ePhgXo4cOHFY/HdfTo0ZQYgmIkEKwTJBKtra2SpO7u7rBPU1OT9u3bp8OHD4fLjh8/Lkk6duyY4vH4oHEladu2bYrH4+rv7w/bu7u7B/V197T/CyNxOsZEbnLZ9sl90v3vnE7t7e26/vrrtWnTJu05eEyj+o6rurJCX//61yVJP/jBDwoaD9Ir9P/FmSb6ZlG67dHV1ZW2rampKeX1ur+/X0eOHAl/b2pqUm9vb/imZnDcaG5u1t69e8PX7eiyw4cPp8wV/N7V1aV4PK6DBw/q0KFD4fLk53lLS0s4fzD20aNH5e5qamrS3r17wxyhublZ3d3d4XHswIED4bE1ONamyyeCfKWzs1OdnZ3q6OgIj+XJx/Ef/vCHYX4wd+7cQcfmuXPnhrlI8hjZpFsnmj8EuUuQywS5WCwWG5R7FFq6PDKf3LIQ8eTSVmrzZxsr17lGElMht3WQc2fKyYcbW/B8ivbLp+Y5k6xcuXLP3Xff/US6trPuUuqWlpbwgNbV1aUNGzbI3bVp0ybFYjFt2rRJ7q62trZweWdnZ7h+Z2dn2Ce6TrRvVPK6mcZP7rtx48bwcdA/iD04cHd1daUdJxaLqa2tbdD6Q823adOmlGVtbW0pY2zYsEEbNmxIaQ8EcUXXT/49FoultCfHmLz+xo0bw4NrsL02btyYsj2kfz/wB9sgGCM6V7pt8dOf/nRQvMmSE6PouuliOF0KeTYPKITGxsa0yzlLjLNBttfsTO3pjqHplp1qwVVM0RwjXRzBsTaaT0TzlcDGjRtTcqQNGzaEx9C2tjb97Gc/G3R83bZtW0ouEuQDQ4nmL9F5o/nDhg0bUnKxfOY6HaJ5ZTT/yZZbFiKeXNpKbf5sY+U610hiKuS2Ts6F0+Xkw40teH5F++VT85SSs64wjp4BDw5S/f39uueeewa9+9vf36+nn346fLx+/fqwT3SdaN+o5HUzjZ/cN5+iKDrOPffck1O/5PmyXTrX19c3okItGlOmGPv6+vT000+nbK++vr68Lu1LHjvdPFzqCxTH1q1bFYvFNKrniHSyX8ePH9eiRYuKHRaAPAX5RKZ8pa+vLyVHih7D77vvvkHrrFixIqVfkA8MJZq/pJs32p4un8hlrtMhmldG859suWUh4smlrdTmzzZWrnONJKZCbutcc/B8Y0uuDZL75VPzlJKshbGZ3WBmLWbWsn///kLENCKZ3oGNx+Nqa2sb9OIej8e1efPm8PGLL74Y9omuE+0blbxupvGT++ZzNjI6TvTM5qmebziiMWWK0d21efPmlO2Vb2xDneUFAAAjE+QTmfKH4ExRpjfU0y0PzkonjzFUXiUNzl+i82aKLd2ybHOdDtG8Mpr/ZMstCxFPLm2lNn+2sXKdayQxFXJb55qD5xubu4fPp+R++dQ8pSRrYezuT7j7DHefUVdXV4iYRmTs2LFpl1dWVqqhoUGVlZWDll9zzTXh46uvvjrsE10n2jcqed1M4yf3NbPc/qg04zQ0NOTUb7jzDUc0pkwxmpmuueaalO2Vb2zJY2eaB0BxTJkyRSfH/JY0qkLnnHOOHn300WKHBCBPQT6RKX8ws7R5VfL6UWPHjk0ZK8gHhhKdPzpvptjSLcs21+kQzSuj+U+23LIQ8eTSVmrzZxsr17lGElMht3WuOXi+sQVf6Bftl0/NU0rO+kupg51WUVGhZcuWadSo1D+5oqJC8+fPDx9fd911YZ/oOtG+UcnrZho/uW+mg0k60XGWLVuWU7/k+aqqqoaco6qqKq+YoqIxZYqxqqpK8+fPT9leVVVVWePLNHa6eSoqKnIeC8CpM3PmzGKHAOAUCPKJTPlKVVVVSo4UPYbfeeedg9ZZuXJlSr8gHxhKNH9JN2+0PV0+kctcp0M0r4zmP9lyy0LEk0tbqc2fbaxc5xpJTIXc1rnm4PnGllwbJPfLp+YpJWddYTxjxozwrPHYsWM1Z84cmZlmzZqlKVOmaNasWeG7jcHy5K8Wr62tDftE14n2jUpeN9P4yX1nz54dPg76B7EH/4TBu6vRcaZMmTLorGm2+WbNmpWyrKGhIWWMOXPmaM6cOSntgXRn4qPzR78aPjnG5PVnz56t2tralO01e/bslO0h/fs7vsE2CMaIzpVuW1x77bWD4k2WfJAf6uzz6T7LPpI3IoAzUabbNb388suFDQQ4DbK9ZmdqT3cMzXSF26lUWVmZkpMMFUdwrI3mE9F8JTB79uyUHGnOnDnhMbShoUFf/vKXBx1fL7vsspRcJMgHhhLNX6LzRvOHOXPmpORi+cx1OkTzymj+ky23LEQ8ubSV2vzZxsp1rpHEVMhtnZwLp8vJhxtb8PyK9sun5iklZ+XtmqZOnaoXX3xR9913n6666irt3LlTixYt0rnnnqupU6dq586duu2229TW1hYuj66fbp10fdPNnW385L5vvvmm6uvrtXTpUrW1tenmm29WU1OTGhsb1dLSolWrVmnPnj1px5k2bZo2b96sSy+9VHfccUdO8+3YsUOf+MQn1NPTozVr1ujKK68Mx7jllls0ffr0lJjefvtt9fT0aNWqVWpvb9e4ceNUW1uriRMnaunSpXrnnXfU3d2tNWvWqKamZtCc06ZN00svvaRVq1bpo48+Un19vRYvXhzGmLxtp0+frh07dmj06NHq6urSkiVL1NramrINmpqadP/99w+aa9q0aXrhhRdUVVWlNWvWaObMmXr99dd17NgxVVZWqrKyUhdffLHOP/989fT0qLGxUa+99poaGhp05513KhaLafz48WpsbFQsFtN5552n3t5eLVy4UFu3btWkSZPU29urqqoqTZo0SSdOnFB9fX34mXYzU1VVVfg5DDPT5MmT1dvbG95vct68eWptbVVdXZ26u7tlZlq+fLn27dun8847T4cPH5aZqba2VsePH9eECRPC+1RGv+BgwYIFeuutt1RRURG219XVqa+vL6VvRUXFKf9s+ekYE0ML3qDJZduPGjUq7FNZWVnQW/PMnDlTV199NbdrOsNVVVWV9S2bxowZk/LZuOB5EjzPzEwTJ04Mjx/J22rZsmWKxWLh7fqqq6t1wQUX6MiRIxo9erTuuOMOvfrqq5o0aZJ6enpUWVmpqqoqrV69Wu+//766u7s1atQoVVdXh8uOHz+uyZMnp9xyL5h34sSJisfj+tSnPqVPfvKT6urqCu+DHNxz+cYbb1RLS4uqq6vD+err63Xs2DEtW7ZMBw4cSMlJtmzZEh7TLrnkEt16661qamoKj7Xp8pcgX6mpqVFtbW3KsTz5OH755ZfrpZdeCo/T0WNzTU1NmIuMHz8+JR8YSrp1ovlDkLssXrxY06dPD3Ox9957b1DuUWjp8sh8cstCxJNLW6nNn22sXOcaSUyF3NZBzp0uTx5JbMHzKdovn5rnTDLU7ZosnwR3xowZHtwvDwAASeG3TgefJV60aJG2vf+xKro7NXZMdXj7tGg/AACAQjKzbe4+I13bWXcpNQAAAAAA+aAwBgAAAACUNQpjAAAAAEBZozAGAAAAAJQ1CmMAAAAAQFnjJqoAgBHJdr/EfPsBAAAUGoUxAGBEFi5ceEr7AQAAFBqXUgMAAAAAyhqFMQAAAACgrFEYAwAAAADKGoUxAAAAAKCsURgDAAAAAMoahTEAAAAAoKxRGAMAAAAAyhqFMQDglKvoPiD1x4sdBgAAQE4qix0AAODsMmXKFEnSrl27NG7cuCJHAwAAkB2FMQDglFq4cGGxQwAAAMgLl1IDAAAAAMoahTEAAAAAoKxRGAMAAAAAyhqFMQAAAACgrJm7597ZbL+kD05fOGec8ZI6ih0Eho39V/rYh6WPfVj62Ielj31Y+tiHpY99eGa42N3r0jXkVRiXGzNrcfcZxY4Dw8P+K33sw9LHPix97MPSxz4sfezD0sc+PPNxKTUAAAAAoKxRGAMAAAAAyhqF8dCeKHYAGBH2X+ljH5Y+9mHpYx+WPvZh6WMflj724RmOzxgDAAAAAMoaZ4wBAAAAAGWNwhgAAAAAUNYojLMws4Vm9o6ZvWVmDxQ7HgyPmd1iZm5m44sdC/JjZg8mnoOtZvZjMxtX7JiQGzObZWa/NrOYmTUWOx7kx8wuMrN/MbO3E8fARcWOCfkzswoze93MflLsWJA/MxtnZj9KHAd3mtkVxY4J+TGzxYnX0B1m9ndmNqbYMSE9CuMhmNmXJP2JpD9w99+T9FCRQ8IwmNlFkv6LpA+LHQuGZbOkae7+WUnvSrqjyPEgB2ZWIelvJM2W9BlJXzOzzxQ3KuQpLukWd/+MpJmSvsk+LEmLJO0sdhAYtkclbXL335H0B2JflhQzmyzpW5JmuPs0SRWS/qy4USETCuOh/ZWkNe5+QpLcfV+R48HwPCLpdkl801wJcvcX3D2eeLhV0oXFjAc5u1xSzN3fd/deSf9XA280okS4+x53/1Xi96MaSMgnFzcq5MPMLpR0raQnix0L8mdmn5R0paSnJMnde939UHGjwjBUSjrHzColnStpd5HjQQYUxkObKuk/m9kvzexfzezzxQ4I+TGzP5G0y93fKHYsOCX+QtLGYgeBnEyW9FHS43ZRVJUsM2uQ9IeSflncSJCn/6WBN4ZPFjsQDMslkvZL+n7icvgnzey8YgeF3Ln7Lg1ccfqhpD2SDrv7C8WNCplUFjuAYjOzFyVNTNP0bQ1snxoNXEL2eUnPmdmlzj2uzihZ9uGdGriMGmewofahu/9jos+3NXBp57OFjA0od2Y2VtLfS7rZ3Y8UOx7kxsy+Kmmfu28zs6uKHQ+GpVLS5yQtdPdfmtmjkholLS9uWMiVmZ2vgaulLpF0SNIPzWyeuz9T3MiQTtkXxu5+daY2M/srSc8nCuFXzeykpPEaePcOZ4hM+9DMfl8DL0RvmJk0cAnur8zscnffW8AQkcVQz0NJMrPrJX1V0ld4Y6pk7JJ0UdLjCxPLUELMrEoDRfGz7v58seNBXr4g6Y/NbI6kMZJ+y8yecfd5RY4LuWuX1O7uwZUaP9JAYYzScbWkf3P3/ZJkZs9L+k+SKIzPQFxKPbR/kPQlSTKzqZKqJXUUNSLkzN3fdPd6d29w9wYNHGA+R1FcWsxslgYuBfxjd+8udjzI2WuSftvMLjGzag182cg/FTkm5MEG3lF8StJOd3+42PEgP+5+h7tfmDj+/Zmkn1EUl5ZEvvKRmX06segrkt4uYkjI34eSZprZuYnX1K+IL1A7Y5X9GeMsvifpe2a2Q1KvpOs4WwUU3F9LGi1pc+LM/1Z3v7G4ISEbd4+b2U2S/lkD38L5PXd/q8hhIT9fkPQNSW+a2fbEsjvdfUMRYwLKzUJJzybeYHxf0p8XOR7kIXEJ/I8k/UoDHwd7XdITxY0KmRh1HgAAAACgnHEpNQAAAACgrFEYAwAAAADKGoUxAAAAAKCsURgDAAAAAMoahTEAAAAAoKxRGAMAyp6ZfdvM3jKzVjPbbmb/0cx+YGb/lni83cymZxljtpm1mNnbZva6mX0nqe0GM3sn8fOqmX0xqe1ZM/u1me0ws++ZWdUQc0wws5+Y2RuJeTYkljckbi0IAACGgfsYAwDKmpldIemrkj7n7ifMbLyk6kTzbe7+oxzGmKaBe25f6+7vmFmFpBsSbV+VtEDSF929w8w+J+kfzOxyd98r6VlJ8xJD/a2kv5T0eIapVkna7O6PJsb+7DD+ZAAAEMEZYwBAubtAUoe7n5Akd+9w9915jnG7pHvd/Z3EGP3uHhS3SzVQYHck2n4lab2kbyYeb/AESa9KujBLrO3BA3dvjXYwszFm9n0zezNx5vpLieXXm9k/mtnLZvaema1IWmde4kz2djP734nCHgCAskFhDAAody9IusjM3jWz75rZHyW13Zu4vPoRMxs9xBjTJG3L0PZ7adpaEstDiUuovyFp0xDz/I2kp8zsXxKXf09K0+ebktzdf1/S1yStN7MxibbLJf2ppM9K+u9mNsPMflfS/5D0BXefLqlf0teHiAEAgLMOhTEAoKy5e5ekyzRw6fN+Sf/PzK6XdIek35H0eUk1Gjjzezp9V9LP3X3LELH+s6RLJf2fRGyvm1ldpNsXJT2T6P+OpA8kTU20bXb3Tnc/Lun5RN+vaODvf83MticeX3rK/ioAAEoAhTEAoOwlLn1+2d1XSLpJ0p+6+57EFc4nJH1fA2dbM3lLA8VlOm+nabsssY4kKXFZc52kJTnEesDd/9bdvyHpNUlXZlsnefU0j03Senefnvj5tLvfnceYAACUPApjAEBZM7NPm9lvJy2aLukDM7sg0W6S5koa6lufH5R0p5lNTawzysxuTLQ9IOl/mlltom26pOs1cIZYZvaXkv6rpK+5+8kssX7ZzM5N/P4JSf9B0oeRbluUuBQ6Ec+nJP060XaNmdWY2TmJv6lJ0kuS/puZ1SfWqTGzi4eKAwCAsw3fSg0AKHdjJa01s3GS4pJiGris+rnEZcomabukGzMN4O6tZnazpL9LFK4u6SeJtn8ys8mSms3MJR2VNM/d9yRWX6eBy51/MVCD63l3X5Vhqssk/bWZxTXw5vaT7v6amTUk9fmupMfN7M3E33N94tu2pYEv9/p7DXzB1zPu3iJJZrZM0gtmNkpSnwY+p/xB9k0HAMDZwQa+BBMAAJzNEp+bnuHuNxU7FgAAzjRcSg0AAAAAKGucMQYAIEdm9ueSFkUWN7n7N0txHgAAMIDCGAAAAABQ1riUGgAAAABQ1iiMAQAAAABljcIYAAAAAFDWKIwBAAAAAGWNwhgAAAAAUNb+P7rQV6MX8fsFAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1224x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "for column in df1:\n",
        "        plt.figure(figsize=(17,1))\n",
        "        sns.boxplot(data=df1, x=column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgbSOcEcKDFG"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(df1,column):\n",
        "  if column in numerical_cols:\n",
        "    percentile75 = np.percentile(df1[column], 75)\n",
        "    percentile25 = np.percentile(df1[column], 25) \n",
        "    iqr = percentile75 - percentile25\n",
        "\n",
        "    df1 = df1[df1[column] < percentile25 - 1.8*iqr]\n",
        "    df1 = df1[df1[column] > percentile75+1.8*iqr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Q4MUEKKF_d"
      },
      "outputs": [],
      "source": [
        "df1 = X_train.copy()\n",
        "for col in df1:\n",
        "  remove_outliers(df1,col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzVuTgLLgLe9"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRM2q8SttGvm"
      },
      "outputs": [],
      "source": [
        "class PCA():\n",
        "\n",
        "  def __init__(self, df,undersample = True, n=1000, oversample=True, encode_y = True,) -> None:\n",
        "    self.df = df\n",
        "    self.n = n\n",
        "    self.undersample = undersample\n",
        "    self.oversample = oversample\n",
        "    self.encode_y = encode_y\n",
        "    self.n_components = None\n",
        "    self.components = None\n",
        "    self.eigenvectors = None\n",
        "\n",
        "  def undersample_0(self):\n",
        "    df = pd.concat([self.X_train, self.y_train], axis=1)\n",
        "    temp1 = df[df['Room_Occupancy_Count'] == 0]\n",
        "    temp2 = df[df['Room_Occupancy_Count'] != 0]\n",
        "\n",
        "    temp1 = temp1.sample(self.n, replace=True, random_state=0)\n",
        "    #print(temp1.shape, temp2.shape)\n",
        "    df = pd.concat([temp1, temp2], ignore_index=True)\n",
        "    #print(self.df.shape)\n",
        "    self.y_train = df['Room_Occupancy_Count']\n",
        "    self.X_train = df.loc[:, df.columns!='Room_Occupancy_Count']\n",
        "\n",
        "  def oversample_123(self):\n",
        "    sm= SMOTE(random_state=42)\n",
        "    self.X_train, self.y_train = sm.fit_resample(self.X_train, self.y_train)\n",
        "\n",
        "  def data_split(self, df):\n",
        "    self.y = df['Room_Occupancy_Count']\n",
        "    self.X = df.loc[:, df.columns!='Room_Occupancy_Count']\n",
        "    X_tv, X_test, y_tv, y_test = train_test_split(self.X, self.y, test_size = 0.25,\n",
        "                                                  random_state= 0, stratify= self.y)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size = 0.2, \n",
        "                                                      random_state= 0, stratify= y_tv)\n",
        "    self.X_train = pd.DataFrame(X_train)\n",
        "    self.X_val = pd.DataFrame(X_val)\n",
        "    self.X_test = pd.DataFrame(X_test)\n",
        "    self.y_train = pd.DataFrame(y_train)\n",
        "    self.y_val = pd.DataFrame(y_val)\n",
        "    self.y_test = pd.DataFrame(y_test)\n",
        "    \n",
        "  def standardize_data(self):\n",
        "    temp = self.X_train\n",
        "    for column in temp:\n",
        "      numerical_types = ['float64', 'int64']\n",
        "      if temp.dtypes[column] in numerical_types:\n",
        "        mean = np.mean(self.X_train[column],0)\n",
        "        std = np.std(self.X_train[column],0)\n",
        "        self.X_train[column] = (self.X_train[column]-mean)/std\n",
        "        self.X_test[column] = (self.X_test[column]-mean)/std\n",
        "        self.X_val[column] = (self.X_val[column]-mean)/std\n",
        "\n",
        "  def encode(self):\n",
        "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
        "\n",
        "    self.y_train = enc.fit_transform(self.y_train.values.reshape(len(self.y_train), -1))\n",
        "    self.y_test = enc.transform(self.y_test.values.reshape(len(self.y_test), -1))\n",
        "    self.y_val = enc.transform(self.y_val.values.reshape(len(self.y_val), -1))\n",
        "\n",
        "  def fit(self):\n",
        "    self.data_split(self.df)\n",
        "    if (self.undersample):\n",
        "      print(\"undersampling\")\n",
        "      self.undersample_0()\n",
        "    if (self.oversample):\n",
        "      print(\"undersampling\")\n",
        "      self.oversample_123()\n",
        "    if (self.encode_y):\n",
        "      self.encode()    \n",
        "    print('standardizing')\n",
        "    self.standardize_data()\n",
        "\n",
        "    #pca\n",
        "    cov = np.dot(self.X_train.T, self.X_train)\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
        "    P = eigenvectors\n",
        "    idx = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvalues = eigenvalues[idx].T\n",
        "    self.eigenvectors = eigenvectors[idx].T\n",
        "    cumsum = []\n",
        "    for i in range(len(eigenvalues)+1):\n",
        "      pc = eigenvalues[0: i]\n",
        "      cumsum.append(pc.sum()/eigenvalues.sum())\n",
        "      print(\"Variance captured by {} Principal Components is {}%\".format(i,pc.sum()/eigenvalues.sum()))\n",
        "  \n",
        "  def transform(self,n_components):\n",
        "    self.components = self.eigenvectors[0: n_components].T\n",
        "    self.X_train = pd.DataFrame(np.dot(self.X_train,self.components))\n",
        "    self.X_test = pd.DataFrame(np.dot(self.X_test,self.components))\n",
        "    self.X_val = pd.DataFrame(np.dot(self.X_val,self.components))\n",
        "    self.y_train = pd.DataFrame(self.y_train)\n",
        "    self.y_val = pd.DataFrame(self.y_val)\n",
        "    self.y_test = pd.DataFrame(self.y_test)\n",
        "    return self.X_train, self.X_val, self.X_test, self.y_train, self.y_val, self.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mYkP3ZTKoHc"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "df1['day_time'] = [1 if (date.hour >= 7 and date.hour <= 19) else 0 for date in df.Time]\n",
        "df1.drop(columns=['Time'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye_ovtYlb8GV",
        "outputId": "f75d022d-581b-4676-b987-c6a4bf20a767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersampling\n",
            "undersampling\n",
            "standardizing\n",
            "Variance captured by 0 Principal Components is 0.0%\n",
            "Variance captured by 1 Principal Components is 0.43371086015539445%\n",
            "Variance captured by 2 Principal Components is 0.5526946941013136%\n",
            "Variance captured by 3 Principal Components is 0.6474742134164487%\n",
            "Variance captured by 4 Principal Components is 0.7070257932630633%\n",
            "Variance captured by 5 Principal Components is 0.7561189536649479%\n",
            "Variance captured by 6 Principal Components is 0.8000864721417629%\n",
            "Variance captured by 7 Principal Components is 0.8373184192910686%\n",
            "Variance captured by 8 Principal Components is 0.8714181639891458%\n",
            "Variance captured by 9 Principal Components is 0.9026997594811724%\n",
            "Variance captured by 10 Principal Components is 0.9302432682001006%\n",
            "Variance captured by 11 Principal Components is 0.9495587526310967%\n",
            "Variance captured by 12 Principal Components is 0.967234473040188%\n",
            "Variance captured by 13 Principal Components is 0.98173560375804%\n",
            "Variance captured by 14 Principal Components is 0.9900267157260866%\n",
            "Variance captured by 15 Principal Components is 0.9952271664048942%\n",
            "Variance captured by 16 Principal Components is 0.9987953802516539%\n",
            "Variance captured by 17 Principal Components is 1.0%\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(df1,encode_y=False)\n",
        "pca.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfs3mNL1-_Cv",
        "outputId": "f3f51ce4-f341-4811-d50d-ff873e6ce276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4000, 6) (1520, 6) (2533, 6) (4000, 1) (1520, 1) (2533, 1)\n"
          ]
        }
      ],
      "source": [
        "X_pca_tr, X_pca_val, X_pca_test, y_pca_tr, y_pca_val, y_pca_test = pca.transform(n_components=6)\n",
        "print(X_pca_tr.shape, X_pca_val.shape, X_pca_test.shape, y_pca_tr.shape, y_pca_val.shape, y_pca_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaClAT78k5D7"
      },
      "source": [
        "# NEUral NetWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy0TYWIkkilV",
        "outputId": "68c56dbf-dc9c-4591-e95a-8fade9c59a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersampling\n",
            "oversampling\n",
            "standardize\n",
            "dropping correlated columns\n",
            "(4000, 17) (1520, 17) (2533, 17) (4000, 4) (1520, 4) (2533, 4)\n"
          ]
        }
      ],
      "source": [
        "pp = Preprocessor(df1, corr_cols = correlated_columns)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pp.preprocess()\n",
        "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
        "#X_train, X_val, X_test, y_train, y_val, y_test = pp.X_train, pp.X_val, pp.X_test, pp.y_train, pp.y_val, pp.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CxQ9j7GvCsam"
      },
      "outputs": [],
      "source": [
        "sm= SMOTE(random_state=42)\n",
        "X_val, y_val = sm.fit_resample(X_val.to_numpy(), y_val.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNpmNcH6hUSF",
        "outputId": "6deb47cb-7142-4d47-aa1a-c90333b3d2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tqdm in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tqdm) (4.64.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-tqdm) (2.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cssvI7wThKMk"
      },
      "outputs": [],
      "source": [
        "from keras_tqdm import TQDMNotebookCallback\n",
        "from numpy.random import seed\n",
        "from keras import regularizers\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSaQ-ptpOjiW"
      },
      "source": [
        "## testing with normal preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hCRJSdKGACdX",
        "outputId": "f2986880-325d-443f-9e0b-71020ceec385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.8661 - accuracy: 0.3610 - val_loss: 1.2884 - val_accuracy: 0.8077\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 1.1034 - accuracy: 0.5242 - val_loss: 1.2417 - val_accuracy: 0.8429\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 1.0454 - accuracy: 0.6572 - val_loss: 1.2055 - val_accuracy: 0.6802\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.9915 - accuracy: 0.6615 - val_loss: 1.1424 - val_accuracy: 0.8330\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.9411 - accuracy: 0.6630 - val_loss: 1.0909 - val_accuracy: 0.8504\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.6633 - val_loss: 1.0544 - val_accuracy: 0.7951\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.8407 - accuracy: 0.6875 - val_loss: 0.9839 - val_accuracy: 0.8733\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.7937 - accuracy: 0.7343 - val_loss: 0.9288 - val_accuracy: 0.8922\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.7499 - accuracy: 0.7598 - val_loss: 0.9001 - val_accuracy: 0.8737\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 10ms/step - loss: 0.7109 - accuracy: 0.7850 - val_loss: 0.8399 - val_accuracy: 0.9096\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.8248 - val_loss: 0.7706 - val_accuracy: 0.9246\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.8330 - val_loss: 0.7127 - val_accuracy: 0.9400\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8515 - val_loss: 0.6561 - val_accuracy: 0.9420\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.8602 - val_loss: 0.6167 - val_accuracy: 0.9471\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.8775 - val_loss: 0.5770 - val_accuracy: 0.9479\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8860 - val_loss: 0.5313 - val_accuracy: 0.9585\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8988 - val_loss: 0.5038 - val_accuracy: 0.9609\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.9095 - val_loss: 0.4667 - val_accuracy: 0.9621\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.9162 - val_loss: 0.4396 - val_accuracy: 0.9672\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.9260 - val_loss: 0.4088 - val_accuracy: 0.9657\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.9252 - val_loss: 0.3809 - val_accuracy: 0.9712\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.9345 - val_loss: 0.3769 - val_accuracy: 0.9704\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.9430 - val_loss: 0.3448 - val_accuracy: 0.9739\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9463 - val_loss: 0.3275 - val_accuracy: 0.9755\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9520 - val_loss: 0.3117 - val_accuracy: 0.9732\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9555 - val_loss: 0.2952 - val_accuracy: 0.9775\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9588 - val_loss: 0.2724 - val_accuracy: 0.9822\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9585 - val_loss: 0.2636 - val_accuracy: 0.9791\n",
            "Epoch 29/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9628 - val_loss: 0.2497 - val_accuracy: 0.9803\n",
            "Epoch 30/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9607 - val_loss: 0.2427 - val_accuracy: 0.9795\n",
            "Epoch 31/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9638 - val_loss: 0.2255 - val_accuracy: 0.9811\n",
            "Epoch 32/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9657 - val_loss: 0.2113 - val_accuracy: 0.9814\n",
            "Epoch 33/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9650 - val_loss: 0.1928 - val_accuracy: 0.9822\n",
            "Epoch 34/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9640 - val_loss: 0.1888 - val_accuracy: 0.9826\n",
            "Epoch 35/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9663 - val_loss: 0.1731 - val_accuracy: 0.9834\n",
            "Epoch 36/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9650 - val_loss: 0.1610 - val_accuracy: 0.9866\n",
            "Epoch 37/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9663 - val_loss: 0.1613 - val_accuracy: 0.9842\n",
            "Epoch 38/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9650 - val_loss: 0.1545 - val_accuracy: 0.9842\n",
            "Epoch 39/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9668 - val_loss: 0.1473 - val_accuracy: 0.9854\n",
            "Epoch 40/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9660 - val_loss: 0.1361 - val_accuracy: 0.9878\n",
            "Epoch 41/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9663 - val_loss: 0.1341 - val_accuracy: 0.9889\n",
            "Epoch 42/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9670 - val_loss: 0.1300 - val_accuracy: 0.9858\n",
            "Epoch 43/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9665 - val_loss: 0.1271 - val_accuracy: 0.9882\n",
            "Epoch 44/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9678 - val_loss: 0.1199 - val_accuracy: 0.9886\n",
            "Epoch 45/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9690 - val_loss: 0.1263 - val_accuracy: 0.9866\n",
            "Epoch 46/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9668 - val_loss: 0.1162 - val_accuracy: 0.9878\n",
            "Epoch 47/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9685 - val_loss: 0.1107 - val_accuracy: 0.9882\n",
            "Epoch 48/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9670 - val_loss: 0.1130 - val_accuracy: 0.9870\n",
            "Epoch 49/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9675 - val_loss: 0.1064 - val_accuracy: 0.9882\n",
            "Epoch 50/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9682 - val_loss: 0.1202 - val_accuracy: 0.9886\n",
            "Epoch 51/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9670 - val_loss: 0.1008 - val_accuracy: 0.9893\n",
            "Epoch 52/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9672 - val_loss: 0.1048 - val_accuracy: 0.9878\n",
            "Epoch 53/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9672 - val_loss: 0.1014 - val_accuracy: 0.9886\n",
            "Epoch 54/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9670 - val_loss: 0.0991 - val_accuracy: 0.9874\n",
            "Epoch 55/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9672 - val_loss: 0.1089 - val_accuracy: 0.9886\n",
            "Epoch 56/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9695 - val_loss: 0.0970 - val_accuracy: 0.9882\n",
            "Epoch 57/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9675 - val_loss: 0.1037 - val_accuracy: 0.9878\n",
            "Epoch 58/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9675 - val_loss: 0.0926 - val_accuracy: 0.9889\n",
            "Epoch 59/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9680 - val_loss: 0.0930 - val_accuracy: 0.9878\n",
            "Epoch 60/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9705 - val_loss: 0.0870 - val_accuracy: 0.9893\n",
            "Epoch 61/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9680 - val_loss: 0.0862 - val_accuracy: 0.9893\n",
            "Epoch 62/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9700 - val_loss: 0.0927 - val_accuracy: 0.9889\n",
            "Epoch 63/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9688 - val_loss: 0.0940 - val_accuracy: 0.9889\n",
            "Epoch 64/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9688 - val_loss: 0.0881 - val_accuracy: 0.9889\n",
            "Epoch 65/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9688 - val_loss: 0.0867 - val_accuracy: 0.9889\n",
            "Epoch 66/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9680 - val_loss: 0.0929 - val_accuracy: 0.9886\n",
            "Epoch 67/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9693 - val_loss: 0.0815 - val_accuracy: 0.9882\n",
            "Epoch 68/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9697 - val_loss: 0.0865 - val_accuracy: 0.9901\n",
            "Epoch 69/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 0.0808 - val_accuracy: 0.9886\n",
            "Epoch 70/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 0.0827 - val_accuracy: 0.9886\n",
            "Epoch 71/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 0.0869 - val_accuracy: 0.9893\n",
            "Epoch 72/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9682 - val_loss: 0.0944 - val_accuracy: 0.9886\n",
            "Epoch 73/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9690 - val_loss: 0.0823 - val_accuracy: 0.9886\n",
            "Epoch 74/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9682 - val_loss: 0.0814 - val_accuracy: 0.9889\n",
            "Epoch 75/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9678 - val_loss: 0.0814 - val_accuracy: 0.9889\n",
            "Epoch 76/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9693 - val_loss: 0.0881 - val_accuracy: 0.9893\n",
            "Epoch 77/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9705 - val_loss: 0.0771 - val_accuracy: 0.9909\n",
            "Epoch 78/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9675 - val_loss: 0.0916 - val_accuracy: 0.9901\n",
            "Epoch 79/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9682 - val_loss: 0.1129 - val_accuracy: 0.9822\n",
            "Epoch 80/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9690 - val_loss: 0.0864 - val_accuracy: 0.9905\n",
            "Epoch 81/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9720 - val_loss: 0.0815 - val_accuracy: 0.9909\n",
            "Epoch 82/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9700 - val_loss: 0.0785 - val_accuracy: 0.9901\n",
            "Epoch 83/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9710 - val_loss: 0.0937 - val_accuracy: 0.9901\n",
            "Epoch 84/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.0844 - val_accuracy: 0.9893\n",
            "Epoch 85/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9703 - val_loss: 0.0871 - val_accuracy: 0.9889\n",
            "Epoch 86/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0812 - val_accuracy: 0.9905\n",
            "Epoch 87/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9707 - val_loss: 0.0853 - val_accuracy: 0.9886\n",
            "Epoch 88/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9688 - val_loss: 0.0812 - val_accuracy: 0.9897\n",
            "Epoch 89/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9707 - val_loss: 0.0816 - val_accuracy: 0.9893\n",
            "Epoch 90/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9720 - val_loss: 0.0887 - val_accuracy: 0.9905\n",
            "Epoch 91/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9710 - val_loss: 0.0940 - val_accuracy: 0.9905\n",
            "Epoch 92/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9715 - val_loss: 0.0846 - val_accuracy: 0.9893\n",
            "Epoch 93/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.0917 - val_accuracy: 0.9901\n",
            "Epoch 94/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9715 - val_loss: 0.0851 - val_accuracy: 0.9893\n",
            "Epoch 95/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9707 - val_loss: 0.0837 - val_accuracy: 0.9909\n",
            "Epoch 96/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9722 - val_loss: 0.0845 - val_accuracy: 0.9901\n",
            "Epoch 97/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9715 - val_loss: 0.0886 - val_accuracy: 0.9897\n",
            "Epoch 98/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9725 - val_loss: 0.0941 - val_accuracy: 0.9913\n",
            "Epoch 99/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9690 - val_loss: 0.0834 - val_accuracy: 0.9893\n",
            "Epoch 100/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9720 - val_loss: 0.0884 - val_accuracy: 0.9893\n",
            "Epoch 101/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9732 - val_loss: 0.0866 - val_accuracy: 0.9893\n",
            "Epoch 102/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9740 - val_loss: 0.0833 - val_accuracy: 0.9893\n",
            "Epoch 103/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9712 - val_loss: 0.0842 - val_accuracy: 0.9889\n",
            "Epoch 104/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9735 - val_loss: 0.0842 - val_accuracy: 0.9897\n",
            "Epoch 105/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9722 - val_loss: 0.0815 - val_accuracy: 0.9913\n",
            "Epoch 106/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.0974 - val_accuracy: 0.9897\n",
            "Epoch 107/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9710 - val_loss: 0.0870 - val_accuracy: 0.9901\n",
            "Epoch 108/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9743 - val_loss: 0.1039 - val_accuracy: 0.9889\n",
            "Epoch 109/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.0948 - val_accuracy: 0.9905\n",
            "Epoch 110/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9735 - val_loss: 0.0862 - val_accuracy: 0.9901\n",
            "Epoch 111/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9720 - val_loss: 0.0857 - val_accuracy: 0.9897\n",
            "Epoch 112/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9735 - val_loss: 0.0904 - val_accuracy: 0.9901\n",
            "Epoch 113/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9730 - val_loss: 0.0867 - val_accuracy: 0.9901\n",
            "Epoch 114/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9743 - val_loss: 0.0876 - val_accuracy: 0.9893\n",
            "Epoch 115/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9732 - val_loss: 0.0833 - val_accuracy: 0.9909\n",
            "Epoch 116/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.1082 - val_accuracy: 0.9893\n",
            "Epoch 117/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9725 - val_loss: 0.1002 - val_accuracy: 0.9886\n",
            "Epoch 118/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 0.0933 - val_accuracy: 0.9897\n",
            "Epoch 119/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9735 - val_loss: 0.0943 - val_accuracy: 0.9897\n",
            "Epoch 120/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9758 - val_loss: 0.0872 - val_accuracy: 0.9897\n",
            "Epoch 121/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9718 - val_loss: 0.0972 - val_accuracy: 0.9889\n",
            "Epoch 122/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9735 - val_loss: 0.0975 - val_accuracy: 0.9893\n",
            "Epoch 123/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9747 - val_loss: 0.0930 - val_accuracy: 0.9897\n",
            "Epoch 124/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9750 - val_loss: 0.0946 - val_accuracy: 0.9893\n",
            "Epoch 125/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9735 - val_loss: 0.0939 - val_accuracy: 0.9905\n",
            "Epoch 126/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.0894 - val_accuracy: 0.9905\n",
            "Epoch 127/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.0897 - val_accuracy: 0.9897\n",
            "Epoch 128/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9762 - val_loss: 0.0929 - val_accuracy: 0.9901\n",
            "Epoch 129/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9745 - val_loss: 0.1071 - val_accuracy: 0.9905\n",
            "Epoch 130/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.0910 - val_accuracy: 0.9905\n",
            "Epoch 131/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9747 - val_loss: 0.0955 - val_accuracy: 0.9905\n",
            "Epoch 132/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9743 - val_loss: 0.1027 - val_accuracy: 0.9893\n",
            "Epoch 133/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 0.0934 - val_accuracy: 0.9913\n",
            "Epoch 134/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9740 - val_loss: 0.0952 - val_accuracy: 0.9893\n",
            "Epoch 135/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9747 - val_loss: 0.1051 - val_accuracy: 0.9897\n",
            "Epoch 136/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9732 - val_loss: 0.0982 - val_accuracy: 0.9889\n",
            "Epoch 137/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9750 - val_loss: 0.0964 - val_accuracy: 0.9905\n",
            "Epoch 138/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9758 - val_loss: 0.0994 - val_accuracy: 0.9897\n",
            "Epoch 139/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9743 - val_loss: 0.1020 - val_accuracy: 0.9897\n",
            "Epoch 140/200\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9755 - val_loss: 0.1120 - val_accuracy: 0.9901\n",
            "Epoch 141/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.1024 - val_accuracy: 0.9893\n",
            "Epoch 142/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9740 - val_loss: 0.0987 - val_accuracy: 0.9889\n",
            "Epoch 143/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9745 - val_loss: 0.0936 - val_accuracy: 0.9909\n",
            "Epoch 144/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9737 - val_loss: 0.0933 - val_accuracy: 0.9901\n",
            "Epoch 145/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9762 - val_loss: 0.0973 - val_accuracy: 0.9905\n",
            "Epoch 146/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9760 - val_loss: 0.1004 - val_accuracy: 0.9901\n",
            "Epoch 147/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.0978 - val_accuracy: 0.9897\n",
            "Epoch 148/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9747 - val_loss: 0.1006 - val_accuracy: 0.9909\n",
            "Epoch 149/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9745 - val_loss: 0.1014 - val_accuracy: 0.9893\n",
            "Epoch 150/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9758 - val_loss: 0.0942 - val_accuracy: 0.9905\n",
            "Epoch 151/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9758 - val_loss: 0.0991 - val_accuracy: 0.9901\n",
            "Epoch 152/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9755 - val_loss: 0.0997 - val_accuracy: 0.9897\n",
            "Epoch 153/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9755 - val_loss: 0.1033 - val_accuracy: 0.9893\n",
            "Epoch 154/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9758 - val_loss: 0.0984 - val_accuracy: 0.9897\n",
            "Epoch 155/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 0.0986 - val_accuracy: 0.9905\n",
            "Epoch 156/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9718 - val_loss: 0.0987 - val_accuracy: 0.9905\n",
            "Epoch 157/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0961 - val_accuracy: 0.9901\n",
            "Epoch 158/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9765 - val_loss: 0.0994 - val_accuracy: 0.9909\n",
            "Epoch 159/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9737 - val_loss: 0.1099 - val_accuracy: 0.9897\n",
            "Epoch 160/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9760 - val_loss: 0.1078 - val_accuracy: 0.9889\n",
            "Epoch 161/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9753 - val_loss: 0.1009 - val_accuracy: 0.9897\n",
            "Epoch 162/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9772 - val_loss: 0.1032 - val_accuracy: 0.9889\n",
            "Epoch 163/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9745 - val_loss: 0.0971 - val_accuracy: 0.9913\n",
            "Epoch 164/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.0984 - val_accuracy: 0.9913\n",
            "Epoch 165/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9753 - val_loss: 0.1000 - val_accuracy: 0.9909\n",
            "Epoch 166/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9755 - val_loss: 0.0956 - val_accuracy: 0.9917\n",
            "Epoch 167/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9740 - val_loss: 0.0994 - val_accuracy: 0.9905\n",
            "Epoch 168/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9750 - val_loss: 0.0948 - val_accuracy: 0.9917\n",
            "Epoch 169/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.0995 - val_accuracy: 0.9913\n",
            "Epoch 170/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9753 - val_loss: 0.0994 - val_accuracy: 0.9913\n",
            "Epoch 171/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9760 - val_loss: 0.1060 - val_accuracy: 0.9889\n",
            "Epoch 172/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9755 - val_loss: 0.1089 - val_accuracy: 0.9893\n",
            "Epoch 173/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9783 - val_loss: 0.0937 - val_accuracy: 0.9917\n",
            "Epoch 174/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9778 - val_loss: 0.1035 - val_accuracy: 0.9897\n",
            "Epoch 175/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9768 - val_loss: 0.1069 - val_accuracy: 0.9901\n",
            "Epoch 176/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9758 - val_loss: 0.1019 - val_accuracy: 0.9901\n",
            "Epoch 177/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9787 - val_loss: 0.1119 - val_accuracy: 0.9889\n",
            "Epoch 178/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.1056 - val_accuracy: 0.9905\n",
            "Epoch 179/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9760 - val_loss: 0.1045 - val_accuracy: 0.9897\n",
            "Epoch 180/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9770 - val_loss: 0.1181 - val_accuracy: 0.9897\n",
            "Epoch 181/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9753 - val_loss: 0.0967 - val_accuracy: 0.9901\n",
            "Epoch 182/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 0.0938 - val_accuracy: 0.9905\n",
            "Epoch 183/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9778 - val_loss: 0.1029 - val_accuracy: 0.9901\n",
            "Epoch 184/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9770 - val_loss: 0.1032 - val_accuracy: 0.9901\n",
            "Epoch 185/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9778 - val_loss: 0.1035 - val_accuracy: 0.9905\n",
            "Epoch 186/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.0981 - val_accuracy: 0.9901\n",
            "Epoch 187/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9745 - val_loss: 0.0992 - val_accuracy: 0.9897\n",
            "Epoch 188/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9783 - val_loss: 0.0985 - val_accuracy: 0.9897\n",
            "Epoch 189/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.1203 - val_accuracy: 0.9889\n",
            "Epoch 190/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9780 - val_loss: 0.1180 - val_accuracy: 0.9893\n",
            "Epoch 191/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9793 - val_loss: 0.1029 - val_accuracy: 0.9893\n",
            "Epoch 192/200\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.1082 - val_accuracy: 0.9893\n",
            "Epoch 193/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9765 - val_loss: 0.1026 - val_accuracy: 0.9893\n",
            "Epoch 194/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9783 - val_loss: 0.1040 - val_accuracy: 0.9913\n",
            "Epoch 195/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9753 - val_loss: 0.1149 - val_accuracy: 0.9905\n",
            "Epoch 196/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9793 - val_loss: 0.1064 - val_accuracy: 0.9897\n",
            "Epoch 197/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9775 - val_loss: 0.1060 - val_accuracy: 0.9905\n",
            "Epoch 198/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9780 - val_loss: 0.1266 - val_accuracy: 0.9882\n",
            "Epoch 199/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9768 - val_loss: 0.1040 - val_accuracy: 0.9897\n",
            "Epoch 200/200\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.1106 - val_accuracy: 0.9882\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9882\n",
            "Test accuracy: 0.9881563186645508\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9645\n",
            "Train accuracy: 0.9645000100135803\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f92dc65b5d0>]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed(1)\n",
        "\n",
        "layer1_shape = X_train.shape[1]\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(layer1_shape, input_dim = layer1_shape, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "Model = model.fit(X_train, y_train, epochs=200, batch_size=50,\n",
        "          validation_data = (X_test, y_test),\n",
        "          shuffle = True)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "test_loss, test_acc = model.evaluate(X_train, y_train)\n",
        "print('Train accuracy:', test_acc)\n",
        "\n",
        "train_loss = Model.history['loss']\n",
        "val_loss   = Model.history['val_loss']\n",
        "train_acc  = Model.history['accuracy']\n",
        "val_acc    = Model.history['val_accuracy']\n",
        "xc         = range(100)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xc, train_loss[0:100], color = 'blue', label='training loss')\n",
        "plt.plot(xc, val_loss[0:100], color = 'red', label='testing loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Y_wQaw-NkDWI",
        "outputId": "802bb579-b2c6-464b-e5cc-c9ab0f57c610"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f92f3720650>]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_loss = Model.history['loss']\n",
        "val_loss   = Model.history['val_loss']\n",
        "train_acc  = Model.history['accuracy']\n",
        "val_acc    = Model.history['val_accuracy']\n",
        "xc         = range(100)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xc, train_acc[0:100], color = 'blue', label='training acc')\n",
        "plt.plot(xc, val_acc[0:100], color = 'red', label='testing acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uAfc84NzjVY"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnMa3uiJh7pT",
        "outputId": "f96f31a1-3b09-4ed6-cadc-a63e00f41c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.9951 - accuracy: 0.4227 - val_loss: 1.9357 - val_accuracy: 0.8579\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2.1606 - accuracy: 0.5038 - val_loss: 1.6037 - val_accuracy: 0.8764\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.9974 - accuracy: 0.5153 - val_loss: 1.4502 - val_accuracy: 0.8579\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.8690 - accuracy: 0.4980 - val_loss: 1.4322 - val_accuracy: 0.8579\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.7678 - accuracy: 0.4972 - val_loss: 1.3293 - val_accuracy: 0.8595\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.6646 - accuracy: 0.4857 - val_loss: 1.1143 - val_accuracy: 0.8638\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.5651 - accuracy: 0.4935 - val_loss: 0.9597 - val_accuracy: 0.8851\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4853 - accuracy: 0.4963 - val_loss: 0.8810 - val_accuracy: 0.8851\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4096 - accuracy: 0.4963 - val_loss: 0.8564 - val_accuracy: 0.8863\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3479 - accuracy: 0.4970 - val_loss: 0.7658 - val_accuracy: 0.8851\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2941 - accuracy: 0.4805 - val_loss: 0.7042 - val_accuracy: 0.8512\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2517 - accuracy: 0.4885 - val_loss: 0.7538 - val_accuracy: 0.8891\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2288 - accuracy: 0.4885 - val_loss: 0.6363 - val_accuracy: 0.8460\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2078 - accuracy: 0.4820 - val_loss: 0.6303 - val_accuracy: 0.8523\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1964 - accuracy: 0.5005 - val_loss: 0.6123 - val_accuracy: 0.8808\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1916 - accuracy: 0.5058 - val_loss: 0.6670 - val_accuracy: 0.8883\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1877 - accuracy: 0.5017 - val_loss: 0.6235 - val_accuracy: 0.8906\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1796 - accuracy: 0.5217 - val_loss: 0.5953 - val_accuracy: 0.8934\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1847 - accuracy: 0.5240 - val_loss: 0.6508 - val_accuracy: 0.8974\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1796 - accuracy: 0.5458 - val_loss: 0.6210 - val_accuracy: 0.8902\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1719 - accuracy: 0.5817 - val_loss: 0.6548 - val_accuracy: 0.9025\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1622 - accuracy: 0.6043 - val_loss: 0.6576 - val_accuracy: 0.9262\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1416 - accuracy: 0.6960 - val_loss: 0.6255 - val_accuracy: 0.9230\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1231 - accuracy: 0.7337 - val_loss: 0.6595 - val_accuracy: 0.9234\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1147 - accuracy: 0.7250 - val_loss: 0.7228 - val_accuracy: 0.9159\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1011 - accuracy: 0.7287 - val_loss: 0.6523 - val_accuracy: 0.9143\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 1.0872 - accuracy: 0.7290 - val_loss: 0.7076 - val_accuracy: 0.9191\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0815 - accuracy: 0.7268 - val_loss: 0.6602 - val_accuracy: 0.9072\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0730 - accuracy: 0.7278 - val_loss: 0.7096 - val_accuracy: 0.9143\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.7170 - val_loss: 0.7044 - val_accuracy: 0.9155\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.7203 - val_loss: 0.6923 - val_accuracy: 0.9120\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.7193 - val_loss: 0.7313 - val_accuracy: 0.9116\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.7270 - val_loss: 0.7070 - val_accuracy: 0.9108\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0514 - accuracy: 0.7253 - val_loss: 0.7341 - val_accuracy: 0.9120\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.7220 - val_loss: 0.7179 - val_accuracy: 0.9112\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0485 - accuracy: 0.7235 - val_loss: 0.6970 - val_accuracy: 0.9092\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0493 - accuracy: 0.7225 - val_loss: 0.6982 - val_accuracy: 0.9100\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.7245 - val_loss: 0.7304 - val_accuracy: 0.9088\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.7258 - val_loss: 0.7231 - val_accuracy: 0.9068\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.7185 - val_loss: 0.6928 - val_accuracy: 0.9088\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.7195 - val_loss: 0.7978 - val_accuracy: 0.8788\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0432 - accuracy: 0.7265 - val_loss: 0.7031 - val_accuracy: 0.9088\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0424 - accuracy: 0.7190 - val_loss: 0.7165 - val_accuracy: 0.9084\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.7230 - val_loss: 0.8214 - val_accuracy: 0.8674\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.7237 - val_loss: 0.7925 - val_accuracy: 0.8824\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0378 - accuracy: 0.7220 - val_loss: 0.6890 - val_accuracy: 0.9001\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0379 - accuracy: 0.7197 - val_loss: 0.7161 - val_accuracy: 0.9049\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0340 - accuracy: 0.7243 - val_loss: 0.6916 - val_accuracy: 0.9100\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.7207 - val_loss: 0.8239 - val_accuracy: 0.8681\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0386 - accuracy: 0.7190 - val_loss: 0.8083 - val_accuracy: 0.8705\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.7220 - val_loss: 0.6947 - val_accuracy: 0.9088\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0337 - accuracy: 0.7220 - val_loss: 0.7019 - val_accuracy: 0.9076\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0356 - accuracy: 0.7165 - val_loss: 0.6832 - val_accuracy: 0.9068\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0374 - accuracy: 0.7212 - val_loss: 0.7604 - val_accuracy: 0.8950\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0318 - accuracy: 0.7207 - val_loss: 0.7448 - val_accuracy: 0.8974\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.7210 - val_loss: 0.8192 - val_accuracy: 0.8685\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0345 - accuracy: 0.7157 - val_loss: 0.7203 - val_accuracy: 0.9056\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.7160 - val_loss: 0.7593 - val_accuracy: 0.8918\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.7178 - val_loss: 0.7113 - val_accuracy: 0.9064\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0341 - accuracy: 0.7243 - val_loss: 0.8156 - val_accuracy: 0.8658\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.7060 - val_loss: 0.7456 - val_accuracy: 0.8997\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.7218 - val_loss: 0.6951 - val_accuracy: 0.9076\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0297 - accuracy: 0.7182 - val_loss: 0.7262 - val_accuracy: 0.8981\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0294 - accuracy: 0.7212 - val_loss: 0.7341 - val_accuracy: 0.9013\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0369 - accuracy: 0.7155 - val_loss: 0.8994 - val_accuracy: 0.8342\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.7207 - val_loss: 0.7203 - val_accuracy: 0.9025\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.7168 - val_loss: 0.7622 - val_accuracy: 0.8851\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0311 - accuracy: 0.7153 - val_loss: 0.7074 - val_accuracy: 0.9029\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.7128 - val_loss: 0.6969 - val_accuracy: 0.9017\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.7215 - val_loss: 0.7059 - val_accuracy: 0.9037\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.7200 - val_loss: 0.7461 - val_accuracy: 0.8950\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0332 - accuracy: 0.7075 - val_loss: 0.7065 - val_accuracy: 0.9060\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.7175 - val_loss: 0.7060 - val_accuracy: 0.9080\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0349 - accuracy: 0.7095 - val_loss: 0.6796 - val_accuracy: 0.8993\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.7117 - val_loss: 0.7079 - val_accuracy: 0.9056\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0321 - accuracy: 0.7185 - val_loss: 0.7564 - val_accuracy: 0.8930\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0266 - accuracy: 0.7185 - val_loss: 0.7786 - val_accuracy: 0.8733\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.7050 - val_loss: 0.7955 - val_accuracy: 0.8693\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.7145 - val_loss: 0.7472 - val_accuracy: 0.8958\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.7067 - val_loss: 0.6840 - val_accuracy: 0.8934\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.7170 - val_loss: 0.7106 - val_accuracy: 0.9041\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.7240 - val_loss: 0.7795 - val_accuracy: 0.8760\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0282 - accuracy: 0.7155 - val_loss: 0.7140 - val_accuracy: 0.9001\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0365 - accuracy: 0.7100 - val_loss: 0.7256 - val_accuracy: 0.9001\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0382 - accuracy: 0.7107 - val_loss: 0.7513 - val_accuracy: 0.8883\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.7138 - val_loss: 0.7785 - val_accuracy: 0.8741\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0331 - accuracy: 0.7140 - val_loss: 0.7062 - val_accuracy: 0.9068\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.7082 - val_loss: 0.6879 - val_accuracy: 0.8989\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.7212 - val_loss: 0.6867 - val_accuracy: 0.8962\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.7105 - val_loss: 0.6899 - val_accuracy: 0.9029\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.7110 - val_loss: 0.6845 - val_accuracy: 0.8946\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.7095 - val_loss: 0.7052 - val_accuracy: 0.8981\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.7082 - val_loss: 0.8583 - val_accuracy: 0.8520\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.7132 - val_loss: 0.7362 - val_accuracy: 0.8985\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0280 - accuracy: 0.7200 - val_loss: 0.7393 - val_accuracy: 0.8950\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0287 - accuracy: 0.7128 - val_loss: 0.7293 - val_accuracy: 0.8930\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0339 - accuracy: 0.7088 - val_loss: 0.7004 - val_accuracy: 0.9005\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.7157 - val_loss: 0.7010 - val_accuracy: 0.9053\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0283 - accuracy: 0.7090 - val_loss: 0.7347 - val_accuracy: 0.9001\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.7132 - val_loss: 0.8988 - val_accuracy: 0.8326\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.7050 - val_loss: 0.7292 - val_accuracy: 0.9001\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.7147 - val_loss: 0.7709 - val_accuracy: 0.8745\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0339 - accuracy: 0.7088 - val_loss: 0.6878 - val_accuracy: 0.9009\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0294 - accuracy: 0.7125 - val_loss: 0.7239 - val_accuracy: 0.9033\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.7145 - val_loss: 0.7268 - val_accuracy: 0.9013\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0342 - accuracy: 0.7140 - val_loss: 0.7796 - val_accuracy: 0.8721\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0313 - accuracy: 0.7097 - val_loss: 0.7741 - val_accuracy: 0.8776\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0330 - accuracy: 0.7085 - val_loss: 0.7224 - val_accuracy: 0.9013\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0333 - accuracy: 0.7120 - val_loss: 0.6880 - val_accuracy: 0.9013\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.7050 - val_loss: 0.7464 - val_accuracy: 0.8930\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0323 - accuracy: 0.7105 - val_loss: 0.6898 - val_accuracy: 0.8977\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0260 - accuracy: 0.7078 - val_loss: 0.7067 - val_accuracy: 0.9037\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0337 - accuracy: 0.7090 - val_loss: 0.7808 - val_accuracy: 0.8776\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0284 - accuracy: 0.7185 - val_loss: 0.7308 - val_accuracy: 0.9009\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.7110 - val_loss: 0.6987 - val_accuracy: 0.8962\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.7107 - val_loss: 0.7352 - val_accuracy: 0.8962\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.7140 - val_loss: 0.7009 - val_accuracy: 0.9068\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0229 - accuracy: 0.7117 - val_loss: 0.7569 - val_accuracy: 0.8891\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.7100 - val_loss: 0.7870 - val_accuracy: 0.8689\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0267 - accuracy: 0.7193 - val_loss: 0.7687 - val_accuracy: 0.8768\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0285 - accuracy: 0.7132 - val_loss: 0.7165 - val_accuracy: 0.8974\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.7097 - val_loss: 0.7783 - val_accuracy: 0.8741\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.0381 - accuracy: 0.7070 - val_loss: 0.6952 - val_accuracy: 0.9072\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0360 - accuracy: 0.7057 - val_loss: 0.7394 - val_accuracy: 0.8962\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0309 - accuracy: 0.7103 - val_loss: 0.7925 - val_accuracy: 0.8685\n",
            "--LR: 0.005\n",
            "--Epochs: 125\n",
            "--Reg params 0.05\n",
            "155/155 [==============================] - 1s 2ms/step - loss: 1.0298 - accuracy: 0.7300\n",
            "Val accuracy: 0.7299594879150391\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.7925 - accuracy: 0.8685\n",
            "Test accuracy: 0.8685353398323059\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.6922 - accuracy: 0.5970 - val_loss: 0.8287 - val_accuracy: 0.9238\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9302 - accuracy: 0.8752 - val_loss: 0.6590 - val_accuracy: 0.9739\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7674 - accuracy: 0.9323 - val_loss: 0.6288 - val_accuracy: 0.9735\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.9520 - val_loss: 0.5913 - val_accuracy: 0.9767\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.9523 - val_loss: 0.5738 - val_accuracy: 0.9803\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.9570 - val_loss: 0.5575 - val_accuracy: 0.9783\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.9588 - val_loss: 0.5045 - val_accuracy: 0.9834\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.9600 - val_loss: 0.5103 - val_accuracy: 0.9799\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.9607 - val_loss: 0.5164 - val_accuracy: 0.9787\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.9582 - val_loss: 0.4605 - val_accuracy: 0.9838\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.9595 - val_loss: 0.4343 - val_accuracy: 0.9826\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.9597 - val_loss: 0.4313 - val_accuracy: 0.9834\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.9585 - val_loss: 0.4256 - val_accuracy: 0.9842\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.9628 - val_loss: 0.4380 - val_accuracy: 0.9791\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.9607 - val_loss: 0.4034 - val_accuracy: 0.9818\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.9625 - val_loss: 0.3951 - val_accuracy: 0.9850\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.9635 - val_loss: 0.4536 - val_accuracy: 0.9799\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.9607 - val_loss: 0.3851 - val_accuracy: 0.9807\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.9610 - val_loss: 0.3734 - val_accuracy: 0.9834\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.9620 - val_loss: 0.3789 - val_accuracy: 0.9811\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.9638 - val_loss: 0.3557 - val_accuracy: 0.9838\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.9645 - val_loss: 0.3540 - val_accuracy: 0.9826\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.9617 - val_loss: 0.4374 - val_accuracy: 0.9771\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.9645 - val_loss: 0.3582 - val_accuracy: 0.9811\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.9620 - val_loss: 0.3562 - val_accuracy: 0.9811\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.9595 - val_loss: 0.3461 - val_accuracy: 0.9834\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.9610 - val_loss: 0.3426 - val_accuracy: 0.9846\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.9613 - val_loss: 0.3362 - val_accuracy: 0.9834\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.9613 - val_loss: 0.4190 - val_accuracy: 0.9791\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.9647 - val_loss: 0.3856 - val_accuracy: 0.9818\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.9635 - val_loss: 0.3461 - val_accuracy: 0.9846\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.9632 - val_loss: 0.3699 - val_accuracy: 0.9807\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.9632 - val_loss: 0.3421 - val_accuracy: 0.9814\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.9632 - val_loss: 0.3276 - val_accuracy: 0.9834\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.9620 - val_loss: 0.3262 - val_accuracy: 0.9842\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.9650 - val_loss: 0.3227 - val_accuracy: 0.9834\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.9653 - val_loss: 0.3253 - val_accuracy: 0.9850\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.9603 - val_loss: 0.3159 - val_accuracy: 0.9846\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.9617 - val_loss: 0.3276 - val_accuracy: 0.9811\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.9625 - val_loss: 0.3058 - val_accuracy: 0.9826\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.9622 - val_loss: 0.3428 - val_accuracy: 0.9783\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.9625 - val_loss: 0.3884 - val_accuracy: 0.9795\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.9645 - val_loss: 0.3161 - val_accuracy: 0.9814\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.9617 - val_loss: 0.3207 - val_accuracy: 0.9795\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.9622 - val_loss: 0.3431 - val_accuracy: 0.9822\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.9645 - val_loss: 0.2999 - val_accuracy: 0.9838\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.9607 - val_loss: 0.2963 - val_accuracy: 0.9838\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.9620 - val_loss: 0.3040 - val_accuracy: 0.9822\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.9617 - val_loss: 0.4627 - val_accuracy: 0.9739\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.9630 - val_loss: 0.3030 - val_accuracy: 0.9803\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.9615 - val_loss: 0.3219 - val_accuracy: 0.9787\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.9638 - val_loss: 0.2964 - val_accuracy: 0.9830\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.9615 - val_loss: 0.3141 - val_accuracy: 0.9822\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.9650 - val_loss: 0.2877 - val_accuracy: 0.9842\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.9610 - val_loss: 0.3047 - val_accuracy: 0.9830\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.9643 - val_loss: 0.3691 - val_accuracy: 0.9783\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.9545 - val_loss: 0.3077 - val_accuracy: 0.9803\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.9653 - val_loss: 0.2886 - val_accuracy: 0.9842\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.9650 - val_loss: 0.3016 - val_accuracy: 0.9807\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.9640 - val_loss: 0.2921 - val_accuracy: 0.9846\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.9647 - val_loss: 0.2847 - val_accuracy: 0.9842\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.9620 - val_loss: 0.3463 - val_accuracy: 0.9791\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.9645 - val_loss: 0.2865 - val_accuracy: 0.9838\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.9630 - val_loss: 0.3231 - val_accuracy: 0.9799\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.9605 - val_loss: 0.2836 - val_accuracy: 0.9838\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.9640 - val_loss: 0.2939 - val_accuracy: 0.9834\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.9643 - val_loss: 0.3535 - val_accuracy: 0.9787\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.9638 - val_loss: 0.2964 - val_accuracy: 0.9846\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.9665 - val_loss: 0.3005 - val_accuracy: 0.9822\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.9638 - val_loss: 0.3267 - val_accuracy: 0.9807\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.9605 - val_loss: 0.3468 - val_accuracy: 0.9763\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.9603 - val_loss: 0.2966 - val_accuracy: 0.9826\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.9653 - val_loss: 0.2928 - val_accuracy: 0.9854\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9665 - val_loss: 0.3577 - val_accuracy: 0.9799\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.9653 - val_loss: 0.3039 - val_accuracy: 0.9834\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.9635 - val_loss: 0.3719 - val_accuracy: 0.9783\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.9597 - val_loss: 0.3054 - val_accuracy: 0.9814\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.9660 - val_loss: 0.2894 - val_accuracy: 0.9846\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.9675 - val_loss: 0.3299 - val_accuracy: 0.9795\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.9668 - val_loss: 0.2879 - val_accuracy: 0.9854\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.9640 - val_loss: 0.2880 - val_accuracy: 0.9858\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.9620 - val_loss: 0.3201 - val_accuracy: 0.9803\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.9600 - val_loss: 0.2916 - val_accuracy: 0.9854\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.9640 - val_loss: 0.2792 - val_accuracy: 0.9854\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.9663 - val_loss: 0.2936 - val_accuracy: 0.9850\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.9615 - val_loss: 0.3075 - val_accuracy: 0.9811\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.9640 - val_loss: 0.3161 - val_accuracy: 0.9807\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.9640 - val_loss: 0.3100 - val_accuracy: 0.9811\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.9643 - val_loss: 0.3396 - val_accuracy: 0.9783\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.9632 - val_loss: 0.2917 - val_accuracy: 0.9850\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.9657 - val_loss: 0.2828 - val_accuracy: 0.9822\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.9650 - val_loss: 0.2966 - val_accuracy: 0.9834\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.9640 - val_loss: 0.3137 - val_accuracy: 0.9803\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.9607 - val_loss: 0.3210 - val_accuracy: 0.9822\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.9670 - val_loss: 0.2800 - val_accuracy: 0.9846\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.9635 - val_loss: 0.3726 - val_accuracy: 0.9787\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.9653 - val_loss: 0.3521 - val_accuracy: 0.9811\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.9675 - val_loss: 0.4159 - val_accuracy: 0.9763\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.9635 - val_loss: 0.2802 - val_accuracy: 0.9846\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.9640 - val_loss: 0.2740 - val_accuracy: 0.9850\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.9645 - val_loss: 0.3052 - val_accuracy: 0.9818\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.9682 - val_loss: 0.3041 - val_accuracy: 0.9818\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.9660 - val_loss: 0.2705 - val_accuracy: 0.9854\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.9665 - val_loss: 0.2740 - val_accuracy: 0.9826\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.9635 - val_loss: 0.2836 - val_accuracy: 0.9846\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.9632 - val_loss: 0.2851 - val_accuracy: 0.9787\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.9643 - val_loss: 0.2682 - val_accuracy: 0.9838\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.9672 - val_loss: 0.2833 - val_accuracy: 0.9854\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.9632 - val_loss: 0.2894 - val_accuracy: 0.9842\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.9675 - val_loss: 0.2773 - val_accuracy: 0.9854\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.9672 - val_loss: 0.2823 - val_accuracy: 0.9803\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.9607 - val_loss: 0.4329 - val_accuracy: 0.9743\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.9572 - val_loss: 0.2976 - val_accuracy: 0.9818\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.9657 - val_loss: 0.2685 - val_accuracy: 0.9846\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.9638 - val_loss: 0.2948 - val_accuracy: 0.9811\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.9688 - val_loss: 0.2866 - val_accuracy: 0.9850\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.9690 - val_loss: 0.2716 - val_accuracy: 0.9862\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.9653 - val_loss: 0.2831 - val_accuracy: 0.9830\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.9660 - val_loss: 0.2843 - val_accuracy: 0.9838\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.9650 - val_loss: 0.4175 - val_accuracy: 0.9787\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.9650 - val_loss: 0.2903 - val_accuracy: 0.9818\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.9685 - val_loss: 0.2853 - val_accuracy: 0.9846\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.9615 - val_loss: 0.2701 - val_accuracy: 0.9862\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.9672 - val_loss: 0.2743 - val_accuracy: 0.9858\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.9680 - val_loss: 0.2777 - val_accuracy: 0.9870\n",
            "--LR: 0.005\n",
            "--Epochs: 125\n",
            "--Reg params 0.01\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9789\n",
            "Val accuracy: 0.9789473414421082\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.9870\n",
            "Test accuracy: 0.9869719743728638\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 2.0975 - accuracy: 0.4568 - val_loss: 1.1220 - val_accuracy: 0.7694\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.8248 - val_loss: 0.2950 - val_accuracy: 0.9360\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9392 - val_loss: 0.1898 - val_accuracy: 0.9763\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9545 - val_loss: 0.2129 - val_accuracy: 0.9747\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9560 - val_loss: 0.2008 - val_accuracy: 0.9755\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9622 - val_loss: 0.1474 - val_accuracy: 0.9803\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9625 - val_loss: 0.1585 - val_accuracy: 0.9791\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9635 - val_loss: 0.1779 - val_accuracy: 0.9787\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9650 - val_loss: 0.1484 - val_accuracy: 0.9826\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9643 - val_loss: 0.1457 - val_accuracy: 0.9814\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9645 - val_loss: 0.1244 - val_accuracy: 0.9858\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9640 - val_loss: 0.1425 - val_accuracy: 0.9830\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9655 - val_loss: 0.1351 - val_accuracy: 0.9866\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9670 - val_loss: 0.1275 - val_accuracy: 0.9874\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9682 - val_loss: 0.1191 - val_accuracy: 0.9866\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9695 - val_loss: 0.1242 - val_accuracy: 0.9893\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9647 - val_loss: 0.1184 - val_accuracy: 0.9897\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9707 - val_loss: 0.1433 - val_accuracy: 0.9858\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9670 - val_loss: 0.1256 - val_accuracy: 0.9878\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9647 - val_loss: 0.1398 - val_accuracy: 0.9866\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9703 - val_loss: 0.1314 - val_accuracy: 0.9882\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9690 - val_loss: 0.1269 - val_accuracy: 0.9874\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9718 - val_loss: 0.1232 - val_accuracy: 0.9889\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9695 - val_loss: 0.1356 - val_accuracy: 0.9886\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9678 - val_loss: 0.1241 - val_accuracy: 0.9886\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9703 - val_loss: 0.1161 - val_accuracy: 0.9897\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9685 - val_loss: 0.1661 - val_accuracy: 0.9866\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9707 - val_loss: 0.1148 - val_accuracy: 0.9901\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9697 - val_loss: 0.1309 - val_accuracy: 0.9882\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9703 - val_loss: 0.1508 - val_accuracy: 0.9866\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9682 - val_loss: 0.1497 - val_accuracy: 0.9866\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9680 - val_loss: 0.1147 - val_accuracy: 0.9909\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9712 - val_loss: 0.1220 - val_accuracy: 0.9901\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9732 - val_loss: 0.1491 - val_accuracy: 0.9866\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9703 - val_loss: 0.1206 - val_accuracy: 0.9901\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9693 - val_loss: 0.1230 - val_accuracy: 0.9917\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9715 - val_loss: 0.1137 - val_accuracy: 0.9909\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9715 - val_loss: 0.1154 - val_accuracy: 0.9901\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9728 - val_loss: 0.1176 - val_accuracy: 0.9886\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9707 - val_loss: 0.1497 - val_accuracy: 0.9878\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9720 - val_loss: 0.1087 - val_accuracy: 0.9905\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9705 - val_loss: 0.1363 - val_accuracy: 0.9897\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9703 - val_loss: 0.1186 - val_accuracy: 0.9905\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9715 - val_loss: 0.1158 - val_accuracy: 0.9897\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9705 - val_loss: 0.1374 - val_accuracy: 0.9870\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9730 - val_loss: 0.1184 - val_accuracy: 0.9886\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9680 - val_loss: 0.1102 - val_accuracy: 0.9905\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9718 - val_loss: 0.1069 - val_accuracy: 0.9905\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9695 - val_loss: 0.1926 - val_accuracy: 0.9818\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9700 - val_loss: 0.1191 - val_accuracy: 0.9882\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9735 - val_loss: 0.1116 - val_accuracy: 0.9889\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9722 - val_loss: 0.1397 - val_accuracy: 0.9889\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.9725 - val_loss: 0.1198 - val_accuracy: 0.9889\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9740 - val_loss: 0.1093 - val_accuracy: 0.9897\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9720 - val_loss: 0.1259 - val_accuracy: 0.9913\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9740 - val_loss: 0.1058 - val_accuracy: 0.9901\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9695 - val_loss: 0.1085 - val_accuracy: 0.9917\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9730 - val_loss: 0.1623 - val_accuracy: 0.9854\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9720 - val_loss: 0.1067 - val_accuracy: 0.9917\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9700 - val_loss: 0.1087 - val_accuracy: 0.9901\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9690 - val_loss: 0.1641 - val_accuracy: 0.9846\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9718 - val_loss: 0.1128 - val_accuracy: 0.9909\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9695 - val_loss: 0.1181 - val_accuracy: 0.9886\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9703 - val_loss: 0.1060 - val_accuracy: 0.9897\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9725 - val_loss: 0.1082 - val_accuracy: 0.9917\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9680 - val_loss: 0.1137 - val_accuracy: 0.9905\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9707 - val_loss: 0.1101 - val_accuracy: 0.9897\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9707 - val_loss: 0.1251 - val_accuracy: 0.9901\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9697 - val_loss: 0.1168 - val_accuracy: 0.9893\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9703 - val_loss: 0.1139 - val_accuracy: 0.9889\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9728 - val_loss: 0.1075 - val_accuracy: 0.9897\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9740 - val_loss: 0.1159 - val_accuracy: 0.9893\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9720 - val_loss: 0.1226 - val_accuracy: 0.9905\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9732 - val_loss: 0.1162 - val_accuracy: 0.9889\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9722 - val_loss: 0.1109 - val_accuracy: 0.9913\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9712 - val_loss: 0.2115 - val_accuracy: 0.9818\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9737 - val_loss: 0.1256 - val_accuracy: 0.9893\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9740 - val_loss: 0.1323 - val_accuracy: 0.9882\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9740 - val_loss: 0.1083 - val_accuracy: 0.9913\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9712 - val_loss: 0.1159 - val_accuracy: 0.9905\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9730 - val_loss: 0.1084 - val_accuracy: 0.9925\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9743 - val_loss: 0.1291 - val_accuracy: 0.9882\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9755 - val_loss: 0.1146 - val_accuracy: 0.9897\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9722 - val_loss: 0.1934 - val_accuracy: 0.9842\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9712 - val_loss: 0.1294 - val_accuracy: 0.9897\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9703 - val_loss: 0.1235 - val_accuracy: 0.9925\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9737 - val_loss: 0.1657 - val_accuracy: 0.9866\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9697 - val_loss: 0.1114 - val_accuracy: 0.9909\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9732 - val_loss: 0.1583 - val_accuracy: 0.9862\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9735 - val_loss: 0.1229 - val_accuracy: 0.9878\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9715 - val_loss: 0.1111 - val_accuracy: 0.9874\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9735 - val_loss: 0.1151 - val_accuracy: 0.9909\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9690 - val_loss: 0.1228 - val_accuracy: 0.9886\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9707 - val_loss: 0.1263 - val_accuracy: 0.9913\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9715 - val_loss: 0.1225 - val_accuracy: 0.9897\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9720 - val_loss: 0.1145 - val_accuracy: 0.9909\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9715 - val_loss: 0.1411 - val_accuracy: 0.9889\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9722 - val_loss: 0.1179 - val_accuracy: 0.9897\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9695 - val_loss: 0.1247 - val_accuracy: 0.9909\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9735 - val_loss: 0.2024 - val_accuracy: 0.9830\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9710 - val_loss: 0.1253 - val_accuracy: 0.9889\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9735 - val_loss: 0.1167 - val_accuracy: 0.9889\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9740 - val_loss: 0.1165 - val_accuracy: 0.9893\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9737 - val_loss: 0.1125 - val_accuracy: 0.9901\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9737 - val_loss: 0.1271 - val_accuracy: 0.9905\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1251 - accuracy: 0.9775 - val_loss: 0.1284 - val_accuracy: 0.9893\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1258 - accuracy: 0.9740 - val_loss: 0.1208 - val_accuracy: 0.9901\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9758 - val_loss: 0.1135 - val_accuracy: 0.9901\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9730 - val_loss: 0.1251 - val_accuracy: 0.9905\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9745 - val_loss: 0.1463 - val_accuracy: 0.9870\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9720 - val_loss: 0.1196 - val_accuracy: 0.9897\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9737 - val_loss: 0.1322 - val_accuracy: 0.9889\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9743 - val_loss: 0.1166 - val_accuracy: 0.9893\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9735 - val_loss: 0.1447 - val_accuracy: 0.9889\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9715 - val_loss: 0.1183 - val_accuracy: 0.9917\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9720 - val_loss: 0.1153 - val_accuracy: 0.9897\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9725 - val_loss: 0.1176 - val_accuracy: 0.9909\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9718 - val_loss: 0.1354 - val_accuracy: 0.9905\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9732 - val_loss: 0.1147 - val_accuracy: 0.9921\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9725 - val_loss: 0.1349 - val_accuracy: 0.9893\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9732 - val_loss: 0.1326 - val_accuracy: 0.9882\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9722 - val_loss: 0.1246 - val_accuracy: 0.9917\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9755 - val_loss: 0.1127 - val_accuracy: 0.9897\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9740 - val_loss: 0.1207 - val_accuracy: 0.9889\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9737 - val_loss: 0.1230 - val_accuracy: 0.9913\n",
            "--LR: 0.005\n",
            "--Epochs: 125\n",
            "--Reg params 0.001\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9858\n",
            "Val accuracy: 0.9858299493789673\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9913\n",
            "Test accuracy: 0.9913146495819092\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.4583 - accuracy: 0.6120 - val_loss: 0.5625 - val_accuracy: 0.9278\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.9417 - val_loss: 0.3951 - val_accuracy: 0.9763\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.9582 - val_loss: 0.3271 - val_accuracy: 0.9795\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.9580 - val_loss: 0.4148 - val_accuracy: 0.9735\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.9592 - val_loss: 0.3882 - val_accuracy: 0.9728\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.9620 - val_loss: 0.3339 - val_accuracy: 0.9799\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.9630 - val_loss: 0.2958 - val_accuracy: 0.9838\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.9632 - val_loss: 0.2868 - val_accuracy: 0.9818\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9655 - val_loss: 0.2988 - val_accuracy: 0.9814\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.9650 - val_loss: 0.3478 - val_accuracy: 0.9775\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.9643 - val_loss: 0.2636 - val_accuracy: 0.9846\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.9622 - val_loss: 0.3094 - val_accuracy: 0.9799\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.9640 - val_loss: 0.2610 - val_accuracy: 0.9850\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.9625 - val_loss: 0.2547 - val_accuracy: 0.9826\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.9635 - val_loss: 0.2532 - val_accuracy: 0.9838\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.9657 - val_loss: 0.2515 - val_accuracy: 0.9799\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.9615 - val_loss: 0.2525 - val_accuracy: 0.9811\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.9622 - val_loss: 0.2659 - val_accuracy: 0.9807\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.9655 - val_loss: 0.2765 - val_accuracy: 0.9818\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.9622 - val_loss: 0.2455 - val_accuracy: 0.9826\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.9665 - val_loss: 0.2638 - val_accuracy: 0.9811\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.9645 - val_loss: 0.2547 - val_accuracy: 0.9807\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.9630 - val_loss: 0.2252 - val_accuracy: 0.9838\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.9617 - val_loss: 0.2959 - val_accuracy: 0.9791\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.9635 - val_loss: 0.2111 - val_accuracy: 0.9866\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9638 - val_loss: 0.2308 - val_accuracy: 0.9842\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9693 - val_loss: 0.2068 - val_accuracy: 0.9858\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9640 - val_loss: 0.2048 - val_accuracy: 0.9854\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9645 - val_loss: 0.2217 - val_accuracy: 0.9842\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9635 - val_loss: 0.2199 - val_accuracy: 0.9822\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.9663 - val_loss: 0.2303 - val_accuracy: 0.9811\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.9647 - val_loss: 0.2167 - val_accuracy: 0.9838\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.9645 - val_loss: 0.1967 - val_accuracy: 0.9858\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9645 - val_loss: 0.2006 - val_accuracy: 0.9854\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9670 - val_loss: 0.2010 - val_accuracy: 0.9858\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.9600 - val_loss: 0.1946 - val_accuracy: 0.9862\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9663 - val_loss: 0.1937 - val_accuracy: 0.9866\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.9635 - val_loss: 0.2026 - val_accuracy: 0.9791\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9663 - val_loss: 0.2187 - val_accuracy: 0.9830\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.9675 - val_loss: 0.1991 - val_accuracy: 0.9830\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9645 - val_loss: 0.2141 - val_accuracy: 0.9834\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9653 - val_loss: 0.2181 - val_accuracy: 0.9854\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9680 - val_loss: 0.2616 - val_accuracy: 0.9803\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.9665 - val_loss: 0.1854 - val_accuracy: 0.9878\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9643 - val_loss: 0.1856 - val_accuracy: 0.9866\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.9675 - val_loss: 0.1856 - val_accuracy: 0.9862\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9678 - val_loss: 0.3683 - val_accuracy: 0.9787\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9682 - val_loss: 0.1861 - val_accuracy: 0.9866\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9660 - val_loss: 0.1809 - val_accuracy: 0.9858\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9685 - val_loss: 0.2187 - val_accuracy: 0.9826\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9628 - val_loss: 0.1848 - val_accuracy: 0.9866\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9697 - val_loss: 0.2344 - val_accuracy: 0.9803\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9685 - val_loss: 0.1936 - val_accuracy: 0.9854\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9682 - val_loss: 0.1822 - val_accuracy: 0.9866\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9690 - val_loss: 0.2600 - val_accuracy: 0.9791\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9653 - val_loss: 0.1805 - val_accuracy: 0.9862\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9665 - val_loss: 0.1835 - val_accuracy: 0.9866\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9678 - val_loss: 0.1854 - val_accuracy: 0.9866\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9643 - val_loss: 0.2296 - val_accuracy: 0.9799\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9678 - val_loss: 0.2322 - val_accuracy: 0.9787\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9657 - val_loss: 0.1831 - val_accuracy: 0.9870\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9647 - val_loss: 0.1743 - val_accuracy: 0.9878\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9660 - val_loss: 0.1735 - val_accuracy: 0.9862\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.9680 - val_loss: 0.1912 - val_accuracy: 0.9858\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9707 - val_loss: 0.1912 - val_accuracy: 0.9870\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9697 - val_loss: 0.1732 - val_accuracy: 0.9858\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.9675 - val_loss: 0.1846 - val_accuracy: 0.9862\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9678 - val_loss: 0.3678 - val_accuracy: 0.9759\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9690 - val_loss: 0.1781 - val_accuracy: 0.9866\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9685 - val_loss: 0.1728 - val_accuracy: 0.9870\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.9635 - val_loss: 0.2401 - val_accuracy: 0.9803\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9657 - val_loss: 0.1808 - val_accuracy: 0.9854\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9682 - val_loss: 0.1809 - val_accuracy: 0.9878\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9668 - val_loss: 0.1930 - val_accuracy: 0.9854\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9695 - val_loss: 0.2028 - val_accuracy: 0.9866\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9697 - val_loss: 0.2166 - val_accuracy: 0.9838\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9653 - val_loss: 0.1945 - val_accuracy: 0.9842\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9685 - val_loss: 0.2289 - val_accuracy: 0.9795\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9685 - val_loss: 0.1758 - val_accuracy: 0.9874\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9668 - val_loss: 0.1971 - val_accuracy: 0.9830\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9647 - val_loss: 0.2772 - val_accuracy: 0.9787\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9700 - val_loss: 0.2373 - val_accuracy: 0.9795\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9675 - val_loss: 0.1790 - val_accuracy: 0.9862\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9678 - val_loss: 0.1746 - val_accuracy: 0.9889\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9703 - val_loss: 0.1717 - val_accuracy: 0.9886\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9675 - val_loss: 0.1699 - val_accuracy: 0.9882\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9678 - val_loss: 0.2213 - val_accuracy: 0.9818\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9675 - val_loss: 0.1677 - val_accuracy: 0.9882\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9670 - val_loss: 0.1840 - val_accuracy: 0.9866\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9703 - val_loss: 0.2566 - val_accuracy: 0.9799\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9672 - val_loss: 0.1875 - val_accuracy: 0.9858\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9693 - val_loss: 0.2705 - val_accuracy: 0.9787\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9705 - val_loss: 0.2233 - val_accuracy: 0.9807\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9688 - val_loss: 0.1772 - val_accuracy: 0.9858\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9660 - val_loss: 0.1726 - val_accuracy: 0.9870\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9655 - val_loss: 0.1733 - val_accuracy: 0.9866\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9697 - val_loss: 0.2006 - val_accuracy: 0.9822\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9712 - val_loss: 0.1877 - val_accuracy: 0.9866\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9722 - val_loss: 0.1825 - val_accuracy: 0.9874\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9675 - val_loss: 0.1718 - val_accuracy: 0.9874\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9693 - val_loss: 0.1831 - val_accuracy: 0.9874\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9707 - val_loss: 0.1895 - val_accuracy: 0.9846\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9660 - val_loss: 0.1931 - val_accuracy: 0.9838\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9705 - val_loss: 0.2117 - val_accuracy: 0.9834\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9707 - val_loss: 0.1896 - val_accuracy: 0.9858\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9715 - val_loss: 0.2351 - val_accuracy: 0.9795\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9693 - val_loss: 0.1697 - val_accuracy: 0.9874\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9737 - val_loss: 0.1702 - val_accuracy: 0.9854\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9695 - val_loss: 0.1772 - val_accuracy: 0.9858\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9695 - val_loss: 0.4067 - val_accuracy: 0.9467\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9607 - val_loss: 0.1716 - val_accuracy: 0.9838\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9697 - val_loss: 0.1692 - val_accuracy: 0.9850\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9693 - val_loss: 0.1723 - val_accuracy: 0.9893\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9663 - val_loss: 0.1779 - val_accuracy: 0.9897\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9700 - val_loss: 0.1757 - val_accuracy: 0.9878\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9690 - val_loss: 0.1734 - val_accuracy: 0.9862\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9685 - val_loss: 0.2154 - val_accuracy: 0.9826\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.9700 - val_loss: 0.1699 - val_accuracy: 0.9882\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9685 - val_loss: 0.1798 - val_accuracy: 0.9866\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9710 - val_loss: 0.1994 - val_accuracy: 0.9830\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9697 - val_loss: 0.1635 - val_accuracy: 0.9882\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9690 - val_loss: 0.1762 - val_accuracy: 0.9893\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9715 - val_loss: 0.2752 - val_accuracy: 0.9779\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9695 - val_loss: 0.1820 - val_accuracy: 0.9862\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9718 - val_loss: 0.1652 - val_accuracy: 0.9897\n",
            "--LR: 0.005\n",
            "--Epochs: 125\n",
            "--Reg params 0.005\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9759\n",
            "Val accuracy: 0.9759109020233154\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9897\n",
            "Test accuracy: 0.98973548412323\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.8534 - accuracy: 0.4515 - val_loss: 1.8401 - val_accuracy: 0.1173\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.6619 - accuracy: 0.6407 - val_loss: 1.5391 - val_accuracy: 0.6451\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4261 - accuracy: 0.7968 - val_loss: 1.2546 - val_accuracy: 0.8606\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3117 - accuracy: 0.8292 - val_loss: 1.0143 - val_accuracy: 0.9503\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2785 - accuracy: 0.8445 - val_loss: 0.9668 - val_accuracy: 0.9491\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2569 - accuracy: 0.8602 - val_loss: 1.0111 - val_accuracy: 0.9266\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2227 - accuracy: 0.8727 - val_loss: 1.0834 - val_accuracy: 0.8835\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2003 - accuracy: 0.8742 - val_loss: 0.8992 - val_accuracy: 0.9526\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1656 - accuracy: 0.8780 - val_loss: 1.0428 - val_accuracy: 0.8910\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1551 - accuracy: 0.8740 - val_loss: 0.9031 - val_accuracy: 0.9546\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1445 - accuracy: 0.8773 - val_loss: 1.0350 - val_accuracy: 0.8879\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1340 - accuracy: 0.8795 - val_loss: 0.9329 - val_accuracy: 0.9206\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1146 - accuracy: 0.8783 - val_loss: 0.9160 - val_accuracy: 0.9356\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1002 - accuracy: 0.8785 - val_loss: 0.9697 - val_accuracy: 0.9037\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1014 - accuracy: 0.8765 - val_loss: 1.1279 - val_accuracy: 0.8445\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0853 - accuracy: 0.8820 - val_loss: 0.9985 - val_accuracy: 0.8816\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0737 - accuracy: 0.8845 - val_loss: 0.9784 - val_accuracy: 0.8974\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0767 - accuracy: 0.8810 - val_loss: 0.8525 - val_accuracy: 0.9562\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0737 - accuracy: 0.8810 - val_loss: 0.8784 - val_accuracy: 0.9475\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0632 - accuracy: 0.8838 - val_loss: 0.8647 - val_accuracy: 0.9475\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0654 - accuracy: 0.8848 - val_loss: 0.8485 - val_accuracy: 0.9479\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.8845 - val_loss: 0.8400 - val_accuracy: 0.9550\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0535 - accuracy: 0.8795 - val_loss: 0.8689 - val_accuracy: 0.9258\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.8813 - val_loss: 0.9281 - val_accuracy: 0.9021\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0340 - accuracy: 0.8810 - val_loss: 0.8158 - val_accuracy: 0.9550\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0246 - accuracy: 0.8845 - val_loss: 0.8953 - val_accuracy: 0.9005\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.8825 - val_loss: 0.9542 - val_accuracy: 0.8879\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.8845 - val_loss: 0.8588 - val_accuracy: 0.9238\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0192 - accuracy: 0.8865 - val_loss: 0.9233 - val_accuracy: 0.8974\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.8802 - val_loss: 0.8026 - val_accuracy: 0.9554\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0213 - accuracy: 0.8823 - val_loss: 0.8461 - val_accuracy: 0.9226\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0236 - accuracy: 0.8835 - val_loss: 1.0865 - val_accuracy: 0.8476\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.8805 - val_loss: 0.8475 - val_accuracy: 0.9301\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.8788 - val_loss: 0.8590 - val_accuracy: 0.9155\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.8840 - val_loss: 0.8445 - val_accuracy: 0.9147\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0134 - accuracy: 0.8813 - val_loss: 0.7938 - val_accuracy: 0.9542\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.8855 - val_loss: 0.8752 - val_accuracy: 0.9068\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.8865 - val_loss: 0.8406 - val_accuracy: 0.9329\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0129 - accuracy: 0.8783 - val_loss: 0.8253 - val_accuracy: 0.9412\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0036 - accuracy: 0.8798 - val_loss: 0.8596 - val_accuracy: 0.9100\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0020 - accuracy: 0.8825 - val_loss: 0.9093 - val_accuracy: 0.8950\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0317 - accuracy: 0.8763 - val_loss: 0.8624 - val_accuracy: 0.9131\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.8758 - val_loss: 0.8083 - val_accuracy: 0.9435\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9917 - accuracy: 0.8825 - val_loss: 0.9455 - val_accuracy: 0.8827\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.8873 - val_loss: 0.9684 - val_accuracy: 0.8752\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9909 - accuracy: 0.8798 - val_loss: 0.7933 - val_accuracy: 0.9463\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9822 - accuracy: 0.8835 - val_loss: 0.8122 - val_accuracy: 0.9392\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9829 - accuracy: 0.8848 - val_loss: 0.7920 - val_accuracy: 0.9526\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9977 - accuracy: 0.8790 - val_loss: 0.9036 - val_accuracy: 0.8981\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.8842 - val_loss: 0.8244 - val_accuracy: 0.9179\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.8832 - val_loss: 0.8186 - val_accuracy: 0.9195\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9841 - accuracy: 0.8830 - val_loss: 0.8057 - val_accuracy: 0.9384\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9857 - accuracy: 0.8840 - val_loss: 0.9030 - val_accuracy: 0.8966\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.8808 - val_loss: 0.9296 - val_accuracy: 0.8883\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.8855 - val_loss: 0.8781 - val_accuracy: 0.9056\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9914 - accuracy: 0.8802 - val_loss: 1.0218 - val_accuracy: 0.8531\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9866 - accuracy: 0.8800 - val_loss: 0.9509 - val_accuracy: 0.8764\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9860 - accuracy: 0.8790 - val_loss: 0.8489 - val_accuracy: 0.9096\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9948 - accuracy: 0.8795 - val_loss: 0.8462 - val_accuracy: 0.9092\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.8785 - val_loss: 0.8108 - val_accuracy: 0.9360\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9821 - accuracy: 0.8850 - val_loss: 0.8131 - val_accuracy: 0.9333\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9955 - accuracy: 0.8775 - val_loss: 0.7933 - val_accuracy: 0.9400\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9831 - accuracy: 0.8860 - val_loss: 0.7822 - val_accuracy: 0.9522\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.8777 - val_loss: 0.8411 - val_accuracy: 0.9151\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9769 - accuracy: 0.8848 - val_loss: 0.8754 - val_accuracy: 0.9033\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9798 - accuracy: 0.8827 - val_loss: 0.7877 - val_accuracy: 0.9451\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9938 - accuracy: 0.8775 - val_loss: 0.9976 - val_accuracy: 0.8606\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.8860 - val_loss: 0.8196 - val_accuracy: 0.9179\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0069 - accuracy: 0.8750 - val_loss: 0.7907 - val_accuracy: 0.9443\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9934 - accuracy: 0.8773 - val_loss: 0.7886 - val_accuracy: 0.9475\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.9887 - accuracy: 0.8798 - val_loss: 0.7990 - val_accuracy: 0.9424\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.9819 - accuracy: 0.8805 - val_loss: 0.8634 - val_accuracy: 0.9068\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.8770 - val_loss: 0.7570 - val_accuracy: 0.9562\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.8852 - val_loss: 0.8055 - val_accuracy: 0.9368\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.8857 - val_loss: 0.8435 - val_accuracy: 0.9120\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9881 - accuracy: 0.8808 - val_loss: 0.8065 - val_accuracy: 0.9353\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.8817 - val_loss: 0.7763 - val_accuracy: 0.9522\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9920 - accuracy: 0.8798 - val_loss: 0.9108 - val_accuracy: 0.8977\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.8792 - val_loss: 0.8082 - val_accuracy: 0.9420\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.8817 - val_loss: 0.8530 - val_accuracy: 0.9080\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.8830 - val_loss: 0.9012 - val_accuracy: 0.8958\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9817 - accuracy: 0.8815 - val_loss: 0.8248 - val_accuracy: 0.9230\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9814 - accuracy: 0.8825 - val_loss: 0.7925 - val_accuracy: 0.9451\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9816 - accuracy: 0.8805 - val_loss: 0.9158 - val_accuracy: 0.8851\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9882 - accuracy: 0.8802 - val_loss: 0.8158 - val_accuracy: 0.9250\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9811 - accuracy: 0.8823 - val_loss: 0.8136 - val_accuracy: 0.9345\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9818 - accuracy: 0.8765 - val_loss: 0.7593 - val_accuracy: 0.9585\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9800 - accuracy: 0.8825 - val_loss: 0.8013 - val_accuracy: 0.9392\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9853 - accuracy: 0.8840 - val_loss: 0.8777 - val_accuracy: 0.9037\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9832 - accuracy: 0.8865 - val_loss: 0.8698 - val_accuracy: 0.9041\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9766 - accuracy: 0.8842 - val_loss: 0.8678 - val_accuracy: 0.9033\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.8832 - val_loss: 0.7815 - val_accuracy: 0.9463\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9765 - accuracy: 0.8817 - val_loss: 0.8571 - val_accuracy: 0.9072\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9773 - accuracy: 0.8845 - val_loss: 0.7932 - val_accuracy: 0.9432\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9827 - accuracy: 0.8800 - val_loss: 0.7745 - val_accuracy: 0.9526\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.8848 - val_loss: 0.8841 - val_accuracy: 0.8993\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.8832 - val_loss: 0.8444 - val_accuracy: 0.9128\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.8802 - val_loss: 0.7995 - val_accuracy: 0.9447\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9911 - accuracy: 0.8802 - val_loss: 0.7784 - val_accuracy: 0.9479\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9847 - accuracy: 0.8840 - val_loss: 0.7936 - val_accuracy: 0.9463\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9825 - accuracy: 0.8832 - val_loss: 1.0298 - val_accuracy: 0.8492\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9837 - accuracy: 0.8820 - val_loss: 0.8487 - val_accuracy: 0.9088\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9791 - accuracy: 0.8852 - val_loss: 0.8320 - val_accuracy: 0.9151\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9792 - accuracy: 0.8815 - val_loss: 0.7989 - val_accuracy: 0.9408\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.8817 - val_loss: 0.8034 - val_accuracy: 0.9424\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.8825 - val_loss: 0.8859 - val_accuracy: 0.9005\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9858 - accuracy: 0.8810 - val_loss: 0.8296 - val_accuracy: 0.9159\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9818 - accuracy: 0.8835 - val_loss: 0.8856 - val_accuracy: 0.9021\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9797 - accuracy: 0.8870 - val_loss: 0.7782 - val_accuracy: 0.9491\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.8790 - val_loss: 0.8111 - val_accuracy: 0.9380\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.8800 - val_loss: 0.7687 - val_accuracy: 0.9526\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9782 - accuracy: 0.8825 - val_loss: 0.8799 - val_accuracy: 0.9025\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9824 - accuracy: 0.8795 - val_loss: 0.9279 - val_accuracy: 0.8835\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 0.8827 - val_loss: 0.9166 - val_accuracy: 0.8899\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9881 - accuracy: 0.8788 - val_loss: 0.8516 - val_accuracy: 0.9096\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.8848 - val_loss: 0.8482 - val_accuracy: 0.9112\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.8838 - val_loss: 0.7681 - val_accuracy: 0.9514\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9780 - accuracy: 0.8827 - val_loss: 0.7846 - val_accuracy: 0.9491\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9874 - accuracy: 0.8832 - val_loss: 0.7694 - val_accuracy: 0.9526\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9860 - accuracy: 0.8825 - val_loss: 0.7820 - val_accuracy: 0.9463\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9770 - accuracy: 0.8855 - val_loss: 0.8832 - val_accuracy: 0.9029\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9811 - accuracy: 0.8810 - val_loss: 0.9140 - val_accuracy: 0.8938\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9821 - accuracy: 0.8838 - val_loss: 0.8130 - val_accuracy: 0.9333\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.8835 - val_loss: 0.9299 - val_accuracy: 0.8875\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.9874 - accuracy: 0.8783 - val_loss: 0.9175 - val_accuracy: 0.8875\n",
            "--LR: 0.01\n",
            "--Epochs: 125\n",
            "--Reg params 0.05\n",
            "155/155 [==============================] - 1s 2ms/step - loss: 0.9825 - accuracy: 0.8848\n",
            "Val accuracy: 0.8848178386688232\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.8875\n",
            "Test accuracy: 0.8874852061271667\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.7079 - accuracy: 0.2457 - val_loss: 1.5091 - val_accuracy: 0.0454\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4824 - accuracy: 0.2355 - val_loss: 1.4424 - val_accuracy: 0.0738\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4406 - accuracy: 0.2435 - val_loss: 1.4292 - val_accuracy: 0.0683\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4139 - accuracy: 0.2393 - val_loss: 1.3994 - val_accuracy: 0.0738\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.2300 - val_loss: 1.3749 - val_accuracy: 0.8125\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3936 - accuracy: 0.2505 - val_loss: 1.4191 - val_accuracy: 0.0738\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3923 - accuracy: 0.2350 - val_loss: 1.3846 - val_accuracy: 0.0454\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3921 - accuracy: 0.2438 - val_loss: 1.3881 - val_accuracy: 0.0683\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3921 - accuracy: 0.2473 - val_loss: 1.3875 - val_accuracy: 0.0454\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3925 - accuracy: 0.2438 - val_loss: 1.4051 - val_accuracy: 0.0454\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2455 - val_loss: 1.4098 - val_accuracy: 0.0454\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3922 - accuracy: 0.2537 - val_loss: 1.3788 - val_accuracy: 0.0738\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2477 - val_loss: 1.4082 - val_accuracy: 0.0738\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3921 - accuracy: 0.2492 - val_loss: 1.4117 - val_accuracy: 0.0738\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3924 - accuracy: 0.2510 - val_loss: 1.4026 - val_accuracy: 0.0454\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3925 - accuracy: 0.2535 - val_loss: 1.3696 - val_accuracy: 0.0683\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2450 - val_loss: 1.3755 - val_accuracy: 0.8125\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3926 - accuracy: 0.2438 - val_loss: 1.4164 - val_accuracy: 0.0454\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3924 - accuracy: 0.2420 - val_loss: 1.4094 - val_accuracy: 0.0683\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3924 - accuracy: 0.2495 - val_loss: 1.3644 - val_accuracy: 0.8125\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2467 - val_loss: 1.4202 - val_accuracy: 0.0454\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2438 - val_loss: 1.3959 - val_accuracy: 0.0454\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3923 - accuracy: 0.2498 - val_loss: 1.4043 - val_accuracy: 0.0738\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2395 - val_loss: 1.3869 - val_accuracy: 0.0683\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.2360 - val_loss: 1.3788 - val_accuracy: 0.8125\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2463 - val_loss: 1.4015 - val_accuracy: 0.0738\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2485 - val_loss: 1.4003 - val_accuracy: 0.0683\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2488 - val_loss: 1.3775 - val_accuracy: 0.8125\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3926 - accuracy: 0.2380 - val_loss: 1.3795 - val_accuracy: 0.0683\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2418 - val_loss: 1.3945 - val_accuracy: 0.0454\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3922 - accuracy: 0.2598 - val_loss: 1.3737 - val_accuracy: 0.0683\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2512 - val_loss: 1.4074 - val_accuracy: 0.0683\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2470 - val_loss: 1.3549 - val_accuracy: 0.8125\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3926 - accuracy: 0.2495 - val_loss: 1.3912 - val_accuracy: 0.0683\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2387 - val_loss: 1.4080 - val_accuracy: 0.0683\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3926 - accuracy: 0.2445 - val_loss: 1.3804 - val_accuracy: 0.8125\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2488 - val_loss: 1.3983 - val_accuracy: 0.0683\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2455 - val_loss: 1.3961 - val_accuracy: 0.0738\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3926 - accuracy: 0.2485 - val_loss: 1.4042 - val_accuracy: 0.0683\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3923 - accuracy: 0.2440 - val_loss: 1.4016 - val_accuracy: 0.0454\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.2467 - val_loss: 1.3890 - val_accuracy: 0.0454\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2438 - val_loss: 1.3999 - val_accuracy: 0.0738\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3925 - accuracy: 0.2498 - val_loss: 1.3762 - val_accuracy: 0.0683\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2383 - val_loss: 1.3812 - val_accuracy: 0.8125\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3933 - accuracy: 0.2310 - val_loss: 1.4049 - val_accuracy: 0.0454\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2395 - val_loss: 1.3856 - val_accuracy: 0.0738\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3929 - accuracy: 0.2453 - val_loss: 1.3803 - val_accuracy: 0.0738\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3929 - accuracy: 0.2482 - val_loss: 1.3502 - val_accuracy: 0.8125\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3931 - accuracy: 0.2525 - val_loss: 1.4083 - val_accuracy: 0.0738\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3924 - accuracy: 0.2475 - val_loss: 1.3524 - val_accuracy: 0.8125\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3931 - accuracy: 0.2415 - val_loss: 1.3976 - val_accuracy: 0.0738\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3932 - accuracy: 0.2395 - val_loss: 1.4049 - val_accuracy: 0.0738\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2432 - val_loss: 1.3584 - val_accuracy: 0.8125\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2405 - val_loss: 1.3784 - val_accuracy: 0.8125\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2420 - val_loss: 1.3770 - val_accuracy: 0.0738\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3931 - accuracy: 0.2490 - val_loss: 1.4468 - val_accuracy: 0.0454\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2430 - val_loss: 1.3866 - val_accuracy: 0.0454\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2477 - val_loss: 1.4245 - val_accuracy: 0.0738\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2438 - val_loss: 1.4117 - val_accuracy: 0.0738\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3933 - accuracy: 0.2405 - val_loss: 1.4286 - val_accuracy: 0.0738\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2438 - val_loss: 1.4142 - val_accuracy: 0.0683\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2370 - val_loss: 1.3805 - val_accuracy: 0.8125\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3926 - accuracy: 0.2412 - val_loss: 1.4058 - val_accuracy: 0.0683\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3931 - accuracy: 0.2485 - val_loss: 1.3837 - val_accuracy: 0.0738\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3929 - accuracy: 0.2325 - val_loss: 1.3952 - val_accuracy: 0.0738\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2515 - val_loss: 1.3776 - val_accuracy: 0.0683\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2553 - val_loss: 1.4043 - val_accuracy: 0.0454\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2340 - val_loss: 1.4130 - val_accuracy: 0.0683\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2295 - val_loss: 1.3813 - val_accuracy: 0.8125\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3934 - accuracy: 0.2375 - val_loss: 1.3812 - val_accuracy: 0.0738\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2385 - val_loss: 1.3886 - val_accuracy: 0.0683\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2368 - val_loss: 1.3884 - val_accuracy: 0.0738\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.2490 - val_loss: 1.3980 - val_accuracy: 0.0683\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.2400 - val_loss: 1.4256 - val_accuracy: 0.0738\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.2510 - val_loss: 1.4072 - val_accuracy: 0.0738\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3923 - accuracy: 0.2530 - val_loss: 1.4014 - val_accuracy: 0.0454\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3925 - accuracy: 0.2470 - val_loss: 1.3875 - val_accuracy: 0.0738\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2467 - val_loss: 1.4519 - val_accuracy: 0.0454\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2453 - val_loss: 1.3800 - val_accuracy: 0.0454\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3941 - accuracy: 0.2345 - val_loss: 1.3966 - val_accuracy: 0.0454\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3926 - accuracy: 0.2412 - val_loss: 1.3854 - val_accuracy: 0.0454\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2383 - val_loss: 1.3810 - val_accuracy: 0.0454\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2390 - val_loss: 1.3920 - val_accuracy: 0.0738\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2365 - val_loss: 1.3924 - val_accuracy: 0.0454\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2498 - val_loss: 1.4207 - val_accuracy: 0.0683\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2467 - val_loss: 1.3808 - val_accuracy: 0.0683\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3935 - accuracy: 0.2400 - val_loss: 1.3964 - val_accuracy: 0.0683\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3933 - accuracy: 0.2442 - val_loss: 1.3798 - val_accuracy: 0.8125\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.2412 - val_loss: 1.3694 - val_accuracy: 0.8125\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2362 - val_loss: 1.4119 - val_accuracy: 0.0738\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2460 - val_loss: 1.3983 - val_accuracy: 0.0454\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3929 - accuracy: 0.2482 - val_loss: 1.3938 - val_accuracy: 0.0683\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3928 - accuracy: 0.2460 - val_loss: 1.3958 - val_accuracy: 0.0738\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3934 - accuracy: 0.2455 - val_loss: 1.3822 - val_accuracy: 0.0683\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3929 - accuracy: 0.2475 - val_loss: 1.4313 - val_accuracy: 0.0738\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3929 - accuracy: 0.2425 - val_loss: 1.4202 - val_accuracy: 0.0738\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3931 - accuracy: 0.2447 - val_loss: 1.3621 - val_accuracy: 0.8125\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2340 - val_loss: 1.4292 - val_accuracy: 0.0454\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2397 - val_loss: 1.3996 - val_accuracy: 0.0454\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2420 - val_loss: 1.3889 - val_accuracy: 0.0454\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3933 - accuracy: 0.2393 - val_loss: 1.4127 - val_accuracy: 0.0683\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2480 - val_loss: 1.3655 - val_accuracy: 0.0454\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2358 - val_loss: 1.3849 - val_accuracy: 0.8125\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3933 - accuracy: 0.2342 - val_loss: 1.4076 - val_accuracy: 0.0738\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2533 - val_loss: 1.3649 - val_accuracy: 0.8125\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2447 - val_loss: 1.3995 - val_accuracy: 0.0738\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2447 - val_loss: 1.3999 - val_accuracy: 0.0738\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.2327 - val_loss: 1.4009 - val_accuracy: 0.0683\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3932 - accuracy: 0.2430 - val_loss: 1.3927 - val_accuracy: 0.0683\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2387 - val_loss: 1.4045 - val_accuracy: 0.0738\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2450 - val_loss: 1.3983 - val_accuracy: 0.0738\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2515 - val_loss: 1.3542 - val_accuracy: 0.8125\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3930 - accuracy: 0.2385 - val_loss: 1.4033 - val_accuracy: 0.0683\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2465 - val_loss: 1.3870 - val_accuracy: 0.0738\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.2395 - val_loss: 1.3986 - val_accuracy: 0.0454\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2397 - val_loss: 1.4045 - val_accuracy: 0.0454\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2467 - val_loss: 1.3655 - val_accuracy: 0.8125\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2533 - val_loss: 1.4090 - val_accuracy: 0.0454\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.2375 - val_loss: 1.4026 - val_accuracy: 0.0683\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.2403 - val_loss: 1.3984 - val_accuracy: 0.0738\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.2395 - val_loss: 1.3771 - val_accuracy: 0.8125\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3925 - accuracy: 0.2520 - val_loss: 1.4365 - val_accuracy: 0.0454\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.2475 - val_loss: 1.3800 - val_accuracy: 0.0738\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.2432 - val_loss: 1.3906 - val_accuracy: 0.0683\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.2515 - val_loss: 1.3805 - val_accuracy: 0.0738\n",
            "--LR: 0.01\n",
            "--Epochs: 125\n",
            "--Reg params 0.01\n",
            "155/155 [==============================] - 1s 2ms/step - loss: 1.3924 - accuracy: 0.2500\n",
            "Val accuracy: 0.25\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 1.3805 - accuracy: 0.0738\n",
            "Test accuracy: 0.07382550090551376\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.0863 - accuracy: 0.5293 - val_loss: 0.3523 - val_accuracy: 0.9206\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.7830 - val_loss: 0.2356 - val_accuracy: 0.9538\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.9133 - val_loss: 0.2053 - val_accuracy: 0.9688\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.9477 - val_loss: 0.1637 - val_accuracy: 0.9811\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.9495 - val_loss: 0.1825 - val_accuracy: 0.9799\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.9600 - val_loss: 0.1323 - val_accuracy: 0.9866\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9653 - val_loss: 0.1497 - val_accuracy: 0.9854\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9663 - val_loss: 0.1358 - val_accuracy: 0.9870\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9620 - val_loss: 0.1754 - val_accuracy: 0.9858\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9567 - val_loss: 0.1361 - val_accuracy: 0.9886\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9665 - val_loss: 0.1252 - val_accuracy: 0.9917\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9657 - val_loss: 0.1619 - val_accuracy: 0.9889\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9678 - val_loss: 0.1371 - val_accuracy: 0.9889\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9720 - val_loss: 0.1182 - val_accuracy: 0.9909\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9685 - val_loss: 0.1969 - val_accuracy: 0.9791\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9655 - val_loss: 0.1463 - val_accuracy: 0.9897\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9700 - val_loss: 0.1324 - val_accuracy: 0.9866\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9670 - val_loss: 0.1722 - val_accuracy: 0.9893\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9718 - val_loss: 0.1091 - val_accuracy: 0.9901\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9635 - val_loss: 0.1211 - val_accuracy: 0.9862\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9712 - val_loss: 0.1157 - val_accuracy: 0.9858\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9730 - val_loss: 0.1063 - val_accuracy: 0.9925\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9710 - val_loss: 0.1088 - val_accuracy: 0.9882\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9728 - val_loss: 0.1287 - val_accuracy: 0.9886\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9737 - val_loss: 0.1217 - val_accuracy: 0.9893\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9715 - val_loss: 0.1044 - val_accuracy: 0.9889\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9712 - val_loss: 0.1068 - val_accuracy: 0.9905\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9718 - val_loss: 0.1062 - val_accuracy: 0.9882\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9718 - val_loss: 0.1124 - val_accuracy: 0.9901\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9732 - val_loss: 0.1338 - val_accuracy: 0.9830\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9710 - val_loss: 0.1063 - val_accuracy: 0.9897\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9690 - val_loss: 0.1493 - val_accuracy: 0.9763\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9688 - val_loss: 0.0977 - val_accuracy: 0.9929\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9705 - val_loss: 0.1018 - val_accuracy: 0.9901\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9747 - val_loss: 0.1041 - val_accuracy: 0.9901\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9740 - val_loss: 0.1142 - val_accuracy: 0.9889\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.9740 - val_loss: 0.1012 - val_accuracy: 0.9901\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9747 - val_loss: 0.0985 - val_accuracy: 0.9897\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9755 - val_loss: 0.1033 - val_accuracy: 0.9889\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9715 - val_loss: 0.1337 - val_accuracy: 0.9889\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9732 - val_loss: 0.0994 - val_accuracy: 0.9921\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9715 - val_loss: 0.0964 - val_accuracy: 0.9901\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9758 - val_loss: 0.0942 - val_accuracy: 0.9937\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9772 - val_loss: 0.1051 - val_accuracy: 0.9889\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9768 - val_loss: 0.1119 - val_accuracy: 0.9862\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9710 - val_loss: 0.1139 - val_accuracy: 0.9882\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9740 - val_loss: 0.0919 - val_accuracy: 0.9905\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9725 - val_loss: 0.0948 - val_accuracy: 0.9897\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9735 - val_loss: 0.0886 - val_accuracy: 0.9941\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9765 - val_loss: 0.0971 - val_accuracy: 0.9937\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9707 - val_loss: 0.1056 - val_accuracy: 0.9886\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9712 - val_loss: 0.0928 - val_accuracy: 0.9937\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9750 - val_loss: 0.0895 - val_accuracy: 0.9937\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9755 - val_loss: 0.0988 - val_accuracy: 0.9889\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9728 - val_loss: 0.0903 - val_accuracy: 0.9949\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9755 - val_loss: 0.1253 - val_accuracy: 0.9870\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9737 - val_loss: 0.0913 - val_accuracy: 0.9909\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9743 - val_loss: 0.1363 - val_accuracy: 0.9874\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9705 - val_loss: 0.0963 - val_accuracy: 0.9889\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9750 - val_loss: 0.0912 - val_accuracy: 0.9921\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9755 - val_loss: 0.0893 - val_accuracy: 0.9901\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9728 - val_loss: 0.1062 - val_accuracy: 0.9917\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9768 - val_loss: 0.1021 - val_accuracy: 0.9866\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9753 - val_loss: 0.0863 - val_accuracy: 0.9917\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9760 - val_loss: 0.0876 - val_accuracy: 0.9897\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9730 - val_loss: 0.1013 - val_accuracy: 0.9889\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9728 - val_loss: 0.0935 - val_accuracy: 0.9941\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9705 - val_loss: 0.0931 - val_accuracy: 0.9909\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9750 - val_loss: 0.1295 - val_accuracy: 0.9866\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9737 - val_loss: 0.0942 - val_accuracy: 0.9893\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9765 - val_loss: 0.0847 - val_accuracy: 0.9949\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9743 - val_loss: 0.1110 - val_accuracy: 0.9878\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9772 - val_loss: 0.0930 - val_accuracy: 0.9889\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9755 - val_loss: 0.1038 - val_accuracy: 0.9834\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9780 - val_loss: 0.0841 - val_accuracy: 0.9905\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9760 - val_loss: 0.1250 - val_accuracy: 0.9842\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9745 - val_loss: 0.0885 - val_accuracy: 0.9893\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9753 - val_loss: 0.0963 - val_accuracy: 0.9897\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9765 - val_loss: 0.0891 - val_accuracy: 0.9901\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9720 - val_loss: 0.0879 - val_accuracy: 0.9945\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9750 - val_loss: 0.1099 - val_accuracy: 0.9921\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9758 - val_loss: 0.0871 - val_accuracy: 0.9933\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9760 - val_loss: 0.0854 - val_accuracy: 0.9941\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9768 - val_loss: 0.0983 - val_accuracy: 0.9889\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9787 - val_loss: 0.0869 - val_accuracy: 0.9921\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9758 - val_loss: 0.0975 - val_accuracy: 0.9901\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9793 - val_loss: 0.0938 - val_accuracy: 0.9917\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9753 - val_loss: 0.0886 - val_accuracy: 0.9925\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9768 - val_loss: 0.0940 - val_accuracy: 0.9901\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9693 - val_loss: 0.0896 - val_accuracy: 0.9893\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9765 - val_loss: 0.0949 - val_accuracy: 0.9909\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9800 - val_loss: 0.0876 - val_accuracy: 0.9913\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9768 - val_loss: 0.1124 - val_accuracy: 0.9905\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9762 - val_loss: 0.0954 - val_accuracy: 0.9846\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9770 - val_loss: 0.0834 - val_accuracy: 0.9893\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9762 - val_loss: 0.1222 - val_accuracy: 0.9866\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9772 - val_loss: 0.0852 - val_accuracy: 0.9921\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9762 - val_loss: 0.0860 - val_accuracy: 0.9905\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9785 - val_loss: 0.0840 - val_accuracy: 0.9917\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9743 - val_loss: 0.0856 - val_accuracy: 0.9917\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9730 - val_loss: 0.0974 - val_accuracy: 0.9886\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9747 - val_loss: 0.0886 - val_accuracy: 0.9925\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9795 - val_loss: 0.0963 - val_accuracy: 0.9917\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9758 - val_loss: 0.0965 - val_accuracy: 0.9889\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9765 - val_loss: 0.0821 - val_accuracy: 0.9905\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9775 - val_loss: 0.0821 - val_accuracy: 0.9913\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9772 - val_loss: 0.1681 - val_accuracy: 0.9889\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9743 - val_loss: 0.0909 - val_accuracy: 0.9893\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9780 - val_loss: 0.0840 - val_accuracy: 0.9945\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9785 - val_loss: 0.0856 - val_accuracy: 0.9933\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9780 - val_loss: 0.0835 - val_accuracy: 0.9921\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9768 - val_loss: 0.0890 - val_accuracy: 0.9889\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9755 - val_loss: 0.1044 - val_accuracy: 0.9886\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9747 - val_loss: 0.0891 - val_accuracy: 0.9937\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9760 - val_loss: 0.1006 - val_accuracy: 0.9811\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9730 - val_loss: 0.0972 - val_accuracy: 0.9882\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9690 - val_loss: 0.0895 - val_accuracy: 0.9893\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9712 - val_loss: 0.0880 - val_accuracy: 0.9886\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9785 - val_loss: 0.0864 - val_accuracy: 0.9937\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9778 - val_loss: 0.0935 - val_accuracy: 0.9889\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9778 - val_loss: 0.1005 - val_accuracy: 0.9889\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9758 - val_loss: 0.0871 - val_accuracy: 0.9889\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9770 - val_loss: 0.1387 - val_accuracy: 0.9866\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9793 - val_loss: 0.0814 - val_accuracy: 0.9921\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9768 - val_loss: 0.0882 - val_accuracy: 0.9921\n",
            "--LR: 0.01\n",
            "--Epochs: 125\n",
            "--Reg params 0.001\n",
            "155/155 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9901\n",
            "Val accuracy: 0.9900809526443481\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9921\n",
            "Test accuracy: 0.9921042323112488\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.0908 - accuracy: 0.7115 - val_loss: 0.4664 - val_accuracy: 0.9759\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.9473 - val_loss: 0.3447 - val_accuracy: 0.9803\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.9490 - val_loss: 0.3174 - val_accuracy: 0.9830\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.9535 - val_loss: 0.2994 - val_accuracy: 0.9807\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.9580 - val_loss: 0.3056 - val_accuracy: 0.9791\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.9585 - val_loss: 0.2860 - val_accuracy: 0.9775\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.9550 - val_loss: 0.2843 - val_accuracy: 0.9791\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.9538 - val_loss: 0.2617 - val_accuracy: 0.9850\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.9660 - val_loss: 0.3179 - val_accuracy: 0.9811\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.9542 - val_loss: 0.3070 - val_accuracy: 0.9803\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.9592 - val_loss: 0.3253 - val_accuracy: 0.9791\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.9668 - val_loss: 0.2888 - val_accuracy: 0.9791\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.9610 - val_loss: 0.2325 - val_accuracy: 0.9850\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.9617 - val_loss: 0.2968 - val_accuracy: 0.9791\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.9620 - val_loss: 0.2552 - val_accuracy: 0.9814\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.9628 - val_loss: 0.2271 - val_accuracy: 0.9838\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.9650 - val_loss: 0.2120 - val_accuracy: 0.9882\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9670 - val_loss: 0.1998 - val_accuracy: 0.9854\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.9630 - val_loss: 0.2021 - val_accuracy: 0.9874\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.9650 - val_loss: 0.3679 - val_accuracy: 0.9554\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.9665 - val_loss: 0.2259 - val_accuracy: 0.9862\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9688 - val_loss: 0.2178 - val_accuracy: 0.9838\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.9617 - val_loss: 0.2414 - val_accuracy: 0.9811\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.9625 - val_loss: 0.1944 - val_accuracy: 0.9870\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.9532 - val_loss: 0.2395 - val_accuracy: 0.9818\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9645 - val_loss: 0.2212 - val_accuracy: 0.9826\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.9645 - val_loss: 0.1929 - val_accuracy: 0.9866\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9645 - val_loss: 0.1859 - val_accuracy: 0.9886\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.9635 - val_loss: 0.1903 - val_accuracy: 0.9799\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.9668 - val_loss: 0.2193 - val_accuracy: 0.9846\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9640 - val_loss: 0.1839 - val_accuracy: 0.9870\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9647 - val_loss: 0.2720 - val_accuracy: 0.9791\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9622 - val_loss: 0.1822 - val_accuracy: 0.9874\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9647 - val_loss: 0.2016 - val_accuracy: 0.9850\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.9617 - val_loss: 0.1835 - val_accuracy: 0.9870\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9622 - val_loss: 0.1820 - val_accuracy: 0.9886\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.9617 - val_loss: 0.1907 - val_accuracy: 0.9866\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9615 - val_loss: 0.2278 - val_accuracy: 0.9826\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9650 - val_loss: 0.1773 - val_accuracy: 0.9882\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9595 - val_loss: 0.1960 - val_accuracy: 0.9850\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.9632 - val_loss: 0.1846 - val_accuracy: 0.9866\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.9590 - val_loss: 0.2060 - val_accuracy: 0.9850\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9680 - val_loss: 0.1953 - val_accuracy: 0.9838\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9632 - val_loss: 0.1921 - val_accuracy: 0.9874\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9635 - val_loss: 0.1822 - val_accuracy: 0.9897\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9670 - val_loss: 0.1918 - val_accuracy: 0.9850\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9620 - val_loss: 0.1917 - val_accuracy: 0.9850\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.9603 - val_loss: 0.3993 - val_accuracy: 0.9680\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9660 - val_loss: 0.1947 - val_accuracy: 0.9850\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9655 - val_loss: 0.1732 - val_accuracy: 0.9874\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9613 - val_loss: 0.2618 - val_accuracy: 0.9791\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.9607 - val_loss: 0.2179 - val_accuracy: 0.9807\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2419 - accuracy: 0.9665 - val_loss: 0.1943 - val_accuracy: 0.9830\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.9657 - val_loss: 0.1924 - val_accuracy: 0.9866\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9665 - val_loss: 0.2127 - val_accuracy: 0.9826\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2375 - accuracy: 0.9668 - val_loss: 0.1992 - val_accuracy: 0.9862\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9655 - val_loss: 0.1906 - val_accuracy: 0.9866\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9655 - val_loss: 0.1859 - val_accuracy: 0.9858\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9663 - val_loss: 0.1872 - val_accuracy: 0.9858\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9678 - val_loss: 0.2333 - val_accuracy: 0.9846\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9655 - val_loss: 0.1752 - val_accuracy: 0.9878\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9665 - val_loss: 0.1818 - val_accuracy: 0.9874\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.9632 - val_loss: 0.1782 - val_accuracy: 0.9870\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.9620 - val_loss: 0.1770 - val_accuracy: 0.9862\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9655 - val_loss: 0.2022 - val_accuracy: 0.9866\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9625 - val_loss: 0.1937 - val_accuracy: 0.9834\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9672 - val_loss: 0.1920 - val_accuracy: 0.9834\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9635 - val_loss: 0.1898 - val_accuracy: 0.9854\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9643 - val_loss: 0.1913 - val_accuracy: 0.9862\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9647 - val_loss: 0.1810 - val_accuracy: 0.9858\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9682 - val_loss: 0.1981 - val_accuracy: 0.9822\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9668 - val_loss: 0.1948 - val_accuracy: 0.9870\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9657 - val_loss: 0.1715 - val_accuracy: 0.9897\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.9635 - val_loss: 0.1925 - val_accuracy: 0.9834\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9610 - val_loss: 0.2610 - val_accuracy: 0.9791\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9657 - val_loss: 0.1716 - val_accuracy: 0.9870\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.9653 - val_loss: 0.2793 - val_accuracy: 0.9775\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9660 - val_loss: 0.1762 - val_accuracy: 0.9886\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9685 - val_loss: 0.2650 - val_accuracy: 0.9807\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9670 - val_loss: 0.1892 - val_accuracy: 0.9854\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9615 - val_loss: 0.1888 - val_accuracy: 0.9850\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9650 - val_loss: 0.1782 - val_accuracy: 0.9858\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9650 - val_loss: 0.2217 - val_accuracy: 0.9795\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9650 - val_loss: 0.1873 - val_accuracy: 0.9854\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9597 - val_loss: 0.1756 - val_accuracy: 0.9862\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2458 - accuracy: 0.9660 - val_loss: 0.1683 - val_accuracy: 0.9846\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.9660 - val_loss: 0.1802 - val_accuracy: 0.9803\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9650 - val_loss: 0.2871 - val_accuracy: 0.9660\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.9650 - val_loss: 0.1839 - val_accuracy: 0.9842\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9700 - val_loss: 0.1861 - val_accuracy: 0.9874\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9632 - val_loss: 0.1851 - val_accuracy: 0.9866\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9672 - val_loss: 0.1925 - val_accuracy: 0.9830\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9630 - val_loss: 0.1712 - val_accuracy: 0.9866\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9680 - val_loss: 0.1664 - val_accuracy: 0.9886\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9672 - val_loss: 0.1696 - val_accuracy: 0.9886\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.9645 - val_loss: 0.1836 - val_accuracy: 0.9870\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9675 - val_loss: 0.1979 - val_accuracy: 0.9834\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9660 - val_loss: 0.1769 - val_accuracy: 0.9870\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9665 - val_loss: 0.1707 - val_accuracy: 0.9889\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9670 - val_loss: 0.1945 - val_accuracy: 0.9846\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9622 - val_loss: 0.2337 - val_accuracy: 0.9799\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9678 - val_loss: 0.2173 - val_accuracy: 0.9811\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9672 - val_loss: 0.1694 - val_accuracy: 0.9870\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9678 - val_loss: 0.2325 - val_accuracy: 0.9822\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9682 - val_loss: 0.1897 - val_accuracy: 0.9834\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9678 - val_loss: 0.2633 - val_accuracy: 0.9775\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9622 - val_loss: 0.1737 - val_accuracy: 0.9882\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9690 - val_loss: 0.1655 - val_accuracy: 0.9878\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9668 - val_loss: 0.1774 - val_accuracy: 0.9878\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9665 - val_loss: 0.2464 - val_accuracy: 0.9787\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9675 - val_loss: 0.1784 - val_accuracy: 0.9842\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.9628 - val_loss: 0.1913 - val_accuracy: 0.9807\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.9660 - val_loss: 0.1725 - val_accuracy: 0.9870\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9678 - val_loss: 0.2688 - val_accuracy: 0.9771\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9653 - val_loss: 0.2500 - val_accuracy: 0.9779\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9665 - val_loss: 0.1705 - val_accuracy: 0.9905\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.9643 - val_loss: 0.1985 - val_accuracy: 0.9834\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.9590 - val_loss: 0.2145 - val_accuracy: 0.9834\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.9665 - val_loss: 0.1827 - val_accuracy: 0.9866\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9653 - val_loss: 0.1991 - val_accuracy: 0.9818\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9680 - val_loss: 0.2053 - val_accuracy: 0.9834\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9678 - val_loss: 0.2232 - val_accuracy: 0.9822\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2405 - accuracy: 0.9665 - val_loss: 0.1725 - val_accuracy: 0.9874\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9657 - val_loss: 0.1805 - val_accuracy: 0.9846\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9693 - val_loss: 0.1654 - val_accuracy: 0.9893\n",
            "--LR: 0.01\n",
            "--Epochs: 125\n",
            "--Reg params 0.005\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.2015 - accuracy: 0.9775\n",
            "Val accuracy: 0.9775303602218628\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9893\n",
            "Test accuracy: 0.9893407225608826\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 2s 10ms/step - loss: 6.3155 - accuracy: 0.2915 - val_loss: 4.4977 - val_accuracy: 0.0774\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 3.7652 - accuracy: 0.5045 - val_loss: 3.0916 - val_accuracy: 0.8460\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2.7291 - accuracy: 0.5788 - val_loss: 2.2048 - val_accuracy: 0.8634\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.2093 - accuracy: 0.5890 - val_loss: 1.9492 - val_accuracy: 0.8981\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.0258 - accuracy: 0.6177 - val_loss: 1.8009 - val_accuracy: 0.8985\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.9125 - accuracy: 0.6352 - val_loss: 1.7195 - val_accuracy: 0.8962\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.8254 - accuracy: 0.6942 - val_loss: 1.6341 - val_accuracy: 0.9045\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.7444 - accuracy: 0.7168 - val_loss: 1.5336 - val_accuracy: 0.9084\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.6714 - accuracy: 0.7460 - val_loss: 1.4254 - val_accuracy: 0.9305\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5997 - accuracy: 0.7853 - val_loss: 1.3183 - val_accuracy: 0.9353\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.5423 - accuracy: 0.8170 - val_loss: 1.3726 - val_accuracy: 0.9281\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4959 - accuracy: 0.8410 - val_loss: 1.2570 - val_accuracy: 0.9416\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4560 - accuracy: 0.8535 - val_loss: 1.1746 - val_accuracy: 0.9463\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4224 - accuracy: 0.8530 - val_loss: 1.2303 - val_accuracy: 0.9396\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3977 - accuracy: 0.8637 - val_loss: 1.1676 - val_accuracy: 0.9471\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3742 - accuracy: 0.8695 - val_loss: 1.1482 - val_accuracy: 0.9463\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3581 - accuracy: 0.8690 - val_loss: 1.1586 - val_accuracy: 0.9400\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3390 - accuracy: 0.8733 - val_loss: 1.1148 - val_accuracy: 0.9475\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3217 - accuracy: 0.8792 - val_loss: 1.0730 - val_accuracy: 0.9491\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3065 - accuracy: 0.8773 - val_loss: 1.1188 - val_accuracy: 0.9333\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2894 - accuracy: 0.8808 - val_loss: 1.1393 - val_accuracy: 0.9104\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2798 - accuracy: 0.8813 - val_loss: 1.0885 - val_accuracy: 0.9341\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2648 - accuracy: 0.8840 - val_loss: 1.0713 - val_accuracy: 0.9368\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2544 - accuracy: 0.8850 - val_loss: 1.0354 - val_accuracy: 0.9495\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.8863 - val_loss: 1.0777 - val_accuracy: 0.9187\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2370 - accuracy: 0.8855 - val_loss: 1.0442 - val_accuracy: 0.9368\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.8860 - val_loss: 1.0519 - val_accuracy: 0.9281\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2185 - accuracy: 0.8863 - val_loss: 1.0266 - val_accuracy: 0.9376\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2095 - accuracy: 0.8875 - val_loss: 1.0215 - val_accuracy: 0.9380\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2021 - accuracy: 0.8875 - val_loss: 1.0054 - val_accuracy: 0.9428\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1942 - accuracy: 0.8890 - val_loss: 1.0058 - val_accuracy: 0.9380\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1895 - accuracy: 0.8880 - val_loss: 1.0193 - val_accuracy: 0.9214\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1783 - accuracy: 0.8867 - val_loss: 0.9827 - val_accuracy: 0.9459\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1718 - accuracy: 0.8892 - val_loss: 0.9781 - val_accuracy: 0.9432\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1655 - accuracy: 0.8898 - val_loss: 1.0547 - val_accuracy: 0.8989\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1598 - accuracy: 0.8870 - val_loss: 0.9884 - val_accuracy: 0.9313\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1534 - accuracy: 0.8878 - val_loss: 1.0127 - val_accuracy: 0.9124\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1477 - accuracy: 0.8888 - val_loss: 0.9926 - val_accuracy: 0.9147\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1415 - accuracy: 0.8875 - val_loss: 1.0085 - val_accuracy: 0.9076\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1386 - accuracy: 0.8860 - val_loss: 0.9445 - val_accuracy: 0.9451\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1314 - accuracy: 0.8898 - val_loss: 0.9669 - val_accuracy: 0.9214\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1270 - accuracy: 0.8865 - val_loss: 0.9752 - val_accuracy: 0.9147\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1216 - accuracy: 0.8880 - val_loss: 0.9841 - val_accuracy: 0.9096\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1173 - accuracy: 0.8865 - val_loss: 0.9502 - val_accuracy: 0.9270\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1137 - accuracy: 0.8863 - val_loss: 0.9431 - val_accuracy: 0.9309\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1129 - accuracy: 0.8870 - val_loss: 0.9497 - val_accuracy: 0.9183\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1087 - accuracy: 0.8863 - val_loss: 0.9291 - val_accuracy: 0.9392\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1086 - accuracy: 0.8873 - val_loss: 0.9827 - val_accuracy: 0.9041\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.8860 - val_loss: 0.9350 - val_accuracy: 0.9258\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1037 - accuracy: 0.8850 - val_loss: 0.9071 - val_accuracy: 0.9471\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1025 - accuracy: 0.8870 - val_loss: 1.0006 - val_accuracy: 0.9005\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1012 - accuracy: 0.8860 - val_loss: 0.9330 - val_accuracy: 0.9187\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0953 - accuracy: 0.8860 - val_loss: 0.9369 - val_accuracy: 0.9159\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0925 - accuracy: 0.8873 - val_loss: 0.9269 - val_accuracy: 0.9199\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0905 - accuracy: 0.8867 - val_loss: 0.8959 - val_accuracy: 0.9495\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0901 - accuracy: 0.8855 - val_loss: 0.9700 - val_accuracy: 0.9033\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.8848 - val_loss: 0.9069 - val_accuracy: 0.9392\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0877 - accuracy: 0.8870 - val_loss: 1.0149 - val_accuracy: 0.8895\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0863 - accuracy: 0.8850 - val_loss: 0.9098 - val_accuracy: 0.9380\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0842 - accuracy: 0.8855 - val_loss: 0.9226 - val_accuracy: 0.9179\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0858 - accuracy: 0.8850 - val_loss: 0.9159 - val_accuracy: 0.9242\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0862 - accuracy: 0.8845 - val_loss: 0.9404 - val_accuracy: 0.9100\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0810 - accuracy: 0.8865 - val_loss: 0.9654 - val_accuracy: 0.9029\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.8863 - val_loss: 0.9043 - val_accuracy: 0.9341\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0791 - accuracy: 0.8863 - val_loss: 0.9196 - val_accuracy: 0.9155\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0774 - accuracy: 0.8832 - val_loss: 0.9098 - val_accuracy: 0.9262\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.8860 - val_loss: 0.9448 - val_accuracy: 0.9072\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0746 - accuracy: 0.8850 - val_loss: 0.9490 - val_accuracy: 0.9033\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0744 - accuracy: 0.8852 - val_loss: 0.9183 - val_accuracy: 0.9151\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0721 - accuracy: 0.8882 - val_loss: 0.9303 - val_accuracy: 0.9108\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.8870 - val_loss: 0.9839 - val_accuracy: 0.9001\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.8855 - val_loss: 0.9605 - val_accuracy: 0.9009\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0693 - accuracy: 0.8848 - val_loss: 0.9341 - val_accuracy: 0.9076\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0689 - accuracy: 0.8850 - val_loss: 0.9137 - val_accuracy: 0.9139\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0663 - accuracy: 0.8855 - val_loss: 0.9084 - val_accuracy: 0.9147\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0642 - accuracy: 0.8863 - val_loss: 0.8919 - val_accuracy: 0.9329\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0627 - accuracy: 0.8857 - val_loss: 0.9489 - val_accuracy: 0.9037\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0606 - accuracy: 0.8863 - val_loss: 0.8833 - val_accuracy: 0.9368\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0594 - accuracy: 0.8857 - val_loss: 0.8761 - val_accuracy: 0.9396\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0577 - accuracy: 0.8855 - val_loss: 0.9349 - val_accuracy: 0.9053\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0553 - accuracy: 0.8878 - val_loss: 0.9099 - val_accuracy: 0.9116\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0550 - accuracy: 0.8882 - val_loss: 0.9035 - val_accuracy: 0.9124\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0509 - accuracy: 0.8860 - val_loss: 0.8955 - val_accuracy: 0.9139\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0474 - accuracy: 0.8857 - val_loss: 0.8889 - val_accuracy: 0.9167\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0479 - accuracy: 0.8867 - val_loss: 0.8793 - val_accuracy: 0.9246\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0450 - accuracy: 0.8875 - val_loss: 0.9210 - val_accuracy: 0.9064\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0449 - accuracy: 0.8857 - val_loss: 0.9064 - val_accuracy: 0.9096\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0468 - accuracy: 0.8878 - val_loss: 0.9127 - val_accuracy: 0.9072\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0437 - accuracy: 0.8845 - val_loss: 0.9434 - val_accuracy: 0.9013\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0441 - accuracy: 0.8865 - val_loss: 0.9154 - val_accuracy: 0.9068\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.8852 - val_loss: 0.9070 - val_accuracy: 0.9092\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0425 - accuracy: 0.8873 - val_loss: 0.9291 - val_accuracy: 0.9037\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0412 - accuracy: 0.8857 - val_loss: 0.8996 - val_accuracy: 0.9124\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0425 - accuracy: 0.8865 - val_loss: 0.9050 - val_accuracy: 0.9092\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0398 - accuracy: 0.8845 - val_loss: 0.9305 - val_accuracy: 0.9033\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0393 - accuracy: 0.8867 - val_loss: 0.8867 - val_accuracy: 0.9139\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0416 - accuracy: 0.8857 - val_loss: 0.8766 - val_accuracy: 0.9238\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0387 - accuracy: 0.8860 - val_loss: 0.8618 - val_accuracy: 0.9384\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0387 - accuracy: 0.8857 - val_loss: 0.8907 - val_accuracy: 0.9131\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0392 - accuracy: 0.8848 - val_loss: 0.8843 - val_accuracy: 0.9147\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0386 - accuracy: 0.8865 - val_loss: 0.8748 - val_accuracy: 0.9222\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0386 - accuracy: 0.8845 - val_loss: 0.9079 - val_accuracy: 0.9072\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0380 - accuracy: 0.8863 - val_loss: 0.8769 - val_accuracy: 0.9191\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0355 - accuracy: 0.8867 - val_loss: 0.9286 - val_accuracy: 0.9025\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0347 - accuracy: 0.8852 - val_loss: 0.8731 - val_accuracy: 0.9214\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0341 - accuracy: 0.8878 - val_loss: 0.8880 - val_accuracy: 0.9143\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.8880 - val_loss: 0.8930 - val_accuracy: 0.9112\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0329 - accuracy: 0.8885 - val_loss: 0.8729 - val_accuracy: 0.9218\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.8855 - val_loss: 0.8990 - val_accuracy: 0.9092\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.8863 - val_loss: 0.9037 - val_accuracy: 0.9076\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0336 - accuracy: 0.8857 - val_loss: 0.8640 - val_accuracy: 0.9341\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0320 - accuracy: 0.8885 - val_loss: 0.8634 - val_accuracy: 0.9309\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0317 - accuracy: 0.8860 - val_loss: 0.8583 - val_accuracy: 0.9364\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.8880 - val_loss: 0.8997 - val_accuracy: 0.9092\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0297 - accuracy: 0.8873 - val_loss: 0.8823 - val_accuracy: 0.9131\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0284 - accuracy: 0.8873 - val_loss: 0.8745 - val_accuracy: 0.9163\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0271 - accuracy: 0.8890 - val_loss: 0.9190 - val_accuracy: 0.9041\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0283 - accuracy: 0.8882 - val_loss: 0.8808 - val_accuracy: 0.9147\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.8865 - val_loss: 0.8956 - val_accuracy: 0.9092\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.8885 - val_loss: 0.9117 - val_accuracy: 0.9045\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0259 - accuracy: 0.8892 - val_loss: 0.8476 - val_accuracy: 0.9384\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0241 - accuracy: 0.8865 - val_loss: 0.8950 - val_accuracy: 0.9088\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0244 - accuracy: 0.8865 - val_loss: 0.8609 - val_accuracy: 0.9246\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0255 - accuracy: 0.8873 - val_loss: 0.8949 - val_accuracy: 0.9076\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0242 - accuracy: 0.8890 - val_loss: 0.8548 - val_accuracy: 0.9329\n",
            "--LR: 0.001\n",
            "--Epochs: 125\n",
            "--Reg params 0.05\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 1.0205 - accuracy: 0.8927\n",
            "Val accuracy: 0.8927125334739685\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.8548 - accuracy: 0.9329\n",
            "Test accuracy: 0.9328858852386475\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 2.8763 - accuracy: 0.4425 - val_loss: 1.6165 - val_accuracy: 0.8279\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5479 - accuracy: 0.7828 - val_loss: 1.2012 - val_accuracy: 0.8910\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2793 - accuracy: 0.8235 - val_loss: 0.9935 - val_accuracy: 0.9183\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1396 - accuracy: 0.8487 - val_loss: 0.9456 - val_accuracy: 0.8977\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0668 - accuracy: 0.8702 - val_loss: 0.9525 - val_accuracy: 0.8847\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0164 - accuracy: 0.8840 - val_loss: 0.8589 - val_accuracy: 0.9203\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9728 - accuracy: 0.8967 - val_loss: 0.8439 - val_accuracy: 0.9179\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.9075 - val_loss: 0.7829 - val_accuracy: 0.9526\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.8871 - accuracy: 0.9258 - val_loss: 0.7501 - val_accuracy: 0.9597\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8588 - accuracy: 0.9293 - val_loss: 0.7672 - val_accuracy: 0.9688\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8238 - accuracy: 0.9373 - val_loss: 0.7143 - val_accuracy: 0.9684\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.9473 - val_loss: 0.7004 - val_accuracy: 0.9732\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7665 - accuracy: 0.9495 - val_loss: 0.6851 - val_accuracy: 0.9747\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.9517 - val_loss: 0.6550 - val_accuracy: 0.9755\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7223 - accuracy: 0.9553 - val_loss: 0.6306 - val_accuracy: 0.9779\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.9572 - val_loss: 0.6571 - val_accuracy: 0.9767\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.9563 - val_loss: 0.6278 - val_accuracy: 0.9779\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.9565 - val_loss: 0.6160 - val_accuracy: 0.9771\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.9610 - val_loss: 0.6054 - val_accuracy: 0.9787\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.9588 - val_loss: 0.6163 - val_accuracy: 0.9775\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.9615 - val_loss: 0.6082 - val_accuracy: 0.9799\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.9575 - val_loss: 0.5942 - val_accuracy: 0.9795\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.9590 - val_loss: 0.5771 - val_accuracy: 0.9826\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.9585 - val_loss: 0.5739 - val_accuracy: 0.9791\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.9610 - val_loss: 0.5884 - val_accuracy: 0.9779\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.9597 - val_loss: 0.5790 - val_accuracy: 0.9787\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.9595 - val_loss: 0.5669 - val_accuracy: 0.9803\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.9610 - val_loss: 0.5617 - val_accuracy: 0.9803\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.9615 - val_loss: 0.5610 - val_accuracy: 0.9783\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.9628 - val_loss: 0.5425 - val_accuracy: 0.9822\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.9605 - val_loss: 0.5495 - val_accuracy: 0.9783\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.9607 - val_loss: 0.5471 - val_accuracy: 0.9787\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.9600 - val_loss: 0.5201 - val_accuracy: 0.9822\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.9638 - val_loss: 0.5121 - val_accuracy: 0.9830\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.9595 - val_loss: 0.5174 - val_accuracy: 0.9818\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5627 - accuracy: 0.9610 - val_loss: 0.5807 - val_accuracy: 0.9775\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.9607 - val_loss: 0.5195 - val_accuracy: 0.9791\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.9595 - val_loss: 0.5028 - val_accuracy: 0.9826\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.9605 - val_loss: 0.5056 - val_accuracy: 0.9822\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.9605 - val_loss: 0.4887 - val_accuracy: 0.9834\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.9625 - val_loss: 0.4829 - val_accuracy: 0.9834\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.9647 - val_loss: 0.5088 - val_accuracy: 0.9811\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.9625 - val_loss: 0.4969 - val_accuracy: 0.9791\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5299 - accuracy: 0.9640 - val_loss: 0.4831 - val_accuracy: 0.9826\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.9582 - val_loss: 0.5246 - val_accuracy: 0.9799\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.9615 - val_loss: 0.5152 - val_accuracy: 0.9811\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.9635 - val_loss: 0.4693 - val_accuracy: 0.9834\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.9647 - val_loss: 0.4658 - val_accuracy: 0.9830\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.9615 - val_loss: 0.4983 - val_accuracy: 0.9803\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5116 - accuracy: 0.9617 - val_loss: 0.4794 - val_accuracy: 0.9799\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.9630 - val_loss: 0.4635 - val_accuracy: 0.9846\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5049 - accuracy: 0.9638 - val_loss: 0.4537 - val_accuracy: 0.9838\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.9638 - val_loss: 0.4714 - val_accuracy: 0.9795\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.9615 - val_loss: 0.4604 - val_accuracy: 0.9822\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.9632 - val_loss: 0.5117 - val_accuracy: 0.9787\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.9653 - val_loss: 0.4516 - val_accuracy: 0.9842\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.9610 - val_loss: 0.4891 - val_accuracy: 0.9799\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.9630 - val_loss: 0.5216 - val_accuracy: 0.9775\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.9638 - val_loss: 0.4355 - val_accuracy: 0.9838\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.9640 - val_loss: 0.4322 - val_accuracy: 0.9842\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.9657 - val_loss: 0.4502 - val_accuracy: 0.9811\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.9620 - val_loss: 0.4307 - val_accuracy: 0.9838\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.9588 - val_loss: 0.4688 - val_accuracy: 0.9791\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.9638 - val_loss: 0.4641 - val_accuracy: 0.9807\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.9638 - val_loss: 0.4221 - val_accuracy: 0.9830\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.9630 - val_loss: 0.4257 - val_accuracy: 0.9826\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.9615 - val_loss: 0.4086 - val_accuracy: 0.9838\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.9605 - val_loss: 0.4780 - val_accuracy: 0.9779\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.9607 - val_loss: 0.4765 - val_accuracy: 0.9779\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.9635 - val_loss: 0.4156 - val_accuracy: 0.9830\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.9610 - val_loss: 0.4384 - val_accuracy: 0.9811\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.9665 - val_loss: 0.4095 - val_accuracy: 0.9838\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.9655 - val_loss: 0.3974 - val_accuracy: 0.9854\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.9638 - val_loss: 0.4475 - val_accuracy: 0.9799\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.9628 - val_loss: 0.3951 - val_accuracy: 0.9846\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.9635 - val_loss: 0.3987 - val_accuracy: 0.9826\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.9655 - val_loss: 0.4092 - val_accuracy: 0.9822\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.9632 - val_loss: 0.3895 - val_accuracy: 0.9826\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.9643 - val_loss: 0.4318 - val_accuracy: 0.9803\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.9632 - val_loss: 0.4040 - val_accuracy: 0.9830\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.9663 - val_loss: 0.3861 - val_accuracy: 0.9846\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4382 - accuracy: 0.9645 - val_loss: 0.4034 - val_accuracy: 0.9822\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4348 - accuracy: 0.9647 - val_loss: 0.4295 - val_accuracy: 0.9807\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.9657 - val_loss: 0.3873 - val_accuracy: 0.9834\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.9645 - val_loss: 0.4249 - val_accuracy: 0.9811\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.9643 - val_loss: 0.3940 - val_accuracy: 0.9834\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4324 - accuracy: 0.9663 - val_loss: 0.4020 - val_accuracy: 0.9811\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.9628 - val_loss: 0.4159 - val_accuracy: 0.9811\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.9635 - val_loss: 0.3774 - val_accuracy: 0.9842\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.9638 - val_loss: 0.4133 - val_accuracy: 0.9814\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.9653 - val_loss: 0.4073 - val_accuracy: 0.9807\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.9647 - val_loss: 0.3957 - val_accuracy: 0.9811\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.9678 - val_loss: 0.3680 - val_accuracy: 0.9818\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.9625 - val_loss: 0.3718 - val_accuracy: 0.9838\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.9645 - val_loss: 0.3788 - val_accuracy: 0.9846\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4170 - accuracy: 0.9655 - val_loss: 0.3811 - val_accuracy: 0.9830\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.9655 - val_loss: 0.3703 - val_accuracy: 0.9834\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4178 - accuracy: 0.9635 - val_loss: 0.3823 - val_accuracy: 0.9822\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.9657 - val_loss: 0.3808 - val_accuracy: 0.9842\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.9660 - val_loss: 0.3868 - val_accuracy: 0.9814\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.9657 - val_loss: 0.3701 - val_accuracy: 0.9846\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.9675 - val_loss: 0.3606 - val_accuracy: 0.9838\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.9650 - val_loss: 0.3803 - val_accuracy: 0.9826\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4099 - accuracy: 0.9650 - val_loss: 0.3709 - val_accuracy: 0.9830\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.9663 - val_loss: 0.3604 - val_accuracy: 0.9846\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.9615 - val_loss: 0.3691 - val_accuracy: 0.9850\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.9645 - val_loss: 0.3802 - val_accuracy: 0.9822\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.9678 - val_loss: 0.3849 - val_accuracy: 0.9811\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4130 - accuracy: 0.9632 - val_loss: 0.3888 - val_accuracy: 0.9803\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.9663 - val_loss: 0.3755 - val_accuracy: 0.9814\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4073 - accuracy: 0.9653 - val_loss: 0.4219 - val_accuracy: 0.9783\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4062 - accuracy: 0.9645 - val_loss: 0.3771 - val_accuracy: 0.9814\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.9647 - val_loss: 0.3900 - val_accuracy: 0.9814\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.9653 - val_loss: 0.3537 - val_accuracy: 0.9858\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.9668 - val_loss: 0.3565 - val_accuracy: 0.9858\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.9653 - val_loss: 0.3607 - val_accuracy: 0.9854\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.9655 - val_loss: 0.3713 - val_accuracy: 0.9830\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.9653 - val_loss: 0.3716 - val_accuracy: 0.9830\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.9660 - val_loss: 0.3541 - val_accuracy: 0.9858\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.9655 - val_loss: 0.3528 - val_accuracy: 0.9854\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.9650 - val_loss: 0.3545 - val_accuracy: 0.9862\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.9643 - val_loss: 0.3521 - val_accuracy: 0.9854\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4023 - accuracy: 0.9638 - val_loss: 0.3657 - val_accuracy: 0.9846\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.9625 - val_loss: 0.3797 - val_accuracy: 0.9814\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.9672 - val_loss: 0.3839 - val_accuracy: 0.9803\n",
            "--LR: 0.001\n",
            "--Epochs: 125\n",
            "--Reg params 0.01\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.9769\n",
            "Val accuracy: 0.9769230484962463\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.9803\n",
            "Test accuracy: 0.9802605509757996\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 3.5729 - accuracy: 0.4678 - val_loss: 0.6512 - val_accuracy: 0.8741\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9687 - accuracy: 0.5013 - val_loss: 0.5543 - val_accuracy: 0.9064\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8314 - accuracy: 0.7150 - val_loss: 0.5027 - val_accuracy: 0.9341\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7318 - accuracy: 0.8145 - val_loss: 0.4378 - val_accuracy: 0.9412\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6517 - accuracy: 0.8528 - val_loss: 0.3255 - val_accuracy: 0.9507\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5810 - accuracy: 0.8683 - val_loss: 0.2785 - val_accuracy: 0.9597\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5081 - accuracy: 0.8925 - val_loss: 0.2460 - val_accuracy: 0.9637\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.9030 - val_loss: 0.2615 - val_accuracy: 0.9574\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.9087 - val_loss: 0.2047 - val_accuracy: 0.9680\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.9168 - val_loss: 0.2064 - val_accuracy: 0.9688\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.9358 - val_loss: 0.2084 - val_accuracy: 0.9720\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.9448 - val_loss: 0.1747 - val_accuracy: 0.9779\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9498 - val_loss: 0.1727 - val_accuracy: 0.9767\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9553 - val_loss: 0.1569 - val_accuracy: 0.9791\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2284 - accuracy: 0.9617 - val_loss: 0.1742 - val_accuracy: 0.9787\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9610 - val_loss: 0.1878 - val_accuracy: 0.9779\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9638 - val_loss: 0.1506 - val_accuracy: 0.9811\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9632 - val_loss: 0.1509 - val_accuracy: 0.9822\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9645 - val_loss: 0.1560 - val_accuracy: 0.9822\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9655 - val_loss: 0.1382 - val_accuracy: 0.9838\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9657 - val_loss: 0.1357 - val_accuracy: 0.9826\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9640 - val_loss: 0.1434 - val_accuracy: 0.9822\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9663 - val_loss: 0.1350 - val_accuracy: 0.9830\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.9685 - val_loss: 0.1284 - val_accuracy: 0.9846\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9665 - val_loss: 0.1431 - val_accuracy: 0.9822\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9670 - val_loss: 0.1422 - val_accuracy: 0.9842\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1698 - accuracy: 0.9678 - val_loss: 0.1451 - val_accuracy: 0.9811\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9663 - val_loss: 0.1477 - val_accuracy: 0.9811\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9685 - val_loss: 0.1252 - val_accuracy: 0.9850\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9675 - val_loss: 0.1197 - val_accuracy: 0.9878\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9680 - val_loss: 0.1218 - val_accuracy: 0.9842\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9688 - val_loss: 0.1102 - val_accuracy: 0.9882\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1599 - accuracy: 0.9675 - val_loss: 0.1248 - val_accuracy: 0.9838\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9665 - val_loss: 0.1386 - val_accuracy: 0.9822\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9690 - val_loss: 0.1225 - val_accuracy: 0.9866\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9688 - val_loss: 0.1158 - val_accuracy: 0.9874\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1545 - accuracy: 0.9680 - val_loss: 0.1256 - val_accuracy: 0.9850\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9688 - val_loss: 0.1250 - val_accuracy: 0.9850\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9682 - val_loss: 0.1205 - val_accuracy: 0.9870\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9693 - val_loss: 0.1487 - val_accuracy: 0.9834\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9685 - val_loss: 0.1115 - val_accuracy: 0.9893\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9693 - val_loss: 0.1235 - val_accuracy: 0.9866\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1511 - accuracy: 0.9710 - val_loss: 0.1061 - val_accuracy: 0.9897\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9693 - val_loss: 0.1195 - val_accuracy: 0.9870\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9712 - val_loss: 0.1123 - val_accuracy: 0.9882\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9697 - val_loss: 0.1174 - val_accuracy: 0.9886\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9705 - val_loss: 0.1056 - val_accuracy: 0.9897\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9700 - val_loss: 0.1004 - val_accuracy: 0.9913\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9715 - val_loss: 0.1105 - val_accuracy: 0.9882\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9712 - val_loss: 0.0998 - val_accuracy: 0.9901\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9705 - val_loss: 0.1023 - val_accuracy: 0.9905\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9722 - val_loss: 0.1035 - val_accuracy: 0.9901\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9722 - val_loss: 0.1017 - val_accuracy: 0.9897\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9693 - val_loss: 0.0998 - val_accuracy: 0.9905\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9722 - val_loss: 0.1044 - val_accuracy: 0.9901\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9715 - val_loss: 0.1095 - val_accuracy: 0.9889\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9710 - val_loss: 0.1057 - val_accuracy: 0.9897\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9705 - val_loss: 0.1092 - val_accuracy: 0.9878\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9718 - val_loss: 0.1039 - val_accuracy: 0.9897\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9722 - val_loss: 0.1028 - val_accuracy: 0.9897\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9725 - val_loss: 0.1142 - val_accuracy: 0.9886\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9715 - val_loss: 0.0956 - val_accuracy: 0.9913\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9688 - val_loss: 0.1049 - val_accuracy: 0.9893\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9715 - val_loss: 0.1170 - val_accuracy: 0.9886\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.9725 - val_loss: 0.0998 - val_accuracy: 0.9897\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9728 - val_loss: 0.1194 - val_accuracy: 0.9893\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9730 - val_loss: 0.1000 - val_accuracy: 0.9925\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1366 - accuracy: 0.9720 - val_loss: 0.0954 - val_accuracy: 0.9909\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9732 - val_loss: 0.0989 - val_accuracy: 0.9905\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9728 - val_loss: 0.0982 - val_accuracy: 0.9901\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1435 - accuracy: 0.9712 - val_loss: 0.0967 - val_accuracy: 0.9901\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1363 - accuracy: 0.9720 - val_loss: 0.1070 - val_accuracy: 0.9893\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9722 - val_loss: 0.1006 - val_accuracy: 0.9893\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9718 - val_loss: 0.1084 - val_accuracy: 0.9882\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9737 - val_loss: 0.1052 - val_accuracy: 0.9889\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9732 - val_loss: 0.1038 - val_accuracy: 0.9893\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9737 - val_loss: 0.0990 - val_accuracy: 0.9897\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1354 - accuracy: 0.9750 - val_loss: 0.1036 - val_accuracy: 0.9886\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9720 - val_loss: 0.0979 - val_accuracy: 0.9901\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9745 - val_loss: 0.0966 - val_accuracy: 0.9921\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9732 - val_loss: 0.1130 - val_accuracy: 0.9886\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9735 - val_loss: 0.1126 - val_accuracy: 0.9886\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9725 - val_loss: 0.0979 - val_accuracy: 0.9893\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1354 - accuracy: 0.9725 - val_loss: 0.0937 - val_accuracy: 0.9909\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9735 - val_loss: 0.0963 - val_accuracy: 0.9893\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9728 - val_loss: 0.0967 - val_accuracy: 0.9917\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9755 - val_loss: 0.0910 - val_accuracy: 0.9929\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9747 - val_loss: 0.0997 - val_accuracy: 0.9886\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9740 - val_loss: 0.0945 - val_accuracy: 0.9921\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9732 - val_loss: 0.1347 - val_accuracy: 0.9882\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9730 - val_loss: 0.0918 - val_accuracy: 0.9897\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9737 - val_loss: 0.1019 - val_accuracy: 0.9889\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9745 - val_loss: 0.1035 - val_accuracy: 0.9893\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9758 - val_loss: 0.0968 - val_accuracy: 0.9897\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9743 - val_loss: 0.0895 - val_accuracy: 0.9905\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9755 - val_loss: 0.0949 - val_accuracy: 0.9893\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9735 - val_loss: 0.0974 - val_accuracy: 0.9897\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9750 - val_loss: 0.0889 - val_accuracy: 0.9905\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9743 - val_loss: 0.1010 - val_accuracy: 0.9893\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9743 - val_loss: 0.1277 - val_accuracy: 0.9878\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9747 - val_loss: 0.0914 - val_accuracy: 0.9905\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1284 - accuracy: 0.9740 - val_loss: 0.0894 - val_accuracy: 0.9913\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9735 - val_loss: 0.1182 - val_accuracy: 0.9886\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9743 - val_loss: 0.0949 - val_accuracy: 0.9889\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9737 - val_loss: 0.0938 - val_accuracy: 0.9897\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9722 - val_loss: 0.1031 - val_accuracy: 0.9889\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9745 - val_loss: 0.0950 - val_accuracy: 0.9893\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1238 - accuracy: 0.9768 - val_loss: 0.1207 - val_accuracy: 0.9882\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9755 - val_loss: 0.0972 - val_accuracy: 0.9893\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9753 - val_loss: 0.0948 - val_accuracy: 0.9901\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9745 - val_loss: 0.0959 - val_accuracy: 0.9917\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9745 - val_loss: 0.0923 - val_accuracy: 0.9893\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9762 - val_loss: 0.0891 - val_accuracy: 0.9897\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9745 - val_loss: 0.0934 - val_accuracy: 0.9897\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9758 - val_loss: 0.0900 - val_accuracy: 0.9905\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9760 - val_loss: 0.0881 - val_accuracy: 0.9909\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9747 - val_loss: 0.0985 - val_accuracy: 0.9889\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9758 - val_loss: 0.0932 - val_accuracy: 0.9901\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9770 - val_loss: 0.0866 - val_accuracy: 0.9933\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9735 - val_loss: 0.0880 - val_accuracy: 0.9921\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9765 - val_loss: 0.0920 - val_accuracy: 0.9893\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9755 - val_loss: 0.1341 - val_accuracy: 0.9854\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9755 - val_loss: 0.0972 - val_accuracy: 0.9882\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9760 - val_loss: 0.1072 - val_accuracy: 0.9886\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1207 - accuracy: 0.9765 - val_loss: 0.0886 - val_accuracy: 0.9913\n",
            "--LR: 0.001\n",
            "--Epochs: 125\n",
            "--Reg params 0.001\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9895\n",
            "Val accuracy: 0.9894737005233765\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9913\n",
            "Test accuracy: 0.9913146495819092\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 2.0566 - accuracy: 0.4723 - val_loss: 0.9889 - val_accuracy: 0.8370\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3373 - accuracy: 0.6070 - val_loss: 0.7808 - val_accuracy: 0.8713\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1425 - accuracy: 0.6635 - val_loss: 0.6643 - val_accuracy: 0.8985\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0093 - accuracy: 0.6970 - val_loss: 0.5934 - val_accuracy: 0.9068\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9122 - accuracy: 0.7330 - val_loss: 0.5363 - val_accuracy: 0.9278\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.8700 - val_loss: 0.4884 - val_accuracy: 0.9716\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.9492 - val_loss: 0.4161 - val_accuracy: 0.9771\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.9517 - val_loss: 0.4023 - val_accuracy: 0.9791\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.9557 - val_loss: 0.4142 - val_accuracy: 0.9763\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.9575 - val_loss: 0.3963 - val_accuracy: 0.9779\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.9567 - val_loss: 0.3862 - val_accuracy: 0.9787\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.9570 - val_loss: 0.3882 - val_accuracy: 0.9767\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.9592 - val_loss: 0.3723 - val_accuracy: 0.9795\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.9582 - val_loss: 0.3514 - val_accuracy: 0.9799\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.9575 - val_loss: 0.3552 - val_accuracy: 0.9783\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4038 - accuracy: 0.9580 - val_loss: 0.3625 - val_accuracy: 0.9775\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.9595 - val_loss: 0.3475 - val_accuracy: 0.9787\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3946 - accuracy: 0.9613 - val_loss: 0.3677 - val_accuracy: 0.9783\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.9620 - val_loss: 0.3393 - val_accuracy: 0.9795\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.9605 - val_loss: 0.3273 - val_accuracy: 0.9803\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.9610 - val_loss: 0.3275 - val_accuracy: 0.9807\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.9635 - val_loss: 0.3108 - val_accuracy: 0.9811\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.9643 - val_loss: 0.3167 - val_accuracy: 0.9807\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.9643 - val_loss: 0.3537 - val_accuracy: 0.9799\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.9645 - val_loss: 0.3055 - val_accuracy: 0.9799\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.9647 - val_loss: 0.3120 - val_accuracy: 0.9795\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.9628 - val_loss: 0.3391 - val_accuracy: 0.9795\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.9647 - val_loss: 0.2955 - val_accuracy: 0.9830\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.9645 - val_loss: 0.3186 - val_accuracy: 0.9818\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.9657 - val_loss: 0.3041 - val_accuracy: 0.9811\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.9660 - val_loss: 0.2903 - val_accuracy: 0.9799\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.9643 - val_loss: 0.2949 - val_accuracy: 0.9822\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.9655 - val_loss: 0.2856 - val_accuracy: 0.9826\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.9672 - val_loss: 0.2968 - val_accuracy: 0.9830\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.9655 - val_loss: 0.3024 - val_accuracy: 0.9834\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.9675 - val_loss: 0.2716 - val_accuracy: 0.9846\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.9668 - val_loss: 0.2884 - val_accuracy: 0.9818\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.9672 - val_loss: 0.2625 - val_accuracy: 0.9826\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.9672 - val_loss: 0.2792 - val_accuracy: 0.9818\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.9660 - val_loss: 0.2565 - val_accuracy: 0.9850\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3161 - accuracy: 0.9660 - val_loss: 0.2609 - val_accuracy: 0.9842\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.9665 - val_loss: 0.2798 - val_accuracy: 0.9830\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.9675 - val_loss: 0.2599 - val_accuracy: 0.9834\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.9668 - val_loss: 0.2869 - val_accuracy: 0.9826\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.9663 - val_loss: 0.2525 - val_accuracy: 0.9850\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.9680 - val_loss: 0.2679 - val_accuracy: 0.9830\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.9675 - val_loss: 0.2590 - val_accuracy: 0.9838\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.9668 - val_loss: 0.2502 - val_accuracy: 0.9846\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.9665 - val_loss: 0.2570 - val_accuracy: 0.9822\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.9685 - val_loss: 0.2662 - val_accuracy: 0.9834\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.9682 - val_loss: 0.2681 - val_accuracy: 0.9846\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.9670 - val_loss: 0.3024 - val_accuracy: 0.9799\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.9665 - val_loss: 0.2422 - val_accuracy: 0.9854\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.9665 - val_loss: 0.2697 - val_accuracy: 0.9834\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.9670 - val_loss: 0.2353 - val_accuracy: 0.9834\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9680 - val_loss: 0.2321 - val_accuracy: 0.9858\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.9663 - val_loss: 0.2561 - val_accuracy: 0.9830\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.9670 - val_loss: 0.2407 - val_accuracy: 0.9850\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.9670 - val_loss: 0.2396 - val_accuracy: 0.9842\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2881 - accuracy: 0.9688 - val_loss: 0.2794 - val_accuracy: 0.9803\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.9680 - val_loss: 0.2381 - val_accuracy: 0.9846\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9657 - val_loss: 0.2410 - val_accuracy: 0.9842\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.9688 - val_loss: 0.2350 - val_accuracy: 0.9858\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2829 - accuracy: 0.9665 - val_loss: 0.2398 - val_accuracy: 0.9838\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2818 - accuracy: 0.9682 - val_loss: 0.2321 - val_accuracy: 0.9854\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.9695 - val_loss: 0.2649 - val_accuracy: 0.9818\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.9678 - val_loss: 0.2520 - val_accuracy: 0.9838\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.9705 - val_loss: 0.2268 - val_accuracy: 0.9858\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9665 - val_loss: 0.2306 - val_accuracy: 0.9858\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9665 - val_loss: 0.2618 - val_accuracy: 0.9842\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.9672 - val_loss: 0.2232 - val_accuracy: 0.9866\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9703 - val_loss: 0.2273 - val_accuracy: 0.9862\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.9685 - val_loss: 0.2521 - val_accuracy: 0.9838\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.9688 - val_loss: 0.2639 - val_accuracy: 0.9814\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.9690 - val_loss: 0.2717 - val_accuracy: 0.9814\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9685 - val_loss: 0.2307 - val_accuracy: 0.9854\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.9680 - val_loss: 0.2377 - val_accuracy: 0.9834\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.9682 - val_loss: 0.2187 - val_accuracy: 0.9874\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9693 - val_loss: 0.2431 - val_accuracy: 0.9862\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.9680 - val_loss: 0.2270 - val_accuracy: 0.9858\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9670 - val_loss: 0.2487 - val_accuracy: 0.9822\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.9678 - val_loss: 0.2495 - val_accuracy: 0.9834\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.9682 - val_loss: 0.2319 - val_accuracy: 0.9850\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2641 - accuracy: 0.9685 - val_loss: 0.2733 - val_accuracy: 0.9803\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.9678 - val_loss: 0.2169 - val_accuracy: 0.9874\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9670 - val_loss: 0.2146 - val_accuracy: 0.9874\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9688 - val_loss: 0.2603 - val_accuracy: 0.9811\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.9700 - val_loss: 0.2407 - val_accuracy: 0.9842\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.9685 - val_loss: 0.2105 - val_accuracy: 0.9874\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.9675 - val_loss: 0.2206 - val_accuracy: 0.9870\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2665 - accuracy: 0.9695 - val_loss: 0.2145 - val_accuracy: 0.9886\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9685 - val_loss: 0.2229 - val_accuracy: 0.9878\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9685 - val_loss: 0.2224 - val_accuracy: 0.9862\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.9705 - val_loss: 0.2450 - val_accuracy: 0.9826\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9695 - val_loss: 0.2151 - val_accuracy: 0.9886\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.9682 - val_loss: 0.2113 - val_accuracy: 0.9886\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9705 - val_loss: 0.2091 - val_accuracy: 0.9874\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2630 - accuracy: 0.9672 - val_loss: 0.2165 - val_accuracy: 0.9886\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2595 - accuracy: 0.9688 - val_loss: 0.2044 - val_accuracy: 0.9878\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2584 - accuracy: 0.9693 - val_loss: 0.2153 - val_accuracy: 0.9862\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9690 - val_loss: 0.2083 - val_accuracy: 0.9886\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9688 - val_loss: 0.2109 - val_accuracy: 0.9889\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9697 - val_loss: 0.2749 - val_accuracy: 0.9807\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9697 - val_loss: 0.2293 - val_accuracy: 0.9854\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9693 - val_loss: 0.2077 - val_accuracy: 0.9886\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.9680 - val_loss: 0.2026 - val_accuracy: 0.9882\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9693 - val_loss: 0.2139 - val_accuracy: 0.9874\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9705 - val_loss: 0.2101 - val_accuracy: 0.9893\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9680 - val_loss: 0.2049 - val_accuracy: 0.9897\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9680 - val_loss: 0.2217 - val_accuracy: 0.9858\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9693 - val_loss: 0.2081 - val_accuracy: 0.9893\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2556 - accuracy: 0.9695 - val_loss: 0.2111 - val_accuracy: 0.9886\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9688 - val_loss: 0.2064 - val_accuracy: 0.9893\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9690 - val_loss: 0.2003 - val_accuracy: 0.9889\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2526 - accuracy: 0.9695 - val_loss: 0.2193 - val_accuracy: 0.9862\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9688 - val_loss: 0.2209 - val_accuracy: 0.9858\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2544 - accuracy: 0.9690 - val_loss: 0.2154 - val_accuracy: 0.9886\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9693 - val_loss: 0.1982 - val_accuracy: 0.9886\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.9682 - val_loss: 0.2065 - val_accuracy: 0.9897\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9705 - val_loss: 0.2010 - val_accuracy: 0.9893\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9690 - val_loss: 0.2052 - val_accuracy: 0.9893\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2490 - accuracy: 0.9690 - val_loss: 0.2280 - val_accuracy: 0.9854\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2517 - accuracy: 0.9707 - val_loss: 0.2154 - val_accuracy: 0.9882\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9700 - val_loss: 0.2296 - val_accuracy: 0.9854\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2521 - accuracy: 0.9697 - val_loss: 0.2011 - val_accuracy: 0.9897\n",
            "--LR: 0.001\n",
            "--Epochs: 125\n",
            "--Reg params 0.005\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.9721\n",
            "Val accuracy: 0.9720647931098938\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9897\n",
            "Test accuracy: 0.98973548412323\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 10.1275 - accuracy: 0.2500 - val_loss: 6.0787 - val_accuracy: 0.8125\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 8.4937 - accuracy: 0.2500 - val_loss: 5.7702 - val_accuracy: 0.8125\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 7.5310 - accuracy: 0.2503 - val_loss: 5.5142 - val_accuracy: 0.8137\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 6.7308 - accuracy: 0.2508 - val_loss: 5.2933 - val_accuracy: 0.8148\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 6.0741 - accuracy: 0.2565 - val_loss: 5.1330 - val_accuracy: 0.8184\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 5.5923 - accuracy: 0.3015 - val_loss: 5.0311 - val_accuracy: 0.8370\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 5.2785 - accuracy: 0.3845 - val_loss: 4.9207 - val_accuracy: 0.8575\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0481 - accuracy: 0.4435 - val_loss: 4.7286 - val_accuracy: 0.8693\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8502 - accuracy: 0.4750 - val_loss: 4.5395 - val_accuracy: 0.8725\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.6645 - accuracy: 0.4908 - val_loss: 4.3449 - val_accuracy: 0.8733\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.4855 - accuracy: 0.4880 - val_loss: 4.1417 - val_accuracy: 0.8721\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.3119 - accuracy: 0.4882 - val_loss: 3.9597 - val_accuracy: 0.8705\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.1436 - accuracy: 0.4870 - val_loss: 3.7677 - val_accuracy: 0.8689\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3.9797 - accuracy: 0.4793 - val_loss: 3.6014 - val_accuracy: 0.8693\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3.8203 - accuracy: 0.4735 - val_loss: 3.4366 - val_accuracy: 0.8681\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 3.6639 - accuracy: 0.4635 - val_loss: 3.2621 - val_accuracy: 0.8693\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3.5066 - accuracy: 0.4640 - val_loss: 3.0968 - val_accuracy: 0.8697\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3.3660 - accuracy: 0.4618 - val_loss: 2.9497 - val_accuracy: 0.8662\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 3.2320 - accuracy: 0.4635 - val_loss: 2.7925 - val_accuracy: 0.8638\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3.1074 - accuracy: 0.4518 - val_loss: 2.6945 - val_accuracy: 0.8658\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.9902 - accuracy: 0.4505 - val_loss: 2.5808 - val_accuracy: 0.8666\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.8786 - accuracy: 0.4543 - val_loss: 2.4532 - val_accuracy: 0.8642\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.7706 - accuracy: 0.4473 - val_loss: 2.3661 - val_accuracy: 0.8646\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.6675 - accuracy: 0.4448 - val_loss: 2.2570 - val_accuracy: 0.8642\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.5703 - accuracy: 0.4420 - val_loss: 2.1573 - val_accuracy: 0.8626\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.4801 - accuracy: 0.4370 - val_loss: 2.0813 - val_accuracy: 0.8630\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.3982 - accuracy: 0.4372 - val_loss: 2.0004 - val_accuracy: 0.8630\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.3208 - accuracy: 0.4308 - val_loss: 1.9198 - val_accuracy: 0.8622\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.2468 - accuracy: 0.4305 - val_loss: 1.8700 - val_accuracy: 0.8622\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.1772 - accuracy: 0.4305 - val_loss: 1.8071 - val_accuracy: 0.8638\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.1128 - accuracy: 0.4345 - val_loss: 1.7427 - val_accuracy: 0.8630\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.0547 - accuracy: 0.4300 - val_loss: 1.6839 - val_accuracy: 0.8630\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.0029 - accuracy: 0.4302 - val_loss: 1.6633 - val_accuracy: 0.8634\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.9609 - accuracy: 0.4295 - val_loss: 1.6149 - val_accuracy: 0.8626\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.9257 - accuracy: 0.4325 - val_loss: 1.5734 - val_accuracy: 0.8626\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.8946 - accuracy: 0.4308 - val_loss: 1.5499 - val_accuracy: 0.8626\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8699 - accuracy: 0.4313 - val_loss: 1.5271 - val_accuracy: 0.8626\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.8483 - accuracy: 0.4335 - val_loss: 1.5123 - val_accuracy: 0.8634\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8283 - accuracy: 0.4392 - val_loss: 1.4915 - val_accuracy: 0.8626\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8105 - accuracy: 0.4380 - val_loss: 1.4700 - val_accuracy: 0.8626\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7933 - accuracy: 0.4417 - val_loss: 1.4668 - val_accuracy: 0.8764\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.7771 - accuracy: 0.4470 - val_loss: 1.4431 - val_accuracy: 0.8681\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7613 - accuracy: 0.4505 - val_loss: 1.4218 - val_accuracy: 0.8642\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7466 - accuracy: 0.4557 - val_loss: 1.4251 - val_accuracy: 0.8741\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.7321 - accuracy: 0.4627 - val_loss: 1.4044 - val_accuracy: 0.8764\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7176 - accuracy: 0.4723 - val_loss: 1.3696 - val_accuracy: 0.8670\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.7037 - accuracy: 0.4755 - val_loss: 1.3648 - val_accuracy: 0.8812\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6905 - accuracy: 0.4863 - val_loss: 1.3560 - val_accuracy: 0.8827\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.6775 - accuracy: 0.5042 - val_loss: 1.3353 - val_accuracy: 0.8824\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.6650 - accuracy: 0.5073 - val_loss: 1.3440 - val_accuracy: 0.8954\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6532 - accuracy: 0.5253 - val_loss: 1.3177 - val_accuracy: 0.8922\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6412 - accuracy: 0.5303 - val_loss: 1.3054 - val_accuracy: 0.8910\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6293 - accuracy: 0.5447 - val_loss: 1.2852 - val_accuracy: 0.8946\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.6176 - accuracy: 0.5558 - val_loss: 1.2818 - val_accuracy: 0.8958\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6057 - accuracy: 0.5663 - val_loss: 1.2836 - val_accuracy: 0.9049\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5947 - accuracy: 0.5840 - val_loss: 1.2580 - val_accuracy: 0.8993\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5836 - accuracy: 0.5905 - val_loss: 1.2509 - val_accuracy: 0.9025\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.5727 - accuracy: 0.6102 - val_loss: 1.2390 - val_accuracy: 0.9068\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5616 - accuracy: 0.6302 - val_loss: 1.2084 - val_accuracy: 0.9060\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5517 - accuracy: 0.6320 - val_loss: 1.2203 - val_accuracy: 0.9116\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.5424 - accuracy: 0.6413 - val_loss: 1.2118 - val_accuracy: 0.9116\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5333 - accuracy: 0.6510 - val_loss: 1.1977 - val_accuracy: 0.9139\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.5246 - accuracy: 0.6685 - val_loss: 1.2018 - val_accuracy: 0.9234\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5159 - accuracy: 0.6837 - val_loss: 1.1949 - val_accuracy: 0.9281\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5076 - accuracy: 0.6925 - val_loss: 1.1950 - val_accuracy: 0.9349\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4991 - accuracy: 0.7172 - val_loss: 1.1806 - val_accuracy: 0.9297\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4912 - accuracy: 0.7278 - val_loss: 1.1597 - val_accuracy: 0.9195\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4831 - accuracy: 0.7300 - val_loss: 1.1545 - val_accuracy: 0.9222\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4749 - accuracy: 0.7380 - val_loss: 1.1538 - val_accuracy: 0.9305\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4665 - accuracy: 0.7588 - val_loss: 1.1446 - val_accuracy: 0.9313\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4584 - accuracy: 0.7617 - val_loss: 1.1448 - val_accuracy: 0.9376\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4503 - accuracy: 0.7812 - val_loss: 1.1346 - val_accuracy: 0.9380\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4418 - accuracy: 0.7785 - val_loss: 1.1337 - val_accuracy: 0.9404\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4341 - accuracy: 0.7983 - val_loss: 1.1232 - val_accuracy: 0.9396\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4265 - accuracy: 0.8030 - val_loss: 1.1208 - val_accuracy: 0.9416\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4189 - accuracy: 0.8112 - val_loss: 1.1108 - val_accuracy: 0.9424\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4111 - accuracy: 0.8190 - val_loss: 1.1044 - val_accuracy: 0.9459\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.4032 - accuracy: 0.8213 - val_loss: 1.1036 - val_accuracy: 0.9491\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3956 - accuracy: 0.8360 - val_loss: 1.0912 - val_accuracy: 0.9507\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3879 - accuracy: 0.8425 - val_loss: 1.0778 - val_accuracy: 0.9479\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3804 - accuracy: 0.8420 - val_loss: 1.0783 - val_accuracy: 0.9526\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3734 - accuracy: 0.8510 - val_loss: 1.0725 - val_accuracy: 0.9514\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3667 - accuracy: 0.8540 - val_loss: 1.0626 - val_accuracy: 0.9530\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3596 - accuracy: 0.8553 - val_loss: 1.0577 - val_accuracy: 0.9554\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3526 - accuracy: 0.8622 - val_loss: 1.0486 - val_accuracy: 0.9542\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3461 - accuracy: 0.8593 - val_loss: 1.0520 - val_accuracy: 0.9558\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3400 - accuracy: 0.8695 - val_loss: 1.0372 - val_accuracy: 0.9562\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3338 - accuracy: 0.8692 - val_loss: 1.0266 - val_accuracy: 0.9582\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3277 - accuracy: 0.8702 - val_loss: 1.0250 - val_accuracy: 0.9574\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3214 - accuracy: 0.8733 - val_loss: 1.0210 - val_accuracy: 0.9582\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3149 - accuracy: 0.8725 - val_loss: 1.0221 - val_accuracy: 0.9585\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3086 - accuracy: 0.8760 - val_loss: 1.0160 - val_accuracy: 0.9585\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3027 - accuracy: 0.8755 - val_loss: 1.0089 - val_accuracy: 0.9613\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2969 - accuracy: 0.8800 - val_loss: 1.0020 - val_accuracy: 0.9613\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2913 - accuracy: 0.8795 - val_loss: 0.9998 - val_accuracy: 0.9613\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2853 - accuracy: 0.8808 - val_loss: 0.9877 - val_accuracy: 0.9617\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2799 - accuracy: 0.8820 - val_loss: 0.9830 - val_accuracy: 0.9617\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2752 - accuracy: 0.8815 - val_loss: 0.9826 - val_accuracy: 0.9613\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2705 - accuracy: 0.8827 - val_loss: 0.9792 - val_accuracy: 0.9617\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2657 - accuracy: 0.8842 - val_loss: 0.9694 - val_accuracy: 0.9625\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2609 - accuracy: 0.8848 - val_loss: 0.9725 - val_accuracy: 0.9625\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2559 - accuracy: 0.8878 - val_loss: 0.9598 - val_accuracy: 0.9621\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2509 - accuracy: 0.8860 - val_loss: 0.9627 - val_accuracy: 0.9625\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2459 - accuracy: 0.8865 - val_loss: 0.9569 - val_accuracy: 0.9625\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2413 - accuracy: 0.8892 - val_loss: 0.9590 - val_accuracy: 0.9625\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2371 - accuracy: 0.8903 - val_loss: 0.9511 - val_accuracy: 0.9625\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2332 - accuracy: 0.8898 - val_loss: 0.9478 - val_accuracy: 0.9621\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2297 - accuracy: 0.8900 - val_loss: 0.9453 - val_accuracy: 0.9621\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2264 - accuracy: 0.8903 - val_loss: 0.9390 - val_accuracy: 0.9621\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2234 - accuracy: 0.8903 - val_loss: 0.9396 - val_accuracy: 0.9621\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2208 - accuracy: 0.8910 - val_loss: 0.9340 - val_accuracy: 0.9621\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2180 - accuracy: 0.8900 - val_loss: 0.9334 - val_accuracy: 0.9621\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2156 - accuracy: 0.8905 - val_loss: 0.9319 - val_accuracy: 0.9621\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.2135 - accuracy: 0.8907 - val_loss: 0.9379 - val_accuracy: 0.9621\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2115 - accuracy: 0.8920 - val_loss: 0.9295 - val_accuracy: 0.9621\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2095 - accuracy: 0.8907 - val_loss: 0.9258 - val_accuracy: 0.9621\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2075 - accuracy: 0.8923 - val_loss: 0.9263 - val_accuracy: 0.9617\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2055 - accuracy: 0.8917 - val_loss: 0.9274 - val_accuracy: 0.9621\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2036 - accuracy: 0.8915 - val_loss: 0.9239 - val_accuracy: 0.9621\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2017 - accuracy: 0.8920 - val_loss: 0.9262 - val_accuracy: 0.9621\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1998 - accuracy: 0.8923 - val_loss: 0.9252 - val_accuracy: 0.9625\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1978 - accuracy: 0.8920 - val_loss: 0.9237 - val_accuracy: 0.9625\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1959 - accuracy: 0.8928 - val_loss: 0.9192 - val_accuracy: 0.9621\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1942 - accuracy: 0.8923 - val_loss: 0.9227 - val_accuracy: 0.9641\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1926 - accuracy: 0.8935 - val_loss: 0.9180 - val_accuracy: 0.9633\n",
            "--LR: 0.0001\n",
            "--Epochs: 125\n",
            "--Reg params 0.05\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 1.1805 - accuracy: 0.9123\n",
            "Val accuracy: 0.9123481512069702\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.9180 - accuracy: 0.9633\n",
            "Test accuracy: 0.9632846713066101\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 5.3411 - accuracy: 0.2560 - val_loss: 2.2657 - val_accuracy: 0.8204\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 3.8069 - accuracy: 0.4087 - val_loss: 2.3058 - val_accuracy: 0.8638\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 3.3304 - accuracy: 0.5842 - val_loss: 2.1609 - val_accuracy: 0.8571\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.9408 - accuracy: 0.6062 - val_loss: 2.0240 - val_accuracy: 0.8662\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 2.6156 - accuracy: 0.6135 - val_loss: 1.9287 - val_accuracy: 0.8030\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.3674 - accuracy: 0.6250 - val_loss: 1.8183 - val_accuracy: 0.8452\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.2033 - accuracy: 0.6405 - val_loss: 1.7434 - val_accuracy: 0.8460\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.0905 - accuracy: 0.6410 - val_loss: 1.6354 - val_accuracy: 0.8654\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.0083 - accuracy: 0.6430 - val_loss: 1.5974 - val_accuracy: 0.8516\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.9410 - accuracy: 0.6505 - val_loss: 1.5025 - val_accuracy: 0.8701\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8809 - accuracy: 0.6525 - val_loss: 1.4764 - val_accuracy: 0.8539\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8260 - accuracy: 0.6538 - val_loss: 1.4581 - val_accuracy: 0.8448\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7787 - accuracy: 0.6635 - val_loss: 1.3860 - val_accuracy: 0.8595\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.7356 - accuracy: 0.6637 - val_loss: 1.3419 - val_accuracy: 0.8630\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6956 - accuracy: 0.6722 - val_loss: 1.2948 - val_accuracy: 0.8670\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6594 - accuracy: 0.6808 - val_loss: 1.2792 - val_accuracy: 0.8630\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6246 - accuracy: 0.6865 - val_loss: 1.2344 - val_accuracy: 0.8705\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5922 - accuracy: 0.6995 - val_loss: 1.2104 - val_accuracy: 0.8717\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.5619 - accuracy: 0.6995 - val_loss: 1.1719 - val_accuracy: 0.8780\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5337 - accuracy: 0.7055 - val_loss: 1.1716 - val_accuracy: 0.8685\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.5051 - accuracy: 0.7130 - val_loss: 1.1256 - val_accuracy: 0.8867\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4790 - accuracy: 0.7172 - val_loss: 1.1134 - val_accuracy: 0.8859\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.4527 - accuracy: 0.7203 - val_loss: 1.1059 - val_accuracy: 0.8764\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4291 - accuracy: 0.7283 - val_loss: 1.0857 - val_accuracy: 0.8847\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4070 - accuracy: 0.7333 - val_loss: 1.0411 - val_accuracy: 0.9017\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3849 - accuracy: 0.7442 - val_loss: 1.0537 - val_accuracy: 0.8867\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3646 - accuracy: 0.7498 - val_loss: 1.0388 - val_accuracy: 0.8883\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3449 - accuracy: 0.7570 - val_loss: 0.9899 - val_accuracy: 0.9076\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.3254 - accuracy: 0.7577 - val_loss: 1.0030 - val_accuracy: 0.8977\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3067 - accuracy: 0.7663 - val_loss: 0.9856 - val_accuracy: 0.9025\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2905 - accuracy: 0.7717 - val_loss: 0.9660 - val_accuracy: 0.9021\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2726 - accuracy: 0.7725 - val_loss: 0.9547 - val_accuracy: 0.9084\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2585 - accuracy: 0.7755 - val_loss: 0.9499 - val_accuracy: 0.9025\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2428 - accuracy: 0.7830 - val_loss: 0.9414 - val_accuracy: 0.8966\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2301 - accuracy: 0.7830 - val_loss: 0.9216 - val_accuracy: 0.9029\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2164 - accuracy: 0.7905 - val_loss: 0.9032 - val_accuracy: 0.9108\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2025 - accuracy: 0.7920 - val_loss: 0.9145 - val_accuracy: 0.9080\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1908 - accuracy: 0.7952 - val_loss: 0.8991 - val_accuracy: 0.9116\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1785 - accuracy: 0.8018 - val_loss: 0.9045 - val_accuracy: 0.9029\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.1667 - accuracy: 0.8058 - val_loss: 0.8902 - val_accuracy: 0.9088\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1567 - accuracy: 0.8080 - val_loss: 0.8725 - val_accuracy: 0.9143\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1456 - accuracy: 0.8117 - val_loss: 0.8970 - val_accuracy: 0.8926\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1356 - accuracy: 0.8145 - val_loss: 0.8579 - val_accuracy: 0.9183\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1251 - accuracy: 0.8223 - val_loss: 0.8619 - val_accuracy: 0.9167\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1153 - accuracy: 0.8215 - val_loss: 0.8504 - val_accuracy: 0.9187\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.8273 - val_loss: 0.8390 - val_accuracy: 0.9195\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0955 - accuracy: 0.8313 - val_loss: 0.8520 - val_accuracy: 0.9108\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0870 - accuracy: 0.8340 - val_loss: 0.8297 - val_accuracy: 0.9218\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0792 - accuracy: 0.8363 - val_loss: 0.8418 - val_accuracy: 0.9147\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0689 - accuracy: 0.8390 - val_loss: 0.8324 - val_accuracy: 0.9218\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0606 - accuracy: 0.8497 - val_loss: 0.8425 - val_accuracy: 0.9104\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0520 - accuracy: 0.8468 - val_loss: 0.8033 - val_accuracy: 0.9368\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0453 - accuracy: 0.8472 - val_loss: 0.8084 - val_accuracy: 0.9313\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0376 - accuracy: 0.8597 - val_loss: 0.8292 - val_accuracy: 0.9163\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.8558 - val_loss: 0.8020 - val_accuracy: 0.9285\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0222 - accuracy: 0.8630 - val_loss: 0.8021 - val_accuracy: 0.9293\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0140 - accuracy: 0.8652 - val_loss: 0.8072 - val_accuracy: 0.9246\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0066 - accuracy: 0.8685 - val_loss: 0.7775 - val_accuracy: 0.9412\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.8750 - val_loss: 0.8027 - val_accuracy: 0.9234\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9907 - accuracy: 0.8752 - val_loss: 0.7726 - val_accuracy: 0.9396\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9833 - accuracy: 0.8815 - val_loss: 0.7782 - val_accuracy: 0.9364\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9755 - accuracy: 0.8817 - val_loss: 0.7663 - val_accuracy: 0.9420\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.8885 - val_loss: 0.7686 - val_accuracy: 0.9376\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9599 - accuracy: 0.8852 - val_loss: 0.7694 - val_accuracy: 0.9404\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.8932 - val_loss: 0.7490 - val_accuracy: 0.9499\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9448 - accuracy: 0.8898 - val_loss: 0.7545 - val_accuracy: 0.9451\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9387 - accuracy: 0.8965 - val_loss: 0.7555 - val_accuracy: 0.9424\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9298 - accuracy: 0.8997 - val_loss: 0.7538 - val_accuracy: 0.9420\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9244 - accuracy: 0.8992 - val_loss: 0.7396 - val_accuracy: 0.9503\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9153 - accuracy: 0.9005 - val_loss: 0.7245 - val_accuracy: 0.9585\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9091 - accuracy: 0.9050 - val_loss: 0.7292 - val_accuracy: 0.9514\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9018 - accuracy: 0.9107 - val_loss: 0.7136 - val_accuracy: 0.9593\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8951 - accuracy: 0.9122 - val_loss: 0.7273 - val_accuracy: 0.9526\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8877 - accuracy: 0.9130 - val_loss: 0.7295 - val_accuracy: 0.9514\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8817 - accuracy: 0.9168 - val_loss: 0.7130 - val_accuracy: 0.9605\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8763 - accuracy: 0.9158 - val_loss: 0.7151 - val_accuracy: 0.9597\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8705 - accuracy: 0.9183 - val_loss: 0.7205 - val_accuracy: 0.9578\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8626 - accuracy: 0.9218 - val_loss: 0.7139 - val_accuracy: 0.9645\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8562 - accuracy: 0.9265 - val_loss: 0.7105 - val_accuracy: 0.9637\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8506 - accuracy: 0.9283 - val_loss: 0.6892 - val_accuracy: 0.9664\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8453 - accuracy: 0.9277 - val_loss: 0.6977 - val_accuracy: 0.9649\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8392 - accuracy: 0.9298 - val_loss: 0.6912 - val_accuracy: 0.9676\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8335 - accuracy: 0.9325 - val_loss: 0.6954 - val_accuracy: 0.9672\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8277 - accuracy: 0.9355 - val_loss: 0.6855 - val_accuracy: 0.9708\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8223 - accuracy: 0.9352 - val_loss: 0.6833 - val_accuracy: 0.9668\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8178 - accuracy: 0.9377 - val_loss: 0.6843 - val_accuracy: 0.9692\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.8128 - accuracy: 0.9388 - val_loss: 0.6863 - val_accuracy: 0.9708\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.9413 - val_loss: 0.6766 - val_accuracy: 0.9732\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.9420 - val_loss: 0.6820 - val_accuracy: 0.9720\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7986 - accuracy: 0.9438 - val_loss: 0.6815 - val_accuracy: 0.9708\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7948 - accuracy: 0.9435 - val_loss: 0.6664 - val_accuracy: 0.9728\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.9452 - val_loss: 0.6663 - val_accuracy: 0.9739\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7858 - accuracy: 0.9450 - val_loss: 0.6684 - val_accuracy: 0.9735\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7811 - accuracy: 0.9480 - val_loss: 0.6550 - val_accuracy: 0.9735\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.9480 - val_loss: 0.6577 - val_accuracy: 0.9732\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7733 - accuracy: 0.9438 - val_loss: 0.6650 - val_accuracy: 0.9747\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7699 - accuracy: 0.9488 - val_loss: 0.6625 - val_accuracy: 0.9743\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.9470 - val_loss: 0.6513 - val_accuracy: 0.9735\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7612 - accuracy: 0.9503 - val_loss: 0.6492 - val_accuracy: 0.9747\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.9498 - val_loss: 0.6617 - val_accuracy: 0.9735\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7544 - accuracy: 0.9507 - val_loss: 0.6480 - val_accuracy: 0.9751\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.9507 - val_loss: 0.6457 - val_accuracy: 0.9763\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.9520 - val_loss: 0.6480 - val_accuracy: 0.9763\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7435 - accuracy: 0.9555 - val_loss: 0.6494 - val_accuracy: 0.9767\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7407 - accuracy: 0.9507 - val_loss: 0.6533 - val_accuracy: 0.9759\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.9545 - val_loss: 0.6610 - val_accuracy: 0.9755\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7341 - accuracy: 0.9560 - val_loss: 0.6510 - val_accuracy: 0.9771\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7307 - accuracy: 0.9582 - val_loss: 0.6398 - val_accuracy: 0.9783\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7288 - accuracy: 0.9550 - val_loss: 0.6473 - val_accuracy: 0.9771\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.9563 - val_loss: 0.6525 - val_accuracy: 0.9763\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7219 - accuracy: 0.9557 - val_loss: 0.6450 - val_accuracy: 0.9771\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7195 - accuracy: 0.9575 - val_loss: 0.6424 - val_accuracy: 0.9775\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7172 - accuracy: 0.9592 - val_loss: 0.6338 - val_accuracy: 0.9783\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.9582 - val_loss: 0.6327 - val_accuracy: 0.9775\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7111 - accuracy: 0.9600 - val_loss: 0.6225 - val_accuracy: 0.9771\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.9575 - val_loss: 0.6394 - val_accuracy: 0.9783\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.9597 - val_loss: 0.6356 - val_accuracy: 0.9775\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.9582 - val_loss: 0.6283 - val_accuracy: 0.9783\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.9592 - val_loss: 0.6229 - val_accuracy: 0.9787\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.9600 - val_loss: 0.6283 - val_accuracy: 0.9791\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.9582 - val_loss: 0.6272 - val_accuracy: 0.9775\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.9613 - val_loss: 0.6185 - val_accuracy: 0.9787\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.9588 - val_loss: 0.6291 - val_accuracy: 0.9779\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.9597 - val_loss: 0.6228 - val_accuracy: 0.9787\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.9607 - val_loss: 0.6189 - val_accuracy: 0.9795\n",
            "--LR: 0.0001\n",
            "--Epochs: 125\n",
            "--Reg params 0.01\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.6832 - accuracy: 0.9607\n",
            "Val accuracy: 0.9607287645339966\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.9795\n",
            "Test accuracy: 0.97947096824646\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.4911 - accuracy: 0.2457 - val_loss: 1.4884 - val_accuracy: 0.8125\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4862 - accuracy: 0.2505 - val_loss: 1.4842 - val_accuracy: 0.0454\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4814 - accuracy: 0.2393 - val_loss: 1.4791 - val_accuracy: 0.0454\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4766 - accuracy: 0.2403 - val_loss: 1.4742 - val_accuracy: 0.0738\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4719 - accuracy: 0.2342 - val_loss: 1.4697 - val_accuracy: 0.0683\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4673 - accuracy: 0.2383 - val_loss: 1.4652 - val_accuracy: 0.0738\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4628 - accuracy: 0.2352 - val_loss: 1.4605 - val_accuracy: 0.8125\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4585 - accuracy: 0.2465 - val_loss: 1.4565 - val_accuracy: 0.0454\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4544 - accuracy: 0.2453 - val_loss: 1.4521 - val_accuracy: 0.0454\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4503 - accuracy: 0.2412 - val_loss: 1.4482 - val_accuracy: 0.8125\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4464 - accuracy: 0.2397 - val_loss: 1.4447 - val_accuracy: 0.0454\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4427 - accuracy: 0.2390 - val_loss: 1.4407 - val_accuracy: 0.0683\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4390 - accuracy: 0.2405 - val_loss: 1.4371 - val_accuracy: 0.8125\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4355 - accuracy: 0.2410 - val_loss: 1.4337 - val_accuracy: 0.8125\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4321 - accuracy: 0.2345 - val_loss: 1.4306 - val_accuracy: 0.0454\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4288 - accuracy: 0.2460 - val_loss: 1.4272 - val_accuracy: 0.0454\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4257 - accuracy: 0.2470 - val_loss: 1.4241 - val_accuracy: 0.0454\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4226 - accuracy: 0.2482 - val_loss: 1.4210 - val_accuracy: 0.0454\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4197 - accuracy: 0.2390 - val_loss: 1.4185 - val_accuracy: 0.0683\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4169 - accuracy: 0.2412 - val_loss: 1.4156 - val_accuracy: 0.0454\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4143 - accuracy: 0.2407 - val_loss: 1.4131 - val_accuracy: 0.0454\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4119 - accuracy: 0.2430 - val_loss: 1.4105 - val_accuracy: 0.0454\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4096 - accuracy: 0.2362 - val_loss: 1.4088 - val_accuracy: 0.0454\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4074 - accuracy: 0.2432 - val_loss: 1.4064 - val_accuracy: 0.0738\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4054 - accuracy: 0.2403 - val_loss: 1.4043 - val_accuracy: 0.8101\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3927 - accuracy: 0.2615 - val_loss: 1.3985 - val_accuracy: 0.6589\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3927 - val_accuracy: 0.5614\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3043 - accuracy: 0.4030 - val_loss: 1.3810 - val_accuracy: 0.5886\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2728 - accuracy: 0.4335 - val_loss: 1.3648 - val_accuracy: 0.6447\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2476 - accuracy: 0.4563 - val_loss: 1.3410 - val_accuracy: 0.7497\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2268 - accuracy: 0.4712 - val_loss: 1.3269 - val_accuracy: 0.7631\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2092 - accuracy: 0.4800 - val_loss: 1.3085 - val_accuracy: 0.8306\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1938 - accuracy: 0.4905 - val_loss: 1.2939 - val_accuracy: 0.8575\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1802 - accuracy: 0.4970 - val_loss: 1.2807 - val_accuracy: 0.8638\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1434 - accuracy: 0.5165 - val_loss: 0.9834 - val_accuracy: 0.8954\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0412 - accuracy: 0.6250 - val_loss: 0.8043 - val_accuracy: 0.9009\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9904 - accuracy: 0.6285 - val_loss: 0.7448 - val_accuracy: 0.9116\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9512 - accuracy: 0.6810 - val_loss: 0.6938 - val_accuracy: 0.9147\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9197 - accuracy: 0.7260 - val_loss: 0.6533 - val_accuracy: 0.9203\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8925 - accuracy: 0.7425 - val_loss: 0.6229 - val_accuracy: 0.9179\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8691 - accuracy: 0.7333 - val_loss: 0.5948 - val_accuracy: 0.9242\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.7465 - val_loss: 0.5754 - val_accuracy: 0.9297\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.7720 - val_loss: 0.5458 - val_accuracy: 0.9258\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8123 - accuracy: 0.7648 - val_loss: 0.5236 - val_accuracy: 0.9262\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.7843 - val_loss: 0.5274 - val_accuracy: 0.9238\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.7765 - val_loss: 0.4843 - val_accuracy: 0.9258\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7696 - accuracy: 0.7747 - val_loss: 0.4895 - val_accuracy: 0.9266\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.7875 - val_loss: 0.4620 - val_accuracy: 0.9254\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7459 - accuracy: 0.7862 - val_loss: 0.4499 - val_accuracy: 0.9274\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7885 - val_loss: 0.4467 - val_accuracy: 0.9210\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.7875 - val_loss: 0.4466 - val_accuracy: 0.9199\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7167 - accuracy: 0.7875 - val_loss: 0.4226 - val_accuracy: 0.9238\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7076 - accuracy: 0.7987 - val_loss: 0.4247 - val_accuracy: 0.9203\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6996 - accuracy: 0.7995 - val_loss: 0.4015 - val_accuracy: 0.9234\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.7868 - val_loss: 0.3930 - val_accuracy: 0.9278\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.8055 - val_loss: 0.3848 - val_accuracy: 0.9278\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.8008 - val_loss: 0.3848 - val_accuracy: 0.9266\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7993 - val_loss: 0.3740 - val_accuracy: 0.9278\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.8073 - val_loss: 0.3886 - val_accuracy: 0.9234\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6609 - accuracy: 0.8030 - val_loss: 0.3831 - val_accuracy: 0.9238\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.8058 - val_loss: 0.3570 - val_accuracy: 0.9281\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.8098 - val_loss: 0.3664 - val_accuracy: 0.9262\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.8117 - val_loss: 0.3719 - val_accuracy: 0.9234\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.8055 - val_loss: 0.3442 - val_accuracy: 0.9285\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.8138 - val_loss: 0.3606 - val_accuracy: 0.9266\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.8155 - val_loss: 0.3507 - val_accuracy: 0.9250\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.8155 - val_loss: 0.3525 - val_accuracy: 0.9246\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6265 - accuracy: 0.8098 - val_loss: 0.3463 - val_accuracy: 0.9270\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.8173 - val_loss: 0.3438 - val_accuracy: 0.9254\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.8087 - val_loss: 0.3563 - val_accuracy: 0.9270\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.8192 - val_loss: 0.3467 - val_accuracy: 0.9258\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8152 - val_loss: 0.3560 - val_accuracy: 0.9266\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6111 - accuracy: 0.8180 - val_loss: 0.3338 - val_accuracy: 0.9289\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.8175 - val_loss: 0.3336 - val_accuracy: 0.9281\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.8198 - val_loss: 0.3544 - val_accuracy: 0.9238\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.8160 - val_loss: 0.3472 - val_accuracy: 0.9270\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.8183 - val_loss: 0.3445 - val_accuracy: 0.9250\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.8227 - val_loss: 0.3601 - val_accuracy: 0.9199\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.8173 - val_loss: 0.3586 - val_accuracy: 0.9195\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.8140 - val_loss: 0.3439 - val_accuracy: 0.9285\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.8275 - val_loss: 0.3430 - val_accuracy: 0.9266\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.8202 - val_loss: 0.3487 - val_accuracy: 0.9230\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.8198 - val_loss: 0.3526 - val_accuracy: 0.9222\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5884 - accuracy: 0.8170 - val_loss: 0.3383 - val_accuracy: 0.9289\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5868 - accuracy: 0.8275 - val_loss: 0.3371 - val_accuracy: 0.9266\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8235 - val_loss: 0.3433 - val_accuracy: 0.9254\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8257 - val_loss: 0.3311 - val_accuracy: 0.9266\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5826 - accuracy: 0.8198 - val_loss: 0.3367 - val_accuracy: 0.9285\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.8263 - val_loss: 0.3447 - val_accuracy: 0.9262\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5802 - accuracy: 0.8217 - val_loss: 0.3483 - val_accuracy: 0.9250\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5792 - accuracy: 0.8270 - val_loss: 0.3286 - val_accuracy: 0.9297\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.8245 - val_loss: 0.3424 - val_accuracy: 0.9281\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5765 - accuracy: 0.8303 - val_loss: 0.3401 - val_accuracy: 0.9274\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5754 - accuracy: 0.8248 - val_loss: 0.3387 - val_accuracy: 0.9274\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.8250 - val_loss: 0.3385 - val_accuracy: 0.9293\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5733 - accuracy: 0.8227 - val_loss: 0.3463 - val_accuracy: 0.9254\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8322 - val_loss: 0.3360 - val_accuracy: 0.9289\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.8265 - val_loss: 0.3558 - val_accuracy: 0.9187\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.8280 - val_loss: 0.3388 - val_accuracy: 0.9281\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.8307 - val_loss: 0.3411 - val_accuracy: 0.9274\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8232 - val_loss: 0.3324 - val_accuracy: 0.9301\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5683 - accuracy: 0.8303 - val_loss: 0.3551 - val_accuracy: 0.9191\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.8295 - val_loss: 0.3355 - val_accuracy: 0.9293\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8275 - val_loss: 0.3394 - val_accuracy: 0.9285\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5660 - accuracy: 0.8298 - val_loss: 0.3427 - val_accuracy: 0.9281\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.8305 - val_loss: 0.3381 - val_accuracy: 0.9293\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.8285 - val_loss: 0.3498 - val_accuracy: 0.9222\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5635 - accuracy: 0.8310 - val_loss: 0.3372 - val_accuracy: 0.9281\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.8325 - val_loss: 0.3434 - val_accuracy: 0.9258\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.8295 - val_loss: 0.3474 - val_accuracy: 0.9230\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.8303 - val_loss: 0.3557 - val_accuracy: 0.9191\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8332 - val_loss: 0.3426 - val_accuracy: 0.9281\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5605 - accuracy: 0.8310 - val_loss: 0.3501 - val_accuracy: 0.9242\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.8290 - val_loss: 0.3515 - val_accuracy: 0.9246\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5595 - accuracy: 0.8298 - val_loss: 0.3427 - val_accuracy: 0.9285\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.8363 - val_loss: 0.3413 - val_accuracy: 0.9285\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5581 - accuracy: 0.8298 - val_loss: 0.3482 - val_accuracy: 0.9250\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.8332 - val_loss: 0.3614 - val_accuracy: 0.9191\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8328 - val_loss: 0.3447 - val_accuracy: 0.9274\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.8342 - val_loss: 0.3442 - val_accuracy: 0.9270\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.8310 - val_loss: 0.3535 - val_accuracy: 0.9214\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.8332 - val_loss: 0.3425 - val_accuracy: 0.9289\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.8338 - val_loss: 0.3543 - val_accuracy: 0.9203\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5544 - accuracy: 0.8330 - val_loss: 0.3516 - val_accuracy: 0.9242\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.8347 - val_loss: 0.3720 - val_accuracy: 0.9104\n",
            "--LR: 0.0001\n",
            "--Epochs: 125\n",
            "--Reg params 0.001\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.5533 - accuracy: 0.8332\n",
            "Val accuracy: 0.8331983685493469\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.9104\n",
            "Test accuracy: 0.9103829264640808\n",
            "Epoch 1/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.6519 - accuracy: 0.2567 - val_loss: 1.3724 - val_accuracy: 0.8243\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.3222 - accuracy: 0.3433 - val_loss: 1.6214 - val_accuracy: 0.7323\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.9680 - accuracy: 0.3565 - val_loss: 1.6171 - val_accuracy: 0.6577\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.8806 - accuracy: 0.3765 - val_loss: 1.5775 - val_accuracy: 0.6609\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.8107 - accuracy: 0.3850 - val_loss: 1.4969 - val_accuracy: 0.6771\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.7480 - accuracy: 0.4010 - val_loss: 1.4044 - val_accuracy: 0.7402\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6906 - accuracy: 0.4142 - val_loss: 1.3574 - val_accuracy: 0.7402\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.6391 - accuracy: 0.4260 - val_loss: 1.3066 - val_accuracy: 0.7592\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5909 - accuracy: 0.4338 - val_loss: 1.2274 - val_accuracy: 0.7987\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.5467 - accuracy: 0.4415 - val_loss: 1.2102 - val_accuracy: 0.7959\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.5039 - accuracy: 0.4638 - val_loss: 1.1498 - val_accuracy: 0.8129\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.4648 - accuracy: 0.4895 - val_loss: 1.1261 - val_accuracy: 0.8160\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.4280 - accuracy: 0.5240 - val_loss: 1.1000 - val_accuracy: 0.8275\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3921 - accuracy: 0.5680 - val_loss: 1.0369 - val_accuracy: 0.8385\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.3570 - accuracy: 0.6080 - val_loss: 1.0063 - val_accuracy: 0.8488\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.3231 - accuracy: 0.6513 - val_loss: 0.9737 - val_accuracy: 0.8685\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2887 - accuracy: 0.6805 - val_loss: 0.9316 - val_accuracy: 0.8650\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.2534 - accuracy: 0.7138 - val_loss: 0.8946 - val_accuracy: 0.8899\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.2183 - accuracy: 0.7383 - val_loss: 0.8682 - val_accuracy: 0.9056\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1819 - accuracy: 0.7642 - val_loss: 0.8497 - val_accuracy: 0.9049\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.1477 - accuracy: 0.7900 - val_loss: 0.8106 - val_accuracy: 0.9120\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.1144 - accuracy: 0.7937 - val_loss: 0.8066 - val_accuracy: 0.8942\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0832 - accuracy: 0.8055 - val_loss: 0.7767 - val_accuracy: 0.9049\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0535 - accuracy: 0.8142 - val_loss: 0.7501 - val_accuracy: 0.8997\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1.0247 - accuracy: 0.8110 - val_loss: 0.7517 - val_accuracy: 0.8918\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9977 - accuracy: 0.8195 - val_loss: 0.7223 - val_accuracy: 0.8906\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.9708 - accuracy: 0.8232 - val_loss: 0.6788 - val_accuracy: 0.9072\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9459 - accuracy: 0.8275 - val_loss: 0.6828 - val_accuracy: 0.8974\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.9240 - accuracy: 0.8385 - val_loss: 0.6424 - val_accuracy: 0.9151\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.9006 - accuracy: 0.8415 - val_loss: 0.6479 - val_accuracy: 0.9013\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.8806 - accuracy: 0.8432 - val_loss: 0.6408 - val_accuracy: 0.8970\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.8608 - accuracy: 0.8482 - val_loss: 0.6467 - val_accuracy: 0.8902\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.8425 - accuracy: 0.8497 - val_loss: 0.6062 - val_accuracy: 0.9072\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.8261 - accuracy: 0.8503 - val_loss: 0.6068 - val_accuracy: 0.9045\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.8081 - accuracy: 0.8622 - val_loss: 0.6061 - val_accuracy: 0.9009\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7927 - accuracy: 0.8645 - val_loss: 0.5739 - val_accuracy: 0.9183\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7786 - accuracy: 0.8687 - val_loss: 0.5699 - val_accuracy: 0.9124\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.8692 - val_loss: 0.5716 - val_accuracy: 0.9108\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7500 - accuracy: 0.8792 - val_loss: 0.5492 - val_accuracy: 0.9317\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7384 - accuracy: 0.8800 - val_loss: 0.5697 - val_accuracy: 0.9049\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7264 - accuracy: 0.8823 - val_loss: 0.5310 - val_accuracy: 0.9404\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.7154 - accuracy: 0.8888 - val_loss: 0.5512 - val_accuracy: 0.9187\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.8907 - val_loss: 0.5529 - val_accuracy: 0.9234\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.8953 - val_loss: 0.5359 - val_accuracy: 0.9281\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6836 - accuracy: 0.8970 - val_loss: 0.5288 - val_accuracy: 0.9309\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.9015 - val_loss: 0.5207 - val_accuracy: 0.9364\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.9057 - val_loss: 0.5190 - val_accuracy: 0.9396\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.9087 - val_loss: 0.5128 - val_accuracy: 0.9376\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.9112 - val_loss: 0.5147 - val_accuracy: 0.9380\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.9143 - val_loss: 0.4941 - val_accuracy: 0.9503\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6296 - accuracy: 0.9155 - val_loss: 0.4871 - val_accuracy: 0.9542\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.9210 - val_loss: 0.4813 - val_accuracy: 0.9593\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.9225 - val_loss: 0.4810 - val_accuracy: 0.9609\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6065 - accuracy: 0.9252 - val_loss: 0.4867 - val_accuracy: 0.9526\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.9252 - val_loss: 0.4801 - val_accuracy: 0.9585\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.9295 - val_loss: 0.4833 - val_accuracy: 0.9538\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.9320 - val_loss: 0.4775 - val_accuracy: 0.9566\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.9342 - val_loss: 0.4640 - val_accuracy: 0.9680\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.9375 - val_loss: 0.4705 - val_accuracy: 0.9629\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.9375 - val_loss: 0.4685 - val_accuracy: 0.9653\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.9398 - val_loss: 0.4601 - val_accuracy: 0.9684\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.9392 - val_loss: 0.4493 - val_accuracy: 0.9716\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5487 - accuracy: 0.9423 - val_loss: 0.4475 - val_accuracy: 0.9720\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.9420 - val_loss: 0.4456 - val_accuracy: 0.9724\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5376 - accuracy: 0.9438 - val_loss: 0.4700 - val_accuracy: 0.9633\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.9438 - val_loss: 0.4492 - val_accuracy: 0.9704\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.9450 - val_loss: 0.4433 - val_accuracy: 0.9720\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5227 - accuracy: 0.9475 - val_loss: 0.4337 - val_accuracy: 0.9728\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.5186 - accuracy: 0.9448 - val_loss: 0.4363 - val_accuracy: 0.9728\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.9490 - val_loss: 0.4315 - val_accuracy: 0.9739\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.9503 - val_loss: 0.4287 - val_accuracy: 0.9735\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.9485 - val_loss: 0.4373 - val_accuracy: 0.9747\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4999 - accuracy: 0.9495 - val_loss: 0.4289 - val_accuracy: 0.9739\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.9520 - val_loss: 0.4184 - val_accuracy: 0.9743\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4916 - accuracy: 0.9532 - val_loss: 0.4221 - val_accuracy: 0.9751\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4876 - accuracy: 0.9525 - val_loss: 0.4145 - val_accuracy: 0.9747\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.9528 - val_loss: 0.4260 - val_accuracy: 0.9767\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.9553 - val_loss: 0.4194 - val_accuracy: 0.9763\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.9555 - val_loss: 0.4289 - val_accuracy: 0.9763\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4731 - accuracy: 0.9567 - val_loss: 0.4072 - val_accuracy: 0.9743\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4702 - accuracy: 0.9555 - val_loss: 0.4093 - val_accuracy: 0.9747\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4667 - accuracy: 0.9578 - val_loss: 0.4099 - val_accuracy: 0.9775\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4640 - accuracy: 0.9553 - val_loss: 0.4132 - val_accuracy: 0.9775\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.9575 - val_loss: 0.4068 - val_accuracy: 0.9763\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.9570 - val_loss: 0.4066 - val_accuracy: 0.9779\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.9563 - val_loss: 0.4193 - val_accuracy: 0.9787\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.9567 - val_loss: 0.3960 - val_accuracy: 0.9747\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.9565 - val_loss: 0.3969 - val_accuracy: 0.9763\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.9580 - val_loss: 0.4026 - val_accuracy: 0.9787\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.9590 - val_loss: 0.3928 - val_accuracy: 0.9775\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.9588 - val_loss: 0.3954 - val_accuracy: 0.9775\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.9575 - val_loss: 0.3948 - val_accuracy: 0.9779\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4384 - accuracy: 0.9588 - val_loss: 0.3937 - val_accuracy: 0.9783\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4361 - accuracy: 0.9592 - val_loss: 0.3911 - val_accuracy: 0.9787\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.9592 - val_loss: 0.3929 - val_accuracy: 0.9791\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.9592 - val_loss: 0.3942 - val_accuracy: 0.9787\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.9605 - val_loss: 0.3903 - val_accuracy: 0.9795\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.9610 - val_loss: 0.3802 - val_accuracy: 0.9775\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.9592 - val_loss: 0.3794 - val_accuracy: 0.9779\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.9600 - val_loss: 0.3940 - val_accuracy: 0.9807\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.9597 - val_loss: 0.3780 - val_accuracy: 0.9779\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4207 - accuracy: 0.9605 - val_loss: 0.3878 - val_accuracy: 0.9795\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.9615 - val_loss: 0.3821 - val_accuracy: 0.9791\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.9610 - val_loss: 0.3809 - val_accuracy: 0.9791\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.9597 - val_loss: 0.3852 - val_accuracy: 0.9803\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.9610 - val_loss: 0.3805 - val_accuracy: 0.9799\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.9615 - val_loss: 0.3836 - val_accuracy: 0.9807\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.9605 - val_loss: 0.3775 - val_accuracy: 0.9799\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.9617 - val_loss: 0.3694 - val_accuracy: 0.9799\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4094 - accuracy: 0.9628 - val_loss: 0.3730 - val_accuracy: 0.9795\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.9625 - val_loss: 0.3791 - val_accuracy: 0.9803\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.9632 - val_loss: 0.3723 - val_accuracy: 0.9795\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.9622 - val_loss: 0.3714 - val_accuracy: 0.9799\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4042 - accuracy: 0.9625 - val_loss: 0.3755 - val_accuracy: 0.9807\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.9617 - val_loss: 0.3608 - val_accuracy: 0.9787\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.9630 - val_loss: 0.3732 - val_accuracy: 0.9799\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4005 - accuracy: 0.9638 - val_loss: 0.3640 - val_accuracy: 0.9799\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.9632 - val_loss: 0.3637 - val_accuracy: 0.9795\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.9625 - val_loss: 0.3690 - val_accuracy: 0.9803\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3972 - accuracy: 0.9635 - val_loss: 0.3672 - val_accuracy: 0.9803\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.9630 - val_loss: 0.3654 - val_accuracy: 0.9803\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.9643 - val_loss: 0.3603 - val_accuracy: 0.9799\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.9632 - val_loss: 0.3579 - val_accuracy: 0.9783\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.9638 - val_loss: 0.3633 - val_accuracy: 0.9807\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.9638 - val_loss: 0.3652 - val_accuracy: 0.9807\n",
            "--LR: 0.0001\n",
            "--Epochs: 125\n",
            "--Reg params 0.005\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.9729\n",
            "Val accuracy: 0.9728745222091675\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.9807\n",
            "Test accuracy: 0.9806553721427917\n"
          ]
        }
      ],
      "source": [
        "learning_rate = [0.005,0.01,0.001,0.0001]\n",
        "maxiter = [125]\n",
        "reg_params = [0.05,0.01,0.001,0.005]\n",
        "\n",
        "for i in learning_rate:\n",
        "  for j in maxiter:\n",
        "    for k in reg_params:\n",
        "        \n",
        "\n",
        "      layer1_shape = X_train.shape[1]\n",
        "      model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(16, input_dim = layer1_shape,\n",
        "                                kernel_regularizer=regularizers.L1(k),\n",
        "                                activation = 'relu'),\n",
        "          tf.keras.layers.Dense(8,kernel_regularizer=regularizers.L1(k),\n",
        "                                activation='relu'),\n",
        "          tf.keras.layers.Dense(4,kernel_regularizer=regularizers.L1(k),\n",
        "                                activation='softmax')\n",
        "      ])\n",
        "      opt = tf.keras.optimizers.Adam(learning_rate=i)\n",
        "\n",
        "      model.compile(optimizer=opt,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "      model.fit(X_train, y_train, epochs=j,validation_data = (X_test, y_test),\n",
        "          shuffle = True)\n",
        "\n",
        "      print('--LR:',i)\n",
        "      print('--Epochs:', j)\n",
        "      print('--Reg params',k)\n",
        "      \n",
        "      val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "      print('Val accuracy:', val_acc)\n",
        "\n",
        "      test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "      print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IUJyZj7nwm3"
      },
      "source": [
        "## testing with PCA Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jMaidTK6hn9",
        "outputId": "bd160007-b18d-4dea-a69c-175b4f471ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 2ms/step - loss: 1.3200 - accuracy: 0.4140\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.0764 - accuracy: 0.6195\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.7117\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7922\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8353\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8685\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3489 - accuracy: 0.9050\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3004 - accuracy: 0.9202\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.9245\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9285\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9312\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9360\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9400\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9417\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9463\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9473\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9490\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9513\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9507\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9530\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9545\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9540\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9540\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9572\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9555\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9548\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9548\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9565\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9555\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9567\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9575\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9560\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9565\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9567\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9578\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9592\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9588\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9595\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9592\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9597\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9597\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9607\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9600\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9622\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9620\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9615\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9647\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9645\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9635\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9653\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9655\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9650\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9657\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9650\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9663\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9660\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9663\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9678\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9685\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9678\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9675\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9690\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9672\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9672\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9693\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9690\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9697\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9705\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9693\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9693\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9703\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9712\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9712\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9710\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9718\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9712\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9722\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9725\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9712\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9718\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9707\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9732\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9725\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9725\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9740\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9732\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9740\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9728\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9732\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9740\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9743\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9728\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9753\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9758\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9740\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9747\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9745\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9747\n",
            "48/48 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9836\n",
            "Val accuracy: 0.9835526347160339\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9763\n",
            "Test accuracy: 0.9763126969337463\n"
          ]
        }
      ],
      "source": [
        "layer1_shape = X_pca_tr.shape[1]\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(layer1_shape, input_dim = layer1_shape, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_pca_tr, y_pca_tr, epochs=100)\n",
        "\n",
        "val_loss, val_acc = model.evaluate(X_pca_val, y_pca_val)\n",
        "print('Val accuracy:', val_acc)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_pca_test, y_pca_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCntl1vQnJIF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxkHGa5EnJiU"
      },
      "source": [
        "## testing with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mGeHIsy9nJiU",
        "outputId": "8b7fe2f4-85a6-4044-f4dd-e1e9eadbcd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "125/125 [==============================] - 4s 18ms/step - loss: 1.5680 - accuracy: 0.2747 - val_loss: 1.2900 - val_accuracy: 0.8902\n",
            "Epoch 2/125\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.8302 - accuracy: 0.6927 - val_loss: 0.3821 - val_accuracy: 0.9218\n",
            "Epoch 3/125\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.4756 - accuracy: 0.8660 - val_loss: 0.2569 - val_accuracy: 0.9589\n",
            "Epoch 4/125\n",
            "125/125 [==============================] - 2s 20ms/step - loss: 0.3351 - accuracy: 0.9170 - val_loss: 0.2065 - val_accuracy: 0.9751\n",
            "Epoch 5/125\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2570 - accuracy: 0.9482 - val_loss: 0.2050 - val_accuracy: 0.9799\n",
            "Epoch 6/125\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2264 - accuracy: 0.9542 - val_loss: 0.1559 - val_accuracy: 0.9826\n",
            "Epoch 7/125\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2445 - accuracy: 0.9475 - val_loss: 0.1737 - val_accuracy: 0.9743\n",
            "Epoch 8/125\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1936 - accuracy: 0.9628 - val_loss: 0.1448 - val_accuracy: 0.9866\n",
            "Epoch 9/125\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1921 - accuracy: 0.9620 - val_loss: 0.1465 - val_accuracy: 0.9878\n",
            "Epoch 10/125\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1882 - accuracy: 0.9600 - val_loss: 0.1801 - val_accuracy: 0.9834\n",
            "Epoch 11/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9640 - val_loss: 0.1624 - val_accuracy: 0.9854\n",
            "Epoch 12/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9650 - val_loss: 0.1483 - val_accuracy: 0.9882\n",
            "Epoch 13/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9630 - val_loss: 0.1395 - val_accuracy: 0.9858\n",
            "Epoch 14/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9675 - val_loss: 0.1426 - val_accuracy: 0.9882\n",
            "Epoch 15/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9647 - val_loss: 0.1504 - val_accuracy: 0.9905\n",
            "Epoch 16/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9670 - val_loss: 0.1408 - val_accuracy: 0.9893\n",
            "Epoch 17/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9588 - val_loss: 0.1346 - val_accuracy: 0.9886\n",
            "Epoch 18/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9647 - val_loss: 0.1373 - val_accuracy: 0.9893\n",
            "Epoch 19/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9668 - val_loss: 0.1626 - val_accuracy: 0.9854\n",
            "Epoch 20/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9653 - val_loss: 0.1360 - val_accuracy: 0.9897\n",
            "Epoch 21/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9660 - val_loss: 0.1567 - val_accuracy: 0.9874\n",
            "Epoch 22/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9718 - val_loss: 0.1389 - val_accuracy: 0.9901\n",
            "Epoch 23/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9670 - val_loss: 0.1441 - val_accuracy: 0.9874\n",
            "Epoch 24/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9675 - val_loss: 0.1378 - val_accuracy: 0.9921\n",
            "Epoch 25/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9705 - val_loss: 0.1332 - val_accuracy: 0.9913\n",
            "Epoch 26/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9695 - val_loss: 0.1444 - val_accuracy: 0.9901\n",
            "Epoch 27/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9685 - val_loss: 0.1756 - val_accuracy: 0.9866\n",
            "Epoch 28/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9660 - val_loss: 0.1542 - val_accuracy: 0.9882\n",
            "Epoch 29/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9695 - val_loss: 0.1535 - val_accuracy: 0.9886\n",
            "Epoch 30/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9693 - val_loss: 0.1421 - val_accuracy: 0.9893\n",
            "Epoch 31/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9678 - val_loss: 0.1437 - val_accuracy: 0.9889\n",
            "Epoch 32/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9700 - val_loss: 0.1530 - val_accuracy: 0.9886\n",
            "Epoch 33/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9675 - val_loss: 0.1346 - val_accuracy: 0.9913\n",
            "Epoch 34/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9703 - val_loss: 0.1392 - val_accuracy: 0.9905\n",
            "Epoch 35/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9680 - val_loss: 0.1534 - val_accuracy: 0.9878\n",
            "Epoch 36/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9755 - val_loss: 0.1506 - val_accuracy: 0.9897\n",
            "Epoch 37/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9703 - val_loss: 0.1576 - val_accuracy: 0.9886\n",
            "Epoch 38/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9712 - val_loss: 0.1441 - val_accuracy: 0.9901\n",
            "Epoch 39/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9728 - val_loss: 0.1610 - val_accuracy: 0.9886\n",
            "Epoch 40/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9700 - val_loss: 0.1547 - val_accuracy: 0.9893\n",
            "Epoch 41/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9720 - val_loss: 0.1467 - val_accuracy: 0.9901\n",
            "Epoch 42/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1500 - accuracy: 0.9725 - val_loss: 0.1552 - val_accuracy: 0.9889\n",
            "Epoch 43/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9682 - val_loss: 0.1627 - val_accuracy: 0.9882\n",
            "Epoch 44/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9697 - val_loss: 0.1446 - val_accuracy: 0.9897\n",
            "Epoch 45/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9710 - val_loss: 0.1527 - val_accuracy: 0.9901\n",
            "Epoch 46/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9712 - val_loss: 0.1463 - val_accuracy: 0.9901\n",
            "Epoch 47/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9732 - val_loss: 0.1562 - val_accuracy: 0.9897\n",
            "Epoch 48/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9740 - val_loss: 0.1377 - val_accuracy: 0.9925\n",
            "Epoch 49/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9730 - val_loss: 0.1394 - val_accuracy: 0.9905\n",
            "Epoch 50/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9718 - val_loss: 0.1470 - val_accuracy: 0.9870\n",
            "Epoch 51/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9730 - val_loss: 0.1627 - val_accuracy: 0.9874\n",
            "Epoch 52/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9705 - val_loss: 0.1708 - val_accuracy: 0.9866\n",
            "Epoch 53/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9660 - val_loss: 0.1397 - val_accuracy: 0.9897\n",
            "Epoch 54/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9720 - val_loss: 0.1358 - val_accuracy: 0.9901\n",
            "Epoch 55/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9740 - val_loss: 0.1359 - val_accuracy: 0.9882\n",
            "Epoch 56/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1297 - accuracy: 0.9740 - val_loss: 0.1463 - val_accuracy: 0.9901\n",
            "Epoch 57/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9730 - val_loss: 0.1516 - val_accuracy: 0.9886\n",
            "Epoch 58/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9737 - val_loss: 0.1424 - val_accuracy: 0.9905\n",
            "Epoch 59/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1339 - accuracy: 0.9722 - val_loss: 0.1392 - val_accuracy: 0.9901\n",
            "Epoch 60/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9693 - val_loss: 0.1367 - val_accuracy: 0.9905\n",
            "Epoch 61/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9722 - val_loss: 0.1376 - val_accuracy: 0.9913\n",
            "Epoch 62/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9758 - val_loss: 0.1358 - val_accuracy: 0.9897\n",
            "Epoch 63/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9753 - val_loss: 0.1305 - val_accuracy: 0.9893\n",
            "Epoch 64/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9712 - val_loss: 0.1391 - val_accuracy: 0.9893\n",
            "Epoch 65/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1298 - accuracy: 0.9728 - val_loss: 0.1658 - val_accuracy: 0.9870\n",
            "Epoch 66/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9755 - val_loss: 0.1499 - val_accuracy: 0.9838\n",
            "Epoch 67/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9743 - val_loss: 0.1286 - val_accuracy: 0.9913\n",
            "Epoch 68/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9743 - val_loss: 0.1290 - val_accuracy: 0.9921\n",
            "Epoch 69/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9688 - val_loss: 0.1620 - val_accuracy: 0.9889\n",
            "Epoch 70/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9720 - val_loss: 0.1362 - val_accuracy: 0.9874\n",
            "Epoch 71/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9728 - val_loss: 0.1444 - val_accuracy: 0.9850\n",
            "Epoch 72/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9740 - val_loss: 0.1342 - val_accuracy: 0.9897\n",
            "Epoch 73/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9722 - val_loss: 0.1917 - val_accuracy: 0.9854\n",
            "Epoch 74/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9730 - val_loss: 0.1371 - val_accuracy: 0.9897\n",
            "Epoch 75/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9703 - val_loss: 0.1583 - val_accuracy: 0.9882\n",
            "Epoch 76/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9730 - val_loss: 0.1361 - val_accuracy: 0.9901\n",
            "Epoch 77/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1211 - accuracy: 0.9750 - val_loss: 0.1774 - val_accuracy: 0.9862\n",
            "Epoch 78/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9753 - val_loss: 0.1407 - val_accuracy: 0.9909\n",
            "Epoch 79/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9722 - val_loss: 0.1500 - val_accuracy: 0.9870\n",
            "Epoch 80/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9770 - val_loss: 0.1329 - val_accuracy: 0.9909\n",
            "Epoch 81/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9735 - val_loss: 0.2535 - val_accuracy: 0.9783\n",
            "Epoch 82/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9758 - val_loss: 0.1299 - val_accuracy: 0.9909\n",
            "Epoch 83/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9743 - val_loss: 0.1268 - val_accuracy: 0.9893\n",
            "Epoch 84/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9762 - val_loss: 0.1311 - val_accuracy: 0.9889\n",
            "Epoch 85/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9753 - val_loss: 0.1240 - val_accuracy: 0.9901\n",
            "Epoch 86/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9770 - val_loss: 0.1349 - val_accuracy: 0.9889\n",
            "Epoch 87/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9730 - val_loss: 0.1391 - val_accuracy: 0.9901\n",
            "Epoch 88/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9728 - val_loss: 0.1285 - val_accuracy: 0.9909\n",
            "Epoch 89/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9735 - val_loss: 0.1238 - val_accuracy: 0.9905\n",
            "Epoch 90/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9728 - val_loss: 0.1375 - val_accuracy: 0.9889\n",
            "Epoch 91/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1321 - accuracy: 0.9725 - val_loss: 0.1323 - val_accuracy: 0.9889\n",
            "Epoch 92/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9745 - val_loss: 0.1227 - val_accuracy: 0.9921\n",
            "Epoch 93/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9745 - val_loss: 0.3437 - val_accuracy: 0.9246\n",
            "Epoch 94/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1301 - accuracy: 0.9745 - val_loss: 0.1588 - val_accuracy: 0.9874\n",
            "Epoch 95/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9750 - val_loss: 0.1293 - val_accuracy: 0.9870\n",
            "Epoch 96/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9765 - val_loss: 0.1222 - val_accuracy: 0.9913\n",
            "Epoch 97/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9765 - val_loss: 0.1293 - val_accuracy: 0.9893\n",
            "Epoch 98/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9793 - val_loss: 0.1237 - val_accuracy: 0.9905\n",
            "Epoch 99/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9730 - val_loss: 0.1352 - val_accuracy: 0.9905\n",
            "Epoch 100/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9750 - val_loss: 0.1581 - val_accuracy: 0.9882\n",
            "Epoch 101/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9722 - val_loss: 0.1231 - val_accuracy: 0.9905\n",
            "Epoch 102/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9778 - val_loss: 0.1261 - val_accuracy: 0.9909\n",
            "Epoch 103/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9745 - val_loss: 0.1313 - val_accuracy: 0.9889\n",
            "Epoch 104/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9760 - val_loss: 0.1316 - val_accuracy: 0.9897\n",
            "Epoch 105/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9728 - val_loss: 0.1438 - val_accuracy: 0.9889\n",
            "Epoch 106/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9743 - val_loss: 0.1449 - val_accuracy: 0.9897\n",
            "Epoch 107/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9753 - val_loss: 0.1455 - val_accuracy: 0.9874\n",
            "Epoch 108/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9660 - val_loss: 0.1301 - val_accuracy: 0.9917\n",
            "Epoch 109/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9750 - val_loss: 0.1332 - val_accuracy: 0.9886\n",
            "Epoch 110/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9765 - val_loss: 0.1302 - val_accuracy: 0.9901\n",
            "Epoch 111/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9743 - val_loss: 0.1469 - val_accuracy: 0.9897\n",
            "Epoch 112/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1255 - accuracy: 0.9712 - val_loss: 0.2084 - val_accuracy: 0.9826\n",
            "Epoch 113/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9728 - val_loss: 0.1204 - val_accuracy: 0.9909\n",
            "Epoch 114/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9747 - val_loss: 0.1221 - val_accuracy: 0.9921\n",
            "Epoch 115/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9755 - val_loss: 0.1222 - val_accuracy: 0.9909\n",
            "Epoch 116/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9693 - val_loss: 0.1387 - val_accuracy: 0.9850\n",
            "Epoch 117/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9740 - val_loss: 0.1291 - val_accuracy: 0.9889\n",
            "Epoch 118/125\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9732 - val_loss: 0.1282 - val_accuracy: 0.9905\n",
            "Epoch 119/125\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9750 - val_loss: 0.1246 - val_accuracy: 0.9905\n",
            "Epoch 120/125\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1161 - accuracy: 0.9728 - val_loss: 0.1267 - val_accuracy: 0.9893\n",
            "Epoch 121/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9753 - val_loss: 0.1187 - val_accuracy: 0.9921\n",
            "Epoch 122/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9768 - val_loss: 0.1200 - val_accuracy: 0.9913\n",
            "Epoch 123/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9772 - val_loss: 0.1420 - val_accuracy: 0.9897\n",
            "Epoch 124/125\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1251 - accuracy: 0.9720 - val_loss: 0.1308 - val_accuracy: 0.9893\n",
            "Epoch 125/125\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9765 - val_loss: 0.2054 - val_accuracy: 0.9858\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9858\n",
            "Test accuracy: 0.9857876300811768\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.1293 - accuracy: 0.9760\n",
            "Train accuracy: 0.9760000109672546\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb7eab04110>]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed(1)\n",
        "\n",
        "layer1_shape = X_train.shape[1]\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(layer1_shape, input_dim = layer1_shape,\n",
        "                          kernel_regularizer=regularizers.L1(0.001),\n",
        "                          activation = 'relu'),\n",
        "    tf.keras.layers.Dense(8,kernel_regularizer=regularizers.L1(0.001),\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.Dense(4,kernel_regularizer=regularizers.L1(0.001),\n",
        "                          activation='softmax')\n",
        "])\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model.compile(optimizer=opt,\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "Model = model.fit(X_train, y_train, epochs=125,\n",
        "          validation_data = (X_test, y_test),\n",
        "          shuffle = True)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
        "print('Train accuracy:', train_acc)\n",
        "\n",
        "xc= range(125)\n",
        "train_loss = Model.history['loss']\n",
        "val_loss   = Model.history['val_loss']\n",
        "train_acc  = Model.history['accuracy']\n",
        "val_acc    = Model.history['val_accuracy']\n",
        "plt.figure()\n",
        "plt.plot(xc, train_loss, color = 'blue', label='training loss')\n",
        "plt.plot(xc, val_loss, color = 'red', label='testing loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "V03AUzCtnJiV",
        "outputId": "12804678-b9c7-49c6-bdab-916617e0d9d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb7e30e4750>]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_loss = Model.history['loss']\n",
        "val_loss   = Model.history['val_loss']\n",
        "train_acc  = Model.history['accuracy']\n",
        "val_acc    = Model.history['val_accuracy']\n",
        "xc         = range(100)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xc, train_acc[0:100], color = 'blue', label='training acc')\n",
        "plt.plot(xc, val_acc[0:100], color = 'red', label='testing acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "653110b3"
      },
      "source": [
        "# MODELLING - K NEAREST NEIGHBORS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24b66276"
      },
      "source": [
        "CHECKING OPTIMAL K VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f61cc10"
      },
      "outputs": [],
      "source": [
        "class KNearestNeighbor:\n",
        "    \n",
        "    def __init__(self,X_tr,y_tr,X_test,y_test):\n",
        "        self.X_train = X_tr\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_tr \n",
        "        self.y_test = y_test \n",
        "\n",
        "    def dist(self, a, b):\n",
        "        dist = np.sqrt(np.sum((a-b)**2))\n",
        "        return dist\n",
        "\n",
        "    def dist_all(self,point):\n",
        "        dist_all = []\n",
        "        for neighbor in self.X_train:\n",
        "            dist = self.dist(point, neighbor)\n",
        "            dist_all.append(dist)\n",
        "        return np.array(dist_all)\n",
        "\n",
        "    def fit(self,k):\n",
        "        preds = []\n",
        "        train_target = self.y_train.copy()\n",
        "        train_target = train_target.reshape(-1,1)\n",
        "        for point in self.X_test:  \n",
        "            dist_all = self.dist_all(point).reshape(-1,1)\n",
        "            neighbors = np.concatenate((dist_all, train_target),axis = 1,)\n",
        "            # sorts training points on the basis of distance  and select k nearest\n",
        "            neighbors_sorted = neighbors[neighbors[:, 0].argsort()]\n",
        "            k_neighbors = neighbors_sorted[:k] \n",
        "            # selects label with highest frequency\n",
        "            frequency = np.unique(k_neighbors[:, 1], return_counts=True)\n",
        "            target_class = frequency[0][frequency[1].argmax()]     \n",
        "            preds = np.append(preds, target_class)\n",
        "        return preds\n",
        "\n",
        "    def evaluate(self,y_preds):\n",
        " \n",
        "        correct,wrong,wrong_0,wrong_1,wrong_2,wrong_3 = 0,0,0,0,0,0    \n",
        "        for i in range(len(self.y_test)):\n",
        "          if int(self.y_test[i]) == int(y_preds[i]):\n",
        "              correct += 1\n",
        "          else:\n",
        "            wrong +=1\n",
        "            if self.y_test[i] ==0:\n",
        "                wrong_0+=1\n",
        "            elif self.y_test[i] ==1:\n",
        "                wrong_1+=1\n",
        "            elif self.y_test[i] ==2:\n",
        "                wrong_2+=1\n",
        "            elif self.y_test[i] ==3:\n",
        "                wrong_3+=1\n",
        "                          \n",
        "        error = wrong/(correct+wrong)\n",
        "        print('Error', error)\n",
        "        return error\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59wEdaTnIEVZ",
        "outputId": "107e220e-2bc9-4811-b7cd-ccce4193958b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersampling\n",
            "oversampling\n",
            "standardize\n",
            "dropping correlated columns\n",
            "(4000, 17) (1520, 17) (2533, 17) (4000, 1) (1520, 1) (2533, 1)\n"
          ]
        }
      ],
      "source": [
        "correlated_columns = ['S3_Temp', 'S4_Temp', 'S1_Light', 'S5_CO2']\n",
        "pp = Preprocessor(df1, corr_cols = correlated_columns, encode_y=False)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = pp.preprocess()\n",
        "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r5AIljlbWdi"
      },
      "outputs": [],
      "source": [
        "knn = KNearestNeighbor(X_train.to_numpy(),y_train.to_numpy(),X_test.to_numpy(),y_test.to_numpy()) \n",
        "errors = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4YDLh1HF2ot",
        "outputId": "6beb697d-4f43-452a-e34d-a5387cd2faca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error 0.012238452427951046\n",
            "Error 0.013422818791946308\n",
            "Error 0.011448874851954205\n",
            "Error 0.012238452427951046\n",
            "Error 0.011843663639952625\n",
            "Error 0.013028030003947888\n",
            "Error 0.016581129095933674\n",
            "Error 0.024871693643900513\n",
            "Error 0.026056060007895777\n",
            "Error 0.02803000394788788\n"
          ]
        }
      ],
      "source": [
        " for k in range(20,40,2): \n",
        "  y_preds = knn.fit(k)\n",
        "  error = knn.evaluate(y_preds) \n",
        "  errors.append(error) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "xBVIGSfUNEX0",
        "outputId": "6bd68958-028c-4900-c4b3-d5211ea606ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "k= np.arange(1,20,2) \n",
        "plt.figure(figsize=(16,8)) \n",
        "plt.plot(k, errors, 'bx-') \n",
        "plt.xlabel('k') \n",
        "plt.ylabel('Error') \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5496de23"
      },
      "source": [
        "Using k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb60e1f",
        "outputId": "3956a5eb-433c-44c3-b44b-e10e7bd603f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error 0.010659297275957363\n"
          ]
        }
      ],
      "source": [
        "y_preds = knn.fit(5)\n",
        "error = knn.evaluate(y_preds) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW-NKNLxba3F",
        "outputId": "b0eb878a-b0f5-4a51-dd26-44f5607423fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      1.00      2047\n",
            "         1.0       0.99      0.97      0.98       118\n",
            "         2.0       0.97      0.94      0.96       192\n",
            "         3.0       0.95      0.93      0.94       176\n",
            "\n",
            "    accuracy                           0.99      2533\n",
            "   macro avg       0.98      0.96      0.97      2533\n",
            "weighted avg       0.99      0.99      0.99      2533\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_preds,y_test.to_numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDCzcUgfGiag"
      },
      "source": [
        "# Softmax Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9s7mRbhLoAU"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self,X_train,X_val,X_test,y_train,y_val,y_test, learningRate, tolerance, maxIteration,reg,reg_param,) -> None:\n",
        "    self.X_train = X_train\n",
        "    self.X_val=X_val\n",
        "    self.X_test= X_test\n",
        "    self.y_train = y_train\n",
        "    self.y_val=y_val\n",
        "    self.y_test = y_test\n",
        "    self.learningRate = learningRate\n",
        "    self.tolerance = tolerance\n",
        "    self.maxIteration = maxIteration\n",
        "    self.error = []\n",
        "    self.iter_count = []\n",
        "    self.reg = reg\n",
        "    self.reg_param = reg_param\n",
        "\n",
        "  def datasetReader(self):\n",
        "    \n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = self.data\n",
        "\n",
        "    return  X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "  def add_X0(self, X):\n",
        "    return np.column_stack([np.ones(X.shape[0]),X])\n",
        "\n",
        "  # def sigmoid(self,z):\n",
        "  #   sig = 1 / (1 + np.exp(-z))\n",
        "  #   return sig\n",
        "\n",
        "  # def softmax(self,z):\n",
        "  #     z = z - np.max(z)\n",
        "  #     z = np.exp(z)\n",
        "  #     return np.divide(z , z.sum(axis=0))\n",
        "  \n",
        "  def costFunction(self,X,Y):\n",
        "      W = self.w\n",
        "      N = X.shape[0]\n",
        "      Z = - X @ W\n",
        "      y_hat = softmax(Z, axis = 1) \n",
        "      cost  = 1/N * (np.trace(X @ W @ Y.T) + np.sum(np.log(np.sum(np.exp(Z), axis=1)))) \n",
        "      if self.reg: \n",
        "        cost  = cost + (self.reg_param * ( np.sum(np.square(self.w)) ) )\n",
        "      return 0.5* np.mean(cost)\n",
        "\n",
        "  def gradient(self, X,Y):\n",
        "    W = self.w\n",
        "    Z = - X @ W\n",
        "    P = softmax(Z, axis=1)\n",
        "    N = X.shape[0]\n",
        "    gd = 1/N * (X.T @ (Y - P)) \n",
        "    return gd\n",
        "\n",
        "  def gradientDescent(self, X,y):\n",
        "    iters = []\n",
        "    errors = []\n",
        "    last_error = 0\n",
        "    testing_errors = []\n",
        "    training_errors = []\n",
        "    for i in tqdm(range(self.maxIteration)):\n",
        "      iters.append(i)\n",
        "      if self.reg: # L2 regularisation \n",
        "        w_update = self.w * (1 - self.learningRate *( self.reg_param / X.shape[0]))\n",
        "        self.w  = w_update - (self.learningRate  * self.gradient(X,y)) \n",
        "      else: \n",
        "        self.w = self.w - self.learningRate * self.gradient(X,y)\n",
        "\n",
        "      currentError = self.costFunction(X,y)\n",
        "      diff = last_error - currentError\n",
        "      last_error = currentError\n",
        "      errors.append(currentError)\n",
        "\n",
        "      y_tr_hat = self.pred(self.X_train)\n",
        "      training_accuracy, precision,recall = self.evaluate(self.y_train.to_numpy(), y_tr_hat.to_numpy())\n",
        "      training_errors.append(training_accuracy)\n",
        "      y_test_hat = self.pred(self.X_test)\n",
        "      testing_accuracy, precision,recall= self.evaluate(self.y_test.to_numpy(), y_test_hat.to_numpy())\n",
        "      testing_errors.append(testing_accuracy)\n",
        "\n",
        "\n",
        "      if np.abs(diff) < self.tolerance:\n",
        "        print('Model stopped learning')\n",
        "        break\n",
        "    plt.plot(iters, training_errors, color='blue',label = 'training error')\n",
        "    plt.plot(iters, testing_errors, color='red',label = 'testing error')\n",
        "    plt.show()\n",
        "    plt.plot(iters,errors)\n",
        "    plt.show()\n",
        "    print(errors.index(min(errors)))\n",
        "    return\n",
        "\n",
        "  def pred(self,X):\n",
        "    z = - X @ self.w\n",
        "    np.column_stack([np.ones([X.shape[0],1]),X])\n",
        "    pred = softmax(z, axis = 1)\n",
        "    return pred\n",
        "\n",
        "  def evaluate(self,y,y_hat):\n",
        "    y = np.argmax(y, axis = 1)\n",
        "    y_hat = np.argmax(y_hat, axis = 1)\n",
        "    accuracy = np.mean(y==y_hat)\n",
        "    precision = (y&y_hat).sum() / y_hat.sum()\n",
        "    recall = (y&y_hat).sum() / y.sum()\n",
        "    '''\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(y, y_hat)\n",
        "\n",
        "    ## Get Class Labels\n",
        "    class_names = y_train.columns.values\n",
        "\n",
        "    # Plot confusion matrix in a beautiful manner\n",
        "    fig = plt.figure(figsize=(16, 14))\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cells\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted', fontsize=20)\n",
        "    ax.xaxis.set_label_position('bottom')\n",
        "    plt.xticks(rotation=90)\n",
        "    ax.xaxis.set_ticklabels(class_names, fontsize = 10)\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    ax.set_ylabel('True', fontsize=20)\n",
        "    ax.yaxis.set_ticklabels(class_names, fontsize = 10)\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    plt.title('Refined Confusion Matrix', fontsize=20)\n",
        "\n",
        "    plt.savefig('ConMat24.png')\n",
        "    plt.show()\n",
        "    '''\n",
        "\n",
        "    return accuracy,precision,recall\n",
        "\n",
        "  def fit(self):\n",
        "    \n",
        "    self.add_X0(self.X_train)\n",
        "    print('Solving using gradient descent')\n",
        "    #print(y_train.shape)\n",
        "    #initializing weights\n",
        "    self.w = np.random.RandomState(25).randn(self.X_train.shape[1], self.y_train.shape[1]) * (2 / np.sqrt(self.X_train.shape[0]))\n",
        "    #self.w = np.ones(X_train.shape[1],dtype = np.float64)*0\n",
        "  \n",
        "    self.gradientDescent(self.X_train,self.y_train)\n",
        "    #print(self.w)\n",
        "  def predict(self,X,y):\n",
        "    y_val_hat = self.pred(X)\n",
        "    #y_test_hat = self.predict(self.X_test)\n",
        "    accuracy,precision,recall = self.evaluate(y.to_numpy(), y_val_hat.to_numpy())\n",
        "    #accuracy_T = self.evaluate(self.y_test.to_numpy(), y_test_hat.to_numpy())\n",
        "\n",
        "    print(self.learningRate,self.reg_param)\n",
        "    print('Accuracy is {}',format(accuracy))\n",
        "    print('precision is {}',format(precision))\n",
        "    print('recall is {}',format(recall))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_0QEkSvoftCM",
        "outputId": "999037a9-00b6-4e83-bc1b-cfa6a59db53b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersampling\n",
            "undersampling\n",
            "standardizing\n",
            "Variance captured by 0 Principal Components is 0.0%\n",
            "Variance captured by 1 Principal Components is 0.49372093651378535%\n",
            "Variance captured by 2 Principal Components is 0.6180088356132694%\n",
            "Variance captured by 3 Principal Components is 0.700090018752357%\n",
            "Variance captured by 4 Principal Components is 0.7562387478267663%\n",
            "Variance captured by 5 Principal Components is 0.8038583691598393%\n",
            "Variance captured by 6 Principal Components is 0.8447980541204152%\n",
            "Variance captured by 7 Principal Components is 0.8785037995563598%\n",
            "Variance captured by 8 Principal Components is 0.9064408481283031%\n",
            "Variance captured by 9 Principal Components is 0.9276598272226568%\n",
            "Variance captured by 10 Principal Components is 0.9467656003709899%\n",
            "Variance captured by 11 Principal Components is 0.962618281915689%\n",
            "Variance captured by 12 Principal Components is 0.974262383429736%\n",
            "Variance captured by 13 Principal Components is 0.9832208572780614%\n",
            "Variance captured by 14 Principal Components is 0.9909023156644838%\n",
            "Variance captured by 15 Principal Components is 0.9954319624730368%\n",
            "Variance captured by 16 Principal Components is 0.998756844115928%\n",
            "Variance captured by 17 Principal Components is 1.0%\n",
            "Solving using gradient descent\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 376/750 [00:05<00:05, 73.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model stopped learning\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "376\n",
            "0.0005 0.01\n",
            "Accuracy is {} 0.6255\n",
            "precision is {} 0.8188452805708726\n",
            "recall is {} 0.8415\n",
            "0.0005 0.01\n",
            "Accuracy is {} 0.8179025888547609\n",
            "precision is {} 0.0\n",
            "recall is {} nan\n",
            "0.0005 0.01\n",
            "Accuracy is {} 0.8945913936044216\n",
            "precision is {} 0.7902033271719039\n",
            "recall is {} 0.8482142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:103: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "lr_error = []\n",
        "reg_param = [0.01]\n",
        "learning_rate = [0.0005]\n",
        "maxiter = [750]\n",
        "pca = PCA(df)\n",
        "pca.fit()\n",
        "X_pca_tr, X_pca_val, X_pca_test, y_pca_tr, y_pca_val, y_pca_test = pca.transform(n_components=6)\n",
        "\n",
        "for i in learning_rate:\n",
        "  for j in reg_param:\n",
        "    for k in maxiter:\n",
        "      reg_logit = LogisticRegression( X_pca_tr, X_pca_val, X_pca_test, y_pca_tr, y_pca_val, y_pca_test,learningRate = i, tolerance= 0.0005, maxIteration = k,reg = True,reg_param = j)\n",
        "      reg_logit.fit()\n",
        "\n",
        "      reg_logit.predict(X_pca_tr,y_pca_tr)\n",
        "      reg_logit.predict(X_pca_val,y_pca_val)\n",
        "      reg_logit.predict(X_pca_test,y_pca_test)\n",
        "      \n",
        "      lr_error.append(np.mean(reg_logit.error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVupJSjsSJg9"
      },
      "outputs": [],
      "source": [
        "df.S5_CO2_Slope = (df.S5_CO2_Slope - min(df['S5_CO2_Slope']))/(max(df['S5_CO2_Slope']-min(df['S5_CO2_Slope'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "nat3FTyYSQm_",
        "outputId": "159dcd87-0e31-48eb-888a-a3a234e7f78e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d03b94a1-4d51-4994-88c0-252a3255895c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1_Temp</th>\n",
              "      <th>S2_Temp</th>\n",
              "      <th>S3_Temp</th>\n",
              "      <th>S4_Temp</th>\n",
              "      <th>S1_Light</th>\n",
              "      <th>S2_Light</th>\n",
              "      <th>S3_Light</th>\n",
              "      <th>S4_Light</th>\n",
              "      <th>S1_Sound</th>\n",
              "      <th>S2_Sound</th>\n",
              "      <th>S3_Sound</th>\n",
              "      <th>S4_Sound</th>\n",
              "      <th>S5_CO2</th>\n",
              "      <th>S5_CO2_Slope</th>\n",
              "      <th>S6_PIR</th>\n",
              "      <th>S7_PIR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>25.38</td>\n",
              "      <td>25.44</td>\n",
              "      <td>24.94</td>\n",
              "      <td>25.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>365</td>\n",
              "      <td>0.412135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3055</th>\n",
              "      <td>26.00</td>\n",
              "      <td>26.31</td>\n",
              "      <td>25.44</td>\n",
              "      <td>26.25</td>\n",
              "      <td>162</td>\n",
              "      <td>250</td>\n",
              "      <td>84</td>\n",
              "      <td>62</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2.91</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.20</td>\n",
              "      <td>560</td>\n",
              "      <td>0.711480</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5890</th>\n",
              "      <td>25.38</td>\n",
              "      <td>25.38</td>\n",
              "      <td>25.31</td>\n",
              "      <td>26.06</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>80</td>\n",
              "      <td>59</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.10</td>\n",
              "      <td>355</td>\n",
              "      <td>0.412135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2815</th>\n",
              "      <td>25.19</td>\n",
              "      <td>25.19</td>\n",
              "      <td>24.94</td>\n",
              "      <td>25.88</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>65</td>\n",
              "      <td>46</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>360</td>\n",
              "      <td>0.412638</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2660</th>\n",
              "      <td>25.06</td>\n",
              "      <td>25.13</td>\n",
              "      <td>24.69</td>\n",
              "      <td>25.63</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>48</td>\n",
              "      <td>33</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>355</td>\n",
              "      <td>0.409114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2953</th>\n",
              "      <td>25.69</td>\n",
              "      <td>25.50</td>\n",
              "      <td>25.19</td>\n",
              "      <td>26.06</td>\n",
              "      <td>155</td>\n",
              "      <td>245</td>\n",
              "      <td>72</td>\n",
              "      <td>53</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>385</td>\n",
              "      <td>0.422709</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3151</th>\n",
              "      <td>25.94</td>\n",
              "      <td>26.94</td>\n",
              "      <td>25.56</td>\n",
              "      <td>26.25</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.11</td>\n",
              "      <td>595</td>\n",
              "      <td>0.297080</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9751</th>\n",
              "      <td>25.13</td>\n",
              "      <td>25.13</td>\n",
              "      <td>24.56</td>\n",
              "      <td>25.19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>345</td>\n",
              "      <td>0.412135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>25.13</td>\n",
              "      <td>25.13</td>\n",
              "      <td>24.75</td>\n",
              "      <td>25.69</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>360</td>\n",
              "      <td>0.422709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4456</th>\n",
              "      <td>25.38</td>\n",
              "      <td>25.38</td>\n",
              "      <td>24.88</td>\n",
              "      <td>25.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>365</td>\n",
              "      <td>0.412135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7596 rows Ã— 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d03b94a1-4d51-4994-88c0-252a3255895c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d03b94a1-4d51-4994-88c0-252a3255895c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d03b94a1-4d51-4994-88c0-252a3255895c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      S1_Temp  S2_Temp  S3_Temp  S4_Temp  S1_Light  S2_Light  S3_Light  \\\n",
              "4411    25.38    25.44    24.94    25.75         0         0         0   \n",
              "3055    26.00    26.31    25.44    26.25       162       250        84   \n",
              "5890    25.38    25.38    25.31    26.06        19        22        80   \n",
              "2815    25.19    25.19    24.94    25.88        14        16        65   \n",
              "2660    25.06    25.13    24.69    25.63        10        10        48   \n",
              "...       ...      ...      ...      ...       ...       ...       ...   \n",
              "2953    25.69    25.50    25.19    26.06       155       245        72   \n",
              "3151    25.94    26.94    25.56    26.25        14        15        72   \n",
              "9751    25.13    25.13    24.56    25.19         0         0         0   \n",
              "2680    25.13    25.13    24.75    25.69        10        11        49   \n",
              "4456    25.38    25.38    24.88    25.69         0         0         0   \n",
              "\n",
              "      S4_Light  S1_Sound  S2_Sound  S3_Sound  S4_Sound  S5_CO2  S5_CO2_Slope  \\\n",
              "4411         0      0.07      0.05      0.06      0.07     365      0.412135   \n",
              "3055        62      0.44      2.91      0.30      0.20     560      0.711480   \n",
              "5890        59      0.08      0.10      0.08      0.10     355      0.412135   \n",
              "2815        46      0.08      0.05      0.06      0.06     360      0.412638   \n",
              "2660        33      0.08      0.05      0.06      0.06     355      0.409114   \n",
              "...        ...       ...       ...       ...       ...     ...           ...   \n",
              "2953        53      0.80      1.00      0.29      0.27     385      0.422709   \n",
              "3151        52      0.16      0.18      0.18      0.11     595      0.297080   \n",
              "9751         0      0.08      0.04      0.06      0.08     345      0.412135   \n",
              "2680        34      0.08      0.04      0.06      0.06     360      0.422709   \n",
              "4456         0      0.07      0.04      0.07      0.07     365      0.412135   \n",
              "\n",
              "      S6_PIR  S7_PIR  \n",
              "4411       0       0  \n",
              "3055       1       1  \n",
              "5890       0       0  \n",
              "2815       0       0  \n",
              "2660       0       0  \n",
              "...      ...     ...  \n",
              "2953       0       1  \n",
              "3151       0       0  \n",
              "9751       0       0  \n",
              "2680       0       0  \n",
              "4456       0       0  \n",
              "\n",
              "[7596 rows x 16 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols = ['Time']\n",
        "df.drop(columns = cols, inplace = True)\n",
        "y = df['Room_Occupancy_Count']\n",
        "X = df.loc[:, df.columns!='Room_Occupancy_Count']\n",
        "X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X, y, test_size = 0.25,\n",
        "                                                  random_state= 0, stratify= y)\n",
        "X_df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBbtyLVJR0-U"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    \n",
        "    def __init__(self,X_train,X_test, y_train,y_test):\n",
        "        self.X_train = X_train\n",
        "        self.X_test =X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "                \n",
        "    def fit_dist(self,data):\n",
        "        mu = np.mean(data)\n",
        "        sigma = np.std(data)\n",
        "        dist = norm(mu,sigma)\n",
        "        return dist\n",
        "\n",
        "    def probability(self,X,prior,distribution):\n",
        "        self.num_features = self.X_train.shape[1]\n",
        "        res = []\n",
        "\n",
        "        for j in range(self.num_features):\n",
        "            for k,v in distribution.items():\n",
        "              res.append(v.pdf(X[j]))\n",
        "        res = res[0::self.num_features]\n",
        "        print('res',res)\n",
        "        a = np.prod(res, axis=None, dtype=None, out=None)\n",
        "        print('a',a)\n",
        "        print('prior',prior)\n",
        "        return a*prior\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          \n",
        "    def run_model(self):\n",
        "\n",
        "        self.X_train = self.X_train.values\n",
        "        self.X_test = self.X_test.values\n",
        "        self.y_train = self.y_train.values\n",
        "        self.y_test = self.y_test.values\n",
        "\n",
        "        self.num_features = self.X_train.shape[1]\n",
        "\n",
        "        self.X0_train = self.X_train[self.y_train == 0]\n",
        "        self.X1_train = self.X_train[self.y_train == 1]\n",
        "        self.X2_train = self.X_train[self.y_train == 2]\n",
        "        self.X3_train = self.X_train[self.y_train == 3]\n",
        "        \n",
        "        \n",
        "\n",
        "        self.prior_y0 = len(self.X0_train) / len(self.X_train)\n",
        "        self.prior_y1 = len(self.X1_train) / len(self.X_train)\n",
        "        self.prior_y2 = len(self.X2_train) / len(self.X_train)\n",
        "        self.prior_y3 = len(self.X3_train) / len(self.X_train)\n",
        "\n",
        "           \n",
        "        print('prior',self.prior_y0)\n",
        "        print(self.prior_y1)\n",
        "        print(self.prior_y2)\n",
        "        print(self.prior_y3)\n",
        "            \n",
        "        \n",
        "        \n",
        "\n",
        "        self.dist1 = {}\n",
        "        self.dist2 = {}\n",
        "        self.dist3 = {}\n",
        "        self.dist4 = {}\n",
        "\n",
        "\n",
        "        \n",
        "        for i in range(self.num_features):\n",
        "            self.dist1['dist_'+'X'+str(i+1)+'y0'] = self.fit_dist(self.X0_train[:,i])\n",
        "            self.dist2['dist_'+'X'+str(i+1)+'y1'] = self.fit_dist(self.X1_train[:,i])\n",
        "            self.dist3['dist_'+'X'+str(i+1)+'y2'] = self.fit_dist(self.X2_train[:,i])\n",
        "            self.dist4['dist_'+'X'+str(i+1)+'y3'] = self.fit_dist(self.X3_train[:,i])\n",
        "           \n",
        "            \n",
        "        print('dist',self.dist1)\n",
        "        print(self.dist2)\n",
        "        print(self.dist3)\n",
        "        print(self.dist4)\n",
        "          \n",
        "\n",
        "\n",
        "    def predict_test(self):\n",
        "      \n",
        "        right = 0\n",
        "        wrong = 0\n",
        "        count0 = 0\n",
        "        count1 = 1\n",
        "        count2 = 2\n",
        "        count3 = 3\n",
        "       \n",
        "\n",
        "        \n",
        "        train_start_time = datetime.now()\n",
        "        for sample, target in zip(self.X_test, self.y_test):\n",
        "            \n",
        "            py0 = self.probability(sample,self.prior_y0,self.dist1)\n",
        "            py1 = self.probability(sample,self.prior_y1,self.dist2)\n",
        "            py2 = self.probability(sample,self.prior_y2,self.dist3)\n",
        "            py3 = self.probability(sample,self.prior_y3,self.dist4)\n",
        "           \n",
        "            \n",
        "            print('p(y=0 | %s) = %.3f' % (sample, py0*100))\n",
        "            print('p(y=1 | %s) = %.3f' % (sample, py1*100))\n",
        "            print('p(y=2 | %s) = %.3f' % (sample, py2*100))\n",
        "            print('p(y=3 | %s) = %.3f' % (sample, py3*100))\n",
        "            \n",
        "\n",
        "            \n",
        "            print('model predicted class {} and the truth was {} \\n' .format(np.argmax([py0*10,py1*10,py2*10,py3*10]), target))\n",
        "            if (np.argmax([py0*100,py1*100,py2*100,py3*100]) == target):\n",
        "                print('Right\\n')\n",
        "                right+=1\n",
        "            else:\n",
        "                if target == 0:\n",
        "                    count0+=1\n",
        "                elif target ==1:\n",
        "                    count1+=1\n",
        "                elif target ==2:\n",
        "                    count2+=1\n",
        "                elif target ==3:\n",
        "                    count3+=1\n",
        "                \n",
        "                print('class being misclassified is',target)\n",
        "                print('Wrong\\n')\n",
        "                wrong+=1\n",
        "        #train_end_time = datetime.now()\n",
        "        #train_time = train_end_time - train_start_time\n",
        "        print('testing error :',(((wrong)/(right+wrong))*100))\n",
        "        print('count for class 0 :', count0)\n",
        "        print('count for class 1 :', count1)\n",
        "        print('count for class 2 :', count2)\n",
        "        print('count for class 3 :', count3)\n",
        "        \n",
        "      \n",
        "        #print('Test Time', train_time)\n",
        "        \n",
        "    def predict_train(self):\n",
        "      \n",
        "        right = 0\n",
        "        wrong = 0\n",
        "        count0 = 0\n",
        "        count1 = 1\n",
        "        count2 = 2\n",
        "        count3 = 3\n",
        "       \n",
        "        test_start_time = datetime.now()\n",
        "        for sample, target in zip(self.X_train, self.y_train):\n",
        "           \n",
        "            py0 = self.probability(sample,self.prior_y0,self.dist1)\n",
        "            py1 = self.probability(sample,self.prior_y1,self.dist2)\n",
        "            py2 = self.probability(sample,self.prior_y2,self.dist3)\n",
        "            py3 = self.probability(sample,self.prior_y3,self.dist4)\n",
        "            \n",
        "            \n",
        "            print('model predicted class {} and the truth was {} \\n' .format(np.argmax([py0*100,py1*100,py2*100,py3*100]), target))\n",
        "            if (np.argmax([py0*100,py1*100,py2*100,py3*100]) == target):\n",
        "                print('Right\\n')\n",
        "                right+=1\n",
        "            else:\n",
        "                if target == 0:\n",
        "                    count0+=1\n",
        "                elif target ==1:\n",
        "                    count1+=1\n",
        "                elif target ==2:\n",
        "                    count2+=1\n",
        "                elif target ==3:\n",
        "                    count3+=1\n",
        "               \n",
        "                \n",
        "                print('class being misclassified is',target)\n",
        "                print('Wrong\\n')\n",
        "                wrong+=1\n",
        "        #test_end_time = datetime.now()\n",
        "        #test_time = test_end_time - test_start_time\n",
        "        print('training Error:',(((wrong)/(right+wrong))*100))\n",
        "        print('count for class 0 :', count0)\n",
        "        print('count for class 1 :', count1)\n",
        "        print('count for class 2 :', count2)\n",
        "        print('count for class 3 :', count3)\n",
        "\n",
        "       \n",
        "       \n",
        "        #print('Train Time', test_time)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRGQiUIUu0d",
        "outputId": "00518af2-5d7e-4306-9514-4bf415cb297f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prior 0.8122696155871512\n",
            "0.04528699315429173\n",
            "0.07385466034755134\n",
            "0.0685887309110058\n",
            "dist {'dist_X1y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9e252110>, 'dist_X2y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9e226890>, 'dist_X3y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c953b10>, 'dist_X4y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8ea590>, 'dist_X5y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2ca125ee50>, 'dist_X6y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c9599d0>, 'dist_X7y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8eaa90>, 'dist_X8y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900210>, 'dist_X9y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900b10>, 'dist_X10y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91f250>, 'dist_X11y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91fb50>, 'dist_X12y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1390>, 'dist_X13y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1b90>, 'dist_X14y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c33d0>, 'dist_X15y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c3bd0>, 'dist_X16y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1410>, 'dist_X17y0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1c10>}\n",
            "{'dist_X1y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c921b90>, 'dist_X2y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2ca1812f90>, 'dist_X3y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c953590>, 'dist_X4y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8ea410>, 'dist_X5y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c921690>, 'dist_X6y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c959750>, 'dist_X7y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8eab10>, 'dist_X8y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900510>, 'dist_X9y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900b90>, 'dist_X10y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91f550>, 'dist_X11y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91fbd0>, 'dist_X12y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1550>, 'dist_X13y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1c10>, 'dist_X14y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c3590>, 'dist_X15y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c3c50>, 'dist_X16y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d15d0>, 'dist_X17y1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1c90>}\n",
            "{'dist_X1y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c921cd0>, 'dist_X2y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9e226b10>, 'dist_X3y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c953a90>, 'dist_X4y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8ea610>, 'dist_X5y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c921350>, 'dist_X6y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c959dd0>, 'dist_X7y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8eab50>, 'dist_X8y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c9006d0>, 'dist_X9y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900f50>, 'dist_X10y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91f710>, 'dist_X11y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91fa90>, 'dist_X12y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1790>, 'dist_X13y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1ed0>, 'dist_X14y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c37d0>, 'dist_X15y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c3f10>, 'dist_X16y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1810>, 'dist_X17y2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2ca12069d0>}\n",
            "{'dist_X1y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9e20d790>, 'dist_X2y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c953790>, 'dist_X3y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c9538d0>, 'dist_X4y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9e24f2d0>, 'dist_X5y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2ca0d48890>, 'dist_X6y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8ea6d0>, 'dist_X7y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8eaf10>, 'dist_X8y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c900910>, 'dist_X9y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91f050>, 'dist_X10y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c91f950>, 'dist_X11y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1090>, 'dist_X12y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8b1990>, 'dist_X13y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c30d0>, 'dist_X14y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8c39d0>, 'dist_X15y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1110>, 'dist_X16y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d1a10>, 'dist_X17y3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2c9c8d2150>}\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.4298858024045102, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py:1870: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py:1870: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 3.96273917e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 3.96273917e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 3.96273917e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 3.96273917e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0067276320461765, 0.369949896396296, 0.7777783298469527, 0.0011257721996219864, 0.0, 5.393742383204728e-11, 0.0, 3.0872726858116797e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6249671870164742, 1.210545739433308, 1.131586042750569, 0.38478853960904225, 0.0, 0.0009207473553425444, 0.0, 8.963491537033661e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.479531085577258, 0.9365612888973045, 0.47004074717167255, 0.9911681328875325, 0.0, 0.00021617358496294118, 0.0, 2.252679407850769e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5406519737696889, 0.7257709170460954, 0.35413111078922477, 1.2093036686472622, 0.0, 0.0014416263967194725, 0.0, 2.560480804893931e-15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61300000e+01 2.57500000e+01 2.56300000e+01 2.62500000e+01\n",
            " 1.18000000e+02 2.70000000e+01 1.99000000e+02 2.40000000e+01\n",
            " 2.40000000e-01 8.00000000e-02 2.60000000e-01 7.00000000e-02\n",
            " 6.30000000e+02 4.35548842e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61300000e+01 2.57500000e+01 2.56300000e+01 2.62500000e+01\n",
            " 1.18000000e+02 2.70000000e+01 1.99000000e+02 2.40000000e+01\n",
            " 2.40000000e-01 8.00000000e-02 2.60000000e-01 7.00000000e-02\n",
            " 6.30000000e+02 4.35548842e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61300000e+01 2.57500000e+01 2.56300000e+01 2.62500000e+01\n",
            " 1.18000000e+02 2.70000000e+01 1.99000000e+02 2.40000000e+01\n",
            " 2.40000000e-01 8.00000000e-02 2.60000000e-01 7.00000000e-02\n",
            " 6.30000000e+02 4.35548842e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61300000e+01 2.57500000e+01 2.56300000e+01 2.62500000e+01\n",
            " 1.18000000e+02 2.70000000e+01 1.99000000e+02 2.40000000e+01\n",
            " 2.40000000e-01 8.00000000e-02 2.60000000e-01 7.00000000e-02\n",
            " 6.30000000e+02 4.35548842e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.15198556504483227, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.02052921913893488, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 3.850964789504696e-06, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 5.525603836091904e-06, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.48100000e+01 2.58100000e+01\n",
            " 1.57000000e+02 2.42000000e+02 6.90000000e+01 5.40000000e+01\n",
            " 5.80000000e-01 5.60000000e-01 2.50000000e-01 1.60000000e-01\n",
            " 4.50000000e+02 4.47381672e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.48100000e+01 2.58100000e+01\n",
            " 1.57000000e+02 2.42000000e+02 6.90000000e+01 5.40000000e+01\n",
            " 5.80000000e-01 5.60000000e-01 2.50000000e-01 1.60000000e-01\n",
            " 4.50000000e+02 4.47381672e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.48100000e+01 2.58100000e+01\n",
            " 1.57000000e+02 2.42000000e+02 6.90000000e+01 5.40000000e+01\n",
            " 5.80000000e-01 5.60000000e-01 2.50000000e-01 1.60000000e-01\n",
            " 4.50000000e+02 4.47381672e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.48100000e+01 2.58100000e+01\n",
            " 1.57000000e+02 2.42000000e+02 6.90000000e+01 5.40000000e+01\n",
            " 5.80000000e-01 5.60000000e-01 2.50000000e-01 1.60000000e-01\n",
            " 4.50000000e+02 4.47381672e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.3884867679491852, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.28419996615678017, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.004002499108730581, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.003553544572701595, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.05840886e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.05840886e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.05840886e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.05840886e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0011257721996219864, 0.0001223097503070933, 0.06831094404501414, 0.0001223097503070933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38478853960904225, 0.19590856594612643, 1.0270646055511061, 0.19590856594612643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9911681328875325, 0.47804205875152145, 1.6339466321252831, 0.47804205875152145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.2093036686472622, 0.7173275394971488, 1.4113696895370869, 0.7173275394971488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.62500000e+01 2.63800000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.86000000e+02 1.00000000e+01\n",
            " 2.50000000e-01 3.44000000e+00 8.40000000e-01 2.40000000e-01\n",
            " 1.05000000e+03 5.48590131e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.62500000e+01 2.63800000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.86000000e+02 1.00000000e+01\n",
            " 2.50000000e-01 3.44000000e+00 8.40000000e-01 2.40000000e-01\n",
            " 1.05000000e+03 5.48590131e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.62500000e+01 2.63800000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.86000000e+02 1.00000000e+01\n",
            " 2.50000000e-01 3.44000000e+00 8.40000000e-01 2.40000000e-01\n",
            " 1.05000000e+03 5.48590131e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.62500000e+01 2.63800000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.86000000e+02 1.00000000e+01\n",
            " 2.50000000e-01 3.44000000e+00 8.40000000e-01 2.40000000e-01\n",
            " 1.05000000e+03 5.48590131e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 3 \n",
            "\n",
            "class being misclassified is 3\n",
            "Wrong\n",
            "\n",
            "res [0.8644591839089937, 1.1572784212086917, 0.0038843930785171306, 1.634738519368388, 0.0, 0.0, 4.157611003110773e-21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.20502885936011442, 0.0008988318898802732, 0.6422648550843036, 0.0, 0.0, 8.93235212604694e-16, 9.586269261857777e-232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0015912588907227808, 1.908674147339961e-09, 0.04824906873551714, 0.0, 0.0, 3.796788013902749e-36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0014925798039521043, 5.110442847234481e-09, 0.03789977035775252, 0.0, 0.0, 3.962682970707894e-33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 4.00000000e+00 5.00000000e+00 2.30000000e+01 1.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 4.00000000e+00 5.00000000e+00 2.30000000e+01 1.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 4.00000000e+00 5.00000000e+00 2.30000000e+01 1.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 4.00000000e+00 5.00000000e+00 2.30000000e+01 1.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.6560892753423306, 1.1572784212086917, 0.06831094404501414, 0.0, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.49437318554825355, 0.20502885936011442, 1.0270646055511061, 9.411427216568543e-191, 8.985884609549385e-67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.02081153447270444, 0.0015912588907227808, 1.6339466321252831, 0.0, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.01694670783654658, 0.0014925798039521043, 1.4113696895370869, 0.0, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.60000000e+01 2.00000000e+01 7.00000000e+01 5.00000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.60000000e+01 2.00000000e+01 7.00000000e+01 5.00000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.60000000e+01 2.00000000e+01 7.00000000e+01 5.00000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.60000000e+01 2.00000000e+01 7.00000000e+01 5.00000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.634738519368388, 0.4298858024045102, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.6422648550843036, 0.0585843072056394, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.04824906873551714, 5.5696255317175676e-05, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.03789977035775252, 6.546247162567774e-05, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.009000306396803447, 1.3884867679491852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0017645850083361874, 0.28419996615678017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 9.540035501867375e-09, 0.004002499108730581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 2.2272536225936306e-08, 0.003553544572701595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0015745886692075798, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0004429132138564848, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 3.576934139915957e-10, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1069783272151325e-09, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.3884867679491852, 0.15198556504483227, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.28419996615678017, 0.02052921913893488, 1.189959701550509, 0.0, 9.791110411060581e-277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.004002499108730581, 3.850964789504696e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.003553544572701595, 5.525603836091904e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51900000e+01 2.48100000e+01 2.56900000e+01\n",
            " 1.20000000e+01 1.40000000e+01 5.40000000e+01 3.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51900000e+01 2.48100000e+01 2.56900000e+01\n",
            " 1.20000000e+01 1.40000000e+01 5.40000000e+01 3.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51900000e+01 2.48100000e+01 2.56900000e+01\n",
            " 1.20000000e+01 1.40000000e+01 5.40000000e+01 3.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51900000e+01 2.48100000e+01 2.56900000e+01\n",
            " 1.20000000e+01 1.40000000e+01 5.40000000e+01 3.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.035163991295557286, 0.2322488409221858, 1.0686121283749463, 0.0004191908302828797, 0.0, 8.305926896659704e-83, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9100484937946683, 1.1913364523126768, 1.0233107530619845, 0.2872837104225711, 0.0, 9.693875764177745e-37, 0.0, 1.1156368421680548e-171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6997792628930506, 1.198484934895971, 0.2786243708311884, 0.735453090688109, 0.0, 2.0430878332126198e-63, 0.0, 1.39193e-319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.544376636821353, 0.9530262922520344, 0.20949847667461025, 0.9827393915425461, 0.0, 2.4472923233745648e-54, 0.0, 6.868413463095594e-278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.60000000e+01 2.58100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.18000000e+02 3.00000000e+01 5.40000000e+01 3.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.95000000e+02 5.21399799e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.60000000e+01 2.58100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.18000000e+02 3.00000000e+01 5.40000000e+01 3.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.95000000e+02 5.21399799e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.60000000e+01 2.58100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.18000000e+02 3.00000000e+01 5.40000000e+01 3.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.95000000e+02 5.21399799e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.60000000e+01 2.58100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.18000000e+02 3.00000000e+01 5.40000000e+01 3.50000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.95000000e+02 5.21399799e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [1.0686121283749463, 1.3109458656169541, 1.1572784212086917, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0233107530619845, 0.9056744868132555, 0.20502885936011442, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.2786243708311884, 0.16579764589159204, 0.0015912588907227808, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.20949847667461025, 0.12550886003790895, 0.0014925798039521043, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55600000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.85000000e+02 3.93756294e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55600000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.85000000e+02 3.93756294e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55600000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.85000000e+02 3.93756294e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55600000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.85000000e+02 3.93756294e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.634738519368388, 0.2759462627217734, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.6422648550843036, 0.03681205778207625, 1.210545739433308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.04824906873551714, 1.686130682736435e-05, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.03789977035775252, 2.1630523427202543e-05, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53800000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.5646734325554212, 0.15198556504483227, 1.6560892753423306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.38109857568304006, 0.02052921913893488, 0.49437318554825355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.009430158603017429, 3.850964789504696e-06, 0.02081153447270444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.007986889838661918, 5.525603836091904e-06, 0.01694670783654658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.2322488409221858, 0.369949896396296, 1.634738519368388, 0.0067276320461765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.1913364523126768, 1.210545739433308, 0.6422648550843036, 0.6249671870164742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.198484934895971, 0.9365612888973045, 0.04824906873551714, 1.479531085577258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.9530262922520344, 0.7257709170460954, 0.03789977035775252, 1.5406519737696889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.58100000e+01 2.57500000e+01 2.53800000e+01 2.61300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.20000000e+02 2.79456193e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.58100000e+01 2.57500000e+01 2.53800000e+01 2.61300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.20000000e+02 2.79456193e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.58100000e+01 2.57500000e+01 2.53800000e+01 2.61300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.20000000e+02 2.79456193e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.58100000e+01 2.57500000e+01 2.53800000e+01 2.61300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.20000000e+02 2.79456193e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.08517122922065898, 0.369949896396296, 0.0, 0.0, 0.0, 2.0245857241639047e-284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.012005783156308833, 1.210545739433308, 0.0, 0.0, 0.0, 1.078801122944882e-136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 1.0118024174082307e-06, 0.9365612888973045, 0.0, 0.0, 0.0, 1.4328229520462304e-252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 1.6116464269829333e-06, 0.7257709170460954, 0.0, 0.0, 0.0, 2.7587400278537175e-219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.10000000e+01 4.90000000e+01 3.40000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.10000000e+01 4.90000000e+01 3.40000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.10000000e+01 4.90000000e+01 3.40000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.10000000e+01 4.90000000e+01 3.40000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.12464087343216625, 0.369949896396296, 1.5105235152729721, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.1213347165497891, 1.210545739433308, 0.7754271574975016, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.4712299622758223, 0.9365612888973045, 0.09241340481217675, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.217643263416463, 0.7257709170460954, 0.07098386153852101, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.58800000e+01 2.57500000e+01 2.54400000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 7.85000000e+02 2.78700906e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.58800000e+01 2.57500000e+01 2.54400000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 7.85000000e+02 2.78700906e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.58800000e+01 2.57500000e+01 2.54400000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 7.85000000e+02 2.78700906e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.58800000e+01 2.57500000e+01 2.54400000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 7.85000000e+02 2.78700906e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.0448292590729217, 1.5105235152729721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.28419996615678017, 0.006792237089151543, 0.7754271574975016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.004002499108730581, 2.4901140005593237e-07, 0.09241340481217675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.003553544572701595, 4.437634360892876e-07, 0.07098386153852101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.51900000e+01 2.46900000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.51900000e+01 2.46900000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.51900000e+01 2.46900000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.51900000e+01 2.46900000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.1572784212086917, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.20502885936011442, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.0015912588907227808, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.0014925798039521043, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.21198389e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.21198389e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.21198389e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.21198389e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.369949896396296, 0.12464087343216625, 1.5105235152729721, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.210545739433308, 1.1213347165497891, 0.7754271574975016, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9365612888973045, 1.4712299622758223, 0.09241340481217675, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.7257709170460954, 1.217643263416463, 0.07098386153852101, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.57500000e+01 2.58800000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.65000000e+02 2.82225579e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.57500000e+01 2.58800000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.65000000e+02 2.82225579e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.57500000e+01 2.58800000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.65000000e+02 2.82225579e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.57500000e+01 2.58800000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.65000000e+02 2.82225579e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.035163991295557286, 5.393742383204728e-11, 1.5105235152729721, 0.0004191908302828797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9100484937946683, 0.0009207473553425444, 0.7754271574975016, 0.2872837104225711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6997792628930506, 0.00021617358496294118, 0.09241340481217675, 0.735453090688109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.544376636821353, 0.0014416263967194725, 0.07098386153852101, 0.9827393915425461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.60000000e+01 2.70000000e+01 2.54400000e+01 2.63100000e+01\n",
            " 1.61000000e+02 2.49000000e+02 8.40000000e+01 6.20000000e+01\n",
            " 1.05000000e+00 1.49000000e+00 4.80000000e-01 5.50000000e-01\n",
            " 5.75000000e+02 5.62940584e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.60000000e+01 2.70000000e+01 2.54400000e+01 2.63100000e+01\n",
            " 1.61000000e+02 2.49000000e+02 8.40000000e+01 6.20000000e+01\n",
            " 1.05000000e+00 1.49000000e+00 4.80000000e-01 5.50000000e-01\n",
            " 5.75000000e+02 5.62940584e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.60000000e+01 2.70000000e+01 2.54400000e+01 2.63100000e+01\n",
            " 1.61000000e+02 2.49000000e+02 8.40000000e+01 6.20000000e+01\n",
            " 1.05000000e+00 1.49000000e+00 4.80000000e-01 5.50000000e-01\n",
            " 5.75000000e+02 5.62940584e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.60000000e+01 2.70000000e+01 2.54400000e+01 2.63100000e+01\n",
            " 1.61000000e+02 2.49000000e+02 8.40000000e+01 6.20000000e+01\n",
            " 1.05000000e+00 1.49000000e+00 4.80000000e-01 5.50000000e-01\n",
            " 5.75000000e+02 5.62940584e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.1572784212086917, 0.8644591839089937, 0.009000306396803447, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.13433108971930502, 0.0017645850083361874, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0004994449026255511, 9.540035501867375e-09, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0005044502023565899, 2.2272536225936306e-08, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.50600000e+01 2.45600000e+01 2.52500000e+01\n",
            " 1.00000000e+00 1.00000000e+00 8.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.50600000e+01 2.45600000e+01 2.52500000e+01\n",
            " 1.00000000e+00 1.00000000e+00 8.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.50600000e+01 2.45600000e+01 2.52500000e+01\n",
            " 1.00000000e+00 1.00000000e+00 8.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.50600000e+01 2.45600000e+01 2.52500000e+01\n",
            " 1.00000000e+00 1.00000000e+00 8.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.022161965778456128, 1.6560892753423306, 0.0, 0.0, 0.0, 3.0872726858116797e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0037174013842863306, 0.49437318554825355, 0.0, 0.0, 1.2029576293546984e-253, 8.963491537033661e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 5.740372827112309e-08, 0.02081153447270444, 0.0, 0.0, 0.0, 2.252679407850769e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1535196110461418e-07, 0.01694670783654658, 0.0, 0.0, 0.0, 2.560480804893931e-15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53100000e+01\n",
            " 7.00000000e+00 7.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53100000e+01\n",
            " 7.00000000e+00 7.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53100000e+01\n",
            " 7.00000000e+00 7.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53100000e+01\n",
            " 7.00000000e+00 7.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.022161965778456128, 1.634738519368388, 0.0, 0.0, 0.0, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0037174013842863306, 0.6422648550843036, 0.0, 0.0, 0.0, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 5.740372827112309e-08, 0.04824906873551714, 0.0, 0.0, 0.0, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1535196110461418e-07, 0.03789977035775252, 0.0, 0.0, 0.0, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53800000e+01\n",
            " 8.00000000e+00 8.00000000e+00 4.00000000e+01 2.60000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53800000e+01\n",
            " 8.00000000e+00 8.00000000e+00 4.00000000e+01 2.60000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53800000e+01\n",
            " 8.00000000e+00 8.00000000e+00 4.00000000e+01 2.60000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.53800000e+01\n",
            " 8.00000000e+00 8.00000000e+00 4.00000000e+01 2.60000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.017001377617694817, 9.737745074227736e-09, 1.0686121283749463, 0.0004191908302828797, 0.0, 4.332835868794435e-108, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7800736083141484, 0.0069324160555860525, 1.0233107530619845, 0.2872837104225711, 0.0, 8.985884609549385e-67, 8.985884609549385e-67, 9.791110411060581e-277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6563211142234864, 0.004809182931984509, 0.2786243708311884, 0.735453090688109, 0.0, 8.35259358049464e-143, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5953551569519269, 0.018581714748583007, 0.20949847667461025, 0.9827393915425461, 0.0, 3.065683770872398e-128, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.60600000e+01 2.68100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.16000000e+02 2.00000000e+01 2.00000000e+01 1.40000000e+01\n",
            " 8.70000000e-01 1.20000000e-01 7.00000000e-02 8.00000000e-02\n",
            " 5.35000000e+02 4.45115811e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.60600000e+01 2.68100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.16000000e+02 2.00000000e+01 2.00000000e+01 1.40000000e+01\n",
            " 8.70000000e-01 1.20000000e-01 7.00000000e-02 8.00000000e-02\n",
            " 5.35000000e+02 4.45115811e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.60600000e+01 2.68100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.16000000e+02 2.00000000e+01 2.00000000e+01 1.40000000e+01\n",
            " 8.70000000e-01 1.20000000e-01 7.00000000e-02 8.00000000e-02\n",
            " 5.35000000e+02 4.45115811e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.60600000e+01 2.68100000e+01 2.55600000e+01 2.63100000e+01\n",
            " 1.16000000e+02 2.00000000e+01 2.00000000e+01 1.40000000e+01\n",
            " 8.70000000e-01 1.20000000e-01 7.00000000e-02 8.00000000e-02\n",
            " 5.35000000e+02 4.45115811e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [0.06831094404501414, 0.12464087343216625, 1.634738519368388, 0.0028396665040279832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0270646055511061, 1.1213347165497891, 0.6422648550843036, 0.4985830770823106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6339466321252831, 1.4712299622758223, 0.04824906873551714, 1.2512296759830819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.4113696895370869, 1.217643263416463, 0.03789977035775252, 1.404831048591556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.59400000e+01 2.58800000e+01 2.53800000e+01 2.61900000e+01\n",
            " 1.60000000e+02 2.47000000e+02 7.80000000e+01 5.70000000e+01\n",
            " 6.00000000e-01 4.20000000e-01 1.60000000e-01 1.20000000e-01\n",
            " 4.95000000e+02 6.17573011e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.59400000e+01 2.58800000e+01 2.53800000e+01 2.61900000e+01\n",
            " 1.60000000e+02 2.47000000e+02 7.80000000e+01 5.70000000e+01\n",
            " 6.00000000e-01 4.20000000e-01 1.60000000e-01 1.20000000e-01\n",
            " 4.95000000e+02 6.17573011e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.59400000e+01 2.58800000e+01 2.53800000e+01 2.61900000e+01\n",
            " 1.60000000e+02 2.47000000e+02 7.80000000e+01 5.70000000e+01\n",
            " 6.00000000e-01 4.20000000e-01 1.60000000e-01 1.20000000e-01\n",
            " 4.95000000e+02 6.17573011e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.59400000e+01 2.58800000e+01 2.53800000e+01 2.61900000e+01\n",
            " 1.60000000e+02 2.47000000e+02 7.80000000e+01 5.70000000e+01\n",
            " 6.00000000e-01 4.20000000e-01 1.60000000e-01 1.20000000e-01\n",
            " 4.95000000e+02 6.17573011e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [0.0028396665040279832, 3.4812606121887743e-06, 0.06831094404501414, 0.0001223097503070933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.4985830770823106, 0.05950598924810357, 1.0270646055511061, 0.19590856594612643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.2512296759830819, 0.10492135655386091, 1.6339466321252831, 0.47804205875152145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.404831048591556, 0.22276544969336284, 1.4113696895370869, 0.7173275394971488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61900000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.15500000e+03 7.12487412e-02 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61900000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.15500000e+03 7.12487412e-02 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61900000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.15500000e+03 7.12487412e-02 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61900000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.15500000e+03 7.12487412e-02 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 0.2759462627217734, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.03681205778207625, 1.210545739433308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 1.686130682736435e-05, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 2.1630523427202543e-05, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.634738519368388, 0.4298858024045102, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.6422648550843036, 0.0585843072056394, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.04824906873551714, 5.5696255317175676e-05, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.03789977035775252, 6.546247162567774e-05, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.53800000e+01 2.49400000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.06831094404501414, 0.06831094404501414, 1.6560892753423306, 0.0011257721996219864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0270646055511061, 1.0270646055511061, 0.49437318554825355, 0.38478853960904225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6339466321252831, 1.6339466321252831, 0.02081153447270444, 0.9911681328875325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.4113696895370869, 1.4113696895370869, 0.01694670783654658, 1.2093036686472622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.59400000e+01 2.59400000e+01 2.53100000e+01 2.62500000e+01\n",
            " 1.62000000e+02 2.53000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 7.70000000e-01 3.90000000e-01 2.70000000e-01 1.80000000e-01\n",
            " 5.10000000e+02 5.63947633e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.59400000e+01 2.59400000e+01 2.53100000e+01 2.62500000e+01\n",
            " 1.62000000e+02 2.53000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 7.70000000e-01 3.90000000e-01 2.70000000e-01 1.80000000e-01\n",
            " 5.10000000e+02 5.63947633e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.59400000e+01 2.59400000e+01 2.53100000e+01 2.62500000e+01\n",
            " 1.62000000e+02 2.53000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 7.70000000e-01 3.90000000e-01 2.70000000e-01 1.80000000e-01\n",
            " 5.10000000e+02 5.63947633e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.59400000e+01 2.59400000e+01 2.53100000e+01 2.62500000e+01\n",
            " 1.62000000e+02 2.53000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 7.70000000e-01 3.90000000e-01 2.70000000e-01 1.80000000e-01\n",
            " 5.10000000e+02 5.63947633e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.634738519368388, 0.0067276320461765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.6422648550843036, 0.6249671870164742, 0.0, 9.411427216568543e-191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.04824906873551714, 1.479531085577258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.03789977035775252, 1.5406519737696889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.30000000e+01 1.60000000e+01 6.40000000e+01 4.60000000e+01\n",
            " 9.00000000e-02 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.30000000e+01 1.60000000e+01 6.40000000e+01 4.60000000e+01\n",
            " 9.00000000e-02 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.30000000e+01 1.60000000e+01 6.40000000e+01 4.60000000e+01\n",
            " 9.00000000e-02 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.30000000e+01 1.60000000e+01 6.40000000e+01 4.60000000e+01\n",
            " 9.00000000e-02 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.7777783298469527, 0.0004191908302828797, 1.3109458656169541, 0.369949896396296, 0.0, 0.0, 0.0, 1.1273757906625717e-222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.131586042750569, 0.2872837104225711, 0.9056744868132555, 1.210545739433308, 0.0, 0.0, 0.0, 1.046039588258801e-105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.47004074717167255, 0.735453090688109, 0.16579764589159204, 0.9365612888973045, 0.0, 0.0, 0.0, 1.9017465068320332e-193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.35413111078922477, 0.9827393915425461, 0.12550886003790895, 0.7257709170460954, 0.0, 0.0, 0.0, 1.2526244681864963e-167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56300000e+01 2.63100000e+01 2.55000000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.00000000e+01 5.30000000e+01 3.30000000e+01\n",
            " 1.20000000e-01 4.60000000e-01 9.00000000e-02 1.00000000e-01\n",
            " 3.80000000e+02 4.40080564e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56300000e+01 2.63100000e+01 2.55000000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.00000000e+01 5.30000000e+01 3.30000000e+01\n",
            " 1.20000000e-01 4.60000000e-01 9.00000000e-02 1.00000000e-01\n",
            " 3.80000000e+02 4.40080564e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56300000e+01 2.63100000e+01 2.55000000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.00000000e+01 5.30000000e+01 3.30000000e+01\n",
            " 1.20000000e-01 4.60000000e-01 9.00000000e-02 1.00000000e-01\n",
            " 3.80000000e+02 4.40080564e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56300000e+01 2.63100000e+01 2.55000000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.00000000e+01 5.30000000e+01 3.30000000e+01\n",
            " 1.20000000e-01 4.60000000e-01 9.00000000e-02 1.00000000e-01\n",
            " 3.80000000e+02 4.40080564e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 3 \n",
            "\n",
            "class being misclassified is 3\n",
            "Wrong\n",
            "\n",
            "res [0.0011257721996219864, 3.4812606121887743e-06, 0.06831094404501414, 0.0001223097503070933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38478853960904225, 0.05950598924810357, 1.0270646055511061, 0.19590856594612643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9911681328875325, 0.10492135655386091, 1.6339466321252831, 0.47804205875152145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.2093036686472622, 0.22276544969336284, 1.4113696895370869, 0.7173275394971488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.62500000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.80000000e+02 1.00000000e+01\n",
            " 3.30000000e-01 2.70000000e-01 1.09000000e+00 2.90000000e-01\n",
            " 1.06500000e+03 5.83836858e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.62500000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.80000000e+02 1.00000000e+01\n",
            " 3.30000000e-01 2.70000000e-01 1.09000000e+00 2.90000000e-01\n",
            " 1.06500000e+03 5.83836858e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.62500000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.80000000e+02 1.00000000e+01\n",
            " 3.30000000e-01 2.70000000e-01 1.09000000e+00 2.90000000e-01\n",
            " 1.06500000e+03 5.83836858e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.62500000e+01 2.65600000e+01 2.59400000e+01 2.63800000e+01\n",
            " 1.50000000e+02 2.35000000e+02 1.80000000e+02 1.00000000e+01\n",
            " 3.30000000e-01 2.70000000e-01 1.09000000e+00 2.90000000e-01\n",
            " 1.06500000e+03 5.83836858e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 3 \n",
            "\n",
            "class being misclassified is 3\n",
            "Wrong\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.15198556504483227, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.02052921913893488, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 3.850964789504696e-06, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 5.525603836091904e-06, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.3109458656169541, 0.8644591839089937, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.9056744868132555, 0.13433108971930502, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.16579764589159204, 0.0004994449026255511, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.12550886003790895, 0.0005044502023565899, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.55000000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.08610272e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.55000000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.08610272e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.55000000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.08610272e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.55000000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.08610272e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.5534907125314652, 0.7777783298469527, 1.5646734325554212, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.189959701550509, 1.131586042750569, 0.38109857568304006, 1.1213347165497891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.6855469125047802, 0.47004074717167255, 0.009430158603017429, 1.4712299622758223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.5217782370505217, 0.35413111078922477, 0.007986889838661918, 1.217643263416463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56900000e+01 2.56300000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.70000000e+02 2.64853978e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56900000e+01 2.56300000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.70000000e+02 2.64853978e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56900000e+01 2.56300000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.70000000e+02 2.64853978e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56900000e+01 2.56300000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.70000000e+02 2.64853978e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.8644591839089937, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.13433108971930502, 1.1213347165497891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 0.0004994449026255511, 1.4712299622758223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 0.0005044502023565899, 1.217643263416463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.09365559e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.009000306396803447, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.0017645850083361874, 0.9056744868132555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 9.540035501867375e-09, 0.16579764589159204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 2.2272536225936306e-08, 0.12550886003790895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.3884867679491852, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.28419996615678017, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.004002499108730581, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.003553544572701595, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.20191339e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.20191339e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.20191339e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.20191339e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.009000306396803447, 1.3884867679491852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.0017645850083361874, 0.28419996615678017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 9.540035501867375e-09, 0.004002499108730581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 2.2272536225936306e-08, 0.003553544572701595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.7777783298469527, 1.0686121283749463, 1.3884867679491852, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.131586042750569, 1.0233107530619845, 0.28419996615678017, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.47004074717167255, 0.2786243708311884, 0.004002499108730581, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.35413111078922477, 0.20949847667461025, 0.003553544572701595, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56300000e+01 2.55600000e+01 2.51900000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 4.45000000e+02 2.68882175e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56300000e+01 2.55600000e+01 2.51900000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 4.45000000e+02 2.68882175e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56300000e+01 2.55600000e+01 2.51900000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 4.45000000e+02 2.68882175e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56300000e+01 2.55600000e+01 2.51900000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 4.45000000e+02 2.68882175e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0038843930785171306, 1.634738519368388, 0.0, 0.0, 7.220955550028693e-122, 1.5575517204141166e-71, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0008988318898802732, 0.6422648550843036, 0.0, 0.0, 9.91576329532513e-56, 8.943502805275155e-46, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 1.908674147339961e-09, 0.04824906873551714, 0.0, 0.0, 7.181247272733421e-99, 2.3119441062361147e-99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 5.110442847234481e-09, 0.03789977035775252, 0.0, 0.0, 3.7308554817866616e-85, 1.3711729711378805e-89, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.53800000e+01\n",
            " 5.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.53800000e+01\n",
            " 5.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.53800000e+01\n",
            " 5.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.53800000e+01\n",
            " 5.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 0.8644591839089937, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.13433108971930502, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.0004994449026255511, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.0005044502023565899, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 1.1572784212086917, 0.12464087343216625, 3.980002255074891e-263, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.20502885936011442, 1.1213347165497891, 9.265087851132551e-154, 8.985884609549385e-67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 0.0015912588907227808, 1.4712299622758223, 1.809e-320, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 0.0014925798039521043, 1.217643263416463, 7.151008623832145e-286, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.51300000e+01 2.58800000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.10000000e+01 5.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.51300000e+01 2.58800000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.10000000e+01 5.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.51300000e+01 2.58800000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.10000000e+01 5.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.51300000e+01 2.58800000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.10000000e+01 5.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.6290132021660307, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.09019381965496992, 1.1213347165497891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 0.00017232889953386433, 1.4712299622758223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 0.00018702923145130673, 1.217643263416463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.50000000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.50000000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.50000000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.50000000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.6290132021660307, 0.2322488409221858, 3.980002255074891e-263, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.09019381965496992, 1.1913364523126768, 9.265087851132551e-154, 8.985884609549385e-67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 0.00017232889953386433, 1.198484934895971, 1.809e-320, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 0.00018702923145130673, 0.9530262922520344, 7.151008623832145e-286, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.50000000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.50000000e+01 5.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 8.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.50000000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.50000000e+01 5.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 8.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.50000000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.50000000e+01 5.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 8.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.50000000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.50000000e+01 5.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 8.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.6290132021660307, 0.8644591839089937, 0.009000306396803447, 1.6560892753423306, 0.0, 0.0, 7.220955550028693e-122, 1.5575517204141166e-71, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.09019381965496992, 0.13433108971930502, 0.0017645850083361874, 0.49437318554825355, 0.0, 0.0, 9.91576329532513e-56, 8.943502805275155e-46, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.00017232889953386433, 0.0004994449026255511, 9.540035501867375e-09, 0.02081153447270444, 0.0, 0.0, 7.181247272733421e-99, 2.3119441062361147e-99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.00018702923145130673, 0.0005044502023565899, 2.2272536225936306e-08, 0.01694670783654658, 0.0, 0.0, 3.7308554817866616e-85, 1.3711729711378805e-89, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50000000e+01 2.50600000e+01 2.45600000e+01 2.53100000e+01\n",
            " 6.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50000000e+01 2.50600000e+01 2.45600000e+01 2.53100000e+01\n",
            " 6.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50000000e+01 2.50600000e+01 2.45600000e+01 2.53100000e+01\n",
            " 6.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50000000e+01 2.50600000e+01 2.45600000e+01 2.53100000e+01\n",
            " 6.00000000e+00 6.00000000e+00 3.10000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.009000306396803447, 1.1572784212086917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0017645850083361874, 0.20502885936011442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 9.540035501867375e-09, 0.0015912588907227808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 2.2272536225936306e-08, 0.0014925798039521043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51300000e+01\n",
            " 1.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51300000e+01\n",
            " 1.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51300000e+01\n",
            " 1.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.51300000e+01\n",
            " 1.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.017001377617694817, 0.369949896396296, 1.0686121283749463, 0.0004191908302828797, 0.0, 2.2700523283260164e-27, 0.0, 2.6214113171808194e-51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7800736083141484, 1.210545739433308, 1.0233107530619845, 0.2872837104225711, 0.0, 9.34124180217853e-11, 0.0, 9.502917026082715e-22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6563211142234864, 0.9365612888973045, 0.2786243708311884, 0.735453090688109, 0.0, 3.544772839419745e-16, 0.0, 7.494624531939523e-36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5953551569519269, 0.7257709170460954, 0.20949847667461025, 0.9827393915425461, 0.0, 1.5212759430620137e-13, 0.0, 1.81475933156938e-30, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.606000e+01 2.575000e+01 2.556000e+01 2.631000e+01 1.180000e+02\n",
            " 2.800000e+01 4.900000e+01 2.900000e+01 1.800000e-01 5.000000e-02\n",
            " 6.000000e-02 6.000000e-02 5.950000e+02 4.224572e-01 0.000000e+00\n",
            " 0.000000e+00 1.000000e+00]) = 0.000\n",
            "p(y=1 | [2.606000e+01 2.575000e+01 2.556000e+01 2.631000e+01 1.180000e+02\n",
            " 2.800000e+01 4.900000e+01 2.900000e+01 1.800000e-01 5.000000e-02\n",
            " 6.000000e-02 6.000000e-02 5.950000e+02 4.224572e-01 0.000000e+00\n",
            " 0.000000e+00 1.000000e+00]) = 0.000\n",
            "p(y=2 | [2.606000e+01 2.575000e+01 2.556000e+01 2.631000e+01 1.180000e+02\n",
            " 2.800000e+01 4.900000e+01 2.900000e+01 1.800000e-01 5.000000e-02\n",
            " 6.000000e-02 6.000000e-02 5.950000e+02 4.224572e-01 0.000000e+00\n",
            " 0.000000e+00 1.000000e+00]) = 0.000\n",
            "p(y=3 | [2.606000e+01 2.575000e+01 2.556000e+01 2.631000e+01 1.180000e+02\n",
            " 2.800000e+01 4.900000e+01 2.900000e+01 1.800000e-01 5.000000e-02\n",
            " 6.000000e-02 6.000000e-02 5.950000e+02 4.224572e-01 0.000000e+00\n",
            " 0.000000e+00 1.000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 0.15198556504483227, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.02052921913893488, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 3.850964789504696e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 5.525603836091904e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.8644591839089937, 0.2322488409221858, 3.980002255074891e-263, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.13433108971930502, 1.1913364523126768, 9.265087851132551e-154, 8.985884609549385e-67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 0.0004994449026255511, 1.198484934895971, 1.809e-320, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 0.0005044502023565899, 0.9530262922520344, 7.151008623832145e-286, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.50600000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.60000000e+01 5.40000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.50600000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.60000000e+01 5.40000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.50600000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.60000000e+01 5.40000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.50600000e+01 2.58100000e+01\n",
            " 1.70000000e+01 2.00000000e+01 7.60000000e+01 5.40000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.5646734325554212, 0.0448292590729217, 1.0686121283749463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.38109857568304006, 0.006792237089151543, 1.0233107530619845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.009430158603017429, 2.4901140005593237e-07, 0.2786243708311884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.007986889838661918, 4.437634360892876e-07, 0.20949847667461025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.11127895e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.2759462627217734, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.03681205778207625, 1.210545739433308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 1.686130682736435e-05, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 2.1630523427202543e-05, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.48800000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3109458656169541, 1.3109458656169541, 0.8644591839089937, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9056744868132555, 0.9056744868132555, 0.13433108971930502, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.16579764589159204, 0.16579764589159204, 0.0004994449026255511, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.12550886003790895, 0.12550886003790895, 0.0005044502023565899, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.5534907125314652, 0.5534907125314652, 1.5646734325554212, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.189959701550509, 1.189959701550509, 0.38109857568304006, 1.1213347165497891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.6855469125047802, 0.6855469125047802, 0.009430158603017429, 1.4712299622758223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.5217782370505217, 0.5217782370505217, 0.007986889838661918, 1.217643263416463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56900000e+01 2.56900000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 6.05000000e+02 2.22306143e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56900000e+01 2.56900000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 6.05000000e+02 2.22306143e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56900000e+01 2.56900000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 6.05000000e+02 2.22306143e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56900000e+01 2.56900000e+01 2.52500000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 6.05000000e+02 2.22306143e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.369949896396296, 0.2322488409221858, 1.634738519368388, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.210545739433308, 1.1913364523126768, 0.6422648550843036, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9365612888973045, 1.198484934895971, 0.04824906873551714, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.7257709170460954, 0.9530262922520344, 0.03789977035775252, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.57500000e+01 2.58100000e+01 2.53800000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.00000000e+02 2.89274924e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.57500000e+01 2.58100000e+01 2.53800000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.00000000e+02 2.89274924e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.57500000e+01 2.58100000e+01 2.53800000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.00000000e+02 2.89274924e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.57500000e+01 2.58100000e+01 2.53800000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.00000000e+02 2.89274924e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0448292590729217, 1.0686121283749463, 0.0, 0.0, 0.0, 8.305926896659704e-83, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.006792237089151543, 1.0233107530619845, 0.0, 0.0, 0.0, 9.693875764177745e-37, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 2.4901140005593237e-07, 0.2786243708311884, 0.0, 0.0, 0.0, 2.0430878332126198e-63, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 4.437634360892876e-07, 0.20949847667461025, 0.0, 0.0, 0.0, 2.4472923233745648e-54, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.55600000e+01\n",
            " 9.00000000e+00 1.00000000e+01 4.40000000e+01 3.00000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.55600000e+01\n",
            " 9.00000000e+00 1.00000000e+01 4.40000000e+01 3.00000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.55600000e+01\n",
            " 9.00000000e+00 1.00000000e+01 4.40000000e+01 3.00000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.55600000e+01\n",
            " 9.00000000e+00 1.00000000e+01 4.40000000e+01 3.00000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0067276320461765, 9.174393581855356e-12, 0.035163991295557286, 0.0004191908302828797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6249671870164742, 0.00045423732874721567, 0.9100484937946683, 0.2872837104225711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.479531085577258, 7.082346613984344e-05, 1.6997792628930506, 0.735453090688109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5406519737696889, 0.0005703641619746738, 1.544376636821353, 0.9827393915425461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61300000e+01 2.70600000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.65000000e+02 2.57000000e+02 2.79000000e+02 7.40000000e+01\n",
            " 3.40000000e-01 1.20000000e-01 7.70000000e-01 1.00000000e-01\n",
            " 9.25000000e+02 5.01258812e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61300000e+01 2.70600000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.65000000e+02 2.57000000e+02 2.79000000e+02 7.40000000e+01\n",
            " 3.40000000e-01 1.20000000e-01 7.70000000e-01 1.00000000e-01\n",
            " 9.25000000e+02 5.01258812e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61300000e+01 2.70600000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.65000000e+02 2.57000000e+02 2.79000000e+02 7.40000000e+01\n",
            " 3.40000000e-01 1.20000000e-01 7.70000000e-01 1.00000000e-01\n",
            " 9.25000000e+02 5.01258812e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61300000e+01 2.70600000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.65000000e+02 2.57000000e+02 2.79000000e+02 7.40000000e+01\n",
            " 3.40000000e-01 1.20000000e-01 7.70000000e-01 1.00000000e-01\n",
            " 9.25000000e+02 5.01258812e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 3 \n",
            "\n",
            "class being misclassified is 3\n",
            "Wrong\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 0.2759462627217734, 1.5105235152729721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.03681205778207625, 0.7754271574975016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 1.686130682736435e-05, 0.09241340481217675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 2.1630523427202543e-05, 0.07098386153852101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.48800000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.6560892753423306, 0.15198556504483227, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.49437318554825355, 0.02052921913893488, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.02081153447270444, 3.850964789504696e-06, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.01694670783654658, 5.525603836091904e-06, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.53100000e+01 2.48100000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.53100000e+01 2.48100000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.53100000e+01 2.48100000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.53100000e+01 2.48100000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.6290132021660307, 0.022161965778456128, 0.8644591839089937, 0.0, 0.0, 3.0872726858116797e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.09019381965496992, 0.0037174013842863306, 0.13433108971930502, 0.0, 0.0, 8.963491537033661e-07, 9.411427216568543e-191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.00017232889953386433, 5.740372827112309e-08, 0.0004994449026255511, 0.0, 0.0, 2.252679407850769e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.00018702923145130673, 1.1535196110461418e-07, 0.0005044502023565899, 0.0, 0.0, 2.560480804893931e-15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50000000e+01 2.46300000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.40000000e+01 1.60000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50000000e+01 2.46300000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.40000000e+01 1.60000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50000000e+01 2.46300000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.40000000e+01 1.60000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50000000e+01 2.46300000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.40000000e+01 1.60000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 7.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 1.5646734325554212, 0.035163991295557286, 0.0, 3.3071632387050217e-152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.38109857568304006, 0.9100484937946683, 9.586269261857777e-232, 9.053202117810136e-92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 0.009430158603017429, 1.6997792628930506, 0.0, 3.890819252125932e-194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 0.007986889838661918, 1.544376636821353, 0.0, 7.7485106595636035e-174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.52500000e+01 2.60000000e+01\n",
            " 1.50000000e+01 1.90000000e+01 6.80000000e+01 4.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.52500000e+01 2.60000000e+01\n",
            " 1.50000000e+01 1.90000000e+01 6.80000000e+01 4.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.52500000e+01 2.60000000e+01\n",
            " 1.50000000e+01 1.90000000e+01 6.80000000e+01 4.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.52500000e+01 2.60000000e+01\n",
            " 1.50000000e+01 1.90000000e+01 6.80000000e+01 4.90000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.15198556504483227, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.02052921913893488, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 3.850964789504696e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 5.525603836091904e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.6560892753423306, 0.2759462627217734, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.49437318554825355, 0.03681205778207625, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.02081153447270444, 1.686130682736435e-05, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.01694670783654658, 2.1630523427202543e-05, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.53100000e+01 2.48800000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 5.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.53100000e+01 2.48800000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 5.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.53100000e+01 2.48800000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 5.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.53100000e+01 2.48800000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 5.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.6560892753423306, 0.4298858024045102, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.49437318554825355, 0.0585843072056394, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.02081153447270444, 5.5696255317175676e-05, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.01694670783654658, 6.546247162567774e-05, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.53100000e+01 2.49400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.53100000e+01 2.49400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.53100000e+01 2.49400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.53100000e+01 2.49400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.1572784212086917, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.20502885936011442, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.0015912588907227808, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.0014925798039521043, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.5440000e+01 2.5440000e+01 2.5130000e+01 2.6000000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0000000e-02 6.0000000e-02\n",
            " 6.0000000e-02 9.0000000e-02 3.5000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=1 | [2.5440000e+01 2.5440000e+01 2.5130000e+01 2.6000000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0000000e-02 6.0000000e-02\n",
            " 6.0000000e-02 9.0000000e-02 3.5000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=2 | [2.5440000e+01 2.5440000e+01 2.5130000e+01 2.6000000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0000000e-02 6.0000000e-02\n",
            " 6.0000000e-02 9.0000000e-02 3.5000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=3 | [2.5440000e+01 2.5440000e+01 2.5130000e+01 2.6000000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0000000e-02 6.0000000e-02\n",
            " 6.0000000e-02 9.0000000e-02 3.5000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.5646734325554212, 0.08517122922065898, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.38109857568304006, 0.012005783156308833, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.009430158603017429, 1.0118024174082307e-06, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.007986889838661918, 1.6116464269829333e-06, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.8644591839089937, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.13433108971930502, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 0.0004994449026255511, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 0.0005044502023565899, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.00805639e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.00805639e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.00805639e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.00805639e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.15198556504483227, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.02052921913893488, 1.210545739433308, 0.0, 0.0, 0.0, 1.2029576293546984e-253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 3.850964789504696e-06, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 5.525603836091904e-06, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.48100000e+01 2.57500000e+01\n",
            " 1.20000000e+01 1.30000000e+01 5.40000000e+01 3.70000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.48100000e+01 2.57500000e+01\n",
            " 1.20000000e+01 1.30000000e+01 5.40000000e+01 3.70000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.48100000e+01 2.57500000e+01\n",
            " 1.20000000e+01 1.30000000e+01 5.40000000e+01 3.70000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.48100000e+01 2.57500000e+01\n",
            " 1.20000000e+01 1.30000000e+01 5.40000000e+01 3.70000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.0686121283749463, 1.0686121283749463, 1.1572784212086917, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0233107530619845, 1.0233107530619845, 0.20502885936011442, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.2786243708311884, 0.2786243708311884, 0.0015912588907227808, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.20949847667461025, 0.20949847667461025, 0.0014925798039521043, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55600000e+01 2.55600000e+01 2.51300000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 4.00000000e+02 3.17724068e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55600000e+01 2.55600000e+01 2.51300000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 4.00000000e+02 3.17724068e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55600000e+01 2.55600000e+01 2.51300000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 4.00000000e+02 3.17724068e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55600000e+01 2.55600000e+01 2.51300000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 4.00000000e+02 3.17724068e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0038843930785171306, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0008988318898802732, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 1.908674147339961e-09, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 5.110442847234481e-09, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 3.60000000e+02 4.16414904e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 3.60000000e+02 4.16414904e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 3.60000000e+02 4.16414904e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45000000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 3.60000000e+02 4.16414904e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.022161965778456128, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.0037174013842863306, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 5.740372827112309e-08, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 1.1535196110461418e-07, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.46300000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.46300000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.46300000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.46300000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0067276320461765, 0.035163991295557286, 0.2322488409221858, 0.0011257721996219864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6249671870164742, 0.9100484937946683, 1.1913364523126768, 0.38478853960904225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.479531085577258, 1.6997792628930506, 1.198484934895971, 0.9911681328875325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5406519737696889, 1.544376636821353, 0.9530262922520344, 1.2093036686472622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61300000e+01 2.60000000e+01 2.58100000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.01500000e+03 4.34541793e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61300000e+01 2.60000000e+01 2.58100000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.01500000e+03 4.34541793e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61300000e+01 2.60000000e+01 2.58100000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.01500000e+03 4.34541793e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61300000e+01 2.60000000e+01 2.58100000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 1.01500000e+03 4.34541793e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.369949896396296, 0.7777783298469527, 1.5646734325554212, 0.0067276320461765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.210545739433308, 1.131586042750569, 0.38109857568304006, 0.6249671870164742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9365612888973045, 0.47004074717167255, 0.009430158603017429, 1.479531085577258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.7257709170460954, 0.35413111078922477, 0.007986889838661918, 1.5406519737696889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.57500000e+01 2.56300000e+01 2.52500000e+01 2.61300000e+01\n",
            " 1.57000000e+02 2.48000000e+02 7.20000000e+01 5.40000000e+01\n",
            " 1.82000000e+00 1.28000000e+00 4.20000000e-01 3.10000000e-01\n",
            " 3.85000000e+02 4.37059416e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.57500000e+01 2.56300000e+01 2.52500000e+01 2.61300000e+01\n",
            " 1.57000000e+02 2.48000000e+02 7.20000000e+01 5.40000000e+01\n",
            " 1.82000000e+00 1.28000000e+00 4.20000000e-01 3.10000000e-01\n",
            " 3.85000000e+02 4.37059416e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.57500000e+01 2.56300000e+01 2.52500000e+01 2.61300000e+01\n",
            " 1.57000000e+02 2.48000000e+02 7.20000000e+01 5.40000000e+01\n",
            " 1.82000000e+00 1.28000000e+00 4.20000000e-01 3.10000000e-01\n",
            " 3.85000000e+02 4.37059416e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.57500000e+01 2.56300000e+01 2.52500000e+01 2.61300000e+01\n",
            " 1.57000000e+02 2.48000000e+02 7.20000000e+01 5.40000000e+01\n",
            " 1.82000000e+00 1.28000000e+00 4.20000000e-01 3.10000000e-01\n",
            " 3.85000000e+02 4.37059416e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [0.06831094404501414, 0.2322488409221858, 1.0686121283749463, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0270646055511061, 1.1913364523126768, 1.0233107530619845, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6339466321252831, 1.198484934895971, 0.2786243708311884, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.4113696895370869, 0.9530262922520344, 0.20949847667461025, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.59400000e+01 2.58100000e+01 2.55600000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 8.45000000e+02 2.48237664e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.59400000e+01 2.58100000e+01 2.55600000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 8.45000000e+02 2.48237664e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.59400000e+01 2.58100000e+01 2.55600000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 8.45000000e+02 2.48237664e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.59400000e+01 2.58100000e+01 2.55600000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 8.45000000e+02 2.48237664e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.009000306396803447, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.0017645850083361874, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 9.540035501867375e-09, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 2.2272536225936306e-08, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.09113797e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.09113797e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.09113797e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.45600000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.55000000e+02 4.09113797e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 1.634738519368388, 0.0067276320461765, 0.0, 6.926162211831406e-204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.6422648550843036, 0.6249671870164742, 9.791110411060581e-277, 9.146012369996701e-121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 0.04824906873551714, 1.479531085577258, 0.0, 2.336880198098833e-253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 0.03789977035775252, 1.5406519737696889, 0.0, 2.2139350905153766e-226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.40000000e+01 1.80000000e+01 6.90000000e+01 4.90000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.40000000e+01 1.80000000e+01 6.90000000e+01 4.90000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.40000000e+01 1.80000000e+01 6.90000000e+01 4.90000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 1.40000000e+01 1.80000000e+01 6.90000000e+01 4.90000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 0.15198556504483227, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.02052921913893488, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 3.850964789504696e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 5.525603836091904e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 0.6290132021660307, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.09019381965496992, 1.210545739433308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.00017232889953386433, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.00018702923145130673, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.50000000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.80000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.50000000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.80000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.50000000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.80000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.50000000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.80000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0448292590729217, 1.5105235152729721, 0.0, 0.0, 0.0, 2.6214113171808194e-51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.006792237089151543, 0.7754271574975016, 0.0, 0.0, 0.0, 9.502917026082715e-22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 2.4901140005593237e-07, 0.09241340481217675, 0.0, 0.0, 0.0, 7.494624531939523e-36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 4.437634360892876e-07, 0.07098386153852101, 0.0, 0.0, 0.0, 1.81475933156938e-30, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.54400000e+01\n",
            " 9.00000000e+00 9.00000000e+00 4.20000000e+01 2.90000000e+01\n",
            " 1.60000000e-01 1.10000000e-01 1.70000000e-01 5.00000000e-02\n",
            " 3.55000000e+02 3.97029204e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.54400000e+01\n",
            " 9.00000000e+00 9.00000000e+00 4.20000000e+01 2.90000000e+01\n",
            " 1.60000000e-01 1.10000000e-01 1.70000000e-01 5.00000000e-02\n",
            " 3.55000000e+02 3.97029204e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.54400000e+01\n",
            " 9.00000000e+00 9.00000000e+00 4.20000000e+01 2.90000000e+01\n",
            " 1.60000000e-01 1.10000000e-01 1.70000000e-01 5.00000000e-02\n",
            " 3.55000000e+02 3.97029204e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.46900000e+01 2.54400000e+01\n",
            " 9.00000000e+00 9.00000000e+00 4.20000000e+01 2.90000000e+01\n",
            " 1.60000000e-01 1.10000000e-01 1.70000000e-01 5.00000000e-02\n",
            " 3.55000000e+02 3.97029204e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.634738519368388, 0.6290132021660307, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.6422648550843036, 0.09019381965496992, 0.9056744868132555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.04824906873551714, 0.00017232889953386433, 0.16579764589159204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.03789977035775252, 0.00018702923145130673, 0.12550886003790895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.53800000e+01 2.50000000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.60000000e+02 3.99295065e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.53800000e+01 2.50000000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.60000000e+02 3.99295065e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.53800000e+01 2.50000000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.60000000e+02 3.99295065e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.53800000e+01 2.50000000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.60000000e+02 3.99295065e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.3884867679491852, 0.0448292590729217, 1.0686121283749463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.28419996615678017, 0.006792237089151543, 1.0233107530619845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.004002499108730581, 2.4901140005593237e-07, 0.2786243708311884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.003553544572701595, 4.437634360892876e-07, 0.20949847667461025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.5250000e+01 2.5190000e+01 2.4690000e+01 2.5560000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0000000e-02 5.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 3.6000000e+02 4.0835851e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=1 | [2.5250000e+01 2.5190000e+01 2.4690000e+01 2.5560000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0000000e-02 5.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 3.6000000e+02 4.0835851e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=2 | [2.5250000e+01 2.5190000e+01 2.4690000e+01 2.5560000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0000000e-02 5.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 3.6000000e+02 4.0835851e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=3 | [2.5250000e+01 2.5190000e+01 2.4690000e+01 2.5560000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0000000e-02 5.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 3.6000000e+02 4.0835851e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.2322488409221858, 0.2322488409221858, 1.5105235152729721, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.1913364523126768, 1.1913364523126768, 0.7754271574975016, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.198484934895971, 1.198484934895971, 0.09241340481217675, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.9530262922520344, 0.9530262922520344, 0.07098386153852101, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.58100000e+01 2.58100000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 7.55000000e+02 2.63595166e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.58100000e+01 2.58100000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 7.55000000e+02 2.63595166e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.58100000e+01 2.58100000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 7.55000000e+02 2.63595166e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.58100000e+01 2.58100000e+01 2.54400000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 5.00000000e-02\n",
            " 7.55000000e+02 2.63595166e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0015745886692075798, 1.6560892753423306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0004429132138564848, 0.49437318554825355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 3.576934139915957e-10, 0.02081153447270444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1069783272151325e-09, 0.01694670783654658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.5534907125314652, 1.3109458656169541, 1.3884867679491852, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.189959701550509, 0.9056744868132555, 0.28419996615678017, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.6855469125047802, 0.16579764589159204, 0.004002499108730581, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.5217782370505217, 0.12550886003790895, 0.003553544572701595, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56900000e+01 2.55000000e+01 2.51900000e+01 2.60000000e+01\n",
            " 1.54000000e+02 2.35000000e+02 7.30000000e+01 5.40000000e+01\n",
            " 3.70000000e-01 5.00000000e-01 1.70000000e-01 1.00000000e-01\n",
            " 3.85000000e+02 4.17925478e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56900000e+01 2.55000000e+01 2.51900000e+01 2.60000000e+01\n",
            " 1.54000000e+02 2.35000000e+02 7.30000000e+01 5.40000000e+01\n",
            " 3.70000000e-01 5.00000000e-01 1.70000000e-01 1.00000000e-01\n",
            " 3.85000000e+02 4.17925478e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56900000e+01 2.55000000e+01 2.51900000e+01 2.60000000e+01\n",
            " 1.54000000e+02 2.35000000e+02 7.30000000e+01 5.40000000e+01\n",
            " 3.70000000e-01 5.00000000e-01 1.70000000e-01 1.00000000e-01\n",
            " 3.85000000e+02 4.17925478e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56900000e+01 2.55000000e+01 2.51900000e+01 2.60000000e+01\n",
            " 1.54000000e+02 2.35000000e+02 7.30000000e+01 5.40000000e+01\n",
            " 3.70000000e-01 5.00000000e-01 1.70000000e-01 1.00000000e-01\n",
            " 3.85000000e+02 4.17925478e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.0686121283749463, 1.6560892753423306, 1.1572784212086917, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0233107530619845, 0.49437318554825355, 0.20502885936011442, 1.0270646055511061, 0.0, 1.2029576293546984e-253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.2786243708311884, 0.02081153447270444, 0.0015912588907227808, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.20949847667461025, 0.01694670783654658, 0.0014925798039521043, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55600000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.23000000e+02 3.70000000e+01 6.60000000e+01 4.80000000e+01\n",
            " 6.00000000e-01 2.10000000e-01 1.50000000e-01 1.30000000e-01\n",
            " 3.70000000e+02 4.30513595e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55600000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.23000000e+02 3.70000000e+01 6.60000000e+01 4.80000000e+01\n",
            " 6.00000000e-01 2.10000000e-01 1.50000000e-01 1.30000000e-01\n",
            " 3.70000000e+02 4.30513595e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55600000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.23000000e+02 3.70000000e+01 6.60000000e+01 4.80000000e+01\n",
            " 6.00000000e-01 2.10000000e-01 1.50000000e-01 1.30000000e-01\n",
            " 3.70000000e+02 4.30513595e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55600000e+01 2.53100000e+01 2.51300000e+01 2.59400000e+01\n",
            " 1.23000000e+02 3.70000000e+01 6.60000000e+01 4.80000000e+01\n",
            " 6.00000000e-01 2.10000000e-01 1.50000000e-01 1.30000000e-01\n",
            " 3.70000000e+02 4.30513595e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.08517122922065898, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.28419996615678017, 0.012005783156308833, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.004002499108730581, 1.0118024174082307e-06, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.003553544572701595, 1.6116464269829333e-06, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.51900000e+01 2.47500000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.51900000e+01 2.47500000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.51900000e+01 2.47500000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.51900000e+01 2.47500000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 1.1572784212086917, 0.0038843930785171306, 1.5105235152729721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.20502885936011442, 0.0008988318898802732, 0.7754271574975016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0015912588907227808, 1.908674147339961e-09, 0.09241340481217675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0014925798039521043, 5.110442847234481e-09, 0.07098386153852101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.54400000e+01\n",
            " 2.00000000e+00 2.00000000e+00 1.30000000e+01 8.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.15156093e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.54400000e+01\n",
            " 2.00000000e+00 2.00000000e+00 1.30000000e+01 8.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.15156093e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.54400000e+01\n",
            " 2.00000000e+00 2.00000000e+00 1.30000000e+01 8.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.15156093e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.54400000e+01\n",
            " 2.00000000e+00 2.00000000e+00 1.30000000e+01 8.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.15156093e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 1.1572784212086917, 0.0015745886692075798, 1.3884867679491852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.20502885936011442, 0.0004429132138564848, 0.28419996615678017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0015912588907227808, 3.576934139915957e-10, 0.004002499108730581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0014925798039521043, 1.1069783272151325e-09, 0.003553544572701595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.51300000e+01 2.44400000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.04330312e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.51300000e+01 2.44400000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.04330312e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.51300000e+01 2.44400000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.04330312e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.51300000e+01 2.44400000e+01 2.51900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.04330312e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0015745886692075798, 1.6560892753423306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0004429132138564848, 0.49437318554825355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 3.576934139915957e-10, 0.02081153447270444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1069783272151325e-09, 0.01694670783654658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12638469e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12638469e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12638469e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.12638469e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 0.8644591839089937, 0.0448292590729217, 1.5646734325554212, 0.0, 0.0, 2.0245857241639047e-284, 1.5362657508397747e-42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.13433108971930502, 0.006792237089151543, 0.38109857568304006, 0.0, 0.0, 1.078801122944882e-136, 8.925707420874425e-29, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0004994449026255511, 2.4901140005593237e-07, 0.009430158603017429, 0.0, 0.0, 1.4328229520462304e-252, 8.251045783244145e-64, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0005044502023565899, 4.437634360892876e-07, 0.007986889838661918, 0.0, 0.0, 2.7587400278537175e-219, 6.932867525067332e-58, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.40000000e+01 2.20000000e+01\n",
            " 1.10000000e-01 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.40000000e+01 2.20000000e+01\n",
            " 1.10000000e-01 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.40000000e+01 2.20000000e+01\n",
            " 1.10000000e-01 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.40000000e+01 2.20000000e+01\n",
            " 1.10000000e-01 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.009000306396803447, 1.5105235152729721, 0.0, 0.0, 0.0, 3.0872726858116797e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0017645850083361874, 0.7754271574975016, 0.0, 0.0, 1.2029576293546984e-253, 8.963491537033661e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 9.540035501867375e-09, 0.09241340481217675, 0.0, 0.0, 0.0, 2.252679407850769e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 2.2272536225936306e-08, 0.07098386153852101, 0.0, 0.0, 0.0, 2.560480804893931e-15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.70000000e+01 2.40000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.12464087343216625, 0.369949896396296, 1.3109458656169541, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.1213347165497891, 1.210545739433308, 0.9056744868132555, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.4712299622758223, 0.9365612888973045, 0.16579764589159204, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.217643263416463, 0.7257709170460954, 0.12550886003790895, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.58800000e+01 2.57500000e+01 2.55000000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.90000000e+02 2.90533736e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.58800000e+01 2.57500000e+01 2.55000000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.90000000e+02 2.90533736e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.58800000e+01 2.57500000e+01 2.55000000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.90000000e+02 2.90533736e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.58800000e+01 2.57500000e+01 2.55000000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 6.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 7.90000000e+02 2.90533736e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0067276320461765, 0.12464087343216625, 0.369949896396296, 0.0004191908302828797, 0.0, 1.5362657508397747e-42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6249671870164742, 1.1213347165497891, 1.210545739433308, 0.2872837104225711, 0.0, 8.925707420874425e-29, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.479531085577258, 1.4712299622758223, 0.9365612888973045, 0.735453090688109, 0.0, 8.251045783244145e-64, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5406519737696889, 1.217643263416463, 0.7257709170460954, 0.9827393915425461, 0.0, 6.932867525067332e-58, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61300000e+01 2.58800000e+01 2.57500000e+01 2.63100000e+01\n",
            " 1.17000000e+02 2.20000000e+01 1.85000000e+02 1.00000000e+01\n",
            " 6.10000000e-01 5.40000000e-01 1.43000000e+00 4.40000000e-01\n",
            " 7.25000000e+02 5.18378651e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61300000e+01 2.58800000e+01 2.57500000e+01 2.63100000e+01\n",
            " 1.17000000e+02 2.20000000e+01 1.85000000e+02 1.00000000e+01\n",
            " 6.10000000e-01 5.40000000e-01 1.43000000e+00 4.40000000e-01\n",
            " 7.25000000e+02 5.18378651e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61300000e+01 2.58800000e+01 2.57500000e+01 2.63100000e+01\n",
            " 1.17000000e+02 2.20000000e+01 1.85000000e+02 1.00000000e+01\n",
            " 6.10000000e-01 5.40000000e-01 1.43000000e+00 4.40000000e-01\n",
            " 7.25000000e+02 5.18378651e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61300000e+01 2.58800000e+01 2.57500000e+01 2.63100000e+01\n",
            " 1.17000000e+02 2.20000000e+01 1.85000000e+02 1.00000000e+01\n",
            " 6.10000000e-01 5.40000000e-01 1.43000000e+00 4.40000000e-01\n",
            " 7.25000000e+02 5.18378651e-01 0.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.1572784212086917, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.20502885936011442, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.0015912588907227808, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.0014925798039521043, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.03826788e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.03826788e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.03826788e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.51300000e+01 2.60000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 9.00000000e-02\n",
            " 3.50000000e+02 4.03826788e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.08517122922065898, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.012005783156308833, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 1.0118024174082307e-06, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 1.6116464269829333e-06, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.47500000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.6560892753423306, 0.15198556504483227, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.49437318554825355, 0.02052921913893488, 1.210545739433308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.02081153447270444, 3.850964789504696e-06, 0.9365612888973045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.01694670783654658, 5.525603836091904e-06, 0.7257709170460954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.65000000e+02 4.09869084e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.65000000e+02 4.09869084e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.65000000e+02 4.09869084e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53100000e+01 2.48100000e+01 2.57500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.65000000e+02 4.09869084e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 0.8644591839089937, 0.0448292590729217, 1.5646734325554212, 0.0, 0.0, 1.1273757906625717e-222, 1.5575517204141166e-71, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.13433108971930502, 0.006792237089151543, 0.38109857568304006, 0.0, 0.0, 1.046039588258801e-105, 8.943502805275155e-46, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0004994449026255511, 2.4901140005593237e-07, 0.009430158603017429, 0.0, 0.0, 1.9017465068320332e-193, 2.3119441062361147e-99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0005044502023565899, 4.437634360892876e-07, 0.007986889838661918, 0.0, 0.0, 1.2526244681864963e-167, 1.3711729711378805e-89, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.30000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.30000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.30000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.50600000e+01 2.46900000e+01 2.52500000e+01\n",
            " 6.00000000e+00 7.00000000e+00 3.30000000e+01 2.10000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.1572784212086917, 0.0448292590729217, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.20502885936011442, 0.006792237089151543, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.0015912588907227808, 2.4901140005593237e-07, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.0014925798039521043, 4.437634360892876e-07, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.51300000e+01 2.46900000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.51300000e+01 2.46900000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.51300000e+01 2.46900000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.51300000e+01 2.46900000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.5646734325554212, 0.15198556504483227, 1.5646734325554212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.38109857568304006, 0.02052921913893488, 0.38109857568304006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.009430158603017429, 3.850964789504696e-06, 0.009430158603017429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.007986889838661918, 5.525603836091904e-06, 0.007986889838661918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.52500000e+01 2.48100000e+01 2.52500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.022161965778456128, 1.5105235152729721, 0.0, 0.0, 0.0, 0.035163991295557286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0037174013842863306, 0.7754271574975016, 0.0, 0.0, 0.0, 0.9100484937946683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 5.740372827112309e-08, 0.09241340481217675, 0.0, 0.0, 0.0, 1.6997792628930506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1535196110461418e-07, 0.07098386153852101, 0.0, 0.0, 0.0, 1.544376636821353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.90000000e+01 2.60000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.90000000e+01 2.60000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.90000000e+01 2.60000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.46300000e+01 2.54400000e+01\n",
            " 7.00000000e+00 8.00000000e+00 3.90000000e+01 2.60000000e+01\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3109458656169541, 1.0686121283749463, 1.1572784212086917, 0.12464087343216625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9056744868132555, 1.0233107530619845, 0.20502885936011442, 1.1213347165497891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.16579764589159204, 0.2786243708311884, 0.0015912588907227808, 1.4712299622758223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.12550886003790895, 0.20949847667461025, 0.0014925798039521043, 1.217643263416463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55000000e+01 2.55600000e+01 2.51300000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 4.40000000e+02 3.31319235e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55000000e+01 2.55600000e+01 2.51300000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 4.40000000e+02 3.31319235e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55000000e+01 2.55600000e+01 2.51300000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 4.40000000e+02 3.31319235e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55000000e+01 2.55600000e+01 2.51300000e+01 2.58800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 7.00000000e-02 6.00000000e-02\n",
            " 4.40000000e+02 3.31319235e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.15198556504483227, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.02052921913893488, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 3.850964789504696e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 5.525603836091904e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.48100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.10000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.3109458656169541, 0.6290132021660307, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.9056744868132555, 0.09019381965496992, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.16579764589159204, 0.00017232889953386433, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.12550886003790895, 0.00018702923145130673, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.55000000e+01 2.50000000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.80000000e+02 4.03323263e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.55000000e+01 2.50000000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.80000000e+02 4.03323263e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.55000000e+01 2.50000000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.80000000e+02 4.03323263e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.55000000e+01 2.50000000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.80000000e+02 4.03323263e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.06831094404501414, 0.035163991295557286, 1.5105235152729721, 0.0011257721996219864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0270646055511061, 0.9100484937946683, 0.7754271574975016, 0.38478853960904225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6339466321252831, 1.6997792628930506, 0.09241340481217675, 0.9911681328875325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.4113696895370869, 1.544376636821353, 0.07098386153852101, 1.2093036686472622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.59400000e+01 2.60000000e+01 2.54400000e+01 2.62500000e+01\n",
            " 1.60000000e+02 2.51000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 5.60000000e-01 1.28000000e+00 4.90000000e-01 3.80000000e-01\n",
            " 5.35000000e+02 7.10725076e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.59400000e+01 2.60000000e+01 2.54400000e+01 2.62500000e+01\n",
            " 1.60000000e+02 2.51000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 5.60000000e-01 1.28000000e+00 4.90000000e-01 3.80000000e-01\n",
            " 5.35000000e+02 7.10725076e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.59400000e+01 2.60000000e+01 2.54400000e+01 2.62500000e+01\n",
            " 1.60000000e+02 2.51000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 5.60000000e-01 1.28000000e+00 4.90000000e-01 3.80000000e-01\n",
            " 5.35000000e+02 7.10725076e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.59400000e+01 2.60000000e+01 2.54400000e+01 2.62500000e+01\n",
            " 1.60000000e+02 2.51000000e+02 8.10000000e+01 6.00000000e+01\n",
            " 5.60000000e-01 1.28000000e+00 4.90000000e-01 3.80000000e-01\n",
            " 5.35000000e+02 7.10725076e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [0.06831094404501414, 0.0028396665040279832, 0.12464087343216625, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.0270646055511061, 0.4985830770823106, 1.1213347165497891, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6339466321252831, 1.2512296759830819, 1.4712299622758223, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.4113696895370869, 1.404831048591556, 1.217643263416463, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.59400000e+01 2.61900000e+01 2.58800000e+01 2.59400000e+01\n",
            " 1.42000000e+02 2.28000000e+02 7.00000000e+00 8.00000000e+00\n",
            " 3.60000000e-01 4.30000000e-01 2.00000000e-01 1.30000000e-01\n",
            " 8.25000000e+02 3.98539778e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.59400000e+01 2.61900000e+01 2.58800000e+01 2.59400000e+01\n",
            " 1.42000000e+02 2.28000000e+02 7.00000000e+00 8.00000000e+00\n",
            " 3.60000000e-01 4.30000000e-01 2.00000000e-01 1.30000000e-01\n",
            " 8.25000000e+02 3.98539778e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.59400000e+01 2.61900000e+01 2.58800000e+01 2.59400000e+01\n",
            " 1.42000000e+02 2.28000000e+02 7.00000000e+00 8.00000000e+00\n",
            " 3.60000000e-01 4.30000000e-01 2.00000000e-01 1.30000000e-01\n",
            " 8.25000000e+02 3.98539778e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.59400000e+01 2.61900000e+01 2.58800000e+01 2.59400000e+01\n",
            " 1.42000000e+02 2.28000000e+02 7.00000000e+00 8.00000000e+00\n",
            " 3.60000000e-01 4.30000000e-01 2.00000000e-01 1.30000000e-01\n",
            " 8.25000000e+02 3.98539778e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.6560892753423306, 1.634738519368388, 0.6290132021660307, 1.5105235152729721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.6422648550843036, 0.09019381965496992, 0.7754271574975016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.04824906873551714, 0.00017232889953386433, 0.09241340481217675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.03789977035775252, 0.00018702923145130673, 0.07098386153852101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.53800000e+01 2.50000000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.55000000e+02 3.94511581e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.53800000e+01 2.50000000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.55000000e+02 3.94511581e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.53800000e+01 2.50000000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.55000000e+02 3.94511581e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.53800000e+01 2.50000000e+01 2.54400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 3.55000000e+02 3.94511581e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.009000306396803447, 0.8644591839089937, 0.0, 0.0, 0.6290132021660307, 3.980002255074891e-263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0017645850083361874, 0.13433108971930502, 0.0, 0.0, 0.09019381965496992, 9.265087851132551e-154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 9.540035501867375e-09, 0.0004994449026255511, 0.0, 0.0, 0.00017232889953386433, 1.809e-320, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 2.2272536225936306e-08, 0.0005044502023565899, 0.0, 0.0, 0.00018702923145130673, 7.151008623832145e-286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.50000000e+01 1.70000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.50000000e+01 1.70000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.50000000e+01 1.70000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.45600000e+01 2.50600000e+01\n",
            " 5.00000000e+00 5.00000000e+00 2.50000000e+01 1.70000000e+01\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0011257721996219864, 0.0028396665040279832, 0.035163991295557286, 0.0004191908302828797, 0.0, 3.3071632387050217e-152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38478853960904225, 0.4985830770823106, 0.9100484937946683, 0.2872837104225711, 0.0, 9.053202117810136e-92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9911681328875325, 1.2512296759830819, 1.6997792628930506, 0.735453090688109, 0.0, 3.890819252125932e-194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.2093036686472622, 1.404831048591556, 1.544376636821353, 0.9827393915425461, 0.0, 7.7485106595636035e-174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.80000000e+02 7.00000000e+00\n",
            " 6.70000000e-01 2.80000000e-01 3.10000000e-01 1.10000000e-01\n",
            " 1.01000000e+03 3.82426989e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.80000000e+02 7.00000000e+00\n",
            " 6.70000000e-01 2.80000000e-01 3.10000000e-01 1.10000000e-01\n",
            " 1.01000000e+03 3.82426989e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.80000000e+02 7.00000000e+00\n",
            " 6.70000000e-01 2.80000000e-01 3.10000000e-01 1.10000000e-01\n",
            " 1.01000000e+03 3.82426989e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.80000000e+02 7.00000000e+00\n",
            " 6.70000000e-01 2.80000000e-01 3.10000000e-01 1.10000000e-01\n",
            " 1.01000000e+03 3.82426989e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.634738519368388, 1.5105235152729721, 0.4298858024045102, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.7754271574975016, 0.0585843072056394, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.09241340481217675, 5.5696255317175676e-05, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.07098386153852101, 6.546247162567774e-05, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.70000000e+02 4.10876133e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.70000000e+02 4.10876133e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.70000000e+02 4.10876133e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.70000000e+02 4.10876133e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.7777783298469527, 0.7777783298469527, 1.6560892753423306, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [1.131586042750569, 1.131586042750569, 0.49437318554825355, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.47004074717167255, 0.47004074717167255, 0.02081153447270444, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.35413111078922477, 0.35413111078922477, 0.01694670783654658, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.56300000e+01 2.56300000e+01 2.53100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 5.55000000e+02 2.86253776e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.56300000e+01 2.56300000e+01 2.53100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 5.55000000e+02 2.86253776e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.56300000e+01 2.56300000e+01 2.53100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 5.55000000e+02 2.86253776e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.56300000e+01 2.56300000e+01 2.53100000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 8.00000000e-02\n",
            " 5.55000000e+02 2.86253776e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.3884867679491852, 0.022161965778456128, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.28419996615678017, 0.0037174013842863306, 0.9056744868132555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.004002499108730581, 5.740372827112309e-08, 0.16579764589159204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.003553544572701595, 1.1535196110461418e-07, 0.12550886003790895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.51900000e+01 2.46300000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.51900000e+01 2.46300000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.51900000e+01 2.46300000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.51900000e+01 2.46300000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.022161965778456128, 1.0686121283749463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.28419996615678017, 0.0037174013842863306, 1.0233107530619845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.004002499108730581, 5.740372827112309e-08, 0.2786243708311884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.003553544572701595, 1.1535196110461418e-07, 0.20949847667461025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.3884867679491852, 0.009000306396803447, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.28419996615678017, 0.0017645850083361874, 0.9056744868132555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.004002499108730581, 9.540035501867375e-09, 0.16579764589159204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.003553544572701595, 2.2272536225936306e-08, 0.12550886003790895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51900000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51900000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51900000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51900000e+01 2.45600000e+01 2.55000000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 0.4298858024045102, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.0585843072056394, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 5.5696255317175676e-05, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 6.546247162567774e-05, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.49400000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.70000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 0.8644591839089937, 0.06831094404501414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.13433108971930502, 1.0270646055511061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.0004994449026255511, 1.6339466321252831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.0005044502023565899, 1.4113696895370869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.50600000e+01 2.59400000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 5.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3109458656169541, 1.3109458656169541, 0.8644591839089937, 0.2322488409221858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9056744868132555, 0.9056744868132555, 0.13433108971930502, 1.1913364523126768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.16579764589159204, 0.16579764589159204, 0.0004994449026255511, 1.198484934895971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.12550886003790895, 0.12550886003790895, 0.0005044502023565899, 0.9530262922520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 3.52215509e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 3.52215509e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 3.52215509e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55000000e+01 2.55000000e+01 2.50600000e+01 2.58100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 5.00000000e-02 6.00000000e-02\n",
            " 3.90000000e+02 3.52215509e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.5105235152729721, 0.0028396665040279832, 0.0, 0.0, 0.0, 7.220955550028693e-122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.7754271574975016, 0.4985830770823106, 0.0, 0.0, 0.0, 9.91576329532513e-56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.09241340481217675, 1.2512296759830819, 0.0, 0.0, 0.0, 7.181247272733421e-99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.07098386153852101, 1.404831048591556, 0.0, 0.0, 0.0, 3.7308554817866616e-85, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.54400000e+01 2.61900000e+01\n",
            " 8.00000000e+00 1.00000000e+01 4.30000000e+01 3.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.54400000e+01 2.61900000e+01\n",
            " 8.00000000e+00 1.00000000e+01 4.30000000e+01 3.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.54400000e+01 2.61900000e+01\n",
            " 8.00000000e+00 1.00000000e+01 4.30000000e+01 3.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.54400000e+01 2.61900000e+01\n",
            " 8.00000000e+00 1.00000000e+01 4.30000000e+01 3.10000000e+01\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.634738519368388, 1.634738519368388, 1.6560892753423306, 0.017001377617694817, 3.3071632387050217e-152, 4.157611003110773e-21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.6422648550843036, 0.6422648550843036, 0.49437318554825355, 0.7800736083141484, 9.053202117810136e-92, 8.93235212604694e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.04824906873551714, 0.04824906873551714, 0.02081153447270444, 1.6563211142234864, 3.890819252125932e-194, 3.796788013902749e-36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.03789977035775252, 0.03789977035775252, 0.01694670783654658, 1.5953551569519269, 7.7485106595636035e-174, 3.962682970707894e-33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53800000e+01 2.53800000e+01 2.53100000e+01 2.60600000e+01\n",
            " 1.90000000e+01 2.30000000e+01 8.10000000e+01 6.00000000e+01\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53800000e+01 2.53800000e+01 2.53100000e+01 2.60600000e+01\n",
            " 1.90000000e+01 2.30000000e+01 8.10000000e+01 6.00000000e+01\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53800000e+01 2.53800000e+01 2.53100000e+01 2.60600000e+01\n",
            " 1.90000000e+01 2.30000000e+01 8.10000000e+01 6.00000000e+01\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53800000e+01 2.53800000e+01 2.53100000e+01 2.60600000e+01\n",
            " 1.90000000e+01 2.30000000e+01 8.10000000e+01 6.00000000e+01\n",
            " 7.00000000e-02 4.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.0028396665040279832, 0.017001377617694817, 0.12464087343216625, 0.0011257721996219864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.4985830770823106, 0.7800736083141484, 1.1213347165497891, 0.38478853960904225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.2512296759830819, 1.6563211142234864, 1.4712299622758223, 0.9911681328875325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.404831048591556, 1.5953551569519269, 1.217643263416463, 1.2093036686472622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.61900000e+01 2.60600000e+01 2.58800000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 1.02000000e+03 4.75327291e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.61900000e+01 2.60600000e+01 2.58800000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 1.02000000e+03 4.75327291e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.61900000e+01 2.60600000e+01 2.58800000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 1.02000000e+03 4.75327291e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.61900000e+01 2.60600000e+01 2.58800000e+01 2.62500000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 1.02000000e+03 4.75327291e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.022161965778456128, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.28419996615678017, 0.0037174013842863306, 0.9056744868132555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.004002499108730581, 5.740372827112309e-08, 0.16579764589159204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.003553544572701595, 1.1535196110461418e-07, 0.12550886003790895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.5190000e+01 2.5190000e+01 2.4630000e+01 2.5500000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0000000e-02 5.0000000e-02\n",
            " 7.0000000e-02 6.0000000e-02 3.6000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=1 | [2.5190000e+01 2.5190000e+01 2.4630000e+01 2.5500000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0000000e-02 5.0000000e-02\n",
            " 7.0000000e-02 6.0000000e-02 3.6000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=2 | [2.5190000e+01 2.5190000e+01 2.4630000e+01 2.5500000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0000000e-02 5.0000000e-02\n",
            " 7.0000000e-02 6.0000000e-02 3.6000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "p(y=3 | [2.5190000e+01 2.5190000e+01 2.4630000e+01 2.5500000e+01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0000000e-02 5.0000000e-02\n",
            " 7.0000000e-02 6.0000000e-02 3.6000000e+02 4.1591138e-01 0.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.634738519368388, 0.0067276320461765, 0.0, 0.0, 4.332835868794435e-108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.6422648550843036, 0.6249671870164742, 0.0, 0.0, 8.985884609549385e-67, 9.791110411060581e-277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.04824906873551714, 1.479531085577258, 0.0, 0.0, 8.35259358049464e-143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.03789977035775252, 1.5406519737696889, 0.0, 0.0, 3.065683770872398e-128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 4.00000000e+00 4.00000000e+00 2.00000000e+01 1.40000000e+01\n",
            " 1.30000000e-01 9.00000000e-02 1.10000000e-01 1.10000000e-01\n",
            " 3.50000000e+02 4.02064451e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 4.00000000e+00 4.00000000e+00 2.00000000e+01 1.40000000e+01\n",
            " 1.30000000e-01 9.00000000e-02 1.10000000e-01 1.10000000e-01\n",
            " 3.50000000e+02 4.02064451e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 4.00000000e+00 4.00000000e+00 2.00000000e+01 1.40000000e+01\n",
            " 1.30000000e-01 9.00000000e-02 1.10000000e-01 1.10000000e-01\n",
            " 3.50000000e+02 4.02064451e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.53800000e+01 2.61300000e+01\n",
            " 4.00000000e+00 4.00000000e+00 2.00000000e+01 1.40000000e+01\n",
            " 1.30000000e-01 9.00000000e-02 1.10000000e-01 1.10000000e-01\n",
            " 3.50000000e+02 4.02064451e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.6560892753423306, 1.5646734325554212, 0.08517122922065898, 0.5534907125314652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.49437318554825355, 0.38109857568304006, 0.012005783156308833, 1.189959701550509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.02081153447270444, 0.009430158603017429, 1.0118024174082307e-06, 0.6855469125047802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.01694670783654658, 0.007986889838661918, 1.6116464269829333e-06, 0.5217782370505217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.53100000e+01 2.52500000e+01 2.47500000e+01 2.56900000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 3.65000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.08517122922065898, 0.369949896396296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.012005783156308833, 1.210545739433308, 0.0, 0.0, 0.0, 1.1156368421680548e-171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 1.0118024174082307e-06, 0.9365612888973045, 0.0, 0.0, 0.0, 1.39193e-319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 1.6116464269829333e-06, 0.7257709170460954, 0.0, 0.0, 0.0, 6.868413463095594e-278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.20000000e+01 4.90000000e+01 3.50000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.20000000e+01 4.90000000e+01 3.50000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.20000000e+01 4.90000000e+01 3.50000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.57500000e+01\n",
            " 1.00000000e+01 1.20000000e+01 4.90000000e+01 3.50000000e+01\n",
            " 8.00000000e-02 4.00000000e-02 6.00000000e-02 9.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3884867679491852, 1.3884867679491852, 0.022161965778456128, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.28419996615678017, 0.28419996615678017, 0.0037174013842863306, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.004002499108730581, 0.004002499108730581, 5.740372827112309e-08, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.003553544572701595, 0.003553544572701595, 1.1535196110461418e-07, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.08862034e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.08862034e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.08862034e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51900000e+01 2.51900000e+01 2.46300000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.50000000e+02 4.08862034e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 0.8644591839089937, 0.0015745886692075798, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.13433108971930502, 0.0004429132138564848, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0004994449026255511, 3.576934139915957e-10, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0005044502023565899, 1.1069783272151325e-09, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.50600000e+01 2.44400000e+01 2.53800000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.55000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.035163991295557286, 0.2322488409221858, 0.7777783298469527, 0.0004191908302828797, 0.0, 1.1273757906625717e-222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9100484937946683, 1.1913364523126768, 1.131586042750569, 0.2872837104225711, 0.0, 1.046039588258801e-105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6997792628930506, 1.198484934895971, 0.47004074717167255, 0.735453090688109, 0.0, 1.9017465068320332e-193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.544376636821353, 0.9530262922520344, 0.35413111078922477, 0.9827393915425461, 0.0, 1.2526244681864963e-167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.60000000e+01 2.58100000e+01 2.56300000e+01 2.63100000e+01\n",
            " 1.19000000e+02 3.30000000e+01 6.50000000e+01 4.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.65000000e+02 3.85196375e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.60000000e+01 2.58100000e+01 2.56300000e+01 2.63100000e+01\n",
            " 1.19000000e+02 3.30000000e+01 6.50000000e+01 4.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.65000000e+02 3.85196375e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.60000000e+01 2.58100000e+01 2.56300000e+01 2.63100000e+01\n",
            " 1.19000000e+02 3.30000000e+01 6.50000000e+01 4.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.65000000e+02 3.85196375e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.60000000e+01 2.58100000e+01 2.56300000e+01 2.63100000e+01\n",
            " 1.19000000e+02 3.30000000e+01 6.50000000e+01 4.10000000e+01\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 6.00000000e-02\n",
            " 5.65000000e+02 3.85196375e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [0.017001377617694817, 4.409065368746929e-08, 1.0686121283749463, 0.0004191908302828797, 0.0, 4.332835868794435e-108, 3.0872726858116797e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7800736083141484, 0.01223939923370541, 1.0233107530619845, 0.2872837104225711, 0.0, 8.985884609549385e-67, 8.963491537033661e-07, 9.411427216568543e-191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6563211142234864, 0.011177698207171849, 0.2786243708311884, 0.735453090688109, 0.0, 8.35259358049464e-143, 2.252679407850769e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.5953551569519269, 0.036947505441661546, 0.20949847667461025, 0.9827393915425461, 0.0, 3.065683770872398e-128, 2.560480804893931e-15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.6060000e+01 2.6750000e+01 2.5560000e+01 2.6310000e+01 1.1500000e+02\n",
            " 2.0000000e+01 2.4000000e+01 1.6000000e+01 7.0000000e-02 7.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 5.3500000e+02 4.7633434e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=1 | [2.6060000e+01 2.6750000e+01 2.5560000e+01 2.6310000e+01 1.1500000e+02\n",
            " 2.0000000e+01 2.4000000e+01 1.6000000e+01 7.0000000e-02 7.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 5.3500000e+02 4.7633434e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=2 | [2.6060000e+01 2.6750000e+01 2.5560000e+01 2.6310000e+01 1.1500000e+02\n",
            " 2.0000000e+01 2.4000000e+01 1.6000000e+01 7.0000000e-02 7.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 5.3500000e+02 4.7633434e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "p(y=3 | [2.6060000e+01 2.6750000e+01 2.5560000e+01 2.6310000e+01 1.1500000e+02\n",
            " 2.0000000e+01 2.4000000e+01 1.6000000e+01 7.0000000e-02 7.0000000e-02\n",
            " 6.0000000e-02 6.0000000e-02 5.3500000e+02 4.7633434e-01 0.0000000e+00\n",
            " 0.0000000e+00 1.0000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "res [1.1572784212086917, 1.3884867679491852, 0.0448292590729217, 1.6560892753423306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.28419996615678017, 0.006792237089151543, 0.49437318554825355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.004002499108730581, 2.4901140005593237e-07, 0.02081153447270444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.003553544572701595, 4.437634360892876e-07, 0.01694670783654658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51900000e+01 2.46900000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51900000e+01 2.46900000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51900000e+01 2.46900000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51900000e+01 2.46900000e+01 2.53100000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 4.00000000e-02 7.00000000e-02 8.00000000e-02\n",
            " 3.45000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.5646734325554212, 0.0448292590729217, 1.0686121283749463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.38109857568304006, 0.006792237089151543, 1.0233107530619845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.009430158603017429, 2.4901140005593237e-07, 0.2786243708311884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.007986889838661918, 4.437634360892876e-07, 0.20949847667461025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.52500000e+01 2.46900000e+01 2.55600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 6.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 1.1572784212086917, 0.08517122922065898, 0.7777783298469527, 0.0, 0.0, 0.0, 7.220955550028693e-122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.20502885936011442, 0.012005783156308833, 1.131586042750569, 0.0, 0.0, 0.0, 9.91576329532513e-56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 0.0015912588907227808, 1.0118024174082307e-06, 0.47004074717167255, 0.0, 0.0, 0.0, 7.181247272733421e-99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 0.0014925798039521043, 1.6116464269829333e-06, 0.35413111078922477, 0.0, 0.0, 0.0, 3.7308554817866616e-85, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.56300000e+01\n",
            " 1.00000000e+01 1.00000000e+01 4.50000000e+01 3.10000000e+01\n",
            " 9.00000000e-02 6.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.13897281e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.56300000e+01\n",
            " 1.00000000e+01 1.00000000e+01 4.50000000e+01 3.10000000e+01\n",
            " 9.00000000e-02 6.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.13897281e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.56300000e+01\n",
            " 1.00000000e+01 1.00000000e+01 4.50000000e+01 3.10000000e+01\n",
            " 9.00000000e-02 6.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.13897281e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.51300000e+01 2.47500000e+01 2.56300000e+01\n",
            " 1.00000000e+01 1.00000000e+01 4.50000000e+01 3.10000000e+01\n",
            " 9.00000000e-02 6.00000000e-02 6.00000000e-02 5.00000000e-02\n",
            " 3.55000000e+02 4.13897281e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.3109458656169541, 1.3109458656169541, 1.1572784212086917, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9056744868132555, 0.9056744868132555, 0.20502885936011442, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.16579764589159204, 0.16579764589159204, 0.0015912588907227808, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.12550886003790895, 0.12550886003790895, 0.0014925798039521043, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.55000000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.90000000e+02 3.01611279e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.55000000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.90000000e+02 3.01611279e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.55000000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.90000000e+02 3.01611279e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.55000000e+01 2.55000000e+01 2.51300000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 8.00000000e-02\n",
            " 3.90000000e+02 3.01611279e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.8644591839089937, 1.1572784212086917, 0.0038843930785171306, 1.634738519368388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.13433108971930502, 0.20502885936011442, 0.0008988318898802732, 0.6422648550843036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0004994449026255511, 0.0015912588907227808, 1.908674147339961e-09, 0.04824906873551714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0005044502023565899, 0.0014925798039521043, 5.110442847234481e-09, 0.03789977035775252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+01 6.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+01 6.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+01 6.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.50600000e+01 2.51300000e+01 2.45000000e+01 2.53800000e+01\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+01 6.00000000e+00\n",
            " 7.00000000e-02 6.00000000e-02 7.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.14149043e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [0.035163991295557286, 1.4417959399530827e-22, 0.5534907125314652, 0.0028396665040279832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.9100484937946683, 1.2408725799551776e-08, 1.189959701550509, 0.4985830770823106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [1.6997792628930506, 1.7200625594108444e-12, 0.6855469125047802, 1.2512296759830819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.544376636821353, 2.1263093615187873e-10, 0.5217782370505217, 1.404831048591556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.60000000e+01 2.77500000e+01 2.56900000e+01 2.61900000e+01\n",
            " 1.63000000e+02 2.52000000e+02 2.67000000e+02 7.00000000e+01\n",
            " 1.24000000e+00 8.40000000e-01 3.65000000e+00 2.80000000e-01\n",
            " 8.55000000e+02 5.24924471e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.60000000e+01 2.77500000e+01 2.56900000e+01 2.61900000e+01\n",
            " 1.63000000e+02 2.52000000e+02 2.67000000e+02 7.00000000e+01\n",
            " 1.24000000e+00 8.40000000e-01 3.65000000e+00 2.80000000e-01\n",
            " 8.55000000e+02 5.24924471e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.60000000e+01 2.77500000e+01 2.56900000e+01 2.61900000e+01\n",
            " 1.63000000e+02 2.52000000e+02 2.67000000e+02 7.00000000e+01\n",
            " 1.24000000e+00 8.40000000e-01 3.65000000e+00 2.80000000e-01\n",
            " 8.55000000e+02 5.24924471e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.60000000e+01 2.77500000e+01 2.56900000e+01 2.61900000e+01\n",
            " 1.63000000e+02 2.52000000e+02 2.67000000e+02 7.00000000e+01\n",
            " 1.24000000e+00 8.40000000e-01 3.65000000e+00 2.80000000e-01\n",
            " 8.55000000e+02 5.24924471e-01 1.00000000e+00 1.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 3 \n",
            "\n",
            "class being misclassified is 3\n",
            "Wrong\n",
            "\n",
            "res [0.0011257721996219864, 0.0028396665040279832, 0.035163991295557286, 0.0004191908302828797, 0.0, 3.3071632387050217e-152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38478853960904225, 0.4985830770823106, 0.9100484937946683, 0.2872837104225711, 0.0, 9.053202117810136e-92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.9911681328875325, 1.2512296759830819, 1.6997792628930506, 0.735453090688109, 0.0, 3.890819252125932e-194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [1.2093036686472622, 1.404831048591556, 1.544376636821353, 0.9827393915425461, 0.0, 7.7485106595636035e-174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.79000000e+02 7.00000000e+00\n",
            " 8.40000000e-01 9.00000000e-02 1.70000000e-01 7.00000000e-02\n",
            " 1.02500000e+03 3.43907351e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.79000000e+02 7.00000000e+00\n",
            " 8.40000000e-01 9.00000000e-02 1.70000000e-01 7.00000000e-02\n",
            " 1.02500000e+03 3.43907351e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.79000000e+02 7.00000000e+00\n",
            " 8.40000000e-01 9.00000000e-02 1.70000000e-01 7.00000000e-02\n",
            " 1.02500000e+03 3.43907351e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.62500000e+01 2.61900000e+01 2.60000000e+01 2.63100000e+01\n",
            " 1.14000000e+02 1.90000000e+01 1.79000000e+02 7.00000000e+00\n",
            " 8.40000000e-01 9.00000000e-02 1.70000000e-01 7.00000000e-02\n",
            " 1.02500000e+03 3.43907351e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 2 \n",
            "\n",
            "class being misclassified is 2\n",
            "Wrong\n",
            "\n",
            "res [1.5105235152729721, 1.5105235152729721, 1.3884867679491852, 0.017001377617694817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.7754271574975016, 0.7754271574975016, 0.28419996615678017, 0.7800736083141484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.09241340481217675, 0.09241340481217675, 0.004002499108730581, 1.6563211142234864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.07098386153852101, 0.07098386153852101, 0.003553544572701595, 1.5953551569519269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.04833837e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.04833837e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.04833837e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.54400000e+01 2.54400000e+01 2.51900000e+01 2.60600000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 8.00000000e-02 6.00000000e-02 6.00000000e-02 1.00000000e-01\n",
            " 3.55000000e+02 4.04833837e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.5646734325554212, 1.6560892753423306, 0.0448292590729217, 0.7777783298469527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.38109857568304006, 0.49437318554825355, 0.006792237089151543, 1.131586042750569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.009430158603017429, 0.02081153447270444, 2.4901140005593237e-07, 0.47004074717167255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.007986889838661918, 0.01694670783654658, 4.437634360892876e-07, 0.35413111078922477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.52500000e+01 2.53100000e+01 2.46900000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.52500000e+01 2.53100000e+01 2.46900000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.52500000e+01 2.53100000e+01 2.46900000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.52500000e+01 2.53100000e+01 2.46900000e+01 2.56300000e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.00000000e-02 5.00000000e-02 5.00000000e-02 7.00000000e-02\n",
            " 3.60000000e+02 4.12134945e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 0 \n",
            "\n",
            "Right\n",
            "\n",
            "res [1.1572784212086917, 0.2759462627217734, 0.0448292590729217, 1.3109458656169541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.8122696155871512\n",
            "res [0.20502885936011442, 0.03681205778207625, 0.006792237089151543, 0.9056744868132555, 0.0, 1.1156368421680548e-171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.04528699315429173\n",
            "res [0.0015912588907227808, 1.686130682736435e-05, 2.4901140005593237e-07, 0.16579764589159204, 0.0, 1.39193e-319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.07385466034755134\n",
            "res [0.0014925798039521043, 2.1630523427202543e-05, 4.437634360892876e-07, 0.12550886003790895, 0.0, 6.868413463095594e-278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "a 0.0\n",
            "prior 0.0685887309110058\n",
            "p(y=0 | [2.51300000e+01 2.48800000e+01 2.46900000e+01 2.55000000e+01\n",
            " 1.23000000e+02 3.50000000e+01 5.90000000e+01 4.40000000e+01\n",
            " 2.10000000e-01 1.90000000e-01 1.70000000e-01 7.00000000e-02\n",
            " 4.05000000e+02 4.43605237e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=1 | [2.51300000e+01 2.48800000e+01 2.46900000e+01 2.55000000e+01\n",
            " 1.23000000e+02 3.50000000e+01 5.90000000e+01 4.40000000e+01\n",
            " 2.10000000e-01 1.90000000e-01 1.70000000e-01 7.00000000e-02\n",
            " 4.05000000e+02 4.43605237e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=2 | [2.51300000e+01 2.48800000e+01 2.46900000e+01 2.55000000e+01\n",
            " 1.23000000e+02 3.50000000e+01 5.90000000e+01 4.40000000e+01\n",
            " 2.10000000e-01 1.90000000e-01 1.70000000e-01 7.00000000e-02\n",
            " 4.05000000e+02 4.43605237e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "p(y=3 | [2.51300000e+01 2.48800000e+01 2.46900000e+01 2.55000000e+01\n",
            " 1.23000000e+02 3.50000000e+01 5.90000000e+01 4.40000000e+01\n",
            " 2.10000000e-01 1.90000000e-01 1.70000000e-01 7.00000000e-02\n",
            " 4.05000000e+02 4.43605237e-01 1.00000000e+00 0.00000000e+00\n",
            " 1.00000000e+00]) = 0.000\n",
            "model predicted class 0 and the truth was 1 \n",
            "\n",
            "class being misclassified is 1\n",
            "Wrong\n",
            "\n",
            "testing error : 18.75246742992499\n",
            "count for class 0 : 0\n",
            "count for class 1 : 116\n",
            "count for class 2 : 189\n",
            "count for class 3 : 176\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "nb = NaiveBayes(X_df_train, y_df_train,X_df_test,y_df_test)\n",
        "nb.run_model()\n",
        "nb.predict_test()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML Project Sec 4 Group 11.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
